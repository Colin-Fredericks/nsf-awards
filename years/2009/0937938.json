{
 "awd_id": "0937938",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Scalable Data Management Using Metadata and Provenance",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2009-10-01",
 "awd_exp_date": "2013-09-30",
 "tot_intn_awd_amt": 553000.0,
 "awd_amount": 553000.0,
 "awd_min_amd_letter_date": "2009-09-16",
 "awd_max_amd_letter_date": "2011-09-20",
 "awd_abstract_narration": "This project is developing new techniques for identifying and managing files, replacing tree-structured file names with content- and metadata- based search access.  By leveraging existing work in search and recognizing the explosion in the volume of data stored, this project enables users to find and access their data in natural and intuitive ways, based on the files' contents, tags the user has assigned, system metadata, and provenance (information about the file's origins). This research targets high-end computing (HEC) users, who manage billions of files generated by measurement devices, experimentation, or scientific workflows.  The techniques and system developed are also applicable to general-purpose computing.\r\n\r\nRealizing this goal requires advances in several areas.  First, the project is designing and developing fast, scalable mechanisms to gather, maintain and index the large volume of metadata and provenance that HEC applications and users generate.  This project is also exploring search algorithms that operate on graph structures, enabling users to find files \"near\" their current workspace.  To enable users to access this functionality, the project is developing a new \"language\" that facilitates the kind of searches that users need.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ethan",
   "pi_last_name": "Miller",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Ethan L Miller",
   "pi_email_addr": "elm@ucsc.edu",
   "nsf_id": "000230226",
   "pi_start_date": "2009-09-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Darrell",
   "pi_last_name": "Long",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Darrell D Long",
   "pi_email_addr": "darrell@cs.ucsc.edu",
   "nsf_id": "000470073",
   "pi_start_date": "2009-09-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Cruz",
  "inst_street_address": "1156 HIGH ST",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA CRUZ",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8314595278",
  "inst_zip_code": "950641077",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "CA19",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA SANTA CRUZ",
  "org_prnt_uei_num": "",
  "org_uei_num": "VXUFPE4MCZH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Cruz",
  "perf_str_addr": "1156 HIGH ST",
  "perf_city_name": "SANTA CRUZ",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "950641077",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "CA19",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "795200",
   "pgm_ele_name": "HECURA"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 361123.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 191877.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Modern science is often done on&nbsp;high-performance computing systems, which generate petabaytes of data across millions of files for just a single experiment. Finding previous results in this data is difficult because, unlike Web searches, files are often poorly labeled and difficult to search because they consist of raw data, not text.</p>\n<p>The goal of this project was to explore better ways to organize metadata - information about files - using provenance (the relationship of files to other files) and other information, such as that provided by users to identify files or generated by programs that analyze files' contents. &nbsp;We analyzed existing file systems to understand how users stored and named their files, and conducted interviews with scientists to understand how they wanted to track their data and how they actually did it. &nbsp;We found that many users could benefit from improved metadata management: for example, some users of multi-petabyte file systems kept notes on their files in Excel spreadsheets or even paper notebooks, risking data loss.</p>\n<p>We investigated techniques to search more metadata using less hardware by partitioning data using different criteria: who could access the data, how the files were generated (workflow), and the tags that made up the metadata itself. &nbsp;We found that partitioning data has great promise for improving metadata management by reducing the amount of metadata that must be searched to find desired results. &nbsp;In effect, this is similar to separating indexes for English and Chinese data at Google and skipping indexes containing Chinese if someone is searching for an English document.</p>\n<p>Since provenance is an important factor in metadata systems, we developed techniques for storing provenance very efficiently, compressing the provenance graph that details which files are descended from which other files. &nbsp;This reduction in storage space allows us to leverage more provenance, resulting in more effective searches.</p>\n<p>We explored new techniques for naming files as well, since file names are the mechanism by which users interact with the file system. &nbsp;We developed TrueNames, a technique that creates standardized file names for files based on templates, allowing users to customize names based on file characteristics and to change name formats as needed. &nbsp;We also began investigating hierarchical namespaces for files, allowing for large flat namespaces that can be searched by \"tag\", in a way similar to Web searches. &nbsp;Unlike Web searches, however, our approach groups a relatively small number of files in each namespace (hundreds to a million or so), and allows namespaces to reference other namespaces. &nbsp;This approach limits the scope of searches, allowing users to find files that may be relevant for them but not others.</p>\n<p>Lastly, we made a major advance in securing large-scale files with minimal impact to metadata overhead. &nbsp;Our approach protects terabyte-scale files used on clusters of thousands of computational nodes from compromise due to one or more \"corrupted\" nodes. &nbsp;In traditional file systems, a corrupt node can read an entire file. &nbsp;Under our approach, a corrupt node can only read the data it needs for its own local computation; this is typically under 1% of the entire file. &nbsp;This is done without increasing the amount of metadata that must be maintained for the file, and without increasing the load on a shared metadata server, facilitating the use of encryption to secure large files without much added cost.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/10/2014<br>\n\t\t\t\t\tModified by: Ethan&nbsp;L&nbsp;Miller</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nModern science is often done on high-performance computing systems, which generate petabaytes of data across millions of files for just a single experiment. Finding previous results in this data is difficult because, unlike Web searches, files are often poorly labeled and difficult to search because they consist of raw data, not text.\n\nThe goal of this project was to explore better ways to organize metadata - information about files - using provenance (the relationship of files to other files) and other information, such as that provided by users to identify files or generated by programs that analyze files' contents.  We analyzed existing file systems to understand how users stored and named their files, and conducted interviews with scientists to understand how they wanted to track their data and how they actually did it.  We found that many users could benefit from improved metadata management: for example, some users of multi-petabyte file systems kept notes on their files in Excel spreadsheets or even paper notebooks, risking data loss.\n\nWe investigated techniques to search more metadata using less hardware by partitioning data using different criteria: who could access the data, how the files were generated (workflow), and the tags that made up the metadata itself.  We found that partitioning data has great promise for improving metadata management by reducing the amount of metadata that must be searched to find desired results.  In effect, this is similar to separating indexes for English and Chinese data at Google and skipping indexes containing Chinese if someone is searching for an English document.\n\nSince provenance is an important factor in metadata systems, we developed techniques for storing provenance very efficiently, compressing the provenance graph that details which files are descended from which other files.  This reduction in storage space allows us to leverage more provenance, resulting in more effective searches.\n\nWe explored new techniques for naming files as well, since file names are the mechanism by which users interact with the file system.  We developed TrueNames, a technique that creates standardized file names for files based on templates, allowing users to customize names based on file characteristics and to change name formats as needed.  We also began investigating hierarchical namespaces for files, allowing for large flat namespaces that can be searched by \"tag\", in a way similar to Web searches.  Unlike Web searches, however, our approach groups a relatively small number of files in each namespace (hundreds to a million or so), and allows namespaces to reference other namespaces.  This approach limits the scope of searches, allowing users to find files that may be relevant for them but not others.\n\nLastly, we made a major advance in securing large-scale files with minimal impact to metadata overhead.  Our approach protects terabyte-scale files used on clusters of thousands of computational nodes from compromise due to one or more \"corrupted\" nodes.  In traditional file systems, a corrupt node can read an entire file.  Under our approach, a corrupt node can only read the data it needs for its own local computation; this is typically under 1% of the entire file.  This is done without increasing the amount of metadata that must be maintained for the file, and without increasing the load on a shared metadata server, facilitating the use of encryption to secure large files without much added cost.\n\n\t\t\t\t\tLast Modified: 02/10/2014\n\n\t\t\t\t\tSubmitted by: Ethan L Miller"
 }
}