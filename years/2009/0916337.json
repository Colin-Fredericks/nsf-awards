{
 "awd_id": "0916337",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Monitoring for Error Detection in Today's High Throughput Applications",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 259000.0,
 "awd_amount": 275000.0,
 "awd_min_amd_letter_date": "2009-08-10",
 "awd_max_amd_letter_date": "2011-05-12",
 "awd_abstract_narration": "CSR: Small: Monitoring for Error Detection in Today?s High Throughput Applications\r\n\r\nAbstract: Much of our critical infrastructure is formed by distributed systems with real-time requirements. Downtime of a system providing critical services in power systems, air traffic control, banking, and railways signaling could be catastrophic. The errors may come from individual software components, interactions between multiple components, or misconfiguration of these components. It is therefore imperative to build low latency detection systems that can subsequently trigger the diagnosis and recovery phases leading to systems that are robust to failures. A powerful approach for error detection is the stateful approach, in which the error detection system builds up state related to the application by aggregating multiple messages. The rules are then based on the state, thus on aggregated information rather than on instantaneous information. Though the merits of stateful detection seem to be well accepted, it is difficult to scale stateful detection with an increasing number of application components or increasing data rate. This is due to the increased processing load of tracking application state and rule matching based on the state. In this project, we address this issue through designing a runtime monitoring system focused on high throughput distributed applications. Our solution is based on intelligent sampling, probabilistic reasoning on the application state, and opportunistic monitoring of the heavy-duty rules. A successful solution will allow reliable operation of high bandwidth distributed applications and those with a large number of consumers. We will also achieve broader impact through an innovative service learning program at Purdue called EPICS and a new course. \r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Saurabh",
   "pi_last_name": "Bagchi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Saurabh Bagchi",
   "pi_email_addr": "sbagchi@purdue.edu",
   "nsf_id": "000309372",
   "pi_start_date": "2009-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "2550 NORTHWESTERN AVE # 1100",
  "perf_city_name": "WEST LAFAYETTE",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479061332",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 259000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our society increasingly depends on large-scale distributed applications for critical operations. They range from the air traffic control system, online financial processing applications, prediction of impending natural disasters, to running our educational computer labs with little to no downtime. To reduce the downtime of this gamut of applications, it is desirable to automatically pinpoint what the root cause of a failure is, and, whenever possible, to predict impending failures based on observed symptoms in the system. The first objective will let either an automated system or a human being quickly diagnose the problem and initiate a mitigation action. The second objective will prevent the end user (i.e., us) from ever being affected by the fault. The faults can be diverse in their origin &ndash; hardware problems (e.g., a network fiber being disconnected), software problems (e.g., an inability of the software to handle a large number of concurrent users), or configuration problems (e.g., the software is configured for only high speed links, while in practice it also experiences slow links). &nbsp;Therefore, the problem localization and prediction must take into account such diversity. The granularity with which the localization can be done depends &ndash; it may be to a single compute node (in a large-scale parallel application), to an executing process, or to a region of code.</p>\n<p>In this project, we designed mechanisms to perform problem localization and failure prediction by monitoring and analyzing a wide variety of metrics from all layers of the system stack. Examples of metrics are CPU utilization (from the system layer), frequency of garbage collection (from the middleware layer), and number of active threads (from the application layer). The intuition is that when the system is performing normally, the metrics will exhibit some pattern, either individually or in groups. An example of the former is that the rate of I/O will stay between certain thresholds; an example of the second kind is that the rate of I/O is correlated with the rate of user requests. Our project&rsquo;s novel contribution was to develop techniques to automatically &ldquo;learn&rdquo; legitimate patterns among groups of metrics (the second kind). Then it would monitor the patterns during the execution of the system and flag any significant deviation from the learned patterns. Typically there would be multiple learned patterns because a system can behave in one of several different manners depending on the kind of workload executed on the system. From the deviation, our system would identify, in a probabilistic manner, what was the root cause of the problem. Our system, called Orion, uses the above steps to find the abnormal window of time, abnormal metrics and abnormal code regions where a fault is manifested.</p>\n<p>We evaluated Orion on two classes of distributed applications:</p>\n<ol>\n<li><strong>Commercial applications</strong>: (i) client-server multi-tier applications in which the presentation, the application processing, and the data management are logically separate processes. Example of these architectures are the Java Enterprise Edition (Java EE) standard; (ii) MapReduce programming model for processing large data sets. MapReduce is typically used to do distributed computing on clusters of computers.</li>\n<li><strong>High Performance Computing (HPC) applications</strong>: scientific and engineering applications that run in large clusters of machines with parallel tasks that communicate with the message passing interface (MPI).</li>\n</ol>\n<p><strong>Intellectual Merit</strong></p>\n<p>Intellectual merit in the project derived from the machine learning-based algorithms used to correlate multiple metrics to determine normal and anomalous patterns, designing the algorithms to be scalable to a large number of machines and to large data sets, and making the algorithms operate i...",
  "por_txt_cntn": "\nOur society increasingly depends on large-scale distributed applications for critical operations. They range from the air traffic control system, online financial processing applications, prediction of impending natural disasters, to running our educational computer labs with little to no downtime. To reduce the downtime of this gamut of applications, it is desirable to automatically pinpoint what the root cause of a failure is, and, whenever possible, to predict impending failures based on observed symptoms in the system. The first objective will let either an automated system or a human being quickly diagnose the problem and initiate a mitigation action. The second objective will prevent the end user (i.e., us) from ever being affected by the fault. The faults can be diverse in their origin &ndash; hardware problems (e.g., a network fiber being disconnected), software problems (e.g., an inability of the software to handle a large number of concurrent users), or configuration problems (e.g., the software is configured for only high speed links, while in practice it also experiences slow links).  Therefore, the problem localization and prediction must take into account such diversity. The granularity with which the localization can be done depends &ndash; it may be to a single compute node (in a large-scale parallel application), to an executing process, or to a region of code.\n\nIn this project, we designed mechanisms to perform problem localization and failure prediction by monitoring and analyzing a wide variety of metrics from all layers of the system stack. Examples of metrics are CPU utilization (from the system layer), frequency of garbage collection (from the middleware layer), and number of active threads (from the application layer). The intuition is that when the system is performing normally, the metrics will exhibit some pattern, either individually or in groups. An example of the former is that the rate of I/O will stay between certain thresholds; an example of the second kind is that the rate of I/O is correlated with the rate of user requests. Our project\u00c6s novel contribution was to develop techniques to automatically \"learn\" legitimate patterns among groups of metrics (the second kind). Then it would monitor the patterns during the execution of the system and flag any significant deviation from the learned patterns. Typically there would be multiple learned patterns because a system can behave in one of several different manners depending on the kind of workload executed on the system. From the deviation, our system would identify, in a probabilistic manner, what was the root cause of the problem. Our system, called Orion, uses the above steps to find the abnormal window of time, abnormal metrics and abnormal code regions where a fault is manifested.\n\nWe evaluated Orion on two classes of distributed applications:\n\nCommercial applications: (i) client-server multi-tier applications in which the presentation, the application processing, and the data management are logically separate processes. Example of these architectures are the Java Enterprise Edition (Java EE) standard; (ii) MapReduce programming model for processing large data sets. MapReduce is typically used to do distributed computing on clusters of computers.\nHigh Performance Computing (HPC) applications: scientific and engineering applications that run in large clusters of machines with parallel tasks that communicate with the message passing interface (MPI).\n\n\nIntellectual Merit\n\nIntellectual merit in the project derived from the machine learning-based algorithms used to correlate multiple metrics to determine normal and anomalous patterns, designing the algorithms to be scalable to a large number of machines and to large data sets, and making the algorithms operate in near real-time so that end-user visible failures can be completely avoided, or their duration reduced.\n\nFor the parallel computing domain, we introduced a way of modeling process behavi..."
 }
}