{
 "awd_id": "0844472",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research:  Bayesian Cue Integration in Probability-Sensitive Language Processing",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Badecker",
 "awd_eff_date": "2009-07-01",
 "awd_exp_date": "2012-06-30",
 "tot_intn_awd_amt": 329713.0,
 "awd_amount": 329713.0,
 "awd_min_amd_letter_date": "2009-06-24",
 "awd_max_amd_letter_date": "2009-06-24",
 "awd_abstract_narration": "This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\r\n\r\nThe process of sentence comprehension involves incrementally accessing the meaning of individual words and combining them into larger representations. In this process, readers / listeners use probabilistic cues to guide their expectations of upcoming words and of the syntactic roles that the words will play.  For example, previous research has demonstrated that people are sensitive to word frequency (more frequent words or word meanings are easier to process than less frequent words or word meanings), syntactic frequency (more frequent rules being easier to process than less frequent rules) and world knowledge (more likely events being easier to process than less likely events).  However, a complete theory of language processing must not only identify the cues that people are sensitive to, but also has to specify a theory of how a reader or listener will combine them.  Towards this end, this project investigates the extent to which readers? syntactic processing mechanisms fit several cue combination models that are based on different Bayesian inference methods. Bayesian models provide a formalism specifying how any set of probabilistic information sources can be optimally weighted and combined.  In this research, each of the cue combination models is applied to a wide range of language cues which people have been shown to rely on. The models will then be compared in terms of their fit to human reading-time data. The project will use existing reading-time data sets from previous experiments, as well as new reading-time data from language materials consisting of single sentences in null contexts and in supportive contexts, systematically varying several cues that have been shown to have measurable reading time effects in previous literature. This will demonstrate which of the inference methods provides the most accurate description of the computations that human readers perform in order to understand sentences.\r\n\r\nPrevious work in the field of sentence comprehension has established that people use a diverse range of probabilistic cues when they interpret a sentence.  However, several important questions that remain unanswered include (a) how much each cue matters in typical texts; and (b) how the cues are combined in the course of comprehension.  The main advance of this research is to use a combination of experimental and computational modeling methods to answer these two questions.  The techniques and results developed will be broadly useful in at least three general areas: (1) cognitive science; (2) engineering; and (3) human applications of language research.  First, this project will help researchers by providing an available database of reading times for a large corpus of English text, which any researcher will be able to use to evaluate theories of language processing.  In addition, the project will provide open source software that researchers can use or modify to evaluate related theoretical questions in language and other fields of cognitive science.  Second, the project will provide a way for computer engineers who research language to investigate the effects that human readers are sensitive to, indicating potential directions for fruitful research.  And third, an understanding of how language is processed will in the long run aid in developing better diagnostic tools and treatments for people with developmental and acquired language disorders.",
 "awd_arra_amount": 329713.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Edward",
   "pi_last_name": "Gibson",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Edward A Gibson",
   "pi_email_addr": "egibson@mit.edu",
   "nsf_id": "000215436",
   "pi_start_date": "2009-06-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 MASSACHUSETTS AVE",
  "perf_city_name": "CAMBRIDGE",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "6890",
   "pgm_ref_txt": "RECOVERY ACT ACTION"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "01R9",
   "app_name": "RRA RECOVERY ACT",
   "app_symb_id": "040101",
   "fund_code": "01R00910DB",
   "fund_name": "RRA RECOVERY ACT",
   "fund_symb_id": "040101"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 329713.0
  }
 ],
 "por": null
}