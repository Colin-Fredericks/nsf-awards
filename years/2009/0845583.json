{
 "awd_id": "0845583",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Adaptive Concurrency Management for Multicore Computing",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2009-02-15",
 "awd_exp_date": "2015-01-31",
 "tot_intn_awd_amt": 459903.0,
 "awd_amount": 491903.0,
 "awd_min_amd_letter_date": "2009-02-13",
 "awd_max_amd_letter_date": "2013-03-13",
 "awd_abstract_narration": "Career: Adaptive Concurrency Management for Multicore Computing\r\nAbstract: Given the increasing emphasis on multicore computing, concurrency management is likely to be one of the key techniques to unleash the power of multicore processors. Concurrency is the capability of executing multiple tasks simultaneously, but it is often difficult to achieve due to data and control dependencies. The proposed research aims to optimize thread-level concurrency for multicore applications. It will investigate architecture features for efficient shared data accesses, and use these features to dynamically control the advancement of concurrent threads and the allocation of CPU resources. The project will target computing platforms of immediate concern and the techniques will be made accessible to the programming community by integrating them into existing programming tools. The project will also extend theoretical results towards efficient multi-threaded algorithms. The proposed research project is expected to significantly improve the performance of multicore computing and expand the range of applications that can benefit from such processor platforms. It is expected to facilitate efficient multicore processing for computation-demanding applications in science, engineering, and business.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bo",
   "pi_last_name": "Hong",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bo Hong",
   "pi_email_addr": "bohong@gatech.edu",
   "nsf_id": "000486099",
   "pi_start_date": "2009-02-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Tech Research Corporation",
  "perf_str_addr": "926 DALNEY ST NW",
  "perf_city_name": "ATLANTA",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303186395",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "409000",
   "pgm_ele_name": "ADVANCED NET INFRA & RSCH"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 116178.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 115161.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 168222.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 84342.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This research project aims to develop a systematic framework to automatically</span></p>\n<p><span>manage and optimize the concurrency of parallel applications.&nbsp; In this project,</span></p>\n<p><span>we have (1) developed concurrency management strategies for transactional</span></p>\n<p><span>memory, (2) developed multi-threaded algorithms with applications in network</span></p>\n<p><span>flow, protein-DNA docking, and </span><span>seismeistic</span><span> data management, (3) designed</span></p>\n<p><span>methods to explore parallelism in </span><span>GPU</span><span>-based </span><span>HPC</span><span> systems, (4) developed</span></p>\n<p><span>strategies to manage concurrency and data locality in distributed computing</span></p>\n<p><span>systems. These research results allow a much wider range of applications to</span></p>\n<p><span>benefit from parallel and distributed computing. For example, we have worked</span></p>\n<p><span>with our collaborators and have shown that </span><span>GPU</span><span> can be used to significantly</span></p>\n<p><span>accelerate protein-DNA docking and seismic data analysis. These </span><span>HPC</span></p>\n<p><span>applications will benefit from our study on </span><span>GPU</span><span>-assisted systems. Other</span></p>\n<p><span>applications, such as Big Data analytics will benefit from our study of data</span></p>\n<p><span>management. As most of such Big Data applications are data intensive, the</span></p>\n<p><span>improvement of data input throughput will have a significant impact on such</span></p>\n<p><span>applications, and subsequently enabling more advanced scientific explorations.</span></p>\n<p><span>Besides scientific and engineering applications that will benefit from the</span></p>\n<p><span>improve processing speed, our research results will have help improve the</span></p>\n<p><span>management of distributed computing systems.</span></p>\n<p><span>&nbsp;</span></p>\n<p><span>Research in this project has produced educational materials for multiple</span></p>\n<p><span>courses at the host institute in the discipline of computer science and</span></p>\n<p><span>engineering. And participation of student research, especially those from</span></p>\n<p><span>underrepresented groups, has prepared them for potential science and</span></p>\n<p><span>engineering&nbsp; career.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/13/2017<br>\n\t\t\t\t\tModified by: Bo&nbsp;Hong</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis research project aims to develop a systematic framework to automatically\n\nmanage and optimize the concurrency of parallel applications.  In this project,\n\nwe have (1) developed concurrency management strategies for transactional\n\nmemory, (2) developed multi-threaded algorithms with applications in network\n\nflow, protein-DNA docking, and seismeistic data management, (3) designed\n\nmethods to explore parallelism in GPU-based HPC systems, (4) developed\n\nstrategies to manage concurrency and data locality in distributed computing\n\nsystems. These research results allow a much wider range of applications to\n\nbenefit from parallel and distributed computing. For example, we have worked\n\nwith our collaborators and have shown that GPU can be used to significantly\n\naccelerate protein-DNA docking and seismic data analysis. These HPC\n\napplications will benefit from our study on GPU-assisted systems. Other\n\napplications, such as Big Data analytics will benefit from our study of data\n\nmanagement. As most of such Big Data applications are data intensive, the\n\nimprovement of data input throughput will have a significant impact on such\n\napplications, and subsequently enabling more advanced scientific explorations.\n\nBesides scientific and engineering applications that will benefit from the\n\nimprove processing speed, our research results will have help improve the\n\nmanagement of distributed computing systems.\n\n \n\nResearch in this project has produced educational materials for multiple\n\ncourses at the host institute in the discipline of computer science and\n\nengineering. And participation of student research, especially those from\n\nunderrepresented groups, has prepared them for potential science and\n\nengineering  career.\n\n \n\n\t\t\t\t\tLast Modified: 10/13/2017\n\n\t\t\t\t\tSubmitted by: Bo Hong"
 }
}