{
 "awd_id": "0924574",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase II:  Tapping Finger Identification for Efficient Mobile Input",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Glenn H. Larsen",
 "awd_eff_date": "2009-08-15",
 "awd_exp_date": "2013-01-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 750000.0,
 "awd_min_amd_letter_date": "2009-08-11",
 "awd_max_amd_letter_date": "2011-11-30",
 "awd_abstract_narration": "This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\r\n\r\nThis Small Business Innovation Research (SBIR) Phase II project aims to further develop the Tapping Finger Identification (TFI) technology investigated in Phase I. As mobile devices become more powerful and ubiquitous, text entry remains a major bottleneck to the wider adoption of mobile computing. To address this urgent need in lack of an acceptable solution, this TFI technology enables high-speed input in mobile devices and gaming applications using conventional typing techniques and keyboard layouts. In addition to demonstrating the feasibility of TFI during Phase I, the project will develop an IP strategy and a set of tools essential to future research and development. To date, one prototype has been implemented and a license agreement to commercialize some portion of the TFI technology was reached with an external partner. Completion of the Phase II research in two years will pave the way for commercialization of this innovative technology as we transition toward mobile computing. The technology developed could potentially impact a broad range of application areas, including mobile computing, gaming, military, and mobile security.\r\n\r\nMobile devices are becoming more powerful and ubiquitous. According to the IDC, convergent mobile devices grew 51% in 2007, and will grow from 124 million to 376 million in 2012. Data entry, however, remains a major bottleneck to the wider adoption of mobile computing. Most users are frustrated with existing input methods on portable devices, such as phones and mobile PCs. Much less a paragraph of text, simply entering a website's URL in a phone or mobile PC would be a burden for many. To address this urgent need in lack of an acceptable solution, the outcomes of this project projects the enablement of high speed, efficient mobile input using conventional typing techniques and keyboard layouts.\r\n\r\n",
 "awd_arra_amount": 500000.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dongge",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dongge Li",
   "pi_email_addr": "derek.li@zienon.com",
   "nsf_id": "000083932",
   "pi_start_date": "2009-08-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Zienon, LLC",
  "inst_street_address": "225 N ARLINGTON HEIGHTS RD STE 108",
  "inst_street_address_2": "",
  "inst_city_name": "ELK GROVE VILLAGE",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "8476974310",
  "inst_zip_code": "600071017",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "IL08",
  "org_lgl_bus_name": "ZIENON",
  "org_prnt_uei_num": "",
  "org_uei_num": "ZTUPVBX8PJP9"
 },
 "perf_inst": {
  "perf_inst_name": "Zienon, LLC",
  "perf_str_addr": "225 N ARLINGTON HEIGHTS RD STE 108",
  "perf_city_name": "ELK GROVE VILLAGE",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "600071017",
  "perf_ctry_code": "US",
  "perf_cong_dist": "08",
  "perf_st_cong_dist": "IL08",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537300",
   "pgm_ele_name": "SBIR Phase II"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1658",
   "pgm_ref_txt": "SOFTWARE"
  },
  {
   "pgm_ref_code": "165E",
   "pgm_ref_txt": "SBIR Phase IIB"
  },
  {
   "pgm_ref_code": "6890",
   "pgm_ref_txt": "RECOVERY ACT ACTION"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "01R9",
   "app_name": "RRA RECOVERY ACT",
   "app_symb_id": "040101",
   "fund_code": "01R00910DB",
   "fund_name": "RRA RECOVERY ACT",
   "fund_symb_id": "040101"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 500000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The objective of this SBIR project is to develop and commercialize our virtual input technology for use in computing devices such as smart phones, PCs, game consoles, etc. Using low-cost, conventional cameras (such as those commonly available in today&rsquo;s handsets) to remotely capture gestures, our solution could significantly enhance user experience by enabling fast, efficient input in a broad array of applications. For example, it provides a natural and better way for interacting with computer games or some virtual applications by allowing users to remotely grab objects or execute commands using various fingers. Furthermore, this could eliminate the power-hungry laser projections needed by existing touch typing virtual keyboards. Several prototypes for PC, gaming, and Smart TV input were developed to demonstrate the feasibility and advantages of our proposed concepts and methods. Our initial commercialization efforts are focused on adapting our virtual input technology to input applications in the Smart TV and Set-top Box (STB) space. The first products integrating our solution are currently undergoing user trial testing. Once they are released to market, gone will be the days when we interact with our TVs and STBs in a cumbersome manner by repeatedly pressing remote control buttons. Users will be able to control their devices remotely via simple and intuitive gestures. We conclude here by expressing our gratitude to the NSF for its financial support and, especially, to our advisors Glenn Larsen and Ian Bennett for their invaluable guidance and support, which were crucial to the success of this project.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/17/2013<br>\n\t\t\t\t\tModified by: Dongge&nbsp;Li</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe objective of this SBIR project is to develop and commercialize our virtual input technology for use in computing devices such as smart phones, PCs, game consoles, etc. Using low-cost, conventional cameras (such as those commonly available in today\u00c6s handsets) to remotely capture gestures, our solution could significantly enhance user experience by enabling fast, efficient input in a broad array of applications. For example, it provides a natural and better way for interacting with computer games or some virtual applications by allowing users to remotely grab objects or execute commands using various fingers. Furthermore, this could eliminate the power-hungry laser projections needed by existing touch typing virtual keyboards. Several prototypes for PC, gaming, and Smart TV input were developed to demonstrate the feasibility and advantages of our proposed concepts and methods. Our initial commercialization efforts are focused on adapting our virtual input technology to input applications in the Smart TV and Set-top Box (STB) space. The first products integrating our solution are currently undergoing user trial testing. Once they are released to market, gone will be the days when we interact with our TVs and STBs in a cumbersome manner by repeatedly pressing remote control buttons. Users will be able to control their devices remotely via simple and intuitive gestures. We conclude here by expressing our gratitude to the NSF for its financial support and, especially, to our advisors Glenn Larsen and Ian Bennett for their invaluable guidance and support, which were crucial to the success of this project.\n\n\t\t\t\t\tLast Modified: 04/17/2013\n\n\t\t\t\t\tSubmitted by: Dongge Li"
 }
}