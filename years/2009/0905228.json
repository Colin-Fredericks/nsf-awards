{
 "awd_id": "0905228",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "HCC: Medium: Collaborative Research: Development of Trust Models and Metrics for Human-Robot Interaction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 560000.0,
 "awd_min_amd_letter_date": "2009-09-15",
 "awd_max_amd_letter_date": "2012-05-02",
 "awd_abstract_narration": "It is often assumed that the use of robots to help people execute tasks will result in better performance than if the person or robot were operating alone. However, research in automated systems suggests that the performance of a human-machine system depends on the extent to which the person trusts the machine and the extent to which this trust (or distrust) is justified.  As robots are being developed to aid people with complex tasks, it is critical not only that we build systems which people can trust, but that these systems also foster an appropriate level of trust based on the capabilities of the systems.  A user who does not have an appropriate level of trust in the robot may misuse or abuse the robot's autonomous capabilities or expose people to danger.  This project proposes to develop quantitative metrics to measure a user's trust in a robot as well as a model to estimate the user's level of trust in real time.  Using this information, the robot will be able to adjust its interaction accordingly. \r\n\r\nPromoting appropriate levels of trust will be particularly beneficial in safety-critical domains such as urban search and rescue and assistive robotics, in which users risk harm to themselves, the robot, or the environment if users do not trust the robot enough to rely on its autonomous capabilities.  The research has the potential for a large impact on the field of human-robot interaction as few studies have explicitly examined issues involving trust of robots.  Being able to model trust and foster appropriate levels of trust will result in more effective use of robotic automation, safer interactions, and better task performance.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Holly",
   "pi_last_name": "Yanco",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Holly A Yanco",
   "pi_email_addr": "holly@cs.uml.edu",
   "nsf_id": "000278965",
   "pi_start_date": "2009-09-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kristen",
   "pi_last_name": "Stubbs",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kristen Stubbs",
   "pi_email_addr": "Kristen_Stubbs@uml.edu",
   "nsf_id": "000515983",
   "pi_start_date": "2009-09-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Lowell",
  "inst_street_address": "220 PAWTUCKET ST STE 400",
  "inst_street_address_2": "",
  "inst_city_name": "LOWELL",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "9789344170",
  "inst_zip_code": "018543573",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "MA03",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS LOWELL",
  "org_prnt_uei_num": "",
  "org_uei_num": "LTNVSTJ3R6D5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Lowell",
  "perf_str_addr": "220 PAWTUCKET ST STE 400",
  "perf_city_name": "LOWELL",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "018543573",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "MA03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "779500",
   "pgm_ele_name": "TRUSTWORTHY COMPUTING"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7218",
   "pgm_ref_txt": "RET SUPP-Res Exp for Tchr Supp"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7795",
   "pgm_ref_txt": "TRUSTWORTHY COMPUTING"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 500000.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 28000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project, in collaboration with Aaron Steinfeld's lab at Carnegie Mellon University (IIS-0905148), explored how robot actions during use influenced human trust in the robot. The team focused heavily on non-social tasks and the variations in robot autonomy, performance, and interface design.</p>\n<p>Our collaborative team developed a new metric for measuring an operator&rsquo;s real time trust in a robot system, validated existing trust metrics for software systems for use in robotics, discovered that status feedback can improve trust of a robot system but increases operator workload, learned that decreasing the operator&rsquo;s situation awareness increases their trust of the robot system, found that system failures have a direct and immediate influence upon a person&rsquo;s trust of the robot system, and constructed a model of the factors that influence an operator&rsquo;s trust in a remotely operated robot system. The team also investigated how the behaviors of robot systems impact bystanders. Aspects of the work were included in our related research, allowing the expansion to other automated system domains such as autonomous cars and medical diagnosis systems to investigate the common and differing factors between these domains. Side projects included an examination of the connection between perceived robot malfunctions and deceptive robot behaviors, how robots influence human honesty, and human willingness to blindly accept robot advice.</p>\n<p>Key outputs for this work include validation of existing trust measures and models within the context of human-robot interaction, development and validation of new measures and models, new methodologies, and improvement of existing research testbeds and systems. The team published 19 papers, two of which are slated for publication in 2015.</p>\n<p>The team also had significant impact on professional capacity through integration of research results into numerous classes and significant participation by numerous students. Combined, the two sites involved one completed PhD degree at UML, 2 PhD students in progress at UML, 3 completed MS degrees at CMU, 2 completed MS degrees at UML, 10 undergraduate students at CMU, 13 undergraduate students at UML, and 1 high school student at UML. Of the 23 undergraduate students who worked on the project, 4 went on to graduate programs (2 at each site).</p>\n<p>Finally, the team has extensively disseminated results to classes, industry, K-12 students and teachers, and through numerous professional organizations and conferences. The two PIs were also the General Co-Chairs of the 2012 ACM/IEEE International Conference on Human-Robot Interaction.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/23/2014<br>\n\t\t\t\t\tModified by: Holly&nbsp;A&nbsp;Yanco</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project, in collaboration with Aaron Steinfeld's lab at Carnegie Mellon University (IIS-0905148), explored how robot actions during use influenced human trust in the robot. The team focused heavily on non-social tasks and the variations in robot autonomy, performance, and interface design.\n\nOur collaborative team developed a new metric for measuring an operator\u00c6s real time trust in a robot system, validated existing trust metrics for software systems for use in robotics, discovered that status feedback can improve trust of a robot system but increases operator workload, learned that decreasing the operator\u00c6s situation awareness increases their trust of the robot system, found that system failures have a direct and immediate influence upon a person\u00c6s trust of the robot system, and constructed a model of the factors that influence an operator\u00c6s trust in a remotely operated robot system. The team also investigated how the behaviors of robot systems impact bystanders. Aspects of the work were included in our related research, allowing the expansion to other automated system domains such as autonomous cars and medical diagnosis systems to investigate the common and differing factors between these domains. Side projects included an examination of the connection between perceived robot malfunctions and deceptive robot behaviors, how robots influence human honesty, and human willingness to blindly accept robot advice.\n\nKey outputs for this work include validation of existing trust measures and models within the context of human-robot interaction, development and validation of new measures and models, new methodologies, and improvement of existing research testbeds and systems. The team published 19 papers, two of which are slated for publication in 2015.\n\nThe team also had significant impact on professional capacity through integration of research results into numerous classes and significant participation by numerous students. Combined, the two sites involved one completed PhD degree at UML, 2 PhD students in progress at UML, 3 completed MS degrees at CMU, 2 completed MS degrees at UML, 10 undergraduate students at CMU, 13 undergraduate students at UML, and 1 high school student at UML. Of the 23 undergraduate students who worked on the project, 4 went on to graduate programs (2 at each site).\n\nFinally, the team has extensively disseminated results to classes, industry, K-12 students and teachers, and through numerous professional organizations and conferences. The two PIs were also the General Co-Chairs of the 2012 ACM/IEEE International Conference on Human-Robot Interaction.\n\n\t\t\t\t\tLast Modified: 12/23/2014\n\n\t\t\t\t\tSubmitted by: Holly A Yanco"
 }
}