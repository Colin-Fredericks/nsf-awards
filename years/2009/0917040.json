{
 "awd_id": "0917040",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "HCC-Small:Interactive Auditory Displays",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2009-07-15",
 "awd_exp_date": "2014-06-30",
 "tot_intn_awd_amt": 499982.0,
 "awd_amount": 547665.0,
 "awd_min_amd_letter_date": "2009-07-10",
 "awd_max_amd_letter_date": "2010-08-20",
 "awd_abstract_narration": "Interactive Auditory Displays\r\n\r\nPI: Ming C. Lin\r\nCo-PIs: Gary Bishop and Dinesh Manocha\r\nDepartment of Computer Science\r\nUniversity of North Carolina at Chapel Hill\r\n\r\nAn auditory display utilizes sound to communicate information to a user and offers an alternative means of visualization.  By harnessing the sense of hearing, audio rendering can further enhance a user's experience in a multimodal virtual world.  Acoustic realism has many areas of applicability including virtual reality, computer gaming, training systems, desktop interfaces, education, and scientific visualization.\r\n\r\nWe are conducting an ambitious research program to develop interactive auditory displays.  Our goal is to develop new algorithms for physics-based sound synthesis and sound propagation for interactive applications including computer gaming, training systems, and enabling technologies. The approach involves the fusion of both geometry (for high frequencies) and physics (for low frequencies) to model sound propagation and the development of techniques for acoustic levels of detail. To this end we are developing efficient numerical algorithms based on domain decomposition and exploiting modern architecture features to further accelerate the overall performance. We are also evaluating the performance of our algorithms on different applications. In addition to acoustic simulation, our research is generating a fundamental scientific foundation and interactive performance methods for solving wave/sound propagation problems in highly complex domains that span many scientific and engineering disciplines.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ming",
   "pi_last_name": "Lin",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Ming C Lin",
   "pi_email_addr": "lin@cs.umd.edu",
   "nsf_id": "000453947",
   "pi_start_date": "2009-07-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gary",
   "pi_last_name": "Bishop",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gary Bishop",
   "pi_email_addr": "bishop@cs.unc.edu",
   "nsf_id": "000260864",
   "pi_start_date": "2009-07-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Dinesh",
   "pi_last_name": "Manocha",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dinesh Manocha",
   "pi_email_addr": "dm@cs.umd.edu",
   "nsf_id": "000291378",
   "pi_start_date": "2009-07-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "104 AIRPORT DR STE 2200",
  "perf_city_name": "CHAPEL HILL",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275995023",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 328894.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 218771.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Extending the frontier of visual computing, an auditory display utilizes sound to communicate information to a user and offers an alternative means of visualization. By harnessing the sense of hearing, audio rendering can further enhance a user&rsquo;s experience in a multimodal virtual world. In addition to immersive environments, auditory displays can provide a natural and intuitive human-computer interface for many desktop applications. Furthermore, audio interfaces are increasingly used to develop assistive technologies for the visually impaired. Despite the significance of hearing as one of the dominant senses, auditory displays have not received as much attention as computer graphics.</p>\n<p>The driving impetus of our research comes from <em><span style=\"text-decoration: underline;\">interactive</span></em> applications, including emergency personnel training systems, desktop interfaces, education, scientific visualization and computer-aided design.&nbsp; Furthermore, interactive modeling and simulation of acoustic spaces can significantly enhance numerous scientific and engineering applications. However, due to intrinsic characteristics of sound, interactive auditory displays pose major computational challenges.</p>\n<p>&nbsp;</p>\n<p><strong>INTELLECTUAL MERIT</strong></p>\n<p>The following major scientific contributions have been achieved during this project:</p>\n<p>(1)&nbsp; new interactive acoustic algorithms for dynamic virtual environments using acoustics transfer operators, equivalent source methods, and adaptive spatial decomposition;</p>\n<p>(2)&nbsp; novel sound generation algorithm for liquids based on bubble acoustics;</p>\n<p>(3)&nbsp; automatic extraction of material properties from one audio sample;</p>\n<p>(4)&nbsp; innovative application for rapid acoustic prototyping of complex 3D structures for conceptual design and assistive technology.</p>\n<p>&nbsp;</p>\n<p><strong>BROADER IMPACT</strong></p>\n<p>Applications and impacts of interactive auditory displays enabled by new scientific advances include enabling technologies for visually impaired, multimodal human-centric interfaces, immersive teleconferencing, rapid prototyping of acoustic spaces for urban planning, structural design, and reduction of noise pollution.&nbsp; In addition, this research could also offer a fundamentally new solver for wave propagation problems in highly complex, vast domains for seismology, geophysics, meteorology, engineering design, urban planning, etc.</p>\n<p>The resulting research has been demonstrated to thousands of K-12 students and senior members in the nearby communities and in NC, helping to attract K-12 students and enhance study opportunities for under-represented groups and women students. &nbsp;&nbsp;Two Ph.D. students have completed their doctoral dissertation supported by this grant; and other graduate and undergraduate students working on the project were also partially supported. Resulting software systems have been licensed to a start-up company, creating new jobs for the local community.&nbsp; They are also under further development for designing accessible games for children with disabilities.&nbsp;&nbsp; Tens of refereed publications are disseminated through websites, courses, and international conferences.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/10/2014<br>\n\t\t\t\t\tModified by: Ming&nbsp;C&nbsp;Lin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nExtending the frontier of visual computing, an auditory display utilizes sound to communicate information to a user and offers an alternative means of visualization. By harnessing the sense of hearing, audio rendering can further enhance a user\u00c6s experience in a multimodal virtual world. In addition to immersive environments, auditory displays can provide a natural and intuitive human-computer interface for many desktop applications. Furthermore, audio interfaces are increasingly used to develop assistive technologies for the visually impaired. Despite the significance of hearing as one of the dominant senses, auditory displays have not received as much attention as computer graphics.\n\nThe driving impetus of our research comes from interactive applications, including emergency personnel training systems, desktop interfaces, education, scientific visualization and computer-aided design.  Furthermore, interactive modeling and simulation of acoustic spaces can significantly enhance numerous scientific and engineering applications. However, due to intrinsic characteristics of sound, interactive auditory displays pose major computational challenges.\n\n \n\nINTELLECTUAL MERIT\n\nThe following major scientific contributions have been achieved during this project:\n\n(1)  new interactive acoustic algorithms for dynamic virtual environments using acoustics transfer operators, equivalent source methods, and adaptive spatial decomposition;\n\n(2)  novel sound generation algorithm for liquids based on bubble acoustics;\n\n(3)  automatic extraction of material properties from one audio sample;\n\n(4)  innovative application for rapid acoustic prototyping of complex 3D structures for conceptual design and assistive technology.\n\n \n\nBROADER IMPACT\n\nApplications and impacts of interactive auditory displays enabled by new scientific advances include enabling technologies for visually impaired, multimodal human-centric interfaces, immersive teleconferencing, rapid prototyping of acoustic spaces for urban planning, structural design, and reduction of noise pollution.  In addition, this research could also offer a fundamentally new solver for wave propagation problems in highly complex, vast domains for seismology, geophysics, meteorology, engineering design, urban planning, etc.\n\nThe resulting research has been demonstrated to thousands of K-12 students and senior members in the nearby communities and in NC, helping to attract K-12 students and enhance study opportunities for under-represented groups and women students.   Two Ph.D. students have completed their doctoral dissertation supported by this grant; and other graduate and undergraduate students working on the project were also partially supported. Resulting software systems have been licensed to a start-up company, creating new jobs for the local community.  They are also under further development for designing accessible games for children with disabilities.   Tens of refereed publications are disseminated through websites, courses, and international conferences.\n\n\t\t\t\t\tLast Modified: 09/10/2014\n\n\t\t\t\t\tSubmitted by: Ming C Lin"
 }
}