{
 "awd_id": "0905232",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "HCC: Medium: Intelligent Agents for Protecting Users in Cyberspace",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 977776.0,
 "awd_amount": 985396.0,
 "awd_min_amd_letter_date": "2009-08-27",
 "awd_max_amd_letter_date": "2011-07-05",
 "awd_abstract_narration": "This interdisciplinary project studies the nature of the risks inherent in normal activity on the Internet, the perception of those risks, the judgment about trade-offs in behavior and the design of a personalized agent that can alert users to risky behavior and help to protect them. The key insight is that adequate security and privacy protection requires the concerted efforts of both the computer and the user. The interdisciplinary research team combines expertise from psychology, computer security and artificial intelligence to propose MIPA (MIxed Initiative Protective Agent) -- a semi-autonomous, intelligent and personalized agent approach that leverages psychological studies of what users want/need and what security and privacy risks are imminent. The techniques will be developed for and tested on a real problem that challenges the current state of the art in artificial intelligence, security and user models.\r\n\r\nAs it is becoming increasingly difficult for users to protect themselves and understand the risks they are taking on the Internet, this project has the potential to positively impact system design to effectively enhance user security. Focusing on home computer users (college students and senior citizens), the proposed research will investigate how they perceive, use and can best be served by Internet application software. Results could improve the experiences of these users as well as significantly advance techniques in intelligent agents and computer security. Additionally, because home users and machines tend to be the weak link in security, protecting them may better protect others.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Adele",
   "pi_last_name": "Howe",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Adele E Howe",
   "pi_email_addr": "howe@cs.colostate.edu",
   "nsf_id": "000225533",
   "pi_start_date": "2009-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Indrajit",
   "pi_last_name": "Ray",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Indrajit Ray",
   "pi_email_addr": "indrajit.ray@colostate.edu",
   "nsf_id": "000484108",
   "pi_start_date": "2009-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Zinta",
   "pi_last_name": "Byrne",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zinta Byrne",
   "pi_email_addr": "zinta.byrne@colostate.edu",
   "nsf_id": "000220942",
   "pi_start_date": "2009-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Colorado State University",
  "inst_street_address": "601 S HOWES ST",
  "inst_street_address_2": "",
  "inst_city_name": "FORT COLLINS",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "9704916355",
  "inst_zip_code": "805212807",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "COLORADO STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "LT9CXX8L19G1"
 },
 "perf_inst": {
  "perf_inst_name": "Colorado State University",
  "perf_str_addr": "601 S HOWES ST",
  "perf_city_name": "FORT COLLINS",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "805212807",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779500",
   "pgm_ele_name": "TRUSTWORTHY COMPUTING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 211749.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 264214.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 509433.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Although home computer users are considered the weakest link in computer security, &nbsp;research has primarily focused on investigating solutions for industrial and governmental institutions. Our project goal was to clarify the needs and perceptions of this group, represent their actions and tendencies towards security-risky actions, and take steps towards improving computer security for them.</p>\n<p>Following the inter-disciplinary nature of this project, our descriptions fall into categories: human subject studies, security model construction, and artificial intelligence algorithms.</p>\n<p><strong>Human Subject Studies:&nbsp; </strong>Initial studies to assess home users&rsquo;, specifically mature adults and college students, attitudes towards computer security and Internet use revealed our inability to identify actual versus intended behaviors and challenges modeling actual computer threat situations using paper surveys. Subsequent studies involved using a survey based on a simulator of online activities, and in the last study, we used a script that guided subjects&rsquo; activities within a &ldquo;sandbox&rdquo;: software framework, called <em>PsychoRithm</em>, discussed later.</p>\n<ul>\n<li>We developed vignettes depicting actual user behavior while attempting to manipulate security threats, to determine whether personality traits could reliably predict reactions to situations. These early vignette studies of 104 users (ages 18-68) and then 111 users (ages 18-25) revealed no identifiable pattern in responses to computer threats, no personality traits that predicted responses, and an inability of users to accurately judge how they would respond if presented actual online situations. </li>\n<li>In our risk/benefit tradeoff study of 261 users (ages 19-68), we attempted to identify decision-making patterns associated with 35 common computer actions developed from earlier expert ratings and focus groups with consumers, in terms of the perceived risk, benefits, and frequency of action, and amount of information they were willing to share with each action. We sampled personality, knowledge, and previous experience, and situational context. Unfortunately, nothing consistently predicted decision-making.&nbsp;</li>\n<li>Our last study involved participants performing tasks within different risky situations related to security, e.g., installing virus software, opening email attachments, and configuring software within an online simulator. We monitored what they did and when they did it. We are still analyzing these data.</li>\n</ul>\n<p><strong>Security Model Construction: </strong>Two models were developed that together support, at a fine grained level, reasoning about what security incidents might happen on a specific home computer with a specific user.</p>\n<ul>\n<li>A Personalized Attack Graph (PAG) model is a representation of actions/events/system states required to trigger specific vulnerabilities. A PAG instance can be easily adapted to a standard AI Planning representation called PDDL. </li>\n<li>A Bayesian User Profile (BUP) probabilistically maps characteristics that influence a home computer user&rsquo;s behavior/actions by calculating a probability distribution over the likelihood a user or attacker would engage in a particular action.</li>\n<li>To support the user studies, we developed PsychoRithm that simulates real security events in a protected environment, insulating the underlying system. PsychoRithm emulates the look and feel of a common platform and applications, and records user actions as they progress through the studies. Several screen shots of PsychoRithm are provided.</li>\n<li>We are currently validating the predictive capabilities of the PAG and BUP by comparing the results of the PsychoRithm supported studies to PAG and BUP models specialized to the actions represented in &nbsp;PDDL for the PAG.</li>\n<li>To support the construction of fine grained a...",
  "por_txt_cntn": "\nAlthough home computer users are considered the weakest link in computer security,  research has primarily focused on investigating solutions for industrial and governmental institutions. Our project goal was to clarify the needs and perceptions of this group, represent their actions and tendencies towards security-risky actions, and take steps towards improving computer security for them.\n\nFollowing the inter-disciplinary nature of this project, our descriptions fall into categories: human subject studies, security model construction, and artificial intelligence algorithms.\n\nHuman Subject Studies:  Initial studies to assess home users\u00c6, specifically mature adults and college students, attitudes towards computer security and Internet use revealed our inability to identify actual versus intended behaviors and challenges modeling actual computer threat situations using paper surveys. Subsequent studies involved using a survey based on a simulator of online activities, and in the last study, we used a script that guided subjects\u00c6 activities within a \"sandbox\": software framework, called PsychoRithm, discussed later.\n\nWe developed vignettes depicting actual user behavior while attempting to manipulate security threats, to determine whether personality traits could reliably predict reactions to situations. These early vignette studies of 104 users (ages 18-68) and then 111 users (ages 18-25) revealed no identifiable pattern in responses to computer threats, no personality traits that predicted responses, and an inability of users to accurately judge how they would respond if presented actual online situations. \nIn our risk/benefit tradeoff study of 261 users (ages 19-68), we attempted to identify decision-making patterns associated with 35 common computer actions developed from earlier expert ratings and focus groups with consumers, in terms of the perceived risk, benefits, and frequency of action, and amount of information they were willing to share with each action. We sampled personality, knowledge, and previous experience, and situational context. Unfortunately, nothing consistently predicted decision-making. \nOur last study involved participants performing tasks within different risky situations related to security, e.g., installing virus software, opening email attachments, and configuring software within an online simulator. We monitored what they did and when they did it. We are still analyzing these data.\n\n\nSecurity Model Construction: Two models were developed that together support, at a fine grained level, reasoning about what security incidents might happen on a specific home computer with a specific user.\n\nA Personalized Attack Graph (PAG) model is a representation of actions/events/system states required to trigger specific vulnerabilities. A PAG instance can be easily adapted to a standard AI Planning representation called PDDL. \nA Bayesian User Profile (BUP) probabilistically maps characteristics that influence a home computer user\u00c6s behavior/actions by calculating a probability distribution over the likelihood a user or attacker would engage in a particular action.\nTo support the user studies, we developed PsychoRithm that simulates real security events in a protected environment, insulating the underlying system. PsychoRithm emulates the look and feel of a common platform and applications, and records user actions as they progress through the studies. Several screen shots of PsychoRithm are provided.\nWe are currently validating the predictive capabilities of the PAG and BUP by comparing the results of the PsychoRithm supported studies to PAG and BUP models specialized to the actions represented in  PDDL for the PAG.\nTo support the construction of fine grained attacker/user models, we built a tool for automatically testing evolving models and for comparing the output to prior results to determine whether bugs were introduced as the model was expanded. Consequently, we significantly expanded the largest PAG model t..."
 }
}