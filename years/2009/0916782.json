{
 "awd_id": "0916782",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "AF: Small: Computer Science and Decision Making",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Balasubramanian Kalyanasundaram",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2009-09-12",
 "awd_max_amd_letter_date": "2012-02-06",
 "awd_abstract_narration": "Increasingly, automated economic transaction systems in eBay, Google and other institutions negotiate, buy and sell goods, services, advertisements etc. They use auctions to make decisions including pricing, allocation and optimization. As a result, we  now have auctions systems far greater in scale than the traditional \"human scale\" of negotiations and specialized auctions, and they impact our lives in sophisticated ways. These systems face many algorithmic challenges in the interface of Economics, Learning Theory, and Optimization, which is the focus of this project.\r\n\r\nIn this project researchers will (a) design and analyze models for the various parties (users, auctioneer, buyer and seller) and their impact on the auctions; (b) design and analyze mechanisms in the presence of parties with mixed utilities that go beyond the traditional linear profit; (c) quantify impacts of budgets in mechanisms on truthfulness, equilibria and utilities, which has been traditionally underemphasized; (d) study the  effect of bounded computational power and rationality on mechanisms; (e) design richer mechanisms for futures, combinatorial goods as well as dynamic settings; (f) study privacy, security and verifiability of  auction mechanisms; (g) study the various learning and optimization problems that are fundamental to the tasks above.\r\n\r\nThis project ultimately addresses the questions of how various parties with natural knobs (budget, utility) interact with automated economic transaction systems, how information is learned, used and controlled in such systems,  and how these systems will evolve over the long term. The project explores these questions via the specific research tasks above, as well as via training undergraduate and graduate students to work in the interface of Economics, Optimization and other areas.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Fred",
   "pi_last_name": "Roberts",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Fred S Roberts",
   "pi_email_addr": "froberts@dimacs.rutgers.edu",
   "nsf_id": "000172929",
   "pi_start_date": "2009-09-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rebecca",
   "pi_last_name": "Wright",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Rebecca N Wright",
   "pi_email_addr": "rwright@barnard.edu",
   "nsf_id": "000099098",
   "pi_start_date": "2009-09-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Shanmugavelayu",
   "pi_last_name": "Muthukrishnan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shanmugavelayu Muthukrishnan",
   "pi_email_addr": "muthu@cs.rutgers.edu",
   "nsf_id": "000158735",
   "pi_start_date": "2010-06-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "3 RUTGERS PLZ",
  "perf_city_name": "NEW BRUNSWICK",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "089018559",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "793200",
   "pgm_ele_name": "COMPUT GAME THEORY & ECON"
  },
  {
   "pgm_ele_code": "794800",
   "pgm_ele_name": "QUANTUM COMMUNICATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 100000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 100000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 100000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Increasingly, automated economic transaction systems in eBay, Google and other institutions negotiate, buy and sell goods, services, advertisements etc. They use auctions to make decisions including pricing, allocation and optimization. As a result, we now have auctions systems far greater in scale than the traditional \"human scale\" of negotiations and specialized auctions, and they impact our lives in sophisticated ways. These systems face many algorithmic challenges in the interface of Economics, Learning Theory, and Optimization, which is the focus of this project. &nbsp;Specifically, this project addressed research problems at the confluence of computer science and decision-making, with a focus on game theory, optimization, data analysis, and underlying mathematical foundations for a variety of applications including Internet advertising systems, privacy, social networks, and science writing. &nbsp;The project produced more than 20 publications in high-quality computer science conferences and journals. &nbsp;We describe some notable project results in more detail.</p>\n<p><br />\"Bandit\" problems arise in decision-making contexts when an agent has to make tradeoffs between exploitation and exploration in a context where only partial information is known about different choice paths, and the paths must be at least partly explored in order to learn more. &nbsp;Our project developed the first known approximation for bandit problems in the case where the payoff functions are adaptive and submodular. We studied the setting where the expected gain is initially unknown, and it is learned by interacting repeatedly with the optimized function. We developed an efficient algorithm whose expected cumulative regret increases logarithmically with time and captures the inherent property of submodular maximization that earlier mistakes are more costly than later ones. We also considered a multi-armed bandit problem where payoffs are a linear function of an observed stochastic contextual variable. In the scenario where there is a gap between optimal and suboptimal rewards, several algorithms have been proposed that achieve O(log T) regret after T time steps. However, previously proposed methods either had a computation complexity per iteration that scales linearly with T or achieve regrets that grow linearly with the number of contexts |X|. We developed an &epsilon; -greedy type of algorithm that solves both limitations: when contexts are d-dimensional real-numbered variables, our algorithm has a constant computation complexity per iteration of O(poly(d)) and can achieve a regret of O(poly(d) log T) even when |X| = &Omega;(2d). Unlike previous algorithms, its space complexity scales like O(Kd2) and does not grow with T. We designed and analyzed a recommendation policy based on modeling the recommendation decision as a multi-armed bandit problem and showed it has logarithmic regret. Our analysis also showed that regret depends linearly on d, the size of the underlying persistent group. We evaluated our policy on movie recommendations over the MovieLens and MoviePilot datasets.</p>\n<p><br />We studied privacy in data analysis, enabling decision-making applications that can provide privacy on the underlying data and understanding the potential costs of providing such privacy. &nbsp;We developed new methods, using sketches, for pan privacy. Our results are very general, applying to many places where linear sketches find uses, and therefore, contributing to the use of pan privacy as a distributed decision-making tool. &nbsp;Previously shown pan private algorithms for basic counting tasks such as distinct counts, heavy hitters, and others are nontrivial and rely on sampling. We reexamined these basic counting tasks using sketching and show improved algorithms. Using noisy decoding, we also presented the first known lower bounds for pan privacy with respect to a single intrusion. Our lo...",
  "por_txt_cntn": "\nIncreasingly, automated economic transaction systems in eBay, Google and other institutions negotiate, buy and sell goods, services, advertisements etc. They use auctions to make decisions including pricing, allocation and optimization. As a result, we now have auctions systems far greater in scale than the traditional \"human scale\" of negotiations and specialized auctions, and they impact our lives in sophisticated ways. These systems face many algorithmic challenges in the interface of Economics, Learning Theory, and Optimization, which is the focus of this project.  Specifically, this project addressed research problems at the confluence of computer science and decision-making, with a focus on game theory, optimization, data analysis, and underlying mathematical foundations for a variety of applications including Internet advertising systems, privacy, social networks, and science writing.  The project produced more than 20 publications in high-quality computer science conferences and journals.  We describe some notable project results in more detail.\n\n\n\"Bandit\" problems arise in decision-making contexts when an agent has to make tradeoffs between exploitation and exploration in a context where only partial information is known about different choice paths, and the paths must be at least partly explored in order to learn more.  Our project developed the first known approximation for bandit problems in the case where the payoff functions are adaptive and submodular. We studied the setting where the expected gain is initially unknown, and it is learned by interacting repeatedly with the optimized function. We developed an efficient algorithm whose expected cumulative regret increases logarithmically with time and captures the inherent property of submodular maximization that earlier mistakes are more costly than later ones. We also considered a multi-armed bandit problem where payoffs are a linear function of an observed stochastic contextual variable. In the scenario where there is a gap between optimal and suboptimal rewards, several algorithms have been proposed that achieve O(log T) regret after T time steps. However, previously proposed methods either had a computation complexity per iteration that scales linearly with T or achieve regrets that grow linearly with the number of contexts |X|. We developed an &epsilon; -greedy type of algorithm that solves both limitations: when contexts are d-dimensional real-numbered variables, our algorithm has a constant computation complexity per iteration of O(poly(d)) and can achieve a regret of O(poly(d) log T) even when |X| = &Omega;(2d). Unlike previous algorithms, its space complexity scales like O(Kd2) and does not grow with T. We designed and analyzed a recommendation policy based on modeling the recommendation decision as a multi-armed bandit problem and showed it has logarithmic regret. Our analysis also showed that regret depends linearly on d, the size of the underlying persistent group. We evaluated our policy on movie recommendations over the MovieLens and MoviePilot datasets.\n\n\nWe studied privacy in data analysis, enabling decision-making applications that can provide privacy on the underlying data and understanding the potential costs of providing such privacy.  We developed new methods, using sketches, for pan privacy. Our results are very general, applying to many places where linear sketches find uses, and therefore, contributing to the use of pan privacy as a distributed decision-making tool.  Previously shown pan private algorithms for basic counting tasks such as distinct counts, heavy hitters, and others are nontrivial and rely on sampling. We reexamined these basic counting tasks using sketching and show improved algorithms. Using noisy decoding, we also presented the first known lower bounds for pan privacy with respect to a single intrusion. Our lower bounds show that, even if allowed to work with unbounded memory, pan private algorithms for distinct counts ca..."
 }
}