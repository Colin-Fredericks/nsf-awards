{
 "awd_id": "0948548",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III/EAGER: TwitterStand: Separating the Wheat from the Chaff in Breaking News",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2009-09-15",
 "awd_exp_date": "2012-08-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 216000.0,
 "awd_min_amd_letter_date": "2009-09-18",
 "awd_max_amd_letter_date": "2012-03-01",
 "awd_abstract_narration": "Twitter is an electronic medium that allows a large user populace to communicate with each other simultaneously. Inherent to Twitter is an asymmetrical relationship between friends and followers thereby provides an interesting social network-like structure among the users of Twitter. Twitter messages, called tweets, are restricted to 140 characters and thus are usually very focused. Twitter is becoming the medium of choice for keeping abreast of rapidly breaking news. This project explores the use of Twitter to build a news processing system from Twitter tweets. The result is analogous to a distributed news wire service. The difference is that the identities of the contributors/reporters are not known in advance and there may be many of them. The tweets are not sent according to a schedule. The tweets occur as news is happening and are noisy while usually arriving at a high throughput rate. \r\n\r\nThe goal of this exploratory research project is to find effective methods for making Twitter a useful news gathering mechanism. Challenges addressed in this project include: removing the noise; determining tweet clusters of interest bearing in mind that the methods must be online; and determining the relevant location associated with the tweets. \r\n\r\nThe broad impact of this research is to make it easier to disseminate late breaking news and enhancing the distributed news gathering and reporting process. Web site (http://www.cs.umd.edu/~hjs/hjscat.html) reports results of this and related research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hanan",
   "pi_last_name": "Samet",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hanan Samet",
   "pi_email_addr": "hjs@umd.edu",
   "nsf_id": "000445634",
   "pi_start_date": "2009-09-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland, College Park",
  "perf_str_addr": "3112 LEE BUILDING",
  "perf_city_name": "COLLEGE PARK",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 200000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Twitter is an electronic medium that allows a large user populace to<br />communicate with each other simultaneously.&nbsp; Inherent to Twitter is an<br />asymmetrical relationship between friends and followers thereby<br />providing an interesting social network-like structure among its users.<br />Twitter messages, called tweets, are restricted to 140 characters and<br />thus are usually very focused.&nbsp; In this project our goal was the<br />investigation of the use of Twitter to build a news processing system<br />from Twitter tweets.&nbsp; The idea was to capture tweets that correspond<br />to late breaking news.&nbsp; The result is analogous to a distributed news<br />wire service.&nbsp; The difference is that the identities of the<br />contributors/reporters are not necessarily known in advance and there<br />may be many of them.&nbsp; The tweets are not sent according to a schedule.<br />Instead, the tweets occur as news is happening and are noisy while<br />usually arriving at a high throughput rate.&nbsp; Some of the issues that<br />we investigated involved the removal of noise which meant trying to <br />determine tweet clusters of interest bearing in mind that the<br />methods must be online, and determining the relevant location<br />associated with the tweets.&nbsp; The latter is quite difficult as our<br />goal is to associate a tweet with the location that the tweet is about<br />rather than the location of the tweeter, which is quite easy to<br />determine given the GPS capabilities of smartphones, which are the<br />tweeting device of choice.&nbsp; The former is also quite difficult as we<br />must identify tweeters who tweet newsworthy tweets.&nbsp; This is analogous<br />to removing the noise tweets.</p>\n<p>Our primary focus was two-parted.&nbsp; The first involved the<br />disambiguation of entities (e.g., people, geographic locations,<br />organizations etc.) in tweets.&nbsp; As tweets are limited to&nbsp; 140<br />characters in length this meant that there was very little information <br />in tweets to aid the disambiguation.&nbsp; Typically, when Twitter<br />users refer to entities with which they are familiar, they include<br />very little contextual information, which makes the disambiguation<br />process all the more difficult.&nbsp; For example, for Twitter users who<br />are residents of London, UK, it is well understood that ``David<br />Cameron'' refers to the Prime Minister of the&nbsp; UK, while a reference<br />to ``Buckingham Palace'' corresponds to a landmark in London, neither<br />of which requires any additional information for the purpose of<br />disambiguation. However, without these additional elaborations it<br />would be almost impossible for a disambiguation algorithm to work<br />properly.&nbsp; Most importantly, note that the Twitter user sending the<br />tweet would find the inclusion of these additional elaboration rather<br />redundant and probably silly if they were required to qualify ``David<br />Cameron'' with the phrase ``Prime Minister of the UK''.&nbsp; In this<br />regard, we say that ``David Cameron'' and ``Buckingham Palace' are<br />part of the local lexicon (i.e., common knowledge) of all Twitter<br />users who are from London, UK.&nbsp;&nbsp; Our approach to resolve ambiguities in<br />tweets from a user at location s is based on computing the local<br />lexicon of s, which is informally defined as a set of concepts that is<br />strongly associated with s and, furthermore, its elements are<br />recognized without ambiguity by Twitter users from s.&nbsp; The Local<br />Lexicon includes, but is not limited to, people, landmarks,<br />organizations, and even historical events.&nbsp; The key to our work was to<br />investigate the use of the Wikipedia to help form that local lexicon.</p>\n<p>The second part of our focus was on determining the trustworthy and<br />noteworthy news tweeters which we termed ...",
  "por_txt_cntn": "\nTwitter is an electronic medium that allows a large user populace to\ncommunicate with each other simultaneously.  Inherent to Twitter is an\nasymmetrical relationship between friends and followers thereby\nproviding an interesting social network-like structure among its users.\nTwitter messages, called tweets, are restricted to 140 characters and\nthus are usually very focused.  In this project our goal was the\ninvestigation of the use of Twitter to build a news processing system\nfrom Twitter tweets.  The idea was to capture tweets that correspond\nto late breaking news.  The result is analogous to a distributed news\nwire service.  The difference is that the identities of the\ncontributors/reporters are not necessarily known in advance and there\nmay be many of them.  The tweets are not sent according to a schedule.\nInstead, the tweets occur as news is happening and are noisy while\nusually arriving at a high throughput rate.  Some of the issues that\nwe investigated involved the removal of noise which meant trying to \ndetermine tweet clusters of interest bearing in mind that the\nmethods must be online, and determining the relevant location\nassociated with the tweets.  The latter is quite difficult as our\ngoal is to associate a tweet with the location that the tweet is about\nrather than the location of the tweeter, which is quite easy to\ndetermine given the GPS capabilities of smartphones, which are the\ntweeting device of choice.  The former is also quite difficult as we\nmust identify tweeters who tweet newsworthy tweets.  This is analogous\nto removing the noise tweets.\n\nOur primary focus was two-parted.  The first involved the\ndisambiguation of entities (e.g., people, geographic locations,\norganizations etc.) in tweets.  As tweets are limited to  140\ncharacters in length this meant that there was very little information \nin tweets to aid the disambiguation.  Typically, when Twitter\nusers refer to entities with which they are familiar, they include\nvery little contextual information, which makes the disambiguation\nprocess all the more difficult.  For example, for Twitter users who\nare residents of London, UK, it is well understood that ``David\nCameron'' refers to the Prime Minister of the  UK, while a reference\nto ``Buckingham Palace'' corresponds to a landmark in London, neither\nof which requires any additional information for the purpose of\ndisambiguation. However, without these additional elaborations it\nwould be almost impossible for a disambiguation algorithm to work\nproperly.  Most importantly, note that the Twitter user sending the\ntweet would find the inclusion of these additional elaboration rather\nredundant and probably silly if they were required to qualify ``David\nCameron'' with the phrase ``Prime Minister of the UK''.  In this\nregard, we say that ``David Cameron'' and ``Buckingham Palace' are\npart of the local lexicon (i.e., common knowledge) of all Twitter\nusers who are from London, UK.   Our approach to resolve ambiguities in\ntweets from a user at location s is based on computing the local\nlexicon of s, which is informally defined as a set of concepts that is\nstrongly associated with s and, furthermore, its elements are\nrecognized without ambiguity by Twitter users from s.  The Local\nLexicon includes, but is not limited to, people, landmarks,\norganizations, and even historical events.  The key to our work was to\ninvestigate the use of the Wikipedia to help form that local lexicon.\n\nThe second part of our focus was on determining the trustworthy and\nnoteworthy news tweeters which we termed seeders.  In order to\nevaluate a user's contribution to TwitterStand, we defined what we\nterm are the important traits of a user and provided a mechanism to\nquantify and monitor that behavior. There are three areas that we\nquantified in order to evaluate a Twitter user:  the number of\nclusters to which a user contributes; how many other users are also\ntweeting about the topics a user tweets about; and the timing of a \nuser's tweets in ..."
 }
}