{
 "awd_id": "0905365",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: Medium: Collaborative Research: Providing Predictable Timing for Task Migration in Embedded Multi-Core Environments (TiME-ME)",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 335000.0,
 "awd_amount": 335000.0,
 "awd_min_amd_letter_date": "2009-08-06",
 "awd_max_amd_letter_date": "2013-08-13",
 "awd_abstract_narration": "Assuring deadlines of embedded tasks for contemporary multicore architectures is becoming increasingly difficult. Real-time scheduling relies on task migration to exploit multicores, yet migration actually reduces timing predictability due to cache warm-up overheads and increased interconnect traffic.\r\n\r\nThis work promotes a fundamentally new approach to increase the timing predictability of multicore architectures aimed at task migration in embedded environments making three major contributions:\r\n\r\n1. The development of novel strategies to guide migration based on cost/benefit tradeoffs exploiting both static and dynamic analyses.\r\n\r\n2. The devising of mechanisms to increase timing predictability under task migration providing explicit support for proactive and reactive real-time data movement across cores and their caches.\r\n\r\n3. The promotion of rate- and bandwidth-adaptive mechanisms as well as monitoring capabilities to increase predictability under task migration.\r\n\r\nThe work aims at initiating a novel research direction investigating the benefits of interactions between hardware and software for embedded multicores with respect to timing predictability. This project fundamentally contributes to the research and educational infrastructure for the design and development of safety- and mission-critical embedded systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Raj",
   "pi_last_name": "Acharya",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Raj Acharya",
   "pi_email_addr": "racharya@iu.edu",
   "nsf_id": "000387224",
   "pi_start_date": "2012-09-26",
   "pi_end_date": "2013-08-13"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yuan",
   "pi_last_name": "Xie",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yuan Xie",
   "pi_email_addr": "yuanxie@ece.ucsb.edu",
   "nsf_id": "000203143",
   "pi_start_date": "2013-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "201 OLD MAIN",
  "perf_city_name": "UNIVERSITY PARK",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168021503",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "PA15",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  },
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 167500.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 83750.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 83750.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Many embedded systems use multi-core/many-core processors. The communication among these processors are through on-chip interconnects and the delay/power/energy of the on-chip interconnect design has significant impact on the system. The project aims at reducing the power/energy and improving the performance of the on-chip interconnect. During this report period, we proposed two techniques.</p>\n<p>(1) NOC-sprinting, which can help reduce the thermal impact and energy consumption of the network-on-chip. To maintain a constant power envelope, the fraction of a silicon chip that can be operated at full frequency is<br />dropping exponentially with each generation of process technology.<br />Consequently, a large portion of silicon chips will become dark or dim<br />silicon, i.e., either idle or significantly under-clocked. However, most<br />previous work focuses on energy-efficient core/cache design while the<br />impact of on-chip interconnect is neglected. In fact, Network-on-chip<br />(NoC) plays a vital role in message passing and memory access that<br />directly influences the overall performance of many-core processors.<br />Moreover, network components dissipate 10% - 36% of total chip<br />power. Therefore, how to design the interconnection network<br />is critical to tackle the challenges of multicore scaling in the dark<br />silicon age. Recently, a concept of&nbsp; computational sprinting was proposed, in<br />which a chip improves its responsiveness to short-burst of computations<br />through temporarily exceeding its sustainable thermal design power<br />(TDP) budget. All the cores will be operated at the highest<br />&nbsp;frequency/voltage to provide instant throughput during sprinting, and<br />after that the chip must return to the single-core nominal operation<br />to cool down. While such mechanism sheds light upon how &ldquo;dark&rdquo;<br />cores can be utilized for transient performance enhancement, it exposes<br />two major design issues: First, the role of interconnect is neglected.<br />NoCs consume a significant portion of chip power when all cores are<br />in sprinting mode. When switching back to the nominal mode, only<br />a single core is active. However, the network routers and links cannot<br />be completely powered down, otherwise a gated-off node would block<br />packet-forwarding and the access of the local but shared resources<br />(e.g., cache and directory). As a result, the ratio of network power<br />over chip power rises substantially and may even lead to higher NoC<br />power than that of the single active core. Second, the mode-switching<br />lacks flexibility and only provides two options: nominal single-core<br />operation and maximum all-core sprinting. Depending on the workload<br />characteristics, an intermediate number of active cores may provide the<br />optimal performance speedup with less power dissipation.<br />To address these two issues, we propose fine-grained sprinting,<br />in which the chip can selectively sprint to any intermediate stages<br />instead of directly activating all the cores in response to short-burst<br />computations. The optimum number of cores to be selected depends<br />on the application characteristics. Scalable applications may opt to a<br />large number of cores that can support highly parallel computation,<br />whereas other applications may mostly consist of sequential programs<br />and would rather execute on a small number of cores. Apparently,<br />fine-grained sprinting can flexibly adapt to a variety of workloads. In<br />addition, landing on intermediate sprinting stages can save chip power<br />and slow down the heating process by power-gating the remaining<br />inactive on-chip resources, which is capable of sustaining longer sprint<br />duration for better system performance.</p>\n<p>&nbsp;</p>\n<p>(2) NOC-Delta, which can compress the information to be transferred on the net...",
  "por_txt_cntn": "\nMany embedded systems use multi-core/many-core processors. The communication among these processors are through on-chip interconnects and the delay/power/energy of the on-chip interconnect design has significant impact on the system. The project aims at reducing the power/energy and improving the performance of the on-chip interconnect. During this report period, we proposed two techniques.\n\n(1) NOC-sprinting, which can help reduce the thermal impact and energy consumption of the network-on-chip. To maintain a constant power envelope, the fraction of a silicon chip that can be operated at full frequency is\ndropping exponentially with each generation of process technology.\nConsequently, a large portion of silicon chips will become dark or dim\nsilicon, i.e., either idle or significantly under-clocked. However, most\nprevious work focuses on energy-efficient core/cache design while the\nimpact of on-chip interconnect is neglected. In fact, Network-on-chip\n(NoC) plays a vital role in message passing and memory access that\ndirectly influences the overall performance of many-core processors.\nMoreover, network components dissipate 10% - 36% of total chip\npower. Therefore, how to design the interconnection network\nis critical to tackle the challenges of multicore scaling in the dark\nsilicon age. Recently, a concept of  computational sprinting was proposed, in\nwhich a chip improves its responsiveness to short-burst of computations\nthrough temporarily exceeding its sustainable thermal design power\n(TDP) budget. All the cores will be operated at the highest\n frequency/voltage to provide instant throughput during sprinting, and\nafter that the chip must return to the single-core nominal operation\nto cool down. While such mechanism sheds light upon how \"dark\"\ncores can be utilized for transient performance enhancement, it exposes\ntwo major design issues: First, the role of interconnect is neglected.\nNoCs consume a significant portion of chip power when all cores are\nin sprinting mode. When switching back to the nominal mode, only\na single core is active. However, the network routers and links cannot\nbe completely powered down, otherwise a gated-off node would block\npacket-forwarding and the access of the local but shared resources\n(e.g., cache and directory). As a result, the ratio of network power\nover chip power rises substantially and may even lead to higher NoC\npower than that of the single active core. Second, the mode-switching\nlacks flexibility and only provides two options: nominal single-core\noperation and maximum all-core sprinting. Depending on the workload\ncharacteristics, an intermediate number of active cores may provide the\noptimal performance speedup with less power dissipation.\nTo address these two issues, we propose fine-grained sprinting,\nin which the chip can selectively sprint to any intermediate stages\ninstead of directly activating all the cores in response to short-burst\ncomputations. The optimum number of cores to be selected depends\non the application characteristics. Scalable applications may opt to a\nlarge number of cores that can support highly parallel computation,\nwhereas other applications may mostly consist of sequential programs\nand would rather execute on a small number of cores. Apparently,\nfine-grained sprinting can flexibly adapt to a variety of workloads. In\naddition, landing on intermediate sprinting stages can save chip power\nand slow down the heating process by power-gating the remaining\ninactive on-chip resources, which is capable of sustaining longer sprint\nduration for better system performance.\n\n \n\n(2) NOC-Delta, which can compress the information to be transferred on the network, so that energy can be saved and performance can be improved. The idea is to conduct data encoding prior to packet injection and\ndecoding before ejection in the network interface. The key idea  is\nto store a data packet in the Network-on-Chip as a common base value\nplus an array of relative differences. It can improve th..."
 }
}