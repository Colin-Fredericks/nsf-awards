{
 "awd_id": "0914927",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: SMALL: LexE: Using Two-part Lexical Entrainment for More Efficient and Reliable Spoken Dialogue Systems",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 430000.0,
 "awd_min_amd_letter_date": "2009-08-18",
 "awd_max_amd_letter_date": "2010-08-15",
 "awd_abstract_narration": "When humans speak to each other and want the dialogue to go well, they adapt to each other?s manner of speaking, using the same words, grammatical constructions and expressions. In order to make fundamental improvements in the performance of spoken dialogue systems, LexE is using subtle techniques to model this adaptation, which is called lexical entrainment. LexE is getting users to adapt their speech to the system, as well as getting the system?s speech to adapt to what the user says. To do this, LexE studies human-human dialogues to find the words and constructions (the ?primes?) that are often adopted by dialogue participants. The spoken dialogue system then uses these primes in its output. The system also detects the expressions that its user employs to refer to objects uses them in its synthetic speech. \r\nTwo real-user spoken dialogue systems are being used as test platforms for LexE. The first is a bus information system for the Port Authority of Allegheny County; the second is the City of Pittsburgh 311 non-emergency service. By making these publicly-available spoken dialogue systems easier to use, LexE makes them (and other spoken dialogue systems) more accessible to a large part of our population, many of whom, the elderly, for example, get much of their information over the telephone. The techniques developed in this project also provide insights for the education of non-native speakers and for speech therapy, where tutoring systems can imitate the way humans implicitly correct errors in what their interlocutors say.\r\n\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maxine",
   "pi_last_name": "Eskenazi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maxine Eskenazi",
   "pi_email_addr": "max@cs.cmu.edu",
   "nsf_id": "000224874",
   "pi_start_date": "2009-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 FORBES AVE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 148065.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 281935.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>LexE aimed at making spoken dialog systems more flexible and acceptable by the average user. In order to do this the system actions were modeled after the manner in which humans interact when speaking to one another. It is known that people adapt their speech to the other person, using the terms that they use, speaking more slowly or faster as well. This not only shows the other person that the speaker is making an effort to have a productive conversation, but it also makes the speech easier to understand.</p>\n<p>LexE first modeled one side of the conversation to see if the system could get users to adopt the words it used, to stop shouting and to slow their speech down. All of this is useful for the system since it makes the speech easier for an automatic speech recognizer to understand.</p>\n<p>Once the system side of the conversation was modeled and successfully implemented, LexE concentrated on the user side. For this, the system adopted words that the user employed and, when the system used words that the user was supposed to copy, if the user did not choose to use the same words as the user, then the system automatically changed its choice of words until it found something that was acceptable to the user.</p>\n<p>These changes were tested in a real application, Let&rsquo;s Go, which has given real time bus scheduling information to Pittsburghers for over 9 years. This application is used daily by bus riders and has led to more than 200,000 calls over its lifetime. If the findings of LexE are to contribute to progress in the field, then they have to be shown to improve system performance significantly here. This was the case for all of our tests of LexE.</p>\n<p>The impact on the everyday user of these ubiquitous dialog systems is shown in both the way that the system can respond in a more understandable manner and in the way that the system more frequently responds correctly. The impact on the field of spoken dialog research is that of adopting this flexible way of interacting with the user: while LexE explored adapting words and expressions as well as the pace and loudness of the speech, there is much more that other researchers can add here, for example in adapting the meaning (focus) of what is being said, the politeness used, the pitch of the voice, and the crispness of the pronunciation. This will lead to a new generation of spoken dialog systems that provide more natural interaction and a much more acceptable user experience.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/01/2014<br>\n\t\t\t\t\tModified by: Maxine&nbsp;Eskenazi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nLexE aimed at making spoken dialog systems more flexible and acceptable by the average user. In order to do this the system actions were modeled after the manner in which humans interact when speaking to one another. It is known that people adapt their speech to the other person, using the terms that they use, speaking more slowly or faster as well. This not only shows the other person that the speaker is making an effort to have a productive conversation, but it also makes the speech easier to understand.\n\nLexE first modeled one side of the conversation to see if the system could get users to adopt the words it used, to stop shouting and to slow their speech down. All of this is useful for the system since it makes the speech easier for an automatic speech recognizer to understand.\n\nOnce the system side of the conversation was modeled and successfully implemented, LexE concentrated on the user side. For this, the system adopted words that the user employed and, when the system used words that the user was supposed to copy, if the user did not choose to use the same words as the user, then the system automatically changed its choice of words until it found something that was acceptable to the user.\n\nThese changes were tested in a real application, Let\u00c6s Go, which has given real time bus scheduling information to Pittsburghers for over 9 years. This application is used daily by bus riders and has led to more than 200,000 calls over its lifetime. If the findings of LexE are to contribute to progress in the field, then they have to be shown to improve system performance significantly here. This was the case for all of our tests of LexE.\n\nThe impact on the everyday user of these ubiquitous dialog systems is shown in both the way that the system can respond in a more understandable manner and in the way that the system more frequently responds correctly. The impact on the field of spoken dialog research is that of adopting this flexible way of interacting with the user: while LexE explored adapting words and expressions as well as the pace and loudness of the speech, there is much more that other researchers can add here, for example in adapting the meaning (focus) of what is being said, the politeness used, the pitch of the voice, and the crispness of the pronunciation. This will lead to a new generation of spoken dialog systems that provide more natural interaction and a much more acceptable user experience.\n\n \n\n\t\t\t\t\tLast Modified: 12/01/2014\n\n\t\t\t\t\tSubmitted by: Maxine Eskenazi"
 }
}