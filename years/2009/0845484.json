{
 "awd_id": "0845484",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Using Rich Information from Speech and Text for Meeting Summarization",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2009-07-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 400077.0,
 "awd_amount": 408077.0,
 "awd_min_amd_letter_date": "2009-06-17",
 "awd_max_amd_letter_date": "2016-07-19",
 "awd_abstract_narration": "Recent advances in text summarization and speech recognition have not been paralleled by similar advances in speech summarization. This project on meeting summarization has three focuses. First, it investigates two different summarization task definitions, generic extractive summarization, and query-based summarization. Second, it addresses the core challenges that arise when simply applying text summarization techniques to speech recognition output. It evaluates the impact of low-level structural information (such as sentence boundaries and disfluencies), uses high-level meeting structural information (such as topics and meeting structure, speaker interaction), and uses rich recognition output (confidence measures in the recognition hypotheses, n-best and lattices) for summarization. Finally, various measurements are used to evaluate the effectiveness of summarization approaches, including comparing to human summary references, extrinsic metrics (e.g., based on a question-answering task), and human evaluation for the usefulness of the query-based summaries.\r\nThis project employs advanced algorithms to combine well-motivated rich information from both speech and text for meeting summarization. An important outcome will be the findings about the usefulness of the summarization task for the meeting domain and development of new approaches to measuring success for this task. This work will advance the frontier of our understanding of human interactions and improve our ability to automatically process human speech. The annotated data and evaluation tools developed in this project will be shared with the community. This project is multidisciplinary, involving speech processing, natural language processing, and conversation analysis. The tight integration of research and education will significantly enhance the excellence of next-generation researchers.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yang",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yang Liu",
   "pi_email_addr": "yangl@hlt.utdallas.edu",
   "nsf_id": "000288465",
   "pi_start_date": "2009-06-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Dallas",
  "inst_street_address": "800 WEST CAMPBELL RD.",
  "inst_street_address_2": "SP2.25",
  "inst_city_name": "RICHARDSON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9728832313",
  "inst_zip_code": "750803021",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "TX24",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT DALLAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "EJCVPNN1WFS5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Dallas",
  "perf_str_addr": "800 WEST CAMPBELL RD.",
  "perf_city_name": "RICHARDSON",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "750803021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "TX24",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 232497.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 82526.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 85054.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Spoken language processing tasks (such as speech summarization) have often been tackled with a pipeline architecture (e.g., simply applying text-based techniques to speech recognition output). However, many barriers arise in this approach due to the differences between recognition output and written text (such as recognition errors and lack of structural information in recognition output), and the inherent differences between spoken and written languages (e.g., disfluencies, multiple speakers, and less focused topics in speech). In addition, this approach does not take advantage of the rich information contained in the speech signal (e.g., salience and emotion).</p>\n<p>The goal of this project is to remedy these barriers and address the core challenges seen in combining speech recognition and language processing technology in the context of extractive speech summarization for the meeting domain. We proposed various methods to effectively use rich information in the meetings, including prosodic features and structural information such as topics, meeting structure. To address issues resulting from the imperfect recognition output, we used multiple recognition hypotheses (n-best or confusion network). We also proposed advanced models to generate abstractive summaries, using either a pipeline approach of extractive summarization followed by compression, or a joint summarization and compression method. Furthermore, we studied the summary evaluation issue and evaluated the correlation between ROUGE scores and human evaluation scores, which provides guidance to future meeting summarization evaluation.</p>\n<p>An important scientific contribution of this project is the development of advanced algorithms that combine well-motivated rich information from both speech and text and thus truly represent the meeting summarization task. The knowledge gained from this work will be extremely useful for many spoken language processing tasks, where speech recognition is followed by text-based processing techniques, such as machine translation. This work greatly benefited the research community in different ways. The annotated data from this project (for example, keywords for the meetings) was shared with the community. The PI organized a workshop and gave tutorials on the topic of summarization. The educational outcome of this project includes a new course the PI developed in the university for speech processing, and more importantly the opportunities students have to conduct cutting-edge research that benefits their own long term career.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/17/2017<br>\n\t\t\t\t\tModified by: Yang&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSpoken language processing tasks (such as speech summarization) have often been tackled with a pipeline architecture (e.g., simply applying text-based techniques to speech recognition output). However, many barriers arise in this approach due to the differences between recognition output and written text (such as recognition errors and lack of structural information in recognition output), and the inherent differences between spoken and written languages (e.g., disfluencies, multiple speakers, and less focused topics in speech). In addition, this approach does not take advantage of the rich information contained in the speech signal (e.g., salience and emotion).\n\nThe goal of this project is to remedy these barriers and address the core challenges seen in combining speech recognition and language processing technology in the context of extractive speech summarization for the meeting domain. We proposed various methods to effectively use rich information in the meetings, including prosodic features and structural information such as topics, meeting structure. To address issues resulting from the imperfect recognition output, we used multiple recognition hypotheses (n-best or confusion network). We also proposed advanced models to generate abstractive summaries, using either a pipeline approach of extractive summarization followed by compression, or a joint summarization and compression method. Furthermore, we studied the summary evaluation issue and evaluated the correlation between ROUGE scores and human evaluation scores, which provides guidance to future meeting summarization evaluation.\n\nAn important scientific contribution of this project is the development of advanced algorithms that combine well-motivated rich information from both speech and text and thus truly represent the meeting summarization task. The knowledge gained from this work will be extremely useful for many spoken language processing tasks, where speech recognition is followed by text-based processing techniques, such as machine translation. This work greatly benefited the research community in different ways. The annotated data from this project (for example, keywords for the meetings) was shared with the community. The PI organized a workshop and gave tutorials on the topic of summarization. The educational outcome of this project includes a new course the PI developed in the university for speech processing, and more importantly the opportunities students have to conduct cutting-edge research that benefits their own long term career. \n\n \n\n\t\t\t\t\tLast Modified: 12/17/2017\n\n\t\t\t\t\tSubmitted by: Yang Liu"
 }
}