{
 "awd_id": "0916870",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Cooperative Coevolutionary Design and Multiagent Systems",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 455000.0,
 "awd_amount": 501000.0,
 "awd_min_amd_letter_date": "2009-09-06",
 "awd_max_amd_letter_date": "2013-05-07",
 "awd_abstract_narration": "Cooperative coevolution is a potent approach to doing large-scale stochastic optimization. The unsolved game-theoretic challenges inherent in this computational method are complex and of significant interest to the evolutionary computation community. This project is advancing the state of the art in coevolution and is applying it to significantly larger problems than commonly found in the literature. These challenges, and their solution, have potentially transformative impact on other co-adaptive environments such as multiagent reinforcement learning, estimation of distribution algorithms, agent modeling, and swarm robotics. Coevolution has strong applicability to fields that use multiagent system models, including multirobotics, biology, economics, land use, and political science. Better models in these fields can positively affect society, policy, homeland security, and the environment.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sean",
   "pi_last_name": "Luke",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sean Luke",
   "pi_email_addr": "sean@cs.gmu.edu",
   "nsf_id": "000239818",
   "pi_start_date": "2009-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "George Mason University",
  "inst_street_address": "4400 UNIVERSITY DR",
  "inst_street_address_2": "",
  "inst_city_name": "FAIRFAX",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "7039932295",
  "inst_zip_code": "220304422",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "VA11",
  "org_lgl_bus_name": "GEORGE MASON UNIVERSITY",
  "org_prnt_uei_num": "H4NRWLFCDF43",
  "org_uei_num": "EADLFP7Z72E5"
 },
 "perf_inst": {
  "perf_inst_name": "George Mason University",
  "perf_str_addr": "4400 UNIVERSITY DR",
  "perf_city_name": "FAIRFAX",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "220304422",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "VA11",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 455000.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 6000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In a multiagent system, multiple computational entities (so-called \"agents\" -- such as robots or artificial intelligence programs) interact in complex ways, often stepping on each other's toes as they trie to achieve their goals. &nbsp;For example, if you have many mobile robots in a warehouse ferrying goods here and there, they must coordinate to avoid crashing into one another or taking each others' goods. &nbsp;The more agents involved, and the more interactions they have, the more difficult the problem. &nbsp;Our work involved multiple agents learning to coordinate with one another, or being collectively trained by a human, to perform a collective task.</p>\n<p>There are various ways you can go about this. &nbsp;One part of the research work examined a multiagent version of evolutionary optimization techniques, commonly known as \"cooperative coevolutionary algorithms\" or CCEAs. &nbsp;CCEAs promise to be far more efficient than regular evolutionary optimization, but the poor interaction among the multiple agents can cause the them to fail badly. &nbsp;We developed new approaches to minimize this likelihood.</p>\n<p>Our work led to the development of various methods for controlling potentially large groups of agents or robots as they negotiate with one another. &nbsp;In particular, we developed a method called M-HiTAB, which allows us to train warms of robots or agents to collaborate on tasks. &nbsp;This training is done by a human actually demonstrating the desired task for the robots to observe. &nbsp;For example, we can train a team of humanoid robots how to play soccer; or train firefighting robots how to work together in a diaster such as a leaking nuclear power plant. &nbsp;This mehod, which we believe is the best among its peers in this area, has since garnered a follow-on NSF grant.</p>\n<p>We have also examined how to create economies of favors among multiple agents to ease negotiation; developed new multiagent algorithms for controlling traffic lights, and to use embedded markers for robot navigation; and have criticized and developed new benchmarks in the field. &nbsp;</p>\n<p>The work has very significantly extended and improved two free and open-source software packages which we developed and which are widely used. &nbsp;The ECJ evolutionary computation library is the most commonly used such package in the world, and the MASON multiagent simulation toolkit is a well-regarded high-performance go-to package for large \"swarm\"-style simulation. &nbsp;Both of these packages are used in multiple other NSF-funded grants in areas ranging from computational biology to the social sciences to robotics and computer science. &nbsp;Each of the packages is over 80,000 lines of code, and has an over 300 page manual.</p>\n<p>The work has broad impact well beyond computer science. &nbsp;Multiagent simulations are used widely in biology, the social sciences, arts and animation, the military, disaster relief, security, and public policy. &nbsp;For example, we personally collaborate with social scientists from other universities and from the Smithsonian Institution to develop and optimize models of economies, farmer and herder conflicts in Africa, fish schools and coral reefs, and methods for improving vehicular traffic flow.</p>\n<p>The work has resulted in a free, downloadable 250-page book called Essentials of Metaheuristics, aimed to teach stochastic and multiagent optimization methods to laymen, basic programmers, and undergraduate students.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/23/2013<br>\n\t\t\t\t\tModified by: Sean&nbsp;Luke</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn a multiagent system, multiple computational entities (so-called \"agents\" -- such as robots or artificial intelligence programs) interact in complex ways, often stepping on each other's toes as they trie to achieve their goals.  For example, if you have many mobile robots in a warehouse ferrying goods here and there, they must coordinate to avoid crashing into one another or taking each others' goods.  The more agents involved, and the more interactions they have, the more difficult the problem.  Our work involved multiple agents learning to coordinate with one another, or being collectively trained by a human, to perform a collective task.\n\nThere are various ways you can go about this.  One part of the research work examined a multiagent version of evolutionary optimization techniques, commonly known as \"cooperative coevolutionary algorithms\" or CCEAs.  CCEAs promise to be far more efficient than regular evolutionary optimization, but the poor interaction among the multiple agents can cause the them to fail badly.  We developed new approaches to minimize this likelihood.\n\nOur work led to the development of various methods for controlling potentially large groups of agents or robots as they negotiate with one another.  In particular, we developed a method called M-HiTAB, which allows us to train warms of robots or agents to collaborate on tasks.  This training is done by a human actually demonstrating the desired task for the robots to observe.  For example, we can train a team of humanoid robots how to play soccer; or train firefighting robots how to work together in a diaster such as a leaking nuclear power plant.  This mehod, which we believe is the best among its peers in this area, has since garnered a follow-on NSF grant.\n\nWe have also examined how to create economies of favors among multiple agents to ease negotiation; developed new multiagent algorithms for controlling traffic lights, and to use embedded markers for robot navigation; and have criticized and developed new benchmarks in the field.  \n\nThe work has very significantly extended and improved two free and open-source software packages which we developed and which are widely used.  The ECJ evolutionary computation library is the most commonly used such package in the world, and the MASON multiagent simulation toolkit is a well-regarded high-performance go-to package for large \"swarm\"-style simulation.  Both of these packages are used in multiple other NSF-funded grants in areas ranging from computational biology to the social sciences to robotics and computer science.  Each of the packages is over 80,000 lines of code, and has an over 300 page manual.\n\nThe work has broad impact well beyond computer science.  Multiagent simulations are used widely in biology, the social sciences, arts and animation, the military, disaster relief, security, and public policy.  For example, we personally collaborate with social scientists from other universities and from the Smithsonian Institution to develop and optimize models of economies, farmer and herder conflicts in Africa, fish schools and coral reefs, and methods for improving vehicular traffic flow.\n\nThe work has resulted in a free, downloadable 250-page book called Essentials of Metaheuristics, aimed to teach stochastic and multiagent optimization methods to laymen, basic programmers, and undergraduate students. \n\n\t\t\t\t\tLast Modified: 10/23/2013\n\n\t\t\t\t\tSubmitted by: Sean Luke"
 }
}