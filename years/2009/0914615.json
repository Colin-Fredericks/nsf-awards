{
 "awd_id": "0914615",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: An Affect-Adaptive Spoken Dialogue System that Responds Based on User Model and Multiple Affective States",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 452745.0,
 "awd_amount": 460745.0,
 "awd_min_amd_letter_date": "2009-09-12",
 "awd_max_amd_letter_date": "2011-03-21",
 "awd_abstract_narration": "There has been increasing interest in affective dialogue systems, motivated by the belief that in human-human dialogues, participants seem to be (at least to some degree) detecting and responding to the emotions, attitudes and metacognitive states of other participants. The goal of the proposed research is to improve the state of the art in affective spoken dialogue systems along three dimensions, by drawing on the results of prior research in the wider spoken dialogue and affective system communities. First, prior research has\r\nshown that not all users interact with a system in the same way; the proposed research hypothesizes that employing different affect adaptations for users with different domain aptitude levels will yield further performance improvement in affective spoken dialogue systems. Second, prior research has shown that users display a range of affective states and attitudes while interacting with a system; the proposed research hypothesizes that adapting to multiple user states will yield further performance improvement in affective spoken dialogue systems. Third, while prior research has shown preliminary performance gains for affect adaptation in semi-automated dialogue systems, similar gains have not yet been realized in fully automated systems. The proposed research will use state of the art empirical methods to build fully automated affect detectors. It is hypothesized that both fully and semi-automated versions of a dialogue systemthat either adapts to affect differently depending on user class, or that adapts to multiple user affective states, can improve performance compared to non-adaptive counterparts, with semi-automation generating the most improvement. The three hypotheses will be investigated in the context of an existing spoken dialogue tutoring system that adapts to the user state of uncertainty. The task domain is conceptual physics typically covered in a first-year physics course (e.g., Newtons Laws, gravity, etc.). To investigate the first hypothesis, a first enhanced system version will be developed; it will use the existing uncertainty adaptation for lower aptitude users with respect to domain knowledge, and a new uncertainty adaptation will be developed and implemented to be employed for higher aptitude users. To investigate the second hypothesis, a second enhanced systemversion will be developed; it will use the existing uncertainty adaptation for all turns displaying uncertainty, and a new disengagement adaptation will be developed and implemented to be employed for all student turns displaying a second state of disengagement. A controlled experiment with the two enhanced systems will then be conducted in a Wizard-of-Oz (WOZ) setup, with a human Wizard detecting affect and performing speech recognition and language understanding. To investigate the third hypothesis, a second controlled experiment will be conducted, which replaces the WOZ system versions with fully-automated systems.\r\n\r\nThe major intellectual contribution of this research will be to demonstrate whether significant performance gains can be achieved in both partially and fully-automated affective spoken dialogue tutoring systems 1) by adapting to user uncertainty based on user aptitude levels, and 2) by adapting to multiple user states hypothesized to be of primary importance within the tutoring domain, namely uncertainty and disengagement. The research project will thus advance the state of the art in both spoken dialogue and computer tutoring technologies, while at the same time demonstrating any differing effects of affect-adaptive systems under ideal versus realistic conditions. More broadly, the research and resulting technology will lead to more natural and effective spoken dialogue-based systems, both for tutoring as well as for more traditional information-seeking domains. In addition, improving the performance of computer tutors will expand their usefulness and thus have substantial benefits for education and society.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Diane",
   "pi_last_name": "Litman",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Diane J Litman",
   "pi_email_addr": "litman@cs.pitt.edu",
   "nsf_id": "000233759",
   "pi_start_date": "2009-09-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Katherine",
   "pi_last_name": "Forbes-Riley",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Katherine M Forbes-Riley",
   "pi_email_addr": "forbesk@pitt.edu",
   "nsf_id": "000205913",
   "pi_start_date": "2009-09-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pittsburgh",
  "inst_street_address": "4200 FIFTH AVENUE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4126247400",
  "inst_zip_code": "152600001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "UNIVERSITY OF PITTSBURGH - OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "MKAGLD59JRL1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pittsburgh",
  "perf_str_addr": "4200 FIFTH AVENUE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152600001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 452745.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project was designed to improve the state of the art in  affective spoken dialogue systems, motivated by the belief that in human-human dialogues, speakers detect and respond to the  emotions and attitudes of other speakers. First, prior research has  shown that not all users interact with a system in the same way.&nbsp; We thus hypothesized that employing different affect  adaptations for users with different domain aptitude levels would&nbsp; improve system performance. Second, prior research has shown that users display a range of affective  states and attitudes while interacting with a system.&nbsp; We thus hypothesized that adapting to multiple user states would&nbsp; yield  performance improvements compared to adapting to only one user state or not adapting at all.&nbsp;&nbsp; Third, while prior research has shown preliminary performance gains for  affect adaptation in semi-automated dialogue systems, similar gains have  not yet been realized in fully automated systems.&nbsp; We hypothesized that&nbsp; fully and semi-automated  affect-adaptive dialogue systems could be developed using empirical methods, and that such systems&nbsp; would improve performance compared to non-adaptive counterparts,  with semi-automation generating the most improvement.</p>\n<p>The three  hypotheses were investigated in the context of an existing spoken  dialogue tutoring system that adapted to the user state of uncertainty.  The task domain was conceptual physics, which is typically covered in a first-year  physics course (e.g., Newtons Laws, gravity, etc.). To investigate the  first hypothesis, a new system was developed that used the existing uncertainty adaptation for lower aptitude users&nbsp; and a new uncertainty adaptation for higher aptitude users.  To investigate the second hypothesis, another new system was developed that not only responded to uncertainty, but also responded to disengagement. To investigate the third hypothesis, controlled experiments with all enhanced systems were conducted in both semi and fully-automated conditions.</p>\n<p>The major intellectual outcome of the research was a demonstration that significant performance gains could be achieved by adapting to multiple user states hypothesized to be of  primary importance within the tutoring domain, namely uncertainty and  disengagement. The investigations regarding user modeling, in contrast, yielded null results. The research project not only advanced the state of the  art in both spoken dialogue and computer tutoring technologies, but at  the same time demonstrated the degradation of results in affect-adaptive  systems under ideal versus realistic conditions.</p>\n<p>More broadly, the  research and resulting technology will lead to more natural and  effective spoken dialogue-based systems, both for tutoring as well as  for more traditional information-seeking domains. In addition, improving  the performance of computer tutors will expand their usefulness and  thus have substantial benefits for education and society.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/27/2013<br>\n\t\t\t\t\tModified by: Diane&nbsp;J&nbsp;Litman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project was designed to improve the state of the art in  affective spoken dialogue systems, motivated by the belief that in human-human dialogues, speakers detect and respond to the  emotions and attitudes of other speakers. First, prior research has  shown that not all users interact with a system in the same way.  We thus hypothesized that employing different affect  adaptations for users with different domain aptitude levels would  improve system performance. Second, prior research has shown that users display a range of affective  states and attitudes while interacting with a system.  We thus hypothesized that adapting to multiple user states would  yield  performance improvements compared to adapting to only one user state or not adapting at all.   Third, while prior research has shown preliminary performance gains for  affect adaptation in semi-automated dialogue systems, similar gains have  not yet been realized in fully automated systems.  We hypothesized that  fully and semi-automated  affect-adaptive dialogue systems could be developed using empirical methods, and that such systems  would improve performance compared to non-adaptive counterparts,  with semi-automation generating the most improvement.\n\nThe three  hypotheses were investigated in the context of an existing spoken  dialogue tutoring system that adapted to the user state of uncertainty.  The task domain was conceptual physics, which is typically covered in a first-year  physics course (e.g., Newtons Laws, gravity, etc.). To investigate the  first hypothesis, a new system was developed that used the existing uncertainty adaptation for lower aptitude users  and a new uncertainty adaptation for higher aptitude users.  To investigate the second hypothesis, another new system was developed that not only responded to uncertainty, but also responded to disengagement. To investigate the third hypothesis, controlled experiments with all enhanced systems were conducted in both semi and fully-automated conditions.\n\nThe major intellectual outcome of the research was a demonstration that significant performance gains could be achieved by adapting to multiple user states hypothesized to be of  primary importance within the tutoring domain, namely uncertainty and  disengagement. The investigations regarding user modeling, in contrast, yielded null results. The research project not only advanced the state of the  art in both spoken dialogue and computer tutoring technologies, but at  the same time demonstrated the degradation of results in affect-adaptive  systems under ideal versus realistic conditions.\n\nMore broadly, the  research and resulting technology will lead to more natural and  effective spoken dialogue-based systems, both for tutoring as well as  for more traditional information-seeking domains. In addition, improving  the performance of computer tutors will expand their usefulness and  thus have substantial benefits for education and society.\n\n\t\t\t\t\tLast Modified: 11/27/2013\n\n\t\t\t\t\tSubmitted by: Diane J Litman"
 }
}