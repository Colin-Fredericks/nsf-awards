{
 "awd_id": "0901491",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Implicit Learning-Based Optimal Control of Uncertain Nonlinear Systems",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Paul Werbos",
 "awd_eff_date": "2009-08-15",
 "awd_exp_date": "2013-07-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 306000.0,
 "awd_min_amd_letter_date": "2009-08-10",
 "awd_max_amd_letter_date": "2010-04-29",
 "awd_abstract_narration": "A Summary\r\nProject Summary: This project focuses on the synthesis of new implicit learning-based methods that\r\ncan optimally achieve some control objective for an uncertain nonlinear system. The main research goals\r\ninclude the development and experimental verification of implicit learning and adaptive methods that enable\r\nthe mismatch between the desired and actual response of an uncertain nonlinear system to converge\r\nwhile optimizing a trade-off between performance and control energy. Efforts will investigate if different\r\nlearning and adaptive methods have properties that yield more optimal solutions or lead to improved stability\r\nmargins. Progress on this research topic has been stymied by the challenge of solving a Hamilton-Jacobi\r\nequation, and the lack of mathematical tools to asymptotically compensate for generic disturbances with a\r\ncontinuous controller. With the emergence of new implicit learning methods and general Lyapunov analysis\r\ntechniques, the community is now well positioned to focus increasing attention on simultaneously achieving\r\noptimality and stability for uncertain nonlinear systems. The learning capacity of the developed controllers\r\nwill enable analytical optimal control solutions for a broader class of engineering systems than is currently\r\npossible. Optimizing the performance of a control system along with the required control effort will yield\r\nimproved efficiency that can lead to timely economic and environmental cost savings.\r\nIntellectual Merit: Few mathematical tools exist to synthesize controllers for nonlinear systems with model\r\nuncertainty and unmodeled disturbances. Of the few tools that exist, either the developed controller requires\r\ndiscontinuous feedback or exhibits degraded steady-state performance in the sense of residual errors.\r\nRecent developments have produced a new class of continuous controllers that can implicitly learn such\r\ndisturbances through a nonlinear differential equation. This advancement opens new possibilities to refocus\r\nthe nonlinear systems community on the dual stability and optimality problem for general systems. Efforts in\r\nthis project seek to explore how such implicit learning controllers (and potential permutations) can be used\r\nto yield analytical solutions to different optimal control problems. The ability to integrate the proposed class\r\nof implicit learning controllers (and such controllers integrated with other adaptive and learning techniques)\r\nwith optimal control methods is an unexplored concept. New closed-loop error system development, stability\r\nanalysis, and optimal analysis methods will be required to determine the interplay of optimality, learning\r\ncapacity, and robustness. Outcomes from these aims may provide an inroad to new ways to augment\r\ncontrollers to incorporate optimality into the design process.\r\nBroad Impact: The theoretical discoveries are expected to have a transformative impact on optimal control\r\nmethods for uncertain nonlinear systems. One approach to solve current optimal control problems is to\r\nuse numerical methods that only provide local optimal results (at best), typically do not have a proof of\r\nstability or optimality, and are typically open-loop. Also, numerical methods are black box approaches, so\r\nthe designer is shielded from any intuition regarding the effect of the system parameters on the optimality.\r\nThese issues motivate the need for analytical methods. Yet, the challenge to develop analytical solutions\r\nis that they often do not optimize the real engineering problem because of the narrow class of systems\r\nthat can be analytically examined. The expected outcomes of this project are new mathematical tools to\r\ndevelop analytical stability and optimality solutions for broad classes of nonlinear systems. Further broad\r\nimpact will be realized by integrating the research outcomes into educational and outreach efforts. Efforts\r\nwill seek to disseminate the research outcomes to engineers in industry, researchers, and students ranging\r\nfrom grade school through graduate school with an emphasis on under-represented groups. Outcomes of\r\nthe research will be disseminated to these groups through outlets including: peer-reviewed publications,\r\nconference workshops, curriculum development, the development of a new certificate program for industrial\r\ncontrol engineers, undergraduate honor?s thesis research, existing University of Florida programs for highschool\r\nand under-represented students, and a robotics summer camp for grade school children.\r\nA-",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Warren",
   "pi_last_name": "Dixon",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Warren E Dixon",
   "pi_email_addr": "wdixon@ufl.edu",
   "nsf_id": "000250994",
   "pi_start_date": "2009-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1523 UNION RD RM 207",
  "perf_city_name": "GAINESVILLE",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326111941",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760700",
   "pgm_ele_name": "EPCN-Energy-Power-Ctrl-Netwrks"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "093E",
   "pgm_ref_txt": "System fab/packaging & assembly"
  },
  {
   "pgm_ref_code": "096E",
   "pgm_ref_txt": "High freq comm/sensing circuits"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 300000.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 6000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Few mathematical tools exist to synthesize controllers to enable autonomy for nonlinear systems with general unstructured uncertainty. Recent breakthroughs in nonlinear systems theory have produced a new class of autonomous controllers that can implicitly learn and accommodate for such disturbances. This advancement opens new possibilities to refocus the autonomous systems community on the dual stability and optimality problem for general systems. Optimizing the performance of a control system while minimizing a user defined cost function can yield improved efficiency that can lead to timely economic and environmental cost savings. The general outcomes from this project are mathematical methods that exploit different learning strategies that produce controllers which ensure stable and predictable response by an autonomous system in the presence of uncertainty while also enabling the system to perform the tasks with minimal cost, in terms of a user defined criteria (e.g., time, energy, accuracy). One set of results that were obtained used a robust control strategy that converges to the best solution over time. This set of results is based on the idea that the controller learns the uncertain disturbances, and then converges to an optimal solution. A second set of controllers was developed that always provides the best control solution, but the objectives result from the analysis, instead of being defined by the user. Both sets of control solutions were developed for an individual system as well as a collection of systems that may have competing objectives.</p>\n<p>In the final stages of the project, a different learning method was explored that leverages reinforcement learning ideas derived from how mammals are thought to learn (i.e., Pavlov&rsquo;s dog experiments). In this approach, reinforcement learning ideas are used to alter the adaptation through evaluative feedback of the controller similar to how a critic evaluates the performance of an actor (i.e., the autonomous controller in this context). The result from this approach is a controller that adapts over time so that it converges to the optimal control solution.</p>\n<p>These accomplishments resulted in broad impact. Within the control systems community, the developed controller provides a framework that illustrates how different learning and adaptation methods can be applied to yield optimal control strategies. The impact of such strategies is that automated process may be able to achieve improved or equal performance at a lower energy cost. Specifically, improved motor control can yield significant fuel savings, which also result in reduced environmental impact of some industrial processes. The project served as a venue to provide training to graduate and undergraduate students. Specifically, two doctoral dissertations were completed that focused on this topic, and two additional dissertations are in progress. Undergraduates were also included in the research process, resulting in an honor&rsquo;s thesis for a student that wants to apply the developed control methods for improved efficiency in hybrid electric vehicles.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/29/2013<br>\n\t\t\t\t\tModified by: Warren&nbsp;E&nbsp;Dixon</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nFew mathematical tools exist to synthesize controllers to enable autonomy for nonlinear systems with general unstructured uncertainty. Recent breakthroughs in nonlinear systems theory have produced a new class of autonomous controllers that can implicitly learn and accommodate for such disturbances. This advancement opens new possibilities to refocus the autonomous systems community on the dual stability and optimality problem for general systems. Optimizing the performance of a control system while minimizing a user defined cost function can yield improved efficiency that can lead to timely economic and environmental cost savings. The general outcomes from this project are mathematical methods that exploit different learning strategies that produce controllers which ensure stable and predictable response by an autonomous system in the presence of uncertainty while also enabling the system to perform the tasks with minimal cost, in terms of a user defined criteria (e.g., time, energy, accuracy). One set of results that were obtained used a robust control strategy that converges to the best solution over time. This set of results is based on the idea that the controller learns the uncertain disturbances, and then converges to an optimal solution. A second set of controllers was developed that always provides the best control solution, but the objectives result from the analysis, instead of being defined by the user. Both sets of control solutions were developed for an individual system as well as a collection of systems that may have competing objectives.\n\nIn the final stages of the project, a different learning method was explored that leverages reinforcement learning ideas derived from how mammals are thought to learn (i.e., Pavlov\u00c6s dog experiments). In this approach, reinforcement learning ideas are used to alter the adaptation through evaluative feedback of the controller similar to how a critic evaluates the performance of an actor (i.e., the autonomous controller in this context). The result from this approach is a controller that adapts over time so that it converges to the optimal control solution.\n\nThese accomplishments resulted in broad impact. Within the control systems community, the developed controller provides a framework that illustrates how different learning and adaptation methods can be applied to yield optimal control strategies. The impact of such strategies is that automated process may be able to achieve improved or equal performance at a lower energy cost. Specifically, improved motor control can yield significant fuel savings, which also result in reduced environmental impact of some industrial processes. The project served as a venue to provide training to graduate and undergraduate students. Specifically, two doctoral dissertations were completed that focused on this topic, and two additional dissertations are in progress. Undergraduates were also included in the research process, resulting in an honor\u00c6s thesis for a student that wants to apply the developed control methods for improved efficiency in hybrid electric vehicles.\n\n \n\n\t\t\t\t\tLast Modified: 10/29/2013\n\n\t\t\t\t\tSubmitted by: Warren E Dixon"
 }
}