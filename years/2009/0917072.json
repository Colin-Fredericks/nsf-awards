{
 "awd_id": "0917072",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "DC:   Small:   Semantic Analysis of Large Multimedia Data Sets",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 466000.0,
 "awd_min_amd_letter_date": "2009-09-04",
 "awd_max_amd_letter_date": "2011-03-21",
 "awd_abstract_narration": "This research addresses interactivity and scalability in automatically analyzing large collections of video and multiple video streams processed continuously. This work is developing mechanisms to enable real-time interactive video search for user defined concepts using intelligent, active processing clusters and methods for performing high-accuracy semantic video analysis from large amounts of weakly-labeled video over distributed computing resources. The methods leverage modern cluster file systems where data is stored on the local disks of the compute servers, and the location of data is made available to the runtime system to allow co-location of compution and storage.\r\n\r\nThe specific research objectives are to allow co-location of compute and storage through a runtime for parallel stream processing that parallelizes data processing and machine learning tasks across a cluster of multi-core compute nodes. The project also extends distributed versions of graphic model algorithms to speed computation of both the basic low-level signal processing steps and for the semantic analysis based on weakly labeled video data as currently available on the web. The main outcome is to demonstrate vastly accelerated, complete processing of parallel live video streams into a retrieval database with immediate search capabilities and accessing cluster resources during interactive search. The goal of this work is to develop principles for interactive applications driven by real-time processing of high-rate streaming data. The processing architecture and modules developed in this work will enable computer vision and multimedia developers to efficiently apply and test their own methods within this framework. \r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alexander",
   "pi_last_name": "Hauptmann",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Alexander G Hauptmann",
   "pi_email_addr": "alex@cs.cmu.edu",
   "nsf_id": "000228336",
   "pi_start_date": "2009-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 FORBES AVE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  },
  {
   "pgm_ele_code": "779300",
   "pgm_ele_name": "DATA-INTENSIVE COMPUTING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7793",
   "pgm_ref_txt": "DATA-INTENSIVE COMPUTING"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 450000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research addressed interactivity and scalability in automatically analyzing large collections of video and multiple video streams processed continuously. This work developed mechanisms to enable real-time interactive video search for user defined concepts using active processing clusters and methods for performing high-accuracy semantic video analysis from large amounts of weakly-labeled video over distributed computing resources. The methods leverage modern cluster file systems where data is stored on local disks of the compute servers, and the location of data is made available to the runtime system to allow co-location of compute and storage.</p>\n<p>One specific research objective was to allow co-location of compute and storage through a runtime for parallel stream processing that parallelizes data processing and machine learning tasks across a cluster of multi-core compute nodes. Another achievement was to extend distributed versions of common analytic algorithms to speed computation of both the basic low-level signal processing steps and for the semantic analysis based on weakly labeled video data as currently available on the web. A main outcome has been to demonstrate vastly accelerated, complete processing of parallel live video streams into a retrieval database with immediate search capabilities and accessing cluster resources during interactive search for healthcare observations. The main impact of this work has been to develop principles for applications driven by real-time processing needs of high-rate streaming data. The processing architecture and modules developed in this work enable computer vision and multimedia developers to efficiently apply and test their own methods within this framework.</p>\n<p>In addition to a number of peer-reviewed publications in major journals and conferences, the project participant were involved in organizing four workshops around key themes of the research, namely, the 1st workshop on multimedia corpus in 2009, the workshop on analysis and evaluation of large-scale multimedia collections, the worshop on the future of multimedia analysis and mining in 2010 and the workshop on the future of mutlimedia analysis in 2012 and mining and the workshop on Multimedia Information Indexing and Retrieval for Healthcare in 2013.<a href=\"http://wsmc09.eurecom.fr/\"><br /></a></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/07/2014<br>\n\t\t\t\t\tModified by: Alexander&nbsp;G&nbsp;Hauptmann</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis research addressed interactivity and scalability in automatically analyzing large collections of video and multiple video streams processed continuously. This work developed mechanisms to enable real-time interactive video search for user defined concepts using active processing clusters and methods for performing high-accuracy semantic video analysis from large amounts of weakly-labeled video over distributed computing resources. The methods leverage modern cluster file systems where data is stored on local disks of the compute servers, and the location of data is made available to the runtime system to allow co-location of compute and storage.\n\nOne specific research objective was to allow co-location of compute and storage through a runtime for parallel stream processing that parallelizes data processing and machine learning tasks across a cluster of multi-core compute nodes. Another achievement was to extend distributed versions of common analytic algorithms to speed computation of both the basic low-level signal processing steps and for the semantic analysis based on weakly labeled video data as currently available on the web. A main outcome has been to demonstrate vastly accelerated, complete processing of parallel live video streams into a retrieval database with immediate search capabilities and accessing cluster resources during interactive search for healthcare observations. The main impact of this work has been to develop principles for applications driven by real-time processing needs of high-rate streaming data. The processing architecture and modules developed in this work enable computer vision and multimedia developers to efficiently apply and test their own methods within this framework.\n\nIn addition to a number of peer-reviewed publications in major journals and conferences, the project participant were involved in organizing four workshops around key themes of the research, namely, the 1st workshop on multimedia corpus in 2009, the workshop on analysis and evaluation of large-scale multimedia collections, the worshop on the future of multimedia analysis and mining in 2010 and the workshop on the future of mutlimedia analysis in 2012 and mining and the workshop on Multimedia Information Indexing and Retrieval for Healthcare in 2013.\n\n\n\t\t\t\t\tLast Modified: 03/07/2014\n\n\t\t\t\t\tSubmitted by: Alexander G Hauptmann"
 }
}