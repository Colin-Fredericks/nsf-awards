{
 "awd_id": "0915560",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "HCC: Small: Modular Tactile Feedback for Whole-Body Motion Guidance",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2009-07-01",
 "awd_exp_date": "2014-06-30",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 532000.0,
 "awd_min_amd_letter_date": "2009-07-13",
 "awd_max_amd_letter_date": "2012-11-16",
 "awd_abstract_narration": "Computers have progressed from their origins as isolated rooms of electronic components to being distributed, highly connected, mobile personal devices that are increasingly intertwined with everyday human experience.  But computers haven't yet permeated the domain that is most intuitive and essential for their users, namely that of three-dimensional space and naturalistic human movement.  In this research the PI will test the hypothesis that graded whole-body tactile feedback can help humans learn or relearn important body postures and motions.  To this end, she will augment commercial human motion tracking with a suit of modular tactile actuators (tactors) that provide spatially-registered naturalistic real-time feedback on the way in which each limb segment should be moved, emulating the light touch of a physical therapist, teacher, or coach.  Through collaboration with a clinical researcher the PI will focus in this project on rehabilitation for apraxic stroke patients.  Our current understanding of stroke indicates that these patients cannot accurately estimate the pose of their limbs when performing purposeful movements, so the PI will augment their motion practice with continuous tactile guidance about the 3D location and magnitude of any configuration errors.  Determining the efficacy of this approach will advance our knowledge of healthy vs. impaired human motor control, and will also improve our understanding of the way in which humans process certain types of tactile signals.  Development of the novel modular tactor system will provide insights on the effectiveness of voice-coil tactors and the range of sensations they can create.  In the course of testing the project's primary hypothesis, the PI will employ human-subject experiments to determine which system design methods best succeed at helping stroke patients recover.  The project will be organized into low- and high-level thrusts, each of which will be spearheaded by a doctoral student.  The PI's prior work on haptic contact feedback will help her successfully lead this project, as will the support and resources of relevant experts at the University of Pennsylvania, at nearby Moss Rehabilitation Research Institute, and at Engineering Acoustics, Inc., a leading tactor company.\r\n\r\nBroader Impacts:  This project will have immediate relevance to stroke rehabilitation, with excellent potential for positive impact on society in the longer term through application to a variety of exciting topics in human-centered computing, especially computer-mediated scenarios in human motion guidance, such as athletic motion training and haptic virtual environments.  The PI will strive to conduct this research so as to enhance its appeal to students from groups that are typically underrepresented in computer science and engineering, especially women.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Katherine",
   "pi_last_name": "Kuchenbecker",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Katherine J Kuchenbecker",
   "pi_email_addr": "kuchenbe@seas.upenn.edu",
   "nsf_id": "000465871",
   "pi_start_date": "2009-07-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "3451 WALNUT ST STE 440A",
  "perf_city_name": "PHILADELPHIA",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 163630.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 352370.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research project investigated a new approach for helping people learn how to move their body in specific ways, such as for sports training or stroke rehabilitation. People typically learn such movements by practicing them over and over with the guidance of a coach or a therapist. We were interested in discovering whether computer technology could make this learning process more efficient, to augment the guidance a human can provide.</p>\n<p>We developed a series of systems that use tactile cues to try to guide a person's movements to follow a desired trajectory over time. We focused on motions of the arm, but the technology could also work for other body parts. Each system uses <strong>sensors</strong> to measure the person's movement and a <strong>computer program</strong> to calculate how far away they are from the desired motion. If the user is not close to the desired motion, the system uses one or more&nbsp;<strong>tactile actuators</strong>&nbsp;that the person is wearing to tell the person which way to move to correct their motion. Because they are inexpensive and widely available, most of the tactile actuators that we studied were eccentric rotating-mass motors that generate vibrations; cell phones use this same type of motor to deliver silent buzzing alerts. We focused on technology that is inexpensive and widely available so that our approach could be easily adopted by other researchers and therapists if it was successful.</p>\n<p>The <strong>main tactile motion guidance system</strong> that we created is shown in the first attached image. This is the third version of this system that we created during this project. It uses a Microsoft Kinect 360 to track the user's body movements, particularly the motion of one of the arms. A computer screen shows the movement that the user is making as well as a wireframe arm that is making a pre-recorded movement that the user is supposed to follow. When the user's upper-arm and/or lower-arm are outside the wireframe, the computer activates the vibrotactile actuator that is closest to the part of the arm that is outside the wireframe. The vibrotactile actuators are inside the two black fabric bands worn by the user. The vibrations tell the user to move away from that location, so that the arm goes back toward the desired trajectory. We had twenty-six healthy adults test this system both with and without the tactile feedback. We found that the tactile feedback helped subjects perform simple movements, such as flexing and extending the elbow, but it didn't help with more complicated movements, like throwing a ball.</p>\n<p>At the end of the project, we created a <strong>new and improved version of our full-arm motion guidance system</strong>. It was designed to address some of the shortcomings that we noticed when we tested the system described above. The new version consists of a set of wearable electronic modules that are about 3 cm by 3 cm by 1 cm. Some of the modules are in charge of tracking the motion of the user's arm, using inertial sensors, and the rest are in charge of delivering vibrotactile cues right on the skin of the user's arm. We have not yet tested the new version of this system with human subjects; when we do, we hope to discover whether the technical improvements help the user learn movements more quickly and accurately.</p>\n<p>The other system that we created was a<strong> tactile guidance system for wrist rotation</strong>. We focused on wrist rotation because we found this joint was particularly hard to track and guide using our other approaches. This system focused on exploring alternative tactile actuators. In addition to vibrations, we created wearable tactile actuators that tap on, drag across, squeeze, and twist the wrist of the user, as shown in the second attached image. These devices were made using low-cost servo motors and 3D-printed plastic parts. &nbsp;Ten human subjects tested the fi...",
  "por_txt_cntn": "\nThis research project investigated a new approach for helping people learn how to move their body in specific ways, such as for sports training or stroke rehabilitation. People typically learn such movements by practicing them over and over with the guidance of a coach or a therapist. We were interested in discovering whether computer technology could make this learning process more efficient, to augment the guidance a human can provide.\n\nWe developed a series of systems that use tactile cues to try to guide a person's movements to follow a desired trajectory over time. We focused on motions of the arm, but the technology could also work for other body parts. Each system uses sensors to measure the person's movement and a computer program to calculate how far away they are from the desired motion. If the user is not close to the desired motion, the system uses one or more tactile actuators that the person is wearing to tell the person which way to move to correct their motion. Because they are inexpensive and widely available, most of the tactile actuators that we studied were eccentric rotating-mass motors that generate vibrations; cell phones use this same type of motor to deliver silent buzzing alerts. We focused on technology that is inexpensive and widely available so that our approach could be easily adopted by other researchers and therapists if it was successful.\n\nThe main tactile motion guidance system that we created is shown in the first attached image. This is the third version of this system that we created during this project. It uses a Microsoft Kinect 360 to track the user's body movements, particularly the motion of one of the arms. A computer screen shows the movement that the user is making as well as a wireframe arm that is making a pre-recorded movement that the user is supposed to follow. When the user's upper-arm and/or lower-arm are outside the wireframe, the computer activates the vibrotactile actuator that is closest to the part of the arm that is outside the wireframe. The vibrotactile actuators are inside the two black fabric bands worn by the user. The vibrations tell the user to move away from that location, so that the arm goes back toward the desired trajectory. We had twenty-six healthy adults test this system both with and without the tactile feedback. We found that the tactile feedback helped subjects perform simple movements, such as flexing and extending the elbow, but it didn't help with more complicated movements, like throwing a ball.\n\nAt the end of the project, we created a new and improved version of our full-arm motion guidance system. It was designed to address some of the shortcomings that we noticed when we tested the system described above. The new version consists of a set of wearable electronic modules that are about 3 cm by 3 cm by 1 cm. Some of the modules are in charge of tracking the motion of the user's arm, using inertial sensors, and the rest are in charge of delivering vibrotactile cues right on the skin of the user's arm. We have not yet tested the new version of this system with human subjects; when we do, we hope to discover whether the technical improvements help the user learn movements more quickly and accurately.\n\nThe other system that we created was a tactile guidance system for wrist rotation. We focused on wrist rotation because we found this joint was particularly hard to track and guide using our other approaches. This system focused on exploring alternative tactile actuators. In addition to vibrations, we created wearable tactile actuators that tap on, drag across, squeeze, and twist the wrist of the user, as shown in the second attached image. These devices were made using low-cost servo motors and 3D-printed plastic parts.  Ten human subjects tested the five devices, each with two algorithms. The best overall performance was by the actuator that repeatedly taps on the side of the user's wrist to show them which way to move.\n\nThe intellectual merit of this..."
 }
}