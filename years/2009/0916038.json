{
 "awd_id": "0916038",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Semi-Supervised Learning for Non-Experts",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 414417.0,
 "awd_amount": 426417.0,
 "awd_min_amd_letter_date": "2009-08-21",
 "awd_max_amd_letter_date": "2010-05-18",
 "awd_abstract_narration": "This project develops semi-supervised machine learning algorithms that are practical, and at the same time guided by rigorous theory. In particular, the project is developing learning theory that quantifies when and to what extent the combination of labeled and unlabeled data is provably beneficial. Based on the theory, novel algorithms are being developed to address issues that currently hinder the wide adoption of semi-supervised learning. The new algorithms will be able to guarantee that using unlabeled data is at least no worse, and often better, than supervised learning. The new algorithms will also be able to learn from unlimited amounts of supervised and unsupervised data as they arrive in real-time, something humans can do but computers cannot so far.  \r\n\r\nThis project has a number of broader impacts: (1) An open-source software will be an enabling tool for new discoveries in science and technology, by making machine learning possible or better in situations where labeled data is scarce. Since the software specifically targets non-machine-learning-experts, the impact is expected to be across the whole spectrum of science and technology that utilizes machine learning. (2) It advances our understanding of the learning process via new machine learning theory, which can be applied to both computers and humans. (3) The proposal contains projects ideally suited to engage students in computer science education and research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiaojin",
   "pi_last_name": "Zhu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaojin Zhu",
   "pi_email_addr": "jerryzhu@cs.wisc.edu",
   "nsf_id": "000211108",
   "pi_start_date": "2009-08-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "21 N PARK ST STE 6301",
  "perf_city_name": "MADISON",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537151218",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 414417.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 12000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>One key task in machine learning is to make automatic decisions: Is this email spam?&nbsp; What is in that photo?&nbsp; Is this patient healthy?&nbsp; Traditionally, computers need to be trained on a large amount of labeled data to make such decisions.&nbsp; Labeling data means someone, usually a domain expert, has to evaluate the email, annotate the photo, or perform medical diagnosis on the patient.&nbsp; Often, such labeling process is slow or expensive, limiting the amount of labeled training data available to the computers and hindering the performance of machine learning.&nbsp; On the other hand, unlabeled data are usually abundant.&nbsp; This projects studied semi-supervised learning, a machine learning method which combines labeled and unlabeled data to improve automatic decisions.<br /><br />In the course of the project we have advanced our fundamental understanding of semi-supervised learning.&nbsp; Our research highlighted the dependency of semi-supervised learning on its underlying assumption on data distribution.&nbsp; We studied theory that quantified when and to what extent the combination of labeled and unlabeled data is beneficial.&nbsp; We proposed semi-supervised learning algorithms that handled big data: The algorithms learn from unlimited amount of supervised and unsupervised data as they stream in.&nbsp; We also created semi-supervised algorithms that can explore complex structures within data, widening the applicability of learning.&nbsp; Overall, we enhanced machine learning's ability to make better automatic decisions.<br /><br />This project also had broader impact beyond machine learning and computer science.&nbsp; For instance, we showed that semi-supervised learning is a valid mathematical model to quantify human learning.&nbsp; As an example, children learn from labeled data (daddy points at a dog and says \"Dog!\"), as well as from unlabeled data (seeing various animals over time, without being told the names).&nbsp; Both kinds of experiences combine to shape concept learning (e.g., dog).&nbsp; Our semi-supervised learning algorithms served as cognitive models that quantitatively fit human behaviors under such settings.&nbsp; Our models also predicted novel human behaviors.&nbsp; For example, we predicted that making decisions on unlabeled items can change human's decision boundary.&nbsp; This has since been validated by human behavioral experiments.&nbsp; In summary, this project advanced the frontier on semi-supervised learning in both computer science and cognitive science, and enriched our understanding of the learning process in both computers and humans.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/11/2014<br>\n\t\t\t\t\tModified by: Xiaojin&nbsp;Zhu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOne key task in machine learning is to make automatic decisions: Is this email spam?  What is in that photo?  Is this patient healthy?  Traditionally, computers need to be trained on a large amount of labeled data to make such decisions.  Labeling data means someone, usually a domain expert, has to evaluate the email, annotate the photo, or perform medical diagnosis on the patient.  Often, such labeling process is slow or expensive, limiting the amount of labeled training data available to the computers and hindering the performance of machine learning.  On the other hand, unlabeled data are usually abundant.  This projects studied semi-supervised learning, a machine learning method which combines labeled and unlabeled data to improve automatic decisions.\n\nIn the course of the project we have advanced our fundamental understanding of semi-supervised learning.  Our research highlighted the dependency of semi-supervised learning on its underlying assumption on data distribution.  We studied theory that quantified when and to what extent the combination of labeled and unlabeled data is beneficial.  We proposed semi-supervised learning algorithms that handled big data: The algorithms learn from unlimited amount of supervised and unsupervised data as they stream in.  We also created semi-supervised algorithms that can explore complex structures within data, widening the applicability of learning.  Overall, we enhanced machine learning's ability to make better automatic decisions.\n\nThis project also had broader impact beyond machine learning and computer science.  For instance, we showed that semi-supervised learning is a valid mathematical model to quantify human learning.  As an example, children learn from labeled data (daddy points at a dog and says \"Dog!\"), as well as from unlabeled data (seeing various animals over time, without being told the names).  Both kinds of experiences combine to shape concept learning (e.g., dog).  Our semi-supervised learning algorithms served as cognitive models that quantitatively fit human behaviors under such settings.  Our models also predicted novel human behaviors.  For example, we predicted that making decisions on unlabeled items can change human's decision boundary.  This has since been validated by human behavioral experiments.  In summary, this project advanced the frontier on semi-supervised learning in both computer science and cognitive science, and enriched our understanding of the learning process in both computers and humans.\n\n\t\t\t\t\tLast Modified: 12/11/2014\n\n\t\t\t\t\tSubmitted by: Xiaojin Zhu"
 }
}