{
 "awd_id": "0909630",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "REESE Empirical Research on Emerging Topics in STEM Education: Statistical Methods for Assessing Teaching and Program Effectiveness",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032928333",
 "po_email": "gesolomo@nsf.gov",
 "po_sign_block_name": "Gregg Solomon",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2012-08-31",
 "tot_intn_awd_amt": 308916.0,
 "awd_amount": 308916.0,
 "awd_min_amd_letter_date": "2009-08-20",
 "awd_max_amd_letter_date": "2011-06-12",
 "awd_abstract_narration": "This basic research project will develop new statistical techniques that will provide more robust estimates of the Value-Added Models (VAM). Multivariate response value-added models will be developed to include continuous and categorical responses and nested data structures, and address missing data problems. These models will employ latent-class mixture models, and will use classification trees and random forest methods for data analyses. The new techniques will allow the models to be used not only with continuous response data, such as test scores, but also categorical response data such as completion of a STEM degree. The techniques will also allow researchers to investigate the effects of missing data on value added models, as can occur when students drop out of STEM degree programs during college. The models will improve upon the current VAM models in three aspects: 1) incorporating the various missing data structures, 2) considering both continuous and categorical outcomes, and 3) taking into account complex relationships among subgroups of students and program characteristics.  \r\n\r\nThe potential benefits of developing such value added statistical models will be for informing educational policy and practice. These benefits will include better decisions based on more precise estimates of teacher effects and the effects of other inputs on student outcomes in STEM. The researchers propose to address limitations of current value-added models to provide stronger models for assessing STEM program effectiveness and measure teacher or school effects on student achievement. \r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sharon",
   "pi_last_name": "Lohr",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sharon Lohr",
   "pi_email_addr": "sharon.lohr@asu.edu",
   "nsf_id": "000314177",
   "pi_start_date": "2009-08-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yan",
   "pi_last_name": "Yang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yan Yang",
   "pi_email_addr": "yy@math.asu.edu",
   "nsf_id": "000517617",
   "pi_start_date": "2009-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "660 S MILL AVENUE STE 204",
  "perf_city_name": "TEMPE",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852813670",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "762500",
   "pgm_ele_name": "REAL"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9177",
   "pgm_ref_txt": "ELEMENTARY/SECONDARY EDUCATION"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0409",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04000910DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0410",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001011DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0411",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001112DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 100791.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 99854.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 108271.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;</p>\n<p>Value-added models are commonly promoted as statistical methods for assessing the contributions made by individual teachers to a student&rsquo;s knowledge. These models attempt, through analyzing student growth on assessment instruments after they have been instructed by different&nbsp; teachers, to assess the degree to which each teacher or school &ldquo;adds&rdquo; to a student&rsquo;s knowledge. The NSF-funded project \"Statistical Methods for Assessing Teaching and Program Effectiveness\" developed new statistical methods for value-added assessment and investigated properties and limitations of the models currently in use.</p>\n<p>One frequently mentioned shortcoming of value-added models is that they focus on test scores, which may be an imperfect measurement of student learning. We developed multiresponse value-added models that assess teachers&rsquo; contributions toward long-term real-world student outcomes such as graduation or employment in a STEM field. While in general teacher effects on successive test scores of students are positively correlated, our data set exhibited a negative correlation between the teacher effect on calculus grade and the teacher effect on whether the student graduated with a science or engineering degree, indicating that the grades were providing incomplete information on possible teacher effects on students.</p>\n<p>Some students consistently obtain a nearly perfect score on standardized tests. These students therefore are limited in the amount of improvement they can show on future tests. This is called a ceiling effect, and it can affect the value-added scores of teachers who instruct classes of high-scoring students. We proposed new value-added models that account for the ceiling effect, and showed that these models could result in less biased assessments of teachers who instruct gifted students.</p>\n<p>Many of the models used for value-added assessment assume that every student has data for every time period studied. In practice, that assumption is rarely met. If the data are missing due to reasons that are unrelated to student or teacher performance, then fitting a standard model with the available observations is a reasonable procedure. But if data are missing because, say, low-performing students are encouraged to skip the exam, then ignoring the missing data can result in biased assessments. We developed new correlated-parameter models to investigate the sensitivity of value-added scores to missing data, and showed that in some data sets, different models for the missing data would result in substantial differences in the ranks of the teachers.</p>\n<p>Longitudinal student achievement outcomes typically have a complex dependence structure. Oftentimes students are not nested within classrooms, because they take classes with different teachers when progressing through school. This non-hierarchical data structure, further complicated by the presence of informative missing data and test-score ceiling effect, imposes great computational challenges on estimation of the current and newly developed value-added models. We developed efficient and stable computational methods for modeling such data with or without missing values, and implemented the methods in the R statistical computing language. The GPvam package (CRAN.r-project.org/package=GPvam)&nbsp;is publicly available software for computing&nbsp;maximum likelihood estimates&nbsp;for several widely used value-added models.</p>\n<p>Many researchers and commentators have expressed concerns that, when value-added models are used for high-stakes decisions such as merit pay or tenure, they may be manipulated and the tests may lose their original value as instruments of assessment. We investigated the sensitivity of seven value-added models to manipulation, and found that it would be very easy for a teacher to inflate his or her value-added score by using information not ...",
  "por_txt_cntn": "\n \n\nValue-added models are commonly promoted as statistical methods for assessing the contributions made by individual teachers to a student\u00c6s knowledge. These models attempt, through analyzing student growth on assessment instruments after they have been instructed by different  teachers, to assess the degree to which each teacher or school \"adds\" to a student\u00c6s knowledge. The NSF-funded project \"Statistical Methods for Assessing Teaching and Program Effectiveness\" developed new statistical methods for value-added assessment and investigated properties and limitations of the models currently in use.\n\nOne frequently mentioned shortcoming of value-added models is that they focus on test scores, which may be an imperfect measurement of student learning. We developed multiresponse value-added models that assess teachers\u00c6 contributions toward long-term real-world student outcomes such as graduation or employment in a STEM field. While in general teacher effects on successive test scores of students are positively correlated, our data set exhibited a negative correlation between the teacher effect on calculus grade and the teacher effect on whether the student graduated with a science or engineering degree, indicating that the grades were providing incomplete information on possible teacher effects on students.\n\nSome students consistently obtain a nearly perfect score on standardized tests. These students therefore are limited in the amount of improvement they can show on future tests. This is called a ceiling effect, and it can affect the value-added scores of teachers who instruct classes of high-scoring students. We proposed new value-added models that account for the ceiling effect, and showed that these models could result in less biased assessments of teachers who instruct gifted students.\n\nMany of the models used for value-added assessment assume that every student has data for every time period studied. In practice, that assumption is rarely met. If the data are missing due to reasons that are unrelated to student or teacher performance, then fitting a standard model with the available observations is a reasonable procedure. But if data are missing because, say, low-performing students are encouraged to skip the exam, then ignoring the missing data can result in biased assessments. We developed new correlated-parameter models to investigate the sensitivity of value-added scores to missing data, and showed that in some data sets, different models for the missing data would result in substantial differences in the ranks of the teachers.\n\nLongitudinal student achievement outcomes typically have a complex dependence structure. Oftentimes students are not nested within classrooms, because they take classes with different teachers when progressing through school. This non-hierarchical data structure, further complicated by the presence of informative missing data and test-score ceiling effect, imposes great computational challenges on estimation of the current and newly developed value-added models. We developed efficient and stable computational methods for modeling such data with or without missing values, and implemented the methods in the R statistical computing language. The GPvam package (CRAN.r-project.org/package=GPvam) is publicly available software for computing maximum likelihood estimates for several widely used value-added models.\n\nMany researchers and commentators have expressed concerns that, when value-added models are used for high-stakes decisions such as merit pay or tenure, they may be manipulated and the tests may lose their original value as instruments of assessment. We investigated the sensitivity of seven value-added models to manipulation, and found that it would be very easy for a teacher to inflate his or her value-added score by using information not included in the model, without resorting to fraud or cheating. These results are consistent with the teachings of the statistician and quality improvemen..."
 }
}