{
 "awd_id": "0916829",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Modeling and Recognition of Landmarks and Urban Environments",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 449179.0,
 "awd_amount": 776979.0,
 "awd_min_amd_letter_date": "2009-09-12",
 "awd_max_amd_letter_date": "2012-08-25",
 "awd_abstract_narration": "The goal of this project is to design a scalable and robust system for modeling and representing the spatiotemporal and semantic structure of large collections of partially geo-referenced imagery. Specifically, the project is aimed at Internet photo collections of images of famous landmarks and cities. The functionalities of the system include 3D reconstruction, browsing, summarization, location recognition, and scene segmentation. In addition, the system incorporates human-created annotations such as text and geo-tags, models scene illumination conditions, and supports incremental model updating using an incoming stream of images. This system is designed to take advantage of the redundancy inherent in community photo collections to achieve levels of robustness and scalability not attainable by existing geometric modeling approaches. The key technical innovation of the project is a novel data structure, the iconic scene graph that efficiently and compactly captures the perceptual, geometric, and semantic relationships between images in the collection.\r\n\r\nThe key methodological insight of this project is that successful representation and recognition of landmarks requires the integration of statistical recognition and geometric reconstruction approaches. The project incorporates statistical inference into all components of the landmark modeling system, and includes a significant layer of high-level semantic functionality that is implemented using recognition techniques.\r\n\r\nPotential applications with societal impact include virtual tourism and navigation, security and surveillance, cultural heritage preservation, immersive environments and computer games, and movie special effects. Datasets and code produced in the course of the project will be made publicly available. The project includes a significant education component through undergraduate and graduate course development.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jan-Michael",
   "pi_last_name": "Frahm",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jan-Michael Frahm",
   "pi_email_addr": "jmf@cs.unc.edu",
   "nsf_id": "000427356",
   "pi_start_date": "2009-09-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Svetlana",
   "pi_last_name": "Lazebnik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Svetlana Lazebnik",
   "pi_email_addr": "slazebni@illinois.edu",
   "nsf_id": "000298493",
   "pi_start_date": "2009-09-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "104 AIRPORT DR STE 2200",
  "perf_city_name": "CHAPEL HILL",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275995023",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "170E",
   "pgm_ref_txt": "Interagency Agreements"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 449179.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 257800.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 70000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In the first phase of the project we focussed on improved modeling for the 3D reconstruction from photo collections. The challenges in the modeling that we more closely investigated&nbsp;were: (i) related to the difficulties related to scene symmetries, which lead to modeling disturbances; and (ii) the challenges of the heterogenous scene appearance across photos ranging from different weather conditions, different time of the day to different seasons alltogether.</p>\n<p>(i) On the first problem we developed a method to correct the output of commonly used reconstruction techniques like Structure-from-motion (SFM) as their reconstruction is often disturbed when there is ambigious scene structure. &nbsp;We researched a method to detect and correct the resulting reconstruction errors but not to modify already correct reconstructions. The main idea of our algorithm is to leverage the fact that scene parts, which are seen together should also be reconstructed together and conversely if parts are not seen jointly the should not be jointly reconstructed. Our experiments on large scale photo collection data demonstrate that our new algorith is robust and outperforms existing state-of-the-art methods.&nbsp;</p>\n<p>(ii) For the problem of dense reconstruction from heterogenous image data, we researched a novel multi-view depthmap estimation approach that carefully selects the images leveraged to obtain the depth estimate for a certain pixel. The selected pixels are then used is in a probabilistic framework to jointly model &nbsp;the specific &nbsp;views selected for the estimation and the depthmap estimation using the appearance consistency of the pixels.Our experiments on large-scale internet photo collection data underline the robustness of our approach against unstructured and heterogeneous image capture characteristics. Moreover, our method is inherently parallel, which leads to an efficient and scalable graphics card based (GPU) &nbsp;implementation.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/25/2013<br>\n\t\t\t\t\tModified by: Jan-Michael&nbsp;Frahm</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn the first phase of the project we focussed on improved modeling for the 3D reconstruction from photo collections. The challenges in the modeling that we more closely investigated were: (i) related to the difficulties related to scene symmetries, which lead to modeling disturbances; and (ii) the challenges of the heterogenous scene appearance across photos ranging from different weather conditions, different time of the day to different seasons alltogether.\n\n(i) On the first problem we developed a method to correct the output of commonly used reconstruction techniques like Structure-from-motion (SFM) as their reconstruction is often disturbed when there is ambigious scene structure.  We researched a method to detect and correct the resulting reconstruction errors but not to modify already correct reconstructions. The main idea of our algorithm is to leverage the fact that scene parts, which are seen together should also be reconstructed together and conversely if parts are not seen jointly the should not be jointly reconstructed. Our experiments on large scale photo collection data demonstrate that our new algorith is robust and outperforms existing state-of-the-art methods. \n\n(ii) For the problem of dense reconstruction from heterogenous image data, we researched a novel multi-view depthmap estimation approach that carefully selects the images leveraged to obtain the depth estimate for a certain pixel. The selected pixels are then used is in a probabilistic framework to jointly model  the specific  views selected for the estimation and the depthmap estimation using the appearance consistency of the pixels.Our experiments on large-scale internet photo collection data underline the robustness of our approach against unstructured and heterogeneous image capture characteristics. Moreover, our method is inherently parallel, which leads to an efficient and scalable graphics card based (GPU)  implementation. \n\n\t\t\t\t\tLast Modified: 11/25/2013\n\n\t\t\t\t\tSubmitted by: Jan-Michael Frahm"
 }
}