{
 "awd_id": "0914488",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "HCC:Small: A New Method for Evaluating Perceptual Fidelity in Computer Graphics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2009-08-01",
 "awd_exp_date": "2014-07-31",
 "tot_intn_awd_amt": 498893.0,
 "awd_amount": 546893.0,
 "awd_min_amd_letter_date": "2009-08-06",
 "awd_max_amd_letter_date": "2012-03-13",
 "awd_abstract_narration": "For many applications of computer graphics, it is important that viewers perceive an accurate sense of the scale and spatial layout depicted in the displayed imagery.  Medical and scientific visualizations need to accurately convey information about the size, shape, and location of entities of potential interest.  Architectural and educational systems should give the user an overall sense of the scale of a real or hypothesized environment, along with the arrangement of objects in that space.  Simulation and training systems need to allow users to perform tasks with the same or similar facility as in the real world.  Despite the importance of achieving a high level of perceptual fidelity in computer graphics, there are as yet no established methodologies for evaluating how well computer graphics imagery conveys spatial information to a viewer.  The lack of such methodologies is a significant impediment to creating more effective computer graphics systems, particularly for non-entertainment applications.  In this multidisciplinary project involving genuine collaboration between computer scientists and cognitive psychologists, the PI and his team will develop a method for quantifying perceptual fidelity that is both generalizable and task-relevant.  This work will be the first systematic use of the concept of perceived affordances, defined as the perception of one's own action capabilities, for characterizing the accuracy of space perception in computer graphics.  The methodology involves a verbal indication that a particular action can or cannot be performed in a viewed environment.  By varying the spatial structure of the environment, these affordance judgments can be used to probe how accurately viewers are able to perceive action-relevant spatial information.  The result is a measure relevant to action, less subject to bias than verbal reports of more primitive properties such as size or distance, and applicable to non-virtual-environment display systems in which the actual action cannot be performed.  \r\n\r\nBroader Impacts:  This research will lead to a methodology that significantly impacts displays and rendering methods not yet developed, and will result in qualitative improvements in domain-specific systems that go beyond current practice.  Project outcomes will be applicable across a broad range of display technologies and rendering techniques, and will reduce the confounds associated with training and prior experience found in more specialized task performance measures.  The nature of this collaboration will lead to an exceptional educational environment, from which students will come away with a depth and breadth of experience which makes them especially well qualified to tackle demanding problems in science and engineering.  The investigators have a well established record of involving undergraduates and women in research, and will continue that tradition with this work.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Thompson",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "William B Thompson",
   "pi_email_addr": "thompson@cs.utah.edu",
   "nsf_id": "000457414",
   "pi_start_date": "2009-08-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sarah",
   "pi_last_name": "Creem-Regehr",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Sarah H Creem-Regehr",
   "pi_email_addr": "sarah.creem@psych.utah.edu",
   "nsf_id": "000116516",
   "pi_start_date": "2009-08-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jeanine",
   "pi_last_name": "Stefanucci",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jeanine Stefanucci",
   "pi_email_addr": "jeanine.stefanucci@psych.utah.edu",
   "nsf_id": "000541122",
   "pi_start_date": "2009-09-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "201 PRESIDENTS CIR",
  "perf_city_name": "SALT LAKE CITY",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841129049",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 498893.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>An architect, viewing a proposed design on a computer workstation, needs&nbsp;</span><span>to have an accurate sense of the size of the structures. Likewise,&nbsp;</span><span>accurate perception of the *scale* of depicted structures is important&nbsp;</span><span>in multiple other applications involving medicine, science, education,&nbsp;</span><span>and more.&nbsp; Despite the importance of knowing how well a computer display&nbsp;</span><span>conveys a correct sense of size, the accuracy of size perception is&nbsp;</span><span>surprisingly hard to measure.&nbsp; While it might seem enough to simply ask&nbsp;</span><span>people looking at such displays to describe how big the pictured objects&nbsp;</span><span>look, such reports are known to be subject to substantial conscious and&nbsp;</span><span>unconscious biases.&nbsp; Over the last 25 years, perceptual psychologists&nbsp;</span><span>have addressed this problem of bias by developing alternative measures&nbsp;</span><span>for evaluating the accuracy of real-world spatial judgments that depend&nbsp;</span><span>on interacting with entities in the world, rather than verbally&nbsp;</span><span>describing properties of these entities.&nbsp; These action-based measurement&nbsp;</span><span>techniques turn out to be of limited value when evaluating the&nbsp;</span><span>perceptual accuracy of computer based displays.&nbsp; The main problem comes </span><span>from the fact that such displays almost always involve a monitor or&nbsp;</span><span>display surface that directly or indirectly impeded the sorts of &nbsp;</span><span>activities involved in the action-based measures that work successfully </span><span>in the real world.</span></p>\n<p><span>This project developed a novel way to evaluate how the spatial </span><span>attributes of computer graphics images are perceived.&nbsp; The new method </span><span>combines the advantages of verbal-based and action-based techniques in a&nbsp;</span><span>way that is relevant to many important applications, generalizable&nbsp;</span><span>across a wide range of display systems, and reduces the chances of bias.&nbsp;</span><span>&nbsp;It builds on a 50 year old theory of perception that presumes that the&nbsp;</span><span>visual system perceives many structures in the environment in terms of&nbsp;</span><span>the viewer's potential for acting on such structures.&nbsp; For example, this&nbsp;</span><span>theory asserts that there are fundamental perceptual mechanisms by which&nbsp;</span><span>an object of appropriate size and shape is seen to be pick-upable.</span><br /><br /><span>We exploit this effect by creating evaluation tasks involving&nbsp;</span><span>*affordance judgments*. These are yes/no decisions about whether or not </span><span>a particular action is possible to perform on an object either in the real world or&nbsp;</span><span>depicted using computer graphics display systems. Examples include </span><span>whether or not an object can be picked up by the viewer, whether or not &nbsp;</span><span>the viewer can walk through a particular aperture, and whether or not&nbsp;</span><span>the viewer can step over a particular gap.&nbsp; These tests are done for&nbsp;</span><span>objects over a range of sizes, from sizes for which the action can&nbsp;</span><span>clearly be performed to sizes for which it clearly cannot be performed.&nbsp;</span><span>The size at which there is a transition from yes to no in the&nbsp;</span><span>responses is an effective measure of the perceived scale seen by the viewer.</span><br /><br /><span>The method we developed has been applied to evaluation the perceptual&nbsp;</span><span>effectiveness of a variety of display devices, ranging from desktop&nbsp;</span><span>monitors to exotic virtual reality systems.&nbsp; Perhaps our most&nbsp;</span><span>significant finding to date is that for at least some applications,&nbsp;</spa...",
  "por_txt_cntn": "\nAn architect, viewing a proposed design on a computer workstation, needs to have an accurate sense of the size of the structures. Likewise, accurate perception of the *scale* of depicted structures is important in multiple other applications involving medicine, science, education, and more.  Despite the importance of knowing how well a computer display conveys a correct sense of size, the accuracy of size perception is surprisingly hard to measure.  While it might seem enough to simply ask people looking at such displays to describe how big the pictured objects look, such reports are known to be subject to substantial conscious and unconscious biases.  Over the last 25 years, perceptual psychologists have addressed this problem of bias by developing alternative measures for evaluating the accuracy of real-world spatial judgments that depend on interacting with entities in the world, rather than verbally describing properties of these entities.  These action-based measurement techniques turn out to be of limited value when evaluating the perceptual accuracy of computer based displays.  The main problem comes from the fact that such displays almost always involve a monitor or display surface that directly or indirectly impeded the sorts of  activities involved in the action-based measures that work successfully in the real world.\n\nThis project developed a novel way to evaluate how the spatial attributes of computer graphics images are perceived.  The new method combines the advantages of verbal-based and action-based techniques in a way that is relevant to many important applications, generalizable across a wide range of display systems, and reduces the chances of bias.  It builds on a 50 year old theory of perception that presumes that the visual system perceives many structures in the environment in terms of the viewer's potential for acting on such structures.  For example, this theory asserts that there are fundamental perceptual mechanisms by which an object of appropriate size and shape is seen to be pick-upable.\n\nWe exploit this effect by creating evaluation tasks involving *affordance judgments*. These are yes/no decisions about whether or not a particular action is possible to perform on an object either in the real world or depicted using computer graphics display systems. Examples include whether or not an object can be picked up by the viewer, whether or not  the viewer can walk through a particular aperture, and whether or not the viewer can step over a particular gap.  These tests are done for objects over a range of sizes, from sizes for which the action can clearly be performed to sizes for which it clearly cannot be performed. The size at which there is a transition from yes to no in the responses is an effective measure of the perceived scale seen by the viewer.\n\nThe method we developed has been applied to evaluation the perceptual effectiveness of a variety of display devices, ranging from desktop monitors to exotic virtual reality systems.  Perhaps our most significant finding to date is that for at least some applications, perception of scale comparable to real-world performance is possible using relatively low cost, home-theater flat panel displays.\n\nBeyond the scientific contributions of this project, we have worked to establish unique interdisciplinary training for undergraduate and graduate students that merges traditional lines of computer science and perceptual psychology, and we have encouraged and supported women in computer science, typically an underrepresented group, to participate in our interdisciplinary research group. \n\nFinally, the methods and results established in this project will likely inform the development and use of graphics applications such as in medical training and architecture, where simulations are increasingly used and the accurate perception of scale of objects is critical.\n\n\t\t\t\t\tLast Modified: 10/29/2014\n\n\t\t\t\t\tSubmitted by: Sarah Creem-Regehr"
 }
}