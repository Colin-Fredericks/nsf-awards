{
 "awd_id": "0906784",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Regularization Methods in High Dimensions with Applications to Functional Data Analysis, Mixed Effects Models and Classification",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2009-08-01",
 "awd_exp_date": "2012-07-31",
 "tot_intn_awd_amt": 200826.0,
 "awd_amount": 200826.0,
 "awd_min_amd_letter_date": "2009-07-26",
 "awd_max_amd_letter_date": "2011-06-09",
 "awd_abstract_narration": "Historically statistics has dealt with the problem of extracting as much information as possible from a small data set. However, over the last decade, because of technological advances in various fields such as image processing, computational biology, climatology, economics and finance, one of the most important active research topics in statistics now involves dealing with data sets with enormous numbers of predictors. Such large scale problems may be abstracted as statistical regression and classification problems with the number of explanatory variables much larger than the number of observations. In these situations some form of regularization is essential. The investigators study a general class of penalty functions and the theoretical properties of the resulting regularization methods in regression and classification settings. In addition, two specific penalty functions that each motivate a different methodology are developed. The theoretical and empirical properties of these methods in the most common linear regression setting are investigated. Finally, the investigators study extending the methodologies to areas that are less well explored in the high dimensional setting, namely, mixed effects models, functional linear regression, and classification problems.\r\n\r\nThe proposed research is expected to have a broad impact on the practice and education, both of statistics, as well as on fields outside statistics. The common theme underlying this entire proposal is that of developing general regularization penalties and related methodologies for high dimensional problems. The investigators together have direct connections in many fields outside statistics such as Computational Biology, Finance, Marketing, Machine Learning, and Econometrics. The investigators will systematically develop software to implement the proposed methods through free software packages, like R, and then make them readily available and publicize them in all these fields. High dimensional data are becoming increasingly common, so the developed methodologies and software will be widely utilized. The research will also contribute to the training and development of future data analysts (including both statisticians and researchers outside statistics who analyze data).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yingying",
   "pi_last_name": "Fan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yingying Fan",
   "pi_email_addr": "fanyingy@usc.edu",
   "nsf_id": "000515680",
   "pi_start_date": "2009-07-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gareth",
   "pi_last_name": "James",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Gareth M James",
   "pi_email_addr": "gareth@usc.edu",
   "nsf_id": "000071176",
   "pi_start_date": "2009-07-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3720 S FLOWER ST FL 3",
  "perf_city_name": "LOS ANGELES",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "90033",
  "perf_ctry_code": "US",
  "perf_cong_dist": "34",
  "perf_st_cong_dist": "CA34",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 64356.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 66778.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 69692.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This three-year project resulted in multiple novel statistical methods in variable selection which can be used to analyze big data sets commonly arising in various scientific areas and real life applications.&nbsp;</p>\n<p>Variable selection is a technique for selecting a subset of important variables (features) to enable robust statistical analyses. It is especially useful for analyzing big data sets, and can help people to acquire a better understanding about their data by telling them which are the important features and how they are related to each other. For example, in order to accurately predict movie revenues for marketing and other strategic planning, it is important for decision makers to know which variables are most related to, and how they are related to, movie revenues. In the study of cancer diseases, it is crucial for biologists to know which genes out of thousands are expressed differently between cancer patients and normal people.</p>\n<p>Classic variable selection methods can only deal with a few variables, and thus are in general insufficient to analyze big data sets with a large number of variables.&nbsp; &nbsp;Regularization is one of the most popular methods for variable selection. In this project, the PI and CO-PI proposed and studied innovative variable selection methods via regularization in commonly used statistical models including the functional regression model, mixed effects models, and the robust regression model. The proposed methods have been carefully studied and justified. For instance, the functional additive regression method has been applied to the Hollywood Stock Exchange data and the important variables for movie revenue prediction have been successfully identified. As a consequence, the prediction accuracy has been improved in comparison to currently available methods. A gene expression data set for studying cancer has been analyzed using the proposed adaptive robust variable selection method, and the important genes accounting for cancer disease classifications have been selected. In summary, the proposed methods in this project have improved the variable selection results in various statistical models and enhanced statistical modeling and prediction powers.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/10/2012<br>\n\t\t\t\t\tModified by: Yingying&nbsp;Fan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis three-year project resulted in multiple novel statistical methods in variable selection which can be used to analyze big data sets commonly arising in various scientific areas and real life applications. \n\nVariable selection is a technique for selecting a subset of important variables (features) to enable robust statistical analyses. It is especially useful for analyzing big data sets, and can help people to acquire a better understanding about their data by telling them which are the important features and how they are related to each other. For example, in order to accurately predict movie revenues for marketing and other strategic planning, it is important for decision makers to know which variables are most related to, and how they are related to, movie revenues. In the study of cancer diseases, it is crucial for biologists to know which genes out of thousands are expressed differently between cancer patients and normal people.\n\nClassic variable selection methods can only deal with a few variables, and thus are in general insufficient to analyze big data sets with a large number of variables.   Regularization is one of the most popular methods for variable selection. In this project, the PI and CO-PI proposed and studied innovative variable selection methods via regularization in commonly used statistical models including the functional regression model, mixed effects models, and the robust regression model. The proposed methods have been carefully studied and justified. For instance, the functional additive regression method has been applied to the Hollywood Stock Exchange data and the important variables for movie revenue prediction have been successfully identified. As a consequence, the prediction accuracy has been improved in comparison to currently available methods. A gene expression data set for studying cancer has been analyzed using the proposed adaptive robust variable selection method, and the important genes accounting for cancer disease classifications have been selected. In summary, the proposed methods in this project have improved the variable selection results in various statistical models and enhanced statistical modeling and prediction powers.\n\n\t\t\t\t\tLast Modified: 09/10/2012\n\n\t\t\t\t\tSubmitted by: Yingying Fan"
 }
}