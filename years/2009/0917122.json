{
 "awd_id": "0917122",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Efficient Reinforcement Learning for Generic Large-Scale Tasks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 485000.0,
 "awd_amount": 501000.0,
 "awd_min_amd_letter_date": "2009-08-22",
 "awd_max_amd_letter_date": "2010-05-25",
 "awd_abstract_narration": "Recent advances in autonomous agents research are pushing our society closer to the brink of the widespread adoption of autonomous agents in everyday life. Applications that incorporate agents already exist or are quickly emerging, such as domestic robots, autonomous vehicles, and financial management agents. Reinforcement learning (RL) of sequential decision making is an important paradigm for enabling the widespread deployment of autonomous agents. However, a few notable successes notwithstanding, state-of-the-art reinforcement learning algorithms are not yet fully capable of addressing generic large-scale applications. \r\n\r\nThis project is advancing in four directions to scale-up application of RL systems. Specifically, the project is (1) developing algorithms to automatically structure the input, output, and policy representations for learning; (2) introducing parallelizable reinforcement learning algorithms so as to exploit modern parallel architectures; (3) unifying abstraction and hierarchical reasoning with model-based learning for the purpose of enabling intelligent exploration of large-scale environments; and (4) enabling reinforcement learning algorithms to benefit from low-bandwidth interactions with human users. Finally, we intend to unify the four research thrusts above into a single algorithm and conduct empirical evaluation on real-world/large-scale applications, to include biped robot balancing and walking, robot soccer in simulation and with real robots, and a full-size autonomous vehicle capable of planning paths in an urban environment.\r\n\r\nIn addition to research advances and implications for improving national infrastructure, the project will contribute to undergraduate and graduate curriculum development.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Stone",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Peter H Stone",
   "pi_email_addr": "pstone@cs.utexas.edu",
   "nsf_id": "000156504",
   "pi_start_date": "2009-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "110 INNER CAMPUS DR",
  "perf_city_name": "AUSTIN",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121139",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 485000.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Recent advances in autonomous agents research are pushing our society<br />closer to the brink of the widespread adoption of autonomous agents in<br />everyday life. Applications that incorporate agents already exist or<br />are quickly emerging, such as domestic robots, autonomous vehicles,<br />and financial management agents. Reinforcement learning (RL) of<br />sequential decision making is an important paradigm for enabling the<br />widespread deployment of autonomous agents. However, a few notable<br />successes notwithstanding, state-of-the-art reinforcement learning<br />algorithms are not yet fully capable of addressing generic large-scale<br />applications.<br /><br />This project advanced in four directions to scale-up application of RL<br />systems. Specifically, the project (1) developed algorithms to<br />automatically structure the input, output, and policy representations<br />for learning; (2) introduced parallelizable reinforcement learning<br />algorithms so as to exploit modern parallel architectures; (3) unified<br />abstraction and hierarchical reasoning with model-based learning for<br />the purpose of enabling intelligent exploration of large-scale<br />environments; and (4) enabled reinforcement learning algorithms to<br />benefit from low-bandwidth interactions with human users. Finally, we<br />unified the four research thrusts above into a single algorithm and<br />conduct empirical evaluation on real-world/large-scale applications,<br />to include biped robot balancing and walking, robot soccer in<br />simulation and with real robots, and a full-size autonomous vehicle<br />capable of planning paths in an urban environment.<br /><br />With regards to broader impacts, the PI actively worked with all of<br />the postdocs and graduate students on the project on all of their<br />research activities. Several of the participants have jointly written<br />papers with the PIs, and then have received detailed feedback on their<br />presentations prior to attending the conferences. Those nearing<br />graduation have worked closely with the PI on securing future job<br />opportunities. They have all also participated actively on the<br />project's outreach activities, including Explore UT, an annual open<br />house for the general public, and First Bytes, an annual summer camp<br />for high school girls, designed to increase female participation in<br />Computer Science.<br /><br />The project also supported two undergrad students, one of whom<br />traveled to a conference as the first author of a paper, and the other<br />of whom traveled with our team to RoboCup and completed a<br />project-related undergraduate thesis.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/19/2014<br>\n\t\t\t\t\tModified by: Peter&nbsp;H&nbsp;Stone</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nRecent advances in autonomous agents research are pushing our society\ncloser to the brink of the widespread adoption of autonomous agents in\neveryday life. Applications that incorporate agents already exist or\nare quickly emerging, such as domestic robots, autonomous vehicles,\nand financial management agents. Reinforcement learning (RL) of\nsequential decision making is an important paradigm for enabling the\nwidespread deployment of autonomous agents. However, a few notable\nsuccesses notwithstanding, state-of-the-art reinforcement learning\nalgorithms are not yet fully capable of addressing generic large-scale\napplications.\n\nThis project advanced in four directions to scale-up application of RL\nsystems. Specifically, the project (1) developed algorithms to\nautomatically structure the input, output, and policy representations\nfor learning; (2) introduced parallelizable reinforcement learning\nalgorithms so as to exploit modern parallel architectures; (3) unified\nabstraction and hierarchical reasoning with model-based learning for\nthe purpose of enabling intelligent exploration of large-scale\nenvironments; and (4) enabled reinforcement learning algorithms to\nbenefit from low-bandwidth interactions with human users. Finally, we\nunified the four research thrusts above into a single algorithm and\nconduct empirical evaluation on real-world/large-scale applications,\nto include biped robot balancing and walking, robot soccer in\nsimulation and with real robots, and a full-size autonomous vehicle\ncapable of planning paths in an urban environment.\n\nWith regards to broader impacts, the PI actively worked with all of\nthe postdocs and graduate students on the project on all of their\nresearch activities. Several of the participants have jointly written\npapers with the PIs, and then have received detailed feedback on their\npresentations prior to attending the conferences. Those nearing\ngraduation have worked closely with the PI on securing future job\nopportunities. They have all also participated actively on the\nproject's outreach activities, including Explore UT, an annual open\nhouse for the general public, and First Bytes, an annual summer camp\nfor high school girls, designed to increase female participation in\nComputer Science.\n\nThe project also supported two undergrad students, one of whom\ntraveled to a conference as the first author of a paper, and the other\nof whom traveled with our team to RoboCup and completed a\nproject-related undergraduate thesis.\n\n \n\n\t\t\t\t\tLast Modified: 10/19/2014\n\n\t\t\t\t\tSubmitted by: Peter H Stone"
 }
}