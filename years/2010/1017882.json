{
 "awd_id": "1017882",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "DC: Small: Adaptive Sparse Data Mining On Multicores",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 449998.0,
 "awd_amount": 449998.0,
 "awd_min_amd_letter_date": "2010-08-18",
 "awd_max_amd_letter_date": "2010-08-18",
 "awd_abstract_narration": "The PIs are working on developing and evaluating a data-driven three-phase adaptive, sparse multicore data mining framework for scalable and efficient supervised classification and statistical analysis.\r\n\r\nPhase-I seeks to characterize data attributes in terms of sparsity, graph-theoretic structure and geometric and numeric measures toward data transformations with a focus on dimensionality reduction. The goal is to explore the trade-offs between quality of solution (accuracy and precision of classification) and total work (sequential computational costs) toward faster, yet improved methods. \r\n\r\nPhase-II operates on the transformed data to increase the degree of fine to coarse grained concurrency while restructuring the data for enhanced reuse and locality of access. This phase provides a weighted annotated graph model of the computations indicating dependencies, data sharing measures and computational costs.\r\n\r\nPhase-III utilizes this model to formulate and explore architecture-aware mappings of data mining computations to the multicore processors, including cache and bandwidth aware thread-to-core mappings that consider both performance and power. \r\n\r\nThe PIs thus seek adaptations to utilize data set attributes, including approximations and concurrency of computations latent in the sparsity structure, toward improved utilization of processor and memory hardware on current and future multicores with larger core counts, complex cache hierarchies and off-chip bandwidth constraints.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Padma",
   "pi_last_name": "Raghavan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Padma Raghavan",
   "pi_email_addr": "padma.raghavan@vanderbilt.edu",
   "nsf_id": "000097691",
   "pi_start_date": "2010-08-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mahmut",
   "pi_last_name": "Kandemir",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Mahmut T Kandemir",
   "pi_email_addr": "mtk2@psu.edu",
   "nsf_id": "000163936",
   "pi_start_date": "2010-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "201 OLD MAIN",
  "perf_city_name": "UNIVERSITY PARK",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168021503",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "PA15",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779300",
   "pgm_ele_name": "DATA-INTENSIVE COMPUTING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7793",
   "pgm_ref_txt": "DATA-INTENSIVE COMPUTING"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 449998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>With the emergence of multiple processing units (called &ldquo;cores&rdquo;) on a processor, it has become increasingly important to advance information technologies for harnessing such hardware to &nbsp;process large volumes of data. In fact, many data-intensive applications can potentially achieve impressive speedups by exploiting these multiple processing units and on-chip data storage capabilities. However, achieving this potential in practice has been proven to be very challenging.</p>\n<p>Motivated by these observations, this research project developed several techniques with the goal of improving the performance and energy consumption of &ldquo;kernels&rdquo; which represent key sets of calculations that are essential for widely-used data-intensive applications such as clustering, classification and graph mining schemes. More specifically, this project optimized the performance of such kernels on emerging parallel architectures with deep memory/storage hierarchies. The&nbsp; main contributions are new data&nbsp; mapping and task scheduling schemes that sought to deliver high performance by&nbsp; exploiting both (i) the properties of the data including sparsity, high dimensionality, irregular access pattern, &nbsp;and (ii) the properties of multiple core processors including&nbsp; network topology, non-uniform memory architectures, bandwidth constraints, and variable latencies of data access.</p>\n<p>&nbsp;</p>\n<p>The detailed experimental evaluations of the new optimization techniques demonstrated by tuning several features of the architecture and algorithms one can take full advantage of emerging parallel architectures. In particular, it is possible, in some cases, to achieve a factor of 20 performance improvement on a 32-core parallel computing system. Further, the results from this project identify new and promising directions for the performance engineering of computing systems so that increasingly higher fractions of the ideal execution rates of the raw hardware can be delivered to end-user applications.&nbsp; The project trained 6 graduate students and 1 post-doctoral researcher at the Pennsylvania State University. Three graduate students and the post-doctoral researcher are employed in industry. One graduate student is employed as tenure-track assistant professor in a US university while a second is employed as a post-doctoral researcher at a US university. The project also enabled activities to broaden the participation of women in computing and the professional development of graduate students and post-doctoral researchers.</p>\n<p>&nbsp;</p>\n<p>For several decades, performance gains to end-user applications from successive generations of general purpose computing hardware were naturally realized through CPU frequency-scaling. However, current and future generation processor architectures with multiple execution units (cores) depend on raw hardware capacity scaling from core, thread and instruction level parallelism. In this context, performance engineering has become increasingly critical to deliver the benefits of such processors to end users. This project has demonstrated that cross-component performance optimizations can be developed and applied to deliver the benefits of parallel computing to data-intensive applications.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/05/2015<br>\n\t\t\t\t\tModified by: Padma&nbsp;Raghavan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWith the emergence of multiple processing units (called \"cores\") on a processor, it has become increasingly important to advance information technologies for harnessing such hardware to  process large volumes of data. In fact, many data-intensive applications can potentially achieve impressive speedups by exploiting these multiple processing units and on-chip data storage capabilities. However, achieving this potential in practice has been proven to be very challenging.\n\nMotivated by these observations, this research project developed several techniques with the goal of improving the performance and energy consumption of \"kernels\" which represent key sets of calculations that are essential for widely-used data-intensive applications such as clustering, classification and graph mining schemes. More specifically, this project optimized the performance of such kernels on emerging parallel architectures with deep memory/storage hierarchies. The  main contributions are new data  mapping and task scheduling schemes that sought to deliver high performance by  exploiting both (i) the properties of the data including sparsity, high dimensionality, irregular access pattern,  and (ii) the properties of multiple core processors including  network topology, non-uniform memory architectures, bandwidth constraints, and variable latencies of data access.\n\n \n\nThe detailed experimental evaluations of the new optimization techniques demonstrated by tuning several features of the architecture and algorithms one can take full advantage of emerging parallel architectures. In particular, it is possible, in some cases, to achieve a factor of 20 performance improvement on a 32-core parallel computing system. Further, the results from this project identify new and promising directions for the performance engineering of computing systems so that increasingly higher fractions of the ideal execution rates of the raw hardware can be delivered to end-user applications.  The project trained 6 graduate students and 1 post-doctoral researcher at the Pennsylvania State University. Three graduate students and the post-doctoral researcher are employed in industry. One graduate student is employed as tenure-track assistant professor in a US university while a second is employed as a post-doctoral researcher at a US university. The project also enabled activities to broaden the participation of women in computing and the professional development of graduate students and post-doctoral researchers.\n\n \n\nFor several decades, performance gains to end-user applications from successive generations of general purpose computing hardware were naturally realized through CPU frequency-scaling. However, current and future generation processor architectures with multiple execution units (cores) depend on raw hardware capacity scaling from core, thread and instruction level parallelism. In this context, performance engineering has become increasingly critical to deliver the benefits of such processors to end users. This project has demonstrated that cross-component performance optimizations can be developed and applied to deliver the benefits of parallel computing to data-intensive applications.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 06/05/2015\n\n\t\t\t\t\tSubmitted by: Padma Raghavan"
 }
}