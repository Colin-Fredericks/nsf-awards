{
 "awd_id": "1048831",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER:  Haplotype Phasing Algorithms and Clark Consistency Graphs",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2011-01-01",
 "awd_exp_date": "2012-12-31",
 "tot_intn_awd_amt": 199999.0,
 "awd_amount": 199999.0,
 "awd_min_amd_letter_date": "2010-08-24",
 "awd_max_amd_letter_date": "2010-08-24",
 "awd_abstract_narration": "Currently, most SNP assay data is made available from genome-wide association studies (GWAS), which proceed by identifying a number of individuals carrying a disease or a trait and comparing them to those that do not or are not known to carry the disease/trait. Both sets of individuals are then genotyped for a large number of single-nucleotide polymorphism (SNP) genetic variants that are then tested for association to the disease/trait. GWAS studies using tens of thousands of individuals are becoming commonplace and are increasingly the norm in the association of genetic variants to disease. These studies generally proceed by pooling large amounts of genome-wide data from multiple studies, for a combined total of tens of thousands of individuals in a single meta-analysis study. It can be expected that hundreds of thousands, if not millions, of individuals will soon be studied for association to a single disease or trait. Although SNPs are the most abundant form of variation between two individuals, other forms of variation exist, such as copy-number variation ? large-scale chromosomal deletions, insertions, and duplications. These variations, which have been shown to be influential factors in many diseases, are not probed using the current technology of SNP arrays. An emerging trend in accounting for ?missing heritability? is ?parent-of-origin? effects, where genetic variants confer risk only when inherited from a specific parent. Long-range haplotype phasing is key to identifying the association of the haplotype pattern to the specific parent of origin.\r\n\r\nThe premise of this research is that long tracts are unlikely (to be shared) unless the haplotypes are identical by descent (IBD), in contrast to short shared tracts, which may be identical by state (IBS). A difficult algorithmic challenge is that of tract finding in genotype matrices of a sample of m people genotyped at n SNPs.  The premise of our research is that long tracts are unlikely (to be shared) unless the haplotypes are identical by descent (IBD), in contrast to short shared tracts, which may be identical by state (IBS). A difficult algorithmic challenge is that of tract finding in genotype matrices of a sample of m people genotyped at n SNPs. To apply such a long-range phasing algorithm to the U.S. population, it is estimated that 2 million individuals must be genotyped. Algorithmic strategies proposed here show promise that the combinatorial structure of Clark Consistency Graphs can provide the basis for powerful algorithms that will decrease this number substantially.  The primary output of this project will be new long-range phasing software, documentation, and source code, all to be immediately and continually available to the scientific community as open-source for research and education.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sorin",
   "pi_last_name": "Istrail",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Sorin C Istrail",
   "pi_email_addr": "sorin@cs.brown.edu",
   "nsf_id": "000112679",
   "pi_start_date": "2010-08-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "1 PROSPECT ST",
  "perf_city_name": "PROVIDENCE",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029129100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 199999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This NSF proposal has been focused on the development of algorithms for genome-wide haplotype phasing.Two aims were proposed:</p>\n<p>AIM 1: Develop Algorithmic Graph Theory and Efficient Data Structures for Long-Range Clark Consistency Graphs and for Tract-Finding for GWAS Data Sets.</p>\n<p>AIM 2: Develop Algorithms and Software Library for Long-Range Haplotype Phasing of a Large Sample of Individuals.</p>\n<p><strong>&nbsp;</strong>The importance of the problem and the need for powerful algorithms that work accurately for genome-wide size data is eloquently presented in the following quote:</p>\n<p><strong>&ldquo;</strong><em>Improving data quality is crucial, because if a human genome cannot be independently assembled then the sequence data cannot be sorted into the two sets of parental chromosomes, or haplotypes. This process haplotype phasing will become one of the most useful tools in genomic medicine. Establishing the complete set of genetic information that we received from each parent is crucial to understanding the links between heritability, gene function, regulatory sequences and our predisposition to disease.&rdquo;</em><strong> </strong></p>\n<p><strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </strong>J. C. Venter, &ldquo;Multiple personal genomes await,&rdquo; Nature, April 2010</p>\n<p>&nbsp;</p>\n<p>In a seminal 1990 paper, &ldquo;Inference of Haplotypes from PCR-amplified Samples of Diploid Populations,&rdquo;&nbsp; Andy Clark proposed a very fast greedy algorithm for separating the maternal and paternal haplotypes of an individual. The quest then, for each individual, is the identification of the two haplotypes (the maternal-paternal explanation) out of the (2 to the power k) possible haplotypes. Clark&rsquo;s algorithm is an algorithm-schema, leaving a number of implementations details open. The algorithmic ideas continue to be effective and actively researched today; in fact, algorithms based on them are called &ldquo;Clark Methods&rdquo; in the literature. &nbsp;Experimental methods to date have not been able to provide a cost-effective technology for the haplotype phasing problem, and with today&rsquo;s genome-wide association studies (GWAS) size samples (thousands of people, hundred of thousands of SNPs), computational methods are the only feasible approach to practical solutions for the problem. And even there, due to the huge SNP array data sets, very fast algorithmic methods like Clark Methods are very important. The search for fast and accurate computational methods for phasing is witnessed by the large literature on the subject and by the many software tools for haplotype phasing and competitions assessing these tools. In addition to the Clark Methods, a variety of other statistical and combinatorial models have been proposed: maximum-likelihood, Bayesian, parsimony, coalescent, perfect and imperfect phylogeny. The PI&rsquo;s work on a number of other synergetic projects has provided algorithmic insights into the haplotype phasing problem as well as a suite of software tools and an environment for haplotype reconstruction visualization. These include: a Genome Browser under development dedicated to GWAS analysis, the ARIADNE GWAS-Browser; unification of linkage disequilibrium measures; a suite of genomic tools including a variety of phasing algorithms based on parsimony haplotyping, maximum-likelihood and haplotyping, coalescent haplotyping, robustness of haplotype blocks analysis, tagging SNPs and minimum informative SNPs selection, SNPs and haplotype assembly, and imperfect ancestral recombination graphs reconstruction. In addition, libr...",
  "por_txt_cntn": "\nThis NSF proposal has been focused on the development of algorithms for genome-wide haplotype phasing.Two aims were proposed:\n\nAIM 1: Develop Algorithmic Graph Theory and Efficient Data Structures for Long-Range Clark Consistency Graphs and for Tract-Finding for GWAS Data Sets.\n\nAIM 2: Develop Algorithms and Software Library for Long-Range Haplotype Phasing of a Large Sample of Individuals.\n\n The importance of the problem and the need for powerful algorithms that work accurately for genome-wide size data is eloquently presented in the following quote:\n\n\"Improving data quality is crucial, because if a human genome cannot be independently assembled then the sequence data cannot be sorted into the two sets of parental chromosomes, or haplotypes. This process haplotype phasing will become one of the most useful tools in genomic medicine. Establishing the complete set of genetic information that we received from each parent is crucial to understanding the links between heritability, gene function, regulatory sequences and our predisposition to disease.\" \n\n                                                           J. C. Venter, \"Multiple personal genomes await,\" Nature, April 2010\n\n \n\nIn a seminal 1990 paper, \"Inference of Haplotypes from PCR-amplified Samples of Diploid Populations,\"  Andy Clark proposed a very fast greedy algorithm for separating the maternal and paternal haplotypes of an individual. The quest then, for each individual, is the identification of the two haplotypes (the maternal-paternal explanation) out of the (2 to the power k) possible haplotypes. Clark\u00c6s algorithm is an algorithm-schema, leaving a number of implementations details open. The algorithmic ideas continue to be effective and actively researched today; in fact, algorithms based on them are called \"Clark Methods\" in the literature.  Experimental methods to date have not been able to provide a cost-effective technology for the haplotype phasing problem, and with today\u00c6s genome-wide association studies (GWAS) size samples (thousands of people, hundred of thousands of SNPs), computational methods are the only feasible approach to practical solutions for the problem. And even there, due to the huge SNP array data sets, very fast algorithmic methods like Clark Methods are very important. The search for fast and accurate computational methods for phasing is witnessed by the large literature on the subject and by the many software tools for haplotype phasing and competitions assessing these tools. In addition to the Clark Methods, a variety of other statistical and combinatorial models have been proposed: maximum-likelihood, Bayesian, parsimony, coalescent, perfect and imperfect phylogeny. The PI\u00c6s work on a number of other synergetic projects has provided algorithmic insights into the haplotype phasing problem as well as a suite of software tools and an environment for haplotype reconstruction visualization. These include: a Genome Browser under development dedicated to GWAS analysis, the ARIADNE GWAS-Browser; unification of linkage disequilibrium measures; a suite of genomic tools including a variety of phasing algorithms based on parsimony haplotyping, maximum-likelihood and haplotyping, coalescent haplotyping, robustness of haplotype blocks analysis, tagging SNPs and minimum informative SNPs selection, SNPs and haplotype assembly, and imperfect ancestral recombination graphs reconstruction. In addition, libraries of tools developed by his group at Celera Genomics 2000-2005 for genome annotation, genome assembly algorithms, and assembly comparison tools, available in open source, provided an effective software development environment for his laboratory research work on in haplotype phasing algorithms.\n\nThe Clark Consistency Graph Theory was introduced by Sharan, Halldorson and Istrail in 2006.  This graph theoretic framework is the basis for the algorithm development of this proposal and responsible for the success of the methods obtained. The concept was..."
 }
}