{
 "awd_id": "0934322",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CI-ADDO-EN: Collaborative Proposal: Supporting Web-Scale Experimentation using the Lemur Toolkit",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2010-06-01",
 "awd_exp_date": "2016-05-31",
 "tot_intn_awd_amt": 530000.0,
 "awd_amount": 530000.0,
 "awd_min_amd_letter_date": "2010-06-15",
 "awd_max_amd_letter_date": "2012-09-10",
 "awd_abstract_narration": "This project maintains and enhances existing community software\r\ninfrastructure, and creates new community data infrastructure to\r\nenable the information retrieval research community and related\r\nresearch communities to conduct research on a \"web scale\",\r\nmeaning datasets of a billion or more web pages together with\r\nlarge query logs. The software infrastructure is based on the\r\nLemur Toolkit and the associated Indri search engine, which are\r\nused by many information retrieval researchers due to the support\r\nfor multiple retrieval models, multiple forms of evidence, and a\r\npowerful probabilistic query language. The enhancements to Lemur\r\ninclude support for the popular MapReduce style of distributed\r\nprocessing and other efficiency improvements to make it practical\r\nto do research on large web datasets 'out of the box' in common\r\ncomputer hardware environments.\r\n\r\nThe new data infrastructure consists of maintenance and\r\ndistribution of a newly created billion-page dataset, another new\r\nweb dataset, and large, anonymized search logs that match the\r\ndatasets. The combination of large datasets and corresponding\r\nlarge search logs enable a broad community to conduct research\r\nwith more realistic data resources than were available\r\npreviously. This research will lead to further advances in the\r\nunderstanding of the underlying issues for large-scale,\r\npersonalized search, which will be an important part of the next\r\ngeneration of search engines.\r\n\r\nFor further information, see the project web site at the URL:\r\nhttp://www.lemurproject.org.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "W. Bruce",
   "pi_last_name": "Croft",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "W. Bruce Croft",
   "pi_email_addr": "croft@cs.umass.edu",
   "nsf_id": "000095962",
   "pi_start_date": "2010-06-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "101 COMMONWEALTH AVE",
  "perf_city_name": "AMHERST",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010039252",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 135000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 135000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 260000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project created, operated, and enhanced software, datasets, and web services used by researchers and scientists studying information retrieval and other topics related to the processing of &ldquo;web scale&rdquo; text datasets.&nbsp; The software infrastructure was based on the Lemur Toolkit and its associated Indri and Galago search engines, which are popular with researchers because they are open-source software that deliver state-of-the-art accuracy and can be modified easily to support varied research and educational needs.</p>\n<p>The Galago search engine was developed originally to support undergraduate and graduate courses that teach students about the software architectures of search engines containing a few million documents.&nbsp; This project made major improvements to Galago to support use in mobile environments such as Android, which have strict memory and storage limitations, as well as Linux computers clusters that support web-scale datasets.&nbsp; A variety of new features were added, for example, n-gram (phrase) indexing, tools for large-scale distributed computing environments, document fields, common document formats, user-developed ranking algorithms, and machine learning algorithms.&nbsp; Additionally, Galago supports many user convenience functions allowing researchers easier analysis of indexed document collections, such as term statistics for specified documents or provided queries, dumping of specified raw input texts or index file contents and self-documentation.</p>\n<p>Machine learning algorithms have become an important method of tuning search engine parameters and effectively combining diverse evidence about how well a document matches a query.&nbsp; A new library of &lsquo;learning to rank&rsquo; machine learning algorithms (<em>RankLib</em>) was developed to support this style of research.</p>\n<p>A prior Lemur project created <em>ClueWeb09</em>, a dataset of 1 billion web pages.&nbsp; This project created ClueWeb12, a dataset of 730 million English web pages.&nbsp; ClueWeb12 contains less &lsquo;spam&rsquo;, malware, and pornography than prior datasets; more coverage of topics discussed in social media; and more complete metadata.&nbsp; The ClueWeb09 and ClueWeb12 datasets were used in the TREC evaluations of information retrieval software conducted by the National Institute of Standards and Technologies (NIST) during each year of the project; they were also used by NTCIR, a similar evaluation conducted in Japan.&nbsp; 263 copies of ClueWeb09 and 147 copies of ClueWeb12 were licensed and distributed during the project.&nbsp; These datasets are used most actively by university-based researchers, but they are also used by small companies to test their products and by large companies to test potential product enhancements.</p>\n<p>Deploying reliable search services for terabytes of web data is a significant burden for organizations and researchers without significant computational resources of their own.&nbsp; The Indri search engine software and machines donated by Yahoo were used to provide web-based search services for the ClueWeb09 and ClueWeb12 datasets.&nbsp; These services serviced 4,000 - 10,000 queries per month from other educational and research institutions.</p>\n<p>Two additional datasets have been made available to researchers focused on question answering tasks.&nbsp; A Web Answer Passages (WebAP) dataset is derived from the 2004 TREC Terabyte Track Gov2 data and contains over 8,000 answer passage judgment annotations for 82 TREC queries.&nbsp; A Yahoo Non-Factoid Question dataset (nfL6)&nbsp; contains over 87,000 questions and corresponding answers, derived from the Yahoo Webscope L6 collection.</p>\n<p>New versions of software were released twice a year (June, December) throughout the project; occasionally there were also interim releases to fix important errors.&nbsp; User support services included wiki-based documenta...",
  "por_txt_cntn": "\nThis project created, operated, and enhanced software, datasets, and web services used by researchers and scientists studying information retrieval and other topics related to the processing of \"web scale\" text datasets.  The software infrastructure was based on the Lemur Toolkit and its associated Indri and Galago search engines, which are popular with researchers because they are open-source software that deliver state-of-the-art accuracy and can be modified easily to support varied research and educational needs.\n\nThe Galago search engine was developed originally to support undergraduate and graduate courses that teach students about the software architectures of search engines containing a few million documents.  This project made major improvements to Galago to support use in mobile environments such as Android, which have strict memory and storage limitations, as well as Linux computers clusters that support web-scale datasets.  A variety of new features were added, for example, n-gram (phrase) indexing, tools for large-scale distributed computing environments, document fields, common document formats, user-developed ranking algorithms, and machine learning algorithms.  Additionally, Galago supports many user convenience functions allowing researchers easier analysis of indexed document collections, such as term statistics for specified documents or provided queries, dumping of specified raw input texts or index file contents and self-documentation.\n\nMachine learning algorithms have become an important method of tuning search engine parameters and effectively combining diverse evidence about how well a document matches a query.  A new library of \u00e6learning to rank\u00c6 machine learning algorithms (RankLib) was developed to support this style of research.\n\nA prior Lemur project created ClueWeb09, a dataset of 1 billion web pages.  This project created ClueWeb12, a dataset of 730 million English web pages.  ClueWeb12 contains less \u00e6spam\u00c6, malware, and pornography than prior datasets; more coverage of topics discussed in social media; and more complete metadata.  The ClueWeb09 and ClueWeb12 datasets were used in the TREC evaluations of information retrieval software conducted by the National Institute of Standards and Technologies (NIST) during each year of the project; they were also used by NTCIR, a similar evaluation conducted in Japan.  263 copies of ClueWeb09 and 147 copies of ClueWeb12 were licensed and distributed during the project.  These datasets are used most actively by university-based researchers, but they are also used by small companies to test their products and by large companies to test potential product enhancements.\n\nDeploying reliable search services for terabytes of web data is a significant burden for organizations and researchers without significant computational resources of their own.  The Indri search engine software and machines donated by Yahoo were used to provide web-based search services for the ClueWeb09 and ClueWeb12 datasets.  These services serviced 4,000 - 10,000 queries per month from other educational and research institutions.\n\nTwo additional datasets have been made available to researchers focused on question answering tasks.  A Web Answer Passages (WebAP) dataset is derived from the 2004 TREC Terabyte Track Gov2 data and contains over 8,000 answer passage judgment annotations for 82 TREC queries.  A Yahoo Non-Factoid Question dataset (nfL6)  contains over 87,000 questions and corresponding answers, derived from the Yahoo Webscope L6 collection.\n\nNew versions of software were released twice a year (June, December) throughout the project; occasionally there were also interim releases to fix important errors.  User support services included wiki-based documentation, a discussion forum where questions and answers were posted, and support by email.\n\nDuring the life of the project, several hundred scientific papers that were published in top information retrieval journals and conferences des..."
 }
}