{
 "awd_id": "1029585",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research:  Computational Behavioral Science:  Modeling, Analysis, and Visualization of Social and Communicative Behavior",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 1500000.0,
 "awd_amount": 1500000.0,
 "awd_min_amd_letter_date": "2010-08-19",
 "awd_max_amd_letter_date": "2013-08-22",
 "awd_abstract_narration": "Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and \r\nCommunicative Behavior\r\nLead PI/Institution: James M. Rehg, Georgia Institute of Technology\r\nThis Expedition will develop novel computational methods for measuring and analyzing the behavior of children and adults during face-to-face social interactions. Social behavior plays a key role in the acquisition of social and communicative skills during childhood. Children with developmental disorders, such as autism, face great challenges in acquiring these skills, resulting in substantial lifetime risks. Current best practices for evaluating behavior and assessing risk are based on direct observation by highly-trained specialists, and cannot be easily scaled to the large number of individuals who need evaluation and treatment. For example, autism affects 1 in 110 children in the U.S., with a lifetime cost of care of $3.2 million per person. By developing methods to automatically collect fine-grained behavioral data, this project will enable large-scale objective screening and more effective delivery and assessment of therapy. Going beyond the treatment of disorders, this technology will make it possible to automatically measure behavior over long periods of time for large numbers of individuals in a wide range of settings. Many disciplines, such as education, advertising, and customer relations, could benefit from a quantitative, data-drive approach to behavioral analysis. \r\nHuman behavior is inherently multi-modal, and individuals use eye gaze, hand gestures, facial expressions, body posture, and tone of voice along with speech to convey engagement and regulate social interactions.  This project will develop multiple sensing technologies, including vision, speech, and wearable sensors, to obtain a comprehensive, integrated portrait of expressed behavior. Cameras and microphones provide an inexpensive, noninvasive means for measuring eye, face, and body movements along with speech and nonspeech utterances. Wearable sensors can measure physiological variables such as heart-rate and skin conductivity, which contain important cues about levels of internal stress and arousal that are linked to expressed behavior. This project is developing unique capabilities for synchronizing multiple sensor streams, correlating these streams to measure behavioral variables such as affect and attention, and modeling extended interactions between two or more individuals. In addition, novel behavior visualization methods are being developed to enable real-time decision support for interventions and the effective use of repositories of behavioral data. Methods are also under development for reflecting the capture and analysis process to users of the technology.\r\nThe long-term goal of this project is the creation of a new scientific discipline of computational behavioral science, which draws equally from computer science and psychology in order to transform the study of human behavior. A comprehensive education plan supports this goal through the creation of an interdisciplinary summer school for young researchers and the development of new courses in computational behavior. Outreach activities include significant and on-going collaborations with major autism research centers in Atlanta, Boston, Pittsburgh, Urbana-Champaign, and Los Angeles.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rosalind",
   "pi_last_name": "Picard",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Rosalind W Picard",
   "pi_email_addr": "picard@media.mit.edu",
   "nsf_id": "000258962",
   "pi_start_date": "2010-08-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Rana",
   "pi_last_name": "el Kaliouby",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rana el Kaliouby",
   "pi_email_addr": "Kaliouby@media.mit.edu",
   "nsf_id": "000495866",
   "pi_start_date": "2010-08-19",
   "pi_end_date": "2013-08-08"
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Goodwin",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew S Goodwin",
   "pi_email_addr": "m.goodwin@neu.edu",
   "nsf_id": "000543036",
   "pi_start_date": "2010-08-19",
   "pi_end_date": "2012-10-10"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Goodwin",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew S Goodwin",
   "pi_email_addr": "m.goodwin@neu.edu",
   "nsf_id": "000543036",
   "pi_start_date": "2013-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 MASSACHUSETTS AVE",
  "perf_city_name": "CAMBRIDGE",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  },
  {
   "pgm_ref_code": "7723",
   "pgm_ref_txt": "EXPERIMENTAL EXPEDITIONS"
  },
  {
   "pgm_ref_code": "7969",
   "pgm_ref_txt": "FY 2010 Funding for PTR"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 900000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 600000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;</p>\n<p>This project has led to new technologies and methods to better understand human behavior and facilitate improved human communication. Our work has been inspired by interactions with people for whom social-emotional and verbal communication can be unusually difficult and challenging, such as people on the autism spectrum. In working with these learners and understanding their huge levels of stress, we decided one of the things that was needed was better tools that make it easier and lower-cost to quantify stress-related physiology.</p>\n<p>Thus, one of the inventions of this project is a new piece of software that can run on an ordinary smartphone or smartwatch, and that can measure your heart-rate and respiration, even when your phone is in your pocket or in your hand. &nbsp;It requires no special sensors; it only requires that you hold still, so it can detect very subtle movements from the heart and lungs. &nbsp;We showed that it was accurate with an error of less than 2.2 heart-beats per minute, and less than 1.2 breaths per minute. &nbsp;</p>\n<p>Another significant outcome of this project is the StoryScape software that you can use at https://storyscape.io or download from the Google Play store. StoryScape makes it easy for people with very different levels of ability to collaborate and create amazing stories -- stories where you, with a couple easy clicks on your phone or tablet, can insert your own face or voice into your story, and share with your friends to play the story on their phone or tablet. &nbsp;The stories can also interact with your physical world - so if you touch, say, the lightening bolt in your story, it can make the light flash for real in your physical room. Stories can also be made to respond to simple shaking gestures, touches, or sounds made by the reader.&nbsp;</p>\n<p>Finally,       we developed a number of statistical methods and web-based tools       that enable a broad array of scientists and practitioners to more       easily visualize, analyze, and understand relationships between       physiology and behavior in individuals with and without autism and       their interaction partners.</p>\n<p>This work had led to many useful products - including many published papers, a book, a patent, and software that can be used by the general public.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2015<br>\n\t\t\t\t\tModified by: Rosalind&nbsp;W&nbsp;Picard</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2015/1029585/1029585_10021039_1448422907971_biophone--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2015/1029585/1029585_10021039_1448422907971_biophone--rgov-800width.jpg\" title=\"BioPhone\"><img src=\"/por/images/Reports/POR/2015/1029585/1029585_10021039_1448422907971_biophone--rgov-66x44.jpg\" alt=\"BioPhone\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">MIT has shown a new way to use the built-in motions sensors of your phone in order to read your heart-rate and respiration when you are holding your phone still, e.g. while listening to a friend on your phone.</div>\n<div class=\"imageCredit\">Javier Hernandez</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Rosalind&nbsp;W&nbsp;Picard</div>\n<div class=\"imageTitle\">BioPhone</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2015/1029585/1029585_10021039_1448422459276_bioglass--rg...",
  "por_txt_cntn": "\n \n\nThis project has led to new technologies and methods to better understand human behavior and facilitate improved human communication. Our work has been inspired by interactions with people for whom social-emotional and verbal communication can be unusually difficult and challenging, such as people on the autism spectrum. In working with these learners and understanding their huge levels of stress, we decided one of the things that was needed was better tools that make it easier and lower-cost to quantify stress-related physiology.\n\nThus, one of the inventions of this project is a new piece of software that can run on an ordinary smartphone or smartwatch, and that can measure your heart-rate and respiration, even when your phone is in your pocket or in your hand.  It requires no special sensors; it only requires that you hold still, so it can detect very subtle movements from the heart and lungs.  We showed that it was accurate with an error of less than 2.2 heart-beats per minute, and less than 1.2 breaths per minute.  \n\nAnother significant outcome of this project is the StoryScape software that you can use at https://storyscape.io or download from the Google Play store. StoryScape makes it easy for people with very different levels of ability to collaborate and create amazing stories -- stories where you, with a couple easy clicks on your phone or tablet, can insert your own face or voice into your story, and share with your friends to play the story on their phone or tablet.  The stories can also interact with your physical world - so if you touch, say, the lightening bolt in your story, it can make the light flash for real in your physical room. Stories can also be made to respond to simple shaking gestures, touches, or sounds made by the reader. \n\nFinally,       we developed a number of statistical methods and web-based tools       that enable a broad array of scientists and practitioners to more       easily visualize, analyze, and understand relationships between       physiology and behavior in individuals with and without autism and       their interaction partners.\n\nThis work had led to many useful products - including many published papers, a book, a patent, and software that can be used by the general public.\n\n\t\t\t\t\tLast Modified: 11/30/2015\n\n\t\t\t\t\tSubmitted by: Rosalind W Picard"
 }
}