{
 "awd_id": "1007513",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Computer-intensive methods for nonparametric time series analysis'",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2010-05-15",
 "awd_exp_date": "2014-04-30",
 "tot_intn_awd_amt": 274986.0,
 "awd_amount": 274986.0,
 "awd_min_amd_letter_date": "2010-05-12",
 "awd_max_amd_letter_date": "2012-02-23",
 "awd_abstract_narration": "The project focuses on the development of  methods of inference for the analysis of time series and random fields that do not rely on unrealistic or unverifiable model assumptions. In particular, the investigator and his colleagues are working on: (a) extending the range of  applicability of the AR-sieve bootstrap  beyond the setting of linear time series; (b) devising  a new Time-Frequency bootstrap procedure in which bootstrap pseudo-series are generated in the time domain although the resampling happens in the frequency domain; (c) devising a residual bootstrap scheme with larger resample size to be used for improved density estimation from time series data; (d) constructing an automatic method of efficient aggregation of spectral density estimators; (e)  testing for the support of a density, as well as testing for overdifferencing and estimating the   spectral density at a vanishing point; (f) devising an improved block bootstrap procedure to handle time series that are periodically or almost periodically correlated; (g)  resampling and inference for locally  stationary time series and inhomogeneous (but locally homogeneous) marked point processes; and (h) investigating  different aspects of resampling   with functional data,  including the difficult problem of   appropriately studentizing a functional statistic.\r\n\r\n\r\nEver since the fundamental recognition of the potential role of the computer in modern statistics, the bootstrap and other computer-intensive statistical methods have been developed extensively for inference with independent data.  Such methods are even more important in the context of dependent data   where  the distribution theory for estimators and tests statistics may be  difficult or impractical to obtain.   Furthermore, the recent information explosion   has resulted in data sets of unprecedented size that call for flexible, nonparametric, computer-intensive  methods of data analysis. Time series analysis in particular  is vital in many diverse scientific disciplines, e.g., in economics, engineering, acoustics,  geostatistics, biostatistics,  medicine, ecology, forestry, seismology, and meteorology.  As a consequence of the proposal's development of efficient and robust methods for the statistical analysis of dependent data,   more accurate and reliable  inferences may be  drawn from  data sets of practical import resulting into appreciable benefits to society.  Examples include data from  meteorology/atmospheric science, such as climate data, economics, such as stock market returns, medicine, such as EEG data, and bioinformatics, such as genomic data.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dimitris",
   "pi_last_name": "Politis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dimitris Politis",
   "pi_email_addr": "dpolitis@ucsd.edu",
   "nsf_id": "000178487",
   "pi_start_date": "2010-05-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 GILMAN DR",
  "perf_city_name": "LA JOLLA",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 92396.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 90692.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 91898.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Starting at the latter part of the 20th century, statisticians have been gradually<br />moving away from parametric models that often rely on restrictive and/or<br />unreliable assumptions, and going towards nonparametric models that are more flexible. Bootstrap methods---also known as `resampling&rsquo;--have been<br />instrumental in that respect since they provide practitioners with a general<br />way to conduct statistical inference in the nonparametric context (e.g.<br />hypothesis tests and confidence intervals) thus effectively replacing R.A. Fisher&rsquo;s Maximum Likelihood inference that is only valid under a narrowly specified parametric model.<br /><br />The computer-intensive methodology of Model-Free prediction was developed under this project, and is expected to have an impact on the field as it pushes the nonparametric envelope a bit further. In the important setting of nonparametric regression, the Model-Free paradigm shows that an additive model is not needed in order to conduct statistical inference, i.e., estimation, prediction, confidence intervals, etc.. Hence, the practitioner can proceed<br />with nonparametric inference under great generality without worrying about the validity of an assumed additive model (and without any apparent loss of accuracy). Until now, practitioners have been going to great lengths (via transformations and other means) to secure an additive model for their problem at hand---but some settings may defy such efforts. By contrast, the need of preliminary transformations and data preprocessing---a main stay of statistical practice for over a hundred years---is now rendered unnecessary and superfluous under the Model-Free paradigm.<br /><br />Another important class of problems involves time series data, i.e., observations obtained over time. Examples include data from meteorology/atmospheric science&nbsp;(e.g. climate data), economics (e.g. stock market returns), biostatistics and bioinformatics (e.g. fMRI data),<br />etc. In this context, the PI and other researches have been devising different resampling algorithms with the purpose of capturing the dependence/correlation that this type of data invariably exhibit. One such new development is the linear process bootstrap proposed by the PI and collaborators in 2010.&nbsp; An older method is the autoregressive sieve<br />bootstrap proposed 25 years ago. Both of these methods have been thought to be valid only for linear time series. Nevertheless, many time series of interest are well-known to be nonlinear; a prime example is financial returns data. In a breakthrough paper of 2011, the PI and co-authors were able to extend the applicability of the autoregressive sieve bootstrap and related methods to nonlinear time series; a similar extension of validity was also proven to hold for the linear process bootstrap.<br /><br />In addition, the PI and collaborators developed resampling methods that are<br />applicable in other useful albeit complicated settings involving correlated<br />data. One such setting has to do with time series that exhibit seasonal<br />variation, e.g., annual variation due to the seasons, or daily variation; for<br />example, consider a time series of a city&rsquo;s electricity demand measured monthly (seasonal variation) or hourly (daily variation). Another interesting setting has to do with measurements that are not obtained at regular time intervals, e.g. daily; the setting of irregularly observed dependent data comes under the general heading of a `marked point process&rsquo;. The PI and co-authors have recently proposed resampling methods for marked point processes that may also&nbsp; exhibit some degree of nonstationarity.<br /><br />The recent work on bootstrap methods for complicated dependent data (nonlinear/nonstationary&nbsp; time series, marked point processes, etc.)<br />has rekindled the interest of practitioners in the subject. The PI r...",
  "por_txt_cntn": "\nStarting at the latter part of the 20th century, statisticians have been gradually\nmoving away from parametric models that often rely on restrictive and/or\nunreliable assumptions, and going towards nonparametric models that are more flexible. Bootstrap methods---also known as `resampling\u00c6--have been\ninstrumental in that respect since they provide practitioners with a general\nway to conduct statistical inference in the nonparametric context (e.g.\nhypothesis tests and confidence intervals) thus effectively replacing R.A. Fisher\u00c6s Maximum Likelihood inference that is only valid under a narrowly specified parametric model.\n\nThe computer-intensive methodology of Model-Free prediction was developed under this project, and is expected to have an impact on the field as it pushes the nonparametric envelope a bit further. In the important setting of nonparametric regression, the Model-Free paradigm shows that an additive model is not needed in order to conduct statistical inference, i.e., estimation, prediction, confidence intervals, etc.. Hence, the practitioner can proceed\nwith nonparametric inference under great generality without worrying about the validity of an assumed additive model (and without any apparent loss of accuracy). Until now, practitioners have been going to great lengths (via transformations and other means) to secure an additive model for their problem at hand---but some settings may defy such efforts. By contrast, the need of preliminary transformations and data preprocessing---a main stay of statistical practice for over a hundred years---is now rendered unnecessary and superfluous under the Model-Free paradigm.\n\nAnother important class of problems involves time series data, i.e., observations obtained over time. Examples include data from meteorology/atmospheric science (e.g. climate data), economics (e.g. stock market returns), biostatistics and bioinformatics (e.g. fMRI data),\netc. In this context, the PI and other researches have been devising different resampling algorithms with the purpose of capturing the dependence/correlation that this type of data invariably exhibit. One such new development is the linear process bootstrap proposed by the PI and collaborators in 2010.  An older method is the autoregressive sieve\nbootstrap proposed 25 years ago. Both of these methods have been thought to be valid only for linear time series. Nevertheless, many time series of interest are well-known to be nonlinear; a prime example is financial returns data. In a breakthrough paper of 2011, the PI and co-authors were able to extend the applicability of the autoregressive sieve bootstrap and related methods to nonlinear time series; a similar extension of validity was also proven to hold for the linear process bootstrap.\n\nIn addition, the PI and collaborators developed resampling methods that are\napplicable in other useful albeit complicated settings involving correlated\ndata. One such setting has to do with time series that exhibit seasonal\nvariation, e.g., annual variation due to the seasons, or daily variation; for\nexample, consider a time series of a city\u00c6s electricity demand measured monthly (seasonal variation) or hourly (daily variation). Another interesting setting has to do with measurements that are not obtained at regular time intervals, e.g. daily; the setting of irregularly observed dependent data comes under the general heading of a `marked point process\u00c6. The PI and co-authors have recently proposed resampling methods for marked point processes that may also  exhibit some degree of nonstationarity.\n\nThe recent work on bootstrap methods for complicated dependent data (nonlinear/nonstationary  time series, marked point processes, etc.)\nhas rekindled the interest of practitioners in the subject. The PI recently\nco-organized a workshop on Bootstrap Methods for Time Series that took place in Copenhagen, Sept 8-10, 2013. In addition, the PI has accepted to be Guest Editor of the Journal of Time Series Analysis for..."
 }
}