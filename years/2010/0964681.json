{
 "awd_id": "0964681",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Medium: Learned Dynamic Prioritization",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2010-08-15",
 "awd_exp_date": "2014-07-31",
 "tot_intn_awd_amt": 899976.0,
 "awd_amount": 899976.0,
 "awd_min_amd_letter_date": "2010-08-16",
 "awd_max_amd_letter_date": "2012-08-13",
 "awd_abstract_narration": "This project uses machine learning to accelerate the execution of a class of computer programs relevant to AI.  Given a program and a class of inputs, the new methods automatically seek execution strategies that are fast while still achieving a high level of accuracy.\r\n\r\nThe project focuses on the main inference algorithms that underlie statistical AI: dynamic programming, belief propagation, Markov chain Monte Carlo, and backtracking search.  Each of these inference algorithms faces an enormous search space, iteratively extending or refining its picture of this space.  Each algorithm must continually choose which computational step to take next.\r\n\r\nThe opportunity is to learn a strategy for making these choices. Some choices are on the \"critical path\" and help the system find an accurate output, while others lead mainly to wasted work.  The learned strategy for evaluating choices in context may itself be computationally intensive, so the method learns to speed that up as well, within the same framework.\r\n\r\nThe project will disseminate software and will have broader impact on several fields.  The targeted algorithms are central to natural language processing, speech processing, machine vision, computational biology, health informatics and music processing.  Their ability to form a coherent global analysis of a set of observations is a hallmark of intelligence, and will enable artificial systems that aid human understanding and performance.  Speeding them up is critical as researchers develop increasingly sophisticated statistical models.\r\nFurthermore, the learning methodologies developed will be useful in other settings that attempt to learn computational or behavioral strategies.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jason",
   "pi_last_name": "Eisner",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jason M Eisner",
   "pi_email_addr": "jason@cs.jhu.edu",
   "nsf_id": "000185365",
   "pi_start_date": "2010-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Hal",
   "pi_last_name": "Daume",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hal Daume",
   "pi_email_addr": "hal@umiacs.umd.edu",
   "nsf_id": "000445461",
   "pi_start_date": "2010-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "3400 N CHARLES ST",
  "perf_city_name": "BALTIMORE",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182608",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 295236.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 298251.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 306489.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Building more intelligent computer systems means asking our computers to do deeper reasoning over more data. Unfortunately, the more we ask of our systems, the slower they are. The good news is that we can turn AI's learning techniques back on the very problem of speeding up the system. Our project devised ways for computers to discover shortcuts.</span></p>\n<p><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Humans are not perfect reasoners, but humans make good decisions most of the time. A skilled human such as a chessmaster has acquired a mental playbook that covers what to do in a large number of common circumstances. In reasoning about the world, a human can make reasonable guesses from relevant and easily available evidence, without considering every datum or reasoning through every possible consequence.</span></p>\n<p><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">In the same way, our systems are able to learn cheap tricks that bypass or approximate portions of the reasoning process, or rely on superficial cues, so long as the results remain sufficiently accurate. </span></p>\n<p><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">To build such a system, we first define a space of possible \"policies\" that a system can follow to do approximate reasoning or decision-making.&nbsp; We then explicitly train the system to optimize a user-specified combination of speed and accuracy, rather than accuracy alone as is traditional.&nbsp; In other words, we search the space of possible policies for an actual policy that achieves a good tradeoff.&nbsp; In general, this is a difficult and computationally intensive search problem.<br /></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/25/2014<br>\n\t\t\t\t\tModified by: Jason&nbsp;M&nbsp;Eisner</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nBuilding more intelligent computer systems means asking our computers to do deeper reasoning over more data. Unfortunately, the more we ask of our systems, the slower they are. The good news is that we can turn AI's learning techniques back on the very problem of speeding up the system. Our project devised ways for computers to discover shortcuts.\n\nHumans are not perfect reasoners, but humans make good decisions most of the time. A skilled human such as a chessmaster has acquired a mental playbook that covers what to do in a large number of common circumstances. In reasoning about the world, a human can make reasonable guesses from relevant and easily available evidence, without considering every datum or reasoning through every possible consequence.\n\nIn the same way, our systems are able to learn cheap tricks that bypass or approximate portions of the reasoning process, or rely on superficial cues, so long as the results remain sufficiently accurate. \n\nTo build such a system, we first define a space of possible \"policies\" that a system can follow to do approximate reasoning or decision-making.  We then explicitly train the system to optimize a user-specified combination of speed and accuracy, rather than accuracy alone as is traditional.  In other words, we search the space of possible policies for an actual policy that achieves a good tradeoff.  In general, this is a difficult and computationally intensive search problem.\n\n\n\t\t\t\t\tLast Modified: 11/25/2014\n\n\t\t\t\t\tSubmitted by: Jason M Eisner"
 }
}