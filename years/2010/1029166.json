{
 "awd_id": "1029166",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research:  Understanding Climate Change: A Data Driven Approach",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 900000.0,
 "awd_amount": 900000.0,
 "awd_min_amd_letter_date": "2010-08-19",
 "awd_max_amd_letter_date": "2012-09-14",
 "awd_abstract_narration": "Understanding Climate Change: A Data Driven Approach\r\n\r\nClimate change is the defining environmental challenge now facing our planet. Whether it is an increase in the frequency or intensity of hurricanes, rising sea levels, droughts, floods, or extreme temperatures and severe weather, the social, economic, and environmental consequences are great as the resource-stressed planet nears 7 billion inhabitants later this century. Yet there is considerable uncertainty as to the social and environmental impacts because the predictive potential of numerical models of the earth system is limited. These models are incapable of addressing important questions relating to food security, water resources, biodiversity, mortality, and other socio-economic issues over relevant time and spatial scales.\r\n\r\nClimate model development has contributed small and incremental improvements; however, extensive modeling gains have not been forthcoming. Modeling limitations have hampered efforts at providing information on climate change impacts and adaptation and mitigation strategies. A new and transformative approach is required to improve prediction of the potential impacts on human welfare. Data driven methods that have been highly successful in other facets of the computational sciences are now being used in the environmental sciences with success. This Expedition project will significantly advance key challenges in climate change science developing exciting and innovative new data driven approaches that take advantage of the wealth of climate and ecosystem data now available from satellite and ground-based sensors, the observational record for atmospheric, oceanic, and terrestrial processes, and physics-based climate model simulations.\r\n\r\nTo realize this ambitious goal, novel methodologies appropriate to climate change science will be developed in four broad areas of data-intensive computer science: relationship mining, complex networks, predictive modeling, and high performance computing.  Analysis and discovery approaches will be cognizant of climate and ecosystem data characteristics, such as non-stationarity, nonlinear processes, multi-scale nature, low-frequency variability, long-range spatial dependence, and long-memory temporal processes such as teleconnections. These innovative new approaches will be used to better understand the complex nature of the earth system and the mechanisms contributing to such climate change phenomena as hurricane frequency and intensity in the tropical Atlantic, precipitation regime shifts in the ecologically sensitive African Sahel or the Southern Great Plains, and the propensity for extreme weather events that weaken our infrastructure and result in environmental disasters with economic losses in excess of $100 billion per year in the U.S. alone.\r\n\r\nAssessments of climate change impacts, which are useful for stakeholders and policymakers, depend critically on regional and decadal scale projections of climate extremes. Thus, climate scientists often need to develop qualitative inferences about inadequately predicted climate extremes based on insights from observations (e.g., increase in hurricane intensity) or conceptual understanding (e.g., relation of wildfires to regional warming or drying and hurricanes to sea surface temperatures). These urgent societal priorities offer fertile grounds for knowledge discovery approaches. In particular, qualitative inferences on climate extremes and impacts may be transformed into quantitative predictive insights based on a combination of hypothesis-guided data analysis and relatively hypothesis-free, yet data-guided discovery processes.\r\n\r\nA primary focus of this Expedition project will be on uncertainty reduction, which can bring the complementary or supplementary skills of physics-based models together with data-guided insights regarding complex climate processes. The systematic evaluation of climate models and their component processes, as well as uncertainty assessments at regional and decadal scales is a fundamental problem that will be addressed. The ability to translate gains in the predictive skills of climate variables to improvements in impact assessments and attributions is a critical requirement for informing policymakers. Novel methodologies will be developed to gain actionable insights from disparate impacts-related datasets as well as for causal attribution or root-cause analysis. \r\n\r\nThis research will be conducted in close collaboration with the climate science community and will complement insights obtained from physics-based climate models.  Improved understanding of salient atmospheric processes will be provided to those contributing to the development and improvement of climate models with the goal of improving predictability. The approaches and formalisms developed in this research are expected to be applicable to a broad range of scientific and engineering problems, which use model simulations to analyze physical processes.  This project will also contribute to efforts in education, diversity, community engagement, and dissemination of tools and computer and atmospheric science findings.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alok",
   "pi_last_name": "Choudhary",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Alok N Choudhary",
   "pi_email_addr": "choudhar@ece.northwestern.edu",
   "nsf_id": "000101070",
   "pi_start_date": "2010-08-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "633 CLARK ST",
  "perf_city_name": "EVANSTON",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602080001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7723",
   "pgm_ref_txt": "EXPERIMENTAL EXPEDITIONS"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "7969",
   "pgm_ref_txt": "FY 2010 Funding for PTR"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 540000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 360000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"Default\">Climate change is the defining environmental challenge now facing our planet. Whether it is rising temperatures, the increasing frequency of hurricanes, or extreme droughts and floods, the social, environmental consequences of climate change are great as the resource-stressed planet nears 9 billion inhabitants by mid-century. Yet there is considerable uncertainty regarding the social and environmental impacts due to the limited capabilities of existing physics-based models of the Earth system. Therefore, a new and transformative approach is required to better understand the climate system and the potential impacts of climate change.</p>\n<p class=\"Default\">&nbsp;</p>\n<p class=\"Default\">Using data-driven approaches, this project aims to address key challenges in understanding climate change and impacts by developing methods that leverage the abundance of climate and ecological data available from satellite and ground-based sensors, and physics-based climate model simulations. As the volume of data is expected to increase roughly 1000-fold over the next 10-20 years, it will be imperative to make use of high performance computing (HPC) solutions in order to process and analyze this data. A comprehensive approach is needed that entails scalability of data access, scaling queries and exploration, scalable and power efficient techniques for data mining on large systems, and the use of accelerators where possible. Moreover, emerging trends in high performance systems do not benefit all stages of the scientific discovery process equally. In particular, there are widening gaps between the capabilities of HPC systems and the ability of application scientists to efficiently store and analyze the data produced by scientific simulations.&nbsp; As such, our project has focused on developing algorithms, software, and tools to accelerate data analysis and I/O to help bridge these gaps.</p>\n<p class=\"Default\">&nbsp;</p>\n<p class=\"Default\">This project has produced several data analysis software libraries that run on large-scale parallel computers. These data analysis libraries include two parallel density-based data clustering algorithms (named DBSCAN and OPTICS), two parallel hierarchical-based clustering algorithms (PINK and SHRINK), a graph-based community detection algorithm (PMEP), a sampling-based spatial data clustering algorithm (AGORAS), a filtering-based geo-statistical interpolation algorithm for spatio-temporal data (Kriging), and a fast maximum clique finder algorithm for graph problems. These algorithms have been developed and evaluated on the supercomputers available in the DOE national laboratories using more than tens of thousands of computer cores. Their source codes are openly available to the public from the URL, http://cucis.ece.northwestern.edu.</p>\n<p class=\"Default\">&nbsp;</p>\n<p class=\"Default\">The other significant product developed from this project is Parallel NetCDF (PnetCDF). PnetCDF is a software library that allows application programs to access files in parallel. The official releases of PnetCDF have been continuously made available to the public in the past five years, from version 1.3.0 to the latest 1.7.0. Many enhancement strategies have been incorporated and demonstrated a significant performance improvement on supercomputers. Some noticeable features include integration to NetCDF library developed at Unidata, a new CDF-5 file format to support large data objects, non-blocking I/O to aggregate small requests for better performance, availability of Fortran and C++ functions, and subfiling to transparently divide a large file to smaller ones to reduce file locking penalty. PnetCDF is now a part of I/O modules of many major large-scale climate applications dunded by NSF and DOE, such as WRF, CQMA, CESM, GCRM, and ACME.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2016<br>\n\t\t\t\t\tModified by: Alok&nbsp;N&nbsp;Choudhary</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Climate change is the defining environmental challenge now facing our planet. Whether it is rising temperatures, the increasing frequency of hurricanes, or extreme droughts and floods, the social, environmental consequences of climate change are great as the resource-stressed planet nears 9 billion inhabitants by mid-century. Yet there is considerable uncertainty regarding the social and environmental impacts due to the limited capabilities of existing physics-based models of the Earth system. Therefore, a new and transformative approach is required to better understand the climate system and the potential impacts of climate change.\n \nUsing data-driven approaches, this project aims to address key challenges in understanding climate change and impacts by developing methods that leverage the abundance of climate and ecological data available from satellite and ground-based sensors, and physics-based climate model simulations. As the volume of data is expected to increase roughly 1000-fold over the next 10-20 years, it will be imperative to make use of high performance computing (HPC) solutions in order to process and analyze this data. A comprehensive approach is needed that entails scalability of data access, scaling queries and exploration, scalable and power efficient techniques for data mining on large systems, and the use of accelerators where possible. Moreover, emerging trends in high performance systems do not benefit all stages of the scientific discovery process equally. In particular, there are widening gaps between the capabilities of HPC systems and the ability of application scientists to efficiently store and analyze the data produced by scientific simulations.  As such, our project has focused on developing algorithms, software, and tools to accelerate data analysis and I/O to help bridge these gaps.\n \nThis project has produced several data analysis software libraries that run on large-scale parallel computers. These data analysis libraries include two parallel density-based data clustering algorithms (named DBSCAN and OPTICS), two parallel hierarchical-based clustering algorithms (PINK and SHRINK), a graph-based community detection algorithm (PMEP), a sampling-based spatial data clustering algorithm (AGORAS), a filtering-based geo-statistical interpolation algorithm for spatio-temporal data (Kriging), and a fast maximum clique finder algorithm for graph problems. These algorithms have been developed and evaluated on the supercomputers available in the DOE national laboratories using more than tens of thousands of computer cores. Their source codes are openly available to the public from the URL, http://cucis.ece.northwestern.edu.\n \nThe other significant product developed from this project is Parallel NetCDF (PnetCDF). PnetCDF is a software library that allows application programs to access files in parallel. The official releases of PnetCDF have been continuously made available to the public in the past five years, from version 1.3.0 to the latest 1.7.0. Many enhancement strategies have been incorporated and demonstrated a significant performance improvement on supercomputers. Some noticeable features include integration to NetCDF library developed at Unidata, a new CDF-5 file format to support large data objects, non-blocking I/O to aggregate small requests for better performance, availability of Fortran and C++ functions, and subfiling to transparently divide a large file to smaller ones to reduce file locking penalty. PnetCDF is now a part of I/O modules of many major large-scale climate applications dunded by NSF and DOE, such as WRF, CQMA, CESM, GCRM, and ACME.\n\n\t\t\t\t\tLast Modified: 11/30/2016\n\n\t\t\t\t\tSubmitted by: Alok N Choudhary"
 }
}