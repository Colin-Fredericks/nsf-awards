{
 "awd_id": "1017952",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "HCC: Small:  Designing Effective Gaze Mechanisms for Cross-Modal Embodied Agents",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Bainbridge",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 499050.0,
 "awd_amount": 499050.0,
 "awd_min_amd_letter_date": "2010-08-16",
 "awd_max_amd_letter_date": "2011-09-30",
 "awd_abstract_narration": "The goal of this project is to design and build gaze mechanisms for embodied agents that can achieve high-level social and communicative goals that people achieve using such mechanisms and that can be applied across a wide range of agent presentations and task domains.\r\n\r\nEmbodied agents promise significant social, cognitive, and organizational benefits through applications in education, training, rehabilitation, and collaborative work. However, in order to be effective across a wide range of applications, agents must be able to use the nonverbal social cues that humans employ in their communication and to employ these cues in whatever modality the agent is presented in - whether it be a social robot, a life-sized virtual human, or an animated avatar on a portable display. Gaze cues are particularly important social signals. Although they are subtle, they can serve as powerful mechanisms for achieving high-level social and communicative goals, such as improving a listener?s comprehension, controlling the flow of a conversation, and indicating interest in or appraisal of objects. This project investigates how such mechanisms might be designed and built for embodied agents and how similar social and communicative goals could be achieved using different agent representations across different task domains.\r\n\r\nThis investigation will involve (1) performing formal observational studies to better understand how people use gaze, (2) developing computational models that synthesize gaze behaviors that can be controlled precisely and retargeted to a range of agent platforms, and (3) evaluating in experimental studies the effectiveness of using gaze cues across a range of agent presentations and task contexts. Success in this project will create new knowledge on human gaze behaviors, connecting the high-level findings in the social science literature to more detailed, low-level cues and mechanisms. It will also produce a set of techniques that are based on this understanding for synthesizing controllable and flexible gaze movements that agents can use in order to achieve social and communicative goals. Finally, it will validate the effectiveness of the use of gaze cues by agents across a variety of agent presentations and task contexts.\r\n\r\nA trans-disciplinary approach will combine rigorous, formal observational studies to build detailed models of human communicative mechanisms with practical efforts to build usable computational models that meet the needs of creating agents that work in real-world tasks. The focus on human models insures that the computational models are well founded, while the focus on developing practical algorithms guides the human studies towards creating understanding that will be most informative for agent design. The project plan involves connecting the disparate communities that work on developing social agents and training students to do the trans-disciplinary work required to create effective embodied agents. The project will also enable K-12 outreach efforts to use robots and connections to social science to engage students and increase participation by under-represented groups.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bilge",
   "pi_last_name": "Mutlu",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Bilge D Mutlu",
   "pi_email_addr": "bilge@cs.wisc.edu",
   "nsf_id": "000546805",
   "pi_start_date": "2010-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Gleicher",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Michael L Gleicher",
   "pi_email_addr": "gleicher@cs.wisc.edu",
   "nsf_id": "000192407",
   "pi_start_date": "2010-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "21 N PARK ST STE 6301",
  "perf_city_name": "MADISON",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537151218",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 194922.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 304128.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Embodied agents, including virtual characters and social robots, promise new interfaces, new products, and new applications in areas including education, training, and rehabilitation, such as a virtual coach that appears on a television screen and guides a patient through a physical therapy program. To successfully assist their users in these areas, agents must display natural, intuitive, and effective social behaviors. The goal of this project was to provide embodied agents with the ability to display social behaviors, particularly gaze behaviors, in the way that humans use them. To achieve this goal, the project team conducted detailed analyses of human gaze behaviors, used this analysis to develop computer algorithms that controlled agent behaviors, and tested whether or not these behaviors helped agents achieve more natural and effective interactions with their users. Following this process, the research team endowed various types of agents with sophisticated gaze capabilities to interact with users across a wide range of scenarios. For instance, the team developed a virtual teacher lecturing in history that gazed at a historical map in a way that improved its student&rsquo;s recall of the locations on the map (see attached images for other examples).</p>\n<p>The algorithms that the research team developed to control agent behaviors and findings from validation studies have significantly improved scientific knowledge on the topic and practical methods for developing real-world applications that benefit society, resulting in a large number of scientific publications. The findings from the project have also been shared with the public through articles, video stories, and radio interviews in the popular press. The project provided three doctoral students in computer science with opportunities for advanced training and professional development, establishing the foundation for three doctoral dissertations in computer science. Several undergraduate students in computer science also engaged in project activities, gaining hands-on research experience and receiving academic mentoring. The research team carried out a number of activities that aimed at informing the public about embodied agents and research findings from the project, including several &ldquo;open lab&rdquo; events, multiple sessions of a two-day summer program that provided children and their grandparents with the opportunity to learn about and gain hands-on experience with social robotics, and public talks for K-12 groups and local communities.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/05/2014<br>\n\t\t\t\t\tModified by: Bilge&nbsp;D&nbsp;Mutlu</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2014/1017952/1017952_10020645_1417811577765_Figures_Agent1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2014/1017952/1017952_10020645_1417811577765_Figures_Agent1--rgov-800width.jpg\" title=\"Life-sized virtual agent\"><img src=\"/por/images/Reports/POR/2014/1017952/1017952_10020645_1417811577765_Figures_Agent1--rgov-66x44.jpg\" alt=\"Life-sized virtual agent\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A life-sized virtual agent uses gaze to effectively engage in conversations</div>\n<div class=\"imageCredit\">University of Wisconsin\u00fbMadison Human-Computer Interaction Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Lif...",
  "por_txt_cntn": "\nEmbodied agents, including virtual characters and social robots, promise new interfaces, new products, and new applications in areas including education, training, and rehabilitation, such as a virtual coach that appears on a television screen and guides a patient through a physical therapy program. To successfully assist their users in these areas, agents must display natural, intuitive, and effective social behaviors. The goal of this project was to provide embodied agents with the ability to display social behaviors, particularly gaze behaviors, in the way that humans use them. To achieve this goal, the project team conducted detailed analyses of human gaze behaviors, used this analysis to develop computer algorithms that controlled agent behaviors, and tested whether or not these behaviors helped agents achieve more natural and effective interactions with their users. Following this process, the research team endowed various types of agents with sophisticated gaze capabilities to interact with users across a wide range of scenarios. For instance, the team developed a virtual teacher lecturing in history that gazed at a historical map in a way that improved its student\u00c6s recall of the locations on the map (see attached images for other examples).\n\nThe algorithms that the research team developed to control agent behaviors and findings from validation studies have significantly improved scientific knowledge on the topic and practical methods for developing real-world applications that benefit society, resulting in a large number of scientific publications. The findings from the project have also been shared with the public through articles, video stories, and radio interviews in the popular press. The project provided three doctoral students in computer science with opportunities for advanced training and professional development, establishing the foundation for three doctoral dissertations in computer science. Several undergraduate students in computer science also engaged in project activities, gaining hands-on research experience and receiving academic mentoring. The research team carried out a number of activities that aimed at informing the public about embodied agents and research findings from the project, including several \"open lab\" events, multiple sessions of a two-day summer program that provided children and their grandparents with the opportunity to learn about and gain hands-on experience with social robotics, and public talks for K-12 groups and local communities.\n\n\t\t\t\t\tLast Modified: 12/05/2014\n\n\t\t\t\t\tSubmitted by: Bilge D Mutlu"
 }
}