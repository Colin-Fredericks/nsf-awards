{
 "awd_id": "1012042",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Large: Collaborative Research:  Compact Representations and Efficient Algorithms for Distributed Geometric Data",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 433000.0,
 "awd_amount": 433000.0,
 "awd_min_amd_letter_date": "2010-08-22",
 "awd_max_amd_letter_date": "2010-08-22",
 "awd_abstract_narration": "Across many fields of science, engineering, and business, massive data sets are being generated at unprecedented rate by high-bandwidth sensors and cameras, large-scale simulations, or web-enabled large scale data collection.  Much of this data has a geometric character, either directly or indirectly.   For example, second generation LiDARs can map the earth's surface at 15-20 cm resolution; the Large Synoptic Telescope is set to produce about 30 terabytes of data each night; thirteen hours of video are uploaded to YouTube every minute; Facebook manages over 40 billion photos requiring more than one petabyte of data.\r\n\r\nThese data sets provide tremendous opportunities to enable novel capabilities that were unimaginable a few years ago.  Capitalizing on these opportunities, however, and transforming these massive amounts of heterogeneous data into useful information for vastly different types of applications and users requires solving challenging algorithmic problems.  An effective way of addressing this challenge is by designing efficient methods for producing informative yet succinct summaries of such geometric data sets.  These summaries must work at multiple scales, and allow a wide variety of queries to be answered approximately but efficiently.  The goal of this project is to study the theoretical underpinnings of compact representations and efficient algorithms for organizing, summarizing, cross-correlating, interlinking, and querying large distributed geometric data sets.\r\n\r\nThis project will design methods for computing summaries of many kinds of flavors, all with provable properties.  Summaries can be combinatorial and metric (core sets and kernels), algebraic (linear sketches), topological (persistence diagrams), feature-based, and structural (encoding self-similarities in the data).  The properties they aim to capture extend from low-level metric attributes, such as the diameter or width of a point set, to higher-level attributes revealing the internal structure of the data, as in the detection of symmetries and repeated patterns.  This processing must be done in the presence of uncertainty in data coming from sensors, and optimize multiple performance measures, including communication cost for data distributed across multiple locations in a network.  Another key aspect of this project is that it aims to understand not individual data sets in isolation but rather the inter-relationships and correspondences among different data sets, and to do so by communicating only summary information, without even having all the data in one place. \r\n\r\nThis work touches upon many topics in theoretical computer science and applied mathematics including low-distortion embeddings, compressive sensing, transportation metrics, spectral graph theory or harmonic analysis, machine learning, and computational topology.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Piotr",
   "pi_last_name": "Indyk",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Piotr Indyk",
   "pi_email_addr": "indyk@mit.edu",
   "nsf_id": "000488958",
   "pi_start_date": "2010-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 MASSACHUSETTS AVE",
  "perf_city_name": "CAMBRIDGE",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "792900",
   "pgm_ele_name": "COMPUTATIONAL GEOMETRY"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 433000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div>\n<p>The goal of this project was to design methods for computing compact summaries of massive data sets, such as large collections of images or audio signals.&nbsp; Such summaries preserve important properties of the data, but are significantly smaller than the full data sets. This makes it possible to analyze and process them much more efficiently, leading to time, space, or energy savings.</p>\n<p>&nbsp;As a result of this project, several such summaries and associated algorithms have been discovered. Our contributions include the following:</p>\n<p>- We have developed algorithms for approximating the Discrete Fourier Transform (DFT) of a signal from its random samples. The DFT is a powerful tool used in many applications involving big data. Multimedia data sets, including video, audio, and images, are typically processed in the frequency domain to compress the data or extract interesting features. The standard approach to computing the DFT is via the Fast Fourier Transform (FFT) algorithm, an efficient algorithm developed in the 1960s. Unfortunately, the running time of the FFT is (more than) linear in the size of the input, which reduces its efficiency for very large signals.</p>\n<p>Our new algorithms (named <strong>Sparse Fourier Transforms</strong>) are significantly faster than the FFT for <strong>sparse</strong>&nbsp;data, i.e., data that exhibits a limited number of dominant frequencies. Many big data problems possess this property. Our methods have already been applied to tasks such as spectrum sensing or GPS synchronization, significantly increasing the time and energy efficiency of these tasks. These findings and other materials related to Sparse Fourier Transforms are described at the publicly available website:&nbsp;</p>\n<p><a href=\"redir.aspx?C=R3JzEx674UuA36saoN1A5CGLONOGkNIIhv2l4na1hvxHRzOFgidspr3ovoIkHBPvkGQO1iEBVU4.&amp;URL=http%3a%2f%2fgroups.csail.mit.edu%2fnetmit%2fsFFT%2f\" target=\"_blank\">http://groups.csail.mit.edu/netmit/sFFT/</a></p>\n<p>- We have developed a new data summarization technique, named &nbsp;<strong>composable core-sets</strong>. Core-sets are small subsets of the data with the property that the value of a given objective function of interest computed over the core-set is approximately the same as the value corresponding to the whole data set. Core-sets are <strong>composable</strong> if one can aggregate several of them together to obtain a summary of the whole data set.&nbsp;</p>\n<p>&nbsp;Composable core-sets are useful in large-scale distributed data processing scenarios where multiple servers hold different parts of the data, and one needs to aggregate them to obtain the \"big picture\". Using our methods, the servers only need to communicate the (small) core-sets, as opposed to the whole data sets, which makes the process much more efficient.&nbsp; Our techniques apply to important computational problems such as clustering and&nbsp;diversity-aware summarization and search.</p>\n<p>We have also developed other summarization techniques, such as adaptive compressive sensing &nbsp;and&nbsp;compressive sensing for local features.&nbsp;</p>\n</div>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/12/2015<br>\n\t\t\t\t\tModified by: Piotr&nbsp;Indyk</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThe goal of this project was to design methods for computing compact summaries of massive data sets, such as large collections of images or audio signals.  Such summaries preserve important properties of the data, but are significantly smaller than the full data sets. This makes it possible to analyze and process them much more efficiently, leading to time, space, or energy savings.\n\n As a result of this project, several such summaries and associated algorithms have been discovered. Our contributions include the following:\n\n- We have developed algorithms for approximating the Discrete Fourier Transform (DFT) of a signal from its random samples. The DFT is a powerful tool used in many applications involving big data. Multimedia data sets, including video, audio, and images, are typically processed in the frequency domain to compress the data or extract interesting features. The standard approach to computing the DFT is via the Fast Fourier Transform (FFT) algorithm, an efficient algorithm developed in the 1960s. Unfortunately, the running time of the FFT is (more than) linear in the size of the input, which reduces its efficiency for very large signals.\n\nOur new algorithms (named Sparse Fourier Transforms) are significantly faster than the FFT for sparse data, i.e., data that exhibits a limited number of dominant frequencies. Many big data problems possess this property. Our methods have already been applied to tasks such as spectrum sensing or GPS synchronization, significantly increasing the time and energy efficiency of these tasks. These findings and other materials related to Sparse Fourier Transforms are described at the publicly available website: \n\nhttp://groups.csail.mit.edu/netmit/sFFT/\n\n- We have developed a new data summarization technique, named  composable core-sets. Core-sets are small subsets of the data with the property that the value of a given objective function of interest computed over the core-set is approximately the same as the value corresponding to the whole data set. Core-sets are composable if one can aggregate several of them together to obtain a summary of the whole data set. \n\n Composable core-sets are useful in large-scale distributed data processing scenarios where multiple servers hold different parts of the data, and one needs to aggregate them to obtain the \"big picture\". Using our methods, the servers only need to communicate the (small) core-sets, as opposed to the whole data sets, which makes the process much more efficient.  Our techniques apply to important computational problems such as clustering and diversity-aware summarization and search.\n\nWe have also developed other summarization techniques, such as adaptive compressive sensing  and compressive sensing for local features. \n\n\n \n\n\t\t\t\t\tLast Modified: 07/12/2015\n\n\t\t\t\t\tSubmitted by: Piotr Indyk"
 }
}