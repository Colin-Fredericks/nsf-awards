{
 "awd_id": "1011919",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "HCC: Large: Collaborative Research:  Beyond Flat Images:  Acquiring, Processing and Fabricating Visually Rich Material Appearance",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 999962.0,
 "awd_amount": 999962.0,
 "awd_min_amd_letter_date": "2010-08-20",
 "awd_max_amd_letter_date": "2014-07-04",
 "awd_abstract_narration": "Despite revolutionary advances in how images are recorded, manipulated, and reproduced, our ability to re-create the visual experience remains remarkably limited.  Few realistic computer models exist for the characteristic appearance of natural materials such as marble, wood, coral, or skin, or man-made ones such as color-shifting automotive paints.  Digitizing and creating realistic images of these substances involves reproducing their interaction with light:  the way light is reflected from surfaces, or scattered and absorbed within the materials.  Full reproducibility also involves \"printing\" a material as a real, physical object that modulates the light around us. However, it is currently impossible to output complex appearance the way we print color on a paper with fixed gloss, or create shapes using a 3D printer. This project encompasses a comprehensive, collaborative research agenda in computer graphics and related areas, to develop an end-to-end framework for acquiring, representing, and fabricating complex appearance, as well as to understand how it is perceived by the human visual system.\r\n\r\nThe enabling technical idea of the project is to treat materials as thin three-dimensional volumes populated with general scattering sites. This is a radical departure from the hitherto standard approach in computer graphics, which has studied materials purely as surfaces.  The volumetric representation subsumes and generalizes the diverse set of conventional representations that currently exist in graphics, including surface-based notions such as bidirectional reflectance (BRDF), spatially varying BRDF, and subsurface scattering distributions (BSSRDF).  Moreover, it enables fundamentally improved approaches to efficient yet general acquisition, fast and realistic rendering, and fabrication of objects exhibiting phenomena beyond simple surface reflectance and spatially homogeneous subsurface scattering.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Steve",
   "pi_last_name": "Marschner",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Steve Marschner",
   "pi_email_addr": "srm@cs.cornell.edu",
   "nsf_id": "000302708",
   "pi_start_date": "2010-08-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kavita",
   "pi_last_name": "Bala",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kavita Bala",
   "pi_email_addr": "kb@cs.cornell.edu",
   "nsf_id": "000179613",
   "pi_start_date": "2010-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "341 PINE TREE RD",
  "perf_city_name": "ITHACA",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148502820",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 239537.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 387883.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 72583.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 267539.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 32420.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-5f188abb-cdbb-90fc-6f09-e935e0dac710\"> </span></p>\n<p dir=\"ltr\"><span>Acquisition</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>Measuring the optical properties of materials involves sending photons toward an object and using cameras to record where they arrive after interacting with the object. Photons take different paths, each undergoing a different combination of scattering, reflection, and refraction inside the object or at its surface. What makes measurement challenging is that each of a camera&rsquo;s pixels records a sum of many such photons: to recover the material properties, one must &ldquo;undo&rdquo; these per-pixel sums, determining which paths were travelled by the measured photons, and what events occurred along the paths.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>In this project, in collaboration with colleagues at the Weizmann Institute of Science and at MIT, we established a foundation for solving these kinds of measurement problems, leading to papers in SIGGRAPH Asia 2013 and SIGGRAPH 2015. The first paper developed mathematical and computational tools for searching the space of possible material properties for those that match any acquired set of photographs. The second introduced an acquisition system that exploits the wave nature of light to produce a richer set of images than conventional photographs: images that not only record where photons arrive but also the precise length of the paths that they travel between source and camera. Together, our theory and acquisition system create opportunities for measuring optical material properties with unprecedented generality, precision, and accuracy.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>Rendering</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>The complex knit or woven structure of cloth creates appearances from smooth and shiny to rough and matte to thick and velvety. &nbsp;In this project we developed micro-appearance models, a new approach to fabric rendering that handles this full range of complexity by explicitly modeling the structure of the material. Using a micro CT scanner to capture micron-scale fiber structure, then simulating the interaction of light with this structure, we produced arguably the most realistic rendered fabrics to date. Through a series of four SIGGRAPH papers, our research first made richly detailed models of simple fabrics, then modeled complex fabrics directly from their weave patterns, and finally explored how to accelerate the rendering process and how to match the results to measurements of real fabrics.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>Another appearance phenomenon in which small structures play a crucial role is that of glints and glitter: surfaces ranging from freshly fallen snow to car paints to sandblasted metal that display complex highlights that change with view and illumination. &nbsp;A collaborative team tackled this topic from two angles, producing a pair of methods reported in two SIGGRAPH papers. &nbsp;One provides an efficient procedural model for random surface structure; the other treats details generally and accurately using a high-resolution detail map. &nbsp;Both method efficiently produce renderings of glinty surfaces, even when illuminated by sharp lighting such as sunlight, which was formerly completely impractical.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>Perception</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>Our ability to effectively design, edit, and render translucent materials like milk, soap, and wax depends on our understanding of how humans perceive translucency. While it is clear that human observers care greatly about translucent appearance in many cases -- as when they distinguish milk from cream, or marble from Formica -- even basic questions about how this occurs remain unanswered.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>During the award period we collaborated with colleagues at MI...",
  "por_txt_cntn": "\n \nAcquisition\n\n \nMeasuring the optical properties of materials involves sending photons toward an object and using cameras to record where they arrive after interacting with the object. Photons take different paths, each undergoing a different combination of scattering, reflection, and refraction inside the object or at its surface. What makes measurement challenging is that each of a camera\u00c6s pixels records a sum of many such photons: to recover the material properties, one must \"undo\" these per-pixel sums, determining which paths were travelled by the measured photons, and what events occurred along the paths.\n\n \nIn this project, in collaboration with colleagues at the Weizmann Institute of Science and at MIT, we established a foundation for solving these kinds of measurement problems, leading to papers in SIGGRAPH Asia 2013 and SIGGRAPH 2015. The first paper developed mathematical and computational tools for searching the space of possible material properties for those that match any acquired set of photographs. The second introduced an acquisition system that exploits the wave nature of light to produce a richer set of images than conventional photographs: images that not only record where photons arrive but also the precise length of the paths that they travel between source and camera. Together, our theory and acquisition system create opportunities for measuring optical material properties with unprecedented generality, precision, and accuracy.\n\n \nRendering\n\n \nThe complex knit or woven structure of cloth creates appearances from smooth and shiny to rough and matte to thick and velvety.  In this project we developed micro-appearance models, a new approach to fabric rendering that handles this full range of complexity by explicitly modeling the structure of the material. Using a micro CT scanner to capture micron-scale fiber structure, then simulating the interaction of light with this structure, we produced arguably the most realistic rendered fabrics to date. Through a series of four SIGGRAPH papers, our research first made richly detailed models of simple fabrics, then modeled complex fabrics directly from their weave patterns, and finally explored how to accelerate the rendering process and how to match the results to measurements of real fabrics.\n\n \nAnother appearance phenomenon in which small structures play a crucial role is that of glints and glitter: surfaces ranging from freshly fallen snow to car paints to sandblasted metal that display complex highlights that change with view and illumination.  A collaborative team tackled this topic from two angles, producing a pair of methods reported in two SIGGRAPH papers.  One provides an efficient procedural model for random surface structure; the other treats details generally and accurately using a high-resolution detail map.  Both method efficiently produce renderings of glinty surfaces, even when illuminated by sharp lighting such as sunlight, which was formerly completely impractical.\n\n \nPerception\n\n \nOur ability to effectively design, edit, and render translucent materials like milk, soap, and wax depends on our understanding of how humans perceive translucency. While it is clear that human observers care greatly about translucent appearance in many cases -- as when they distinguish milk from cream, or marble from Formica -- even basic questions about how this occurs remain unanswered.\n\n \nDuring the award period we collaborated with colleagues at MIT to perform some of the first qualitative and quantitative analyses of the perception of translucent materials. Using a unique combination of large-scale simulations, psychophysical experiments with human subjects, and data-mining, we studied the perception of objects that are composed of spatially-homogeneous material. We were able to unveil qualitative and quantitative models of how an object\u00c6s appearance is related to the physical properties of the material, and how both of these are related to perception. These res..."
 }
}