{
 "awd_id": "0968489",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SoCS:  Assessing Information Credibility Without Authoritative Sources",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Laura Stanley",
 "awd_eff_date": "2010-07-01",
 "awd_exp_date": "2015-06-30",
 "tot_intn_awd_amt": 749994.0,
 "awd_amount": 765994.0,
 "awd_min_amd_letter_date": "2010-06-23",
 "awd_max_amd_letter_date": "2011-07-21",
 "awd_abstract_narration": "Rumors, smears, and conspiracy theories can now spread quickly through email, blogs, and other social media. Recipients of such messages may not question their validity. Moreover, even upon careful investigation and reflection, not everyone will agree about the validity of particular claims. This project will develop tools that help people make personal assessments of credibility. Rather than relying on particular sources as authoritative arbiters of ground truth, the goal is to minimize the amount of \"social implausibility.\" That is, the tool will identify assertions that are disbelieved by \"similar\" people (those who, after careful consideration, someone tended to agree with in the past) or come from sources that someone has tended to disagree with. A text mining system for online media will be developed to extract controversial assertions and the beliefs expressed by users about those assertions. Comparisons of beliefs about common assertions, and retractions or updates to beliefs, will be tracked as part of personalized reputation measures.\r\n\r\nThis work is the first attempt to formally address the automatic assessment of information credibility based on text mining and social computational systems. The techniques will provide the solution to many challenging research problems in information retrieval and reputation networks. The techniques are broadly applicable to other domains where the credibility of content and reputation of sources is a concern, to help a broad class of information consumers.  Prototype tools will be released freely and demonstrated in high schools, thereby building awareness of the diversity of beliefs around topics of public interest.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Qiaozhu",
   "pi_last_name": "Mei",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Qiaozhu Mei",
   "pi_email_addr": "qmei@umich.edu",
   "nsf_id": "000537865",
   "pi_start_date": "2010-06-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Paul",
   "pi_last_name": "Resnick",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Paul Resnick",
   "pi_email_addr": "presnick@umich.edu",
   "nsf_id": "000185853",
   "pi_start_date": "2010-06-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Dragomir",
   "pi_last_name": "Radev",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Dragomir R Radev",
   "pi_email_addr": "dragomir.radev@yale.edu",
   "nsf_id": "000087661",
   "pi_start_date": "2010-06-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rahul",
   "pi_last_name": "Sami",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rahul Sami",
   "pi_email_addr": "rsami@umich.edu",
   "nsf_id": "000113488",
   "pi_start_date": "2010-06-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "Regents of the University of Michigan - Ann Arbor",
  "perf_str_addr": "1109 GEDDES AVE STE 3300",
  "perf_city_name": "ANN ARBOR",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091015",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "795300",
   "pgm_ele_name": "SOCIAL-COMPUTATIONAL SYSTEMS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7953",
   "pgm_ref_txt": "SOCIAL-COMPUTATIONAL SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 749994.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we developed techniques for detecting, analyzing, and visualizing disputed, fact-checkable claims (or rumors) from the overload of social media posts generated in real time (e.g., 400 million Tweets every day).</p>\n<p>1) We developed a technique for detecting emerging, unverified rumors soon after they start to spread. The technique monitors the real-time stream of public Tweets and tries to identify expressions of skepticism (e.g., &ldquo;Is this true?&rdquo;). These signals come from users who have received a rumor and enquire for the truth. Tweets with these signals are clustered and summarized, and clusters are ranked by the likelihood of being rumors. On a dataset of Tweets related to the Boston Marathon bombing, our detector found 110 distinct rumors, far more than those that received media coverage. Moreover, candidate rumors were detectable, on average, just ten minutes after the first tweet about them. The detector outputs 100 or so candidate rumors per day, of which about a third are real rumors; this volume would be manageable for professional journalists or citizen journalists to take action on.</p>\n<p>2) We developed a technique for collecting all the Tweets related to a rumor and classify them as either spreading or correcting the rumor. This involves an interactive retrieval and classification system. The system automatically generates related queries to find additional Tweets that may be related to the rumor and selects a small subset of Tweets and requests the user to provide judgment labels for each of them: whether it spreads the rumor, corrects it, or is unrelated to the rumor. The labeled Tweets are used to train a classifier, an automatic program that picks up language and social network patterns from human labeled examples of a given rumor and uses them to infer the label of a new Tweet. When there are abundant annotated examples of a rumor, the technique identifies Tweets containing that rumor at an accuracy higher than 90%. Besides collecting rumor Tweets, the interactive retrieval technique can also be used to help scientists to review academic literature, attorneys to review legal documents, and physicians to review electronic health records.</p>\n<p>3) We developed a tool, named the RumerLens, to analyze and visualize the audience of a target rumor once it is detected. Analysts can use this tool to digest the impact of the rumor and its corrections. Some rumors may have reached too small an audience to be worth investigating or reporting on at all. In other cases, the dissemination patterns may themselves be worthy of investigation and reporting. The new visualization tool features an interactive Sankey diagram that makes it easy to see the audience overlap for rumors and corrections, as well as a network diagram that highlights the paths of the spread. We found several interesting cases where correction tweets reached large audiences, but the wrong audiences: almost no one who received the rumor also received a correction. Through a study with 31 users, we found that nonexpert users can easily use this tool to answer questions related to the audience analysis of real rumors.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/19/2015<br>\n\t\t\t\t\tModified by: Qiaozhu&nbsp;Mei</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this project, we developed techniques for detecting, analyzing, and visualizing disputed, fact-checkable claims (or rumors) from the overload of social media posts generated in real time (e.g., 400 million Tweets every day).\n\n1) We developed a technique for detecting emerging, unverified rumors soon after they start to spread. The technique monitors the real-time stream of public Tweets and tries to identify expressions of skepticism (e.g., \"Is this true?\"). These signals come from users who have received a rumor and enquire for the truth. Tweets with these signals are clustered and summarized, and clusters are ranked by the likelihood of being rumors. On a dataset of Tweets related to the Boston Marathon bombing, our detector found 110 distinct rumors, far more than those that received media coverage. Moreover, candidate rumors were detectable, on average, just ten minutes after the first tweet about them. The detector outputs 100 or so candidate rumors per day, of which about a third are real rumors; this volume would be manageable for professional journalists or citizen journalists to take action on.\n\n2) We developed a technique for collecting all the Tweets related to a rumor and classify them as either spreading or correcting the rumor. This involves an interactive retrieval and classification system. The system automatically generates related queries to find additional Tweets that may be related to the rumor and selects a small subset of Tweets and requests the user to provide judgment labels for each of them: whether it spreads the rumor, corrects it, or is unrelated to the rumor. The labeled Tweets are used to train a classifier, an automatic program that picks up language and social network patterns from human labeled examples of a given rumor and uses them to infer the label of a new Tweet. When there are abundant annotated examples of a rumor, the technique identifies Tweets containing that rumor at an accuracy higher than 90%. Besides collecting rumor Tweets, the interactive retrieval technique can also be used to help scientists to review academic literature, attorneys to review legal documents, and physicians to review electronic health records.\n\n3) We developed a tool, named the RumerLens, to analyze and visualize the audience of a target rumor once it is detected. Analysts can use this tool to digest the impact of the rumor and its corrections. Some rumors may have reached too small an audience to be worth investigating or reporting on at all. In other cases, the dissemination patterns may themselves be worthy of investigation and reporting. The new visualization tool features an interactive Sankey diagram that makes it easy to see the audience overlap for rumors and corrections, as well as a network diagram that highlights the paths of the spread. We found several interesting cases where correction tweets reached large audiences, but the wrong audiences: almost no one who received the rumor also received a correction. Through a study with 31 users, we found that nonexpert users can easily use this tool to answer questions related to the audience analysis of real rumors.\n\n \n\n\t\t\t\t\tLast Modified: 12/19/2015\n\n\t\t\t\t\tSubmitted by: Qiaozhu Mei"
 }
}