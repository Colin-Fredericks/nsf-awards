{
 "awd_id": "1049723",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Usability of Voting Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "clifton bingham",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 170000.0,
 "awd_amount": 170000.0,
 "awd_min_amd_letter_date": "2010-08-07",
 "awd_max_amd_letter_date": "2010-08-07",
 "awd_abstract_narration": "This research investigates the usability of a number of remote voting platforms that are among the most viable candidates for fielding as states begin to consider the implementation of remote voting. The main focus of these usability studies is on the use of impoverished-display handheld mobile computers (i.e. smartphones) and traditional landline telephony interfaces delivered using interactive voice response systems, although vote-by-mail, kiosk, personal PC and hybrid systems are also being studied. Usability is being measured using the usability metrics outlined in ISO 9241-11 (effectiveness, efficiency, satisfaction) in order to establish usability baselines for these kinds of remote voting technologies and allow for direct comparisons to usability metrics that have been established for current precinct-based voting systems. This investigation is also aimed at gaining an understanding of the human factors issues that might impact the ability of voters to accurately and successfully cast their ballots with these potential new platforms.  Results from these studies will play an important role in helping voting officials make better informed decisions about the kinds of technologies to consider and the attendant human factors issues as states begin to legislate the adoption of remote voting.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Philip",
   "pi_last_name": "Kortum",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Philip T Kortum",
   "pi_email_addr": "pkortum@rice.edu",
   "nsf_id": "000406157",
   "pi_start_date": "2010-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "William Marsh Rice University",
  "inst_street_address": "6100 MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "Houston",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7133484820",
  "inst_zip_code": "770051827",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "TX09",
  "org_lgl_bus_name": "WILLIAM MARSH RICE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "K51LECU1G8N3"
 },
 "perf_inst": {
  "perf_inst_name": "William Marsh Rice University",
  "perf_str_addr": "6100 MAIN ST",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "770051827",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "TX09",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779500",
   "pgm_ele_name": "TRUSTWORTHY COMPUTING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 170000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Project Outcomes Summary for NSF CNS-1049723: Usability of Voting Systems. Philip Kortum, PI</strong></p>\n<p>This research examined various aspects of the usability of voting systems to further the understanding of how to design this critical technology. Seven projects were undertaken as part of this effort.&nbsp;</p>\n<p><strong>Project 1: </strong>We implemented and tested a small screen voting platform on an iPhone to determine if voters could successfully vote on such a platform. Results showed that while voters were somewhat slower in voting, they did not make more errors on the systems, and they were as satisfied with the mobile voting platform when compared with standard paper ballots.</p>\n<p><strong>Project 2:</strong>&nbsp; We both Implemented and tested an interactive voice response voting interface for presentation on a telephone. Results showed that while it took longer to vote on the IVR system, error rates and satisfaction were approximately the same as other voting technologies. Blind users expressed particularly high satisfaction with the system.</p>\n<p><strong>Project 3:</strong> We developed and then further refined a psychometrically validated measure of trust in voting systems.</p>\n<p><strong>Project 4:</strong> We assessed the relationship between ballot usability and voter trust. There was a strong linear relationship between the usability of a ballot and the voter&rsquo;s reported trust in it. Other research examining this relationship in the context of non-voting systems, such as popular consumer products, found similar results&mdash;except that some users did not always associate highly usable products as being more trustworthy.&nbsp; This subtle difference implies that the relationship between trust and usability might change across situations</p>\n<p><strong>Project 5:</strong> We explored the relationship between polling station physical parameters and voters&rsquo; anticipated usability of the voting system. Results showed that the spatial configuration of electronic voting machines inside a polling station impacted anticipated system usability. Physical parameters associated with higher privacy and security (i.e. space between booths, presence of dividers and orientation of the booths towards the entrance) showed the highest usability ratings.</p>\n<p><strong>Project 6: </strong>We assessed users&rsquo; expectations and mental models of end-to-end (e2e) voting systems. Results showed that a majority of voters would like to be able to check that their votes had been cast as intended after they have left the polling station. The desired form of this information varied considerably across users, with some wanting verification of names or ballot markings, while others simply wanted confirmation that their vote was cast. Data from the mental model experiment are still being analyzed.</p>\n<p><strong>Project 7:</strong> We examined if voters can detect changes to their votes on review screens in ecologically valid settings. We presented participants with review screens that showed votes different than the ones they had just cast. We then sought to determine if voters could detect these errors. Results showed that even when voters are fully engaged in the voting process they are remarkably poor at detecting malicious changes to their ballots on the review screen.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/24/2013<br>\n\t\t\t\t\tModified by: Philip&nbsp;T&nbsp;Kortum</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nProject Outcomes Summary for NSF CNS-1049723: Usability of Voting Systems. Philip Kortum, PI\n\nThis research examined various aspects of the usability of voting systems to further the understanding of how to design this critical technology. Seven projects were undertaken as part of this effort. \n\nProject 1: We implemented and tested a small screen voting platform on an iPhone to determine if voters could successfully vote on such a platform. Results showed that while voters were somewhat slower in voting, they did not make more errors on the systems, and they were as satisfied with the mobile voting platform when compared with standard paper ballots.\n\nProject 2:  We both Implemented and tested an interactive voice response voting interface for presentation on a telephone. Results showed that while it took longer to vote on the IVR system, error rates and satisfaction were approximately the same as other voting technologies. Blind users expressed particularly high satisfaction with the system.\n\nProject 3: We developed and then further refined a psychometrically validated measure of trust in voting systems.\n\nProject 4: We assessed the relationship between ballot usability and voter trust. There was a strong linear relationship between the usability of a ballot and the voter\u00c6s reported trust in it. Other research examining this relationship in the context of non-voting systems, such as popular consumer products, found similar results&mdash;except that some users did not always associate highly usable products as being more trustworthy.  This subtle difference implies that the relationship between trust and usability might change across situations\n\nProject 5: We explored the relationship between polling station physical parameters and voters\u00c6 anticipated usability of the voting system. Results showed that the spatial configuration of electronic voting machines inside a polling station impacted anticipated system usability. Physical parameters associated with higher privacy and security (i.e. space between booths, presence of dividers and orientation of the booths towards the entrance) showed the highest usability ratings.\n\nProject 6: We assessed users\u00c6 expectations and mental models of end-to-end (e2e) voting systems. Results showed that a majority of voters would like to be able to check that their votes had been cast as intended after they have left the polling station. The desired form of this information varied considerably across users, with some wanting verification of names or ballot markings, while others simply wanted confirmation that their vote was cast. Data from the mental model experiment are still being analyzed.\n\nProject 7: We examined if voters can detect changes to their votes on review screens in ecologically valid settings. We presented participants with review screens that showed votes different than the ones they had just cast. We then sought to determine if voters could detect these errors. Results showed that even when voters are fully engaged in the voting process they are remarkably poor at detecting malicious changes to their ballots on the review screen. \n\n \n\n\t\t\t\t\tLast Modified: 10/24/2013\n\n\t\t\t\t\tSubmitted by: Philip T Kortum"
 }
}