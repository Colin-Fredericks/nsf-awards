{
 "awd_id": "0959979",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MRI-R2: Development of an Immersive Giga-pixel Display",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rita Rodriguez",
 "awd_eff_date": "2010-05-01",
 "awd_exp_date": "2014-04-30",
 "tot_intn_awd_amt": 1400000.0,
 "awd_amount": 1400000.0,
 "awd_min_amd_letter_date": "2010-04-23",
 "awd_max_amd_letter_date": "2012-02-09",
 "awd_abstract_narration": "\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\" \r\nProposal #:\t09-59979\r\nPI(s):\t\tKaufman, Arie E., Mueller, Klaus, Qin, Hong, Samaras, Dimitrios, Varshney, Amitabh\r\nInstitution:\tSUNY at Stony Brook\r\nTitle:  \t\tMRI-R2: Development of an Immersive Giga-pixel Display\r\nProject Proposed: \r\nThis project, developing a next generation of immersive display instrument (called 'Reality Deck'), aims to explore and visualize data from many fields. To satisfy the need driven by the explosive growth of data size and environments already at the institution, the work builds on the existing experience with immersive environments (e.g., the 'Immersive Cabin' a current generation device using projectors). This unique project generates a one-of-a-kind exploration theater, using 308 high-resolution 30 LCD display monitors, by contributing an environment whose visual resolution is at the limit of the human eye's acuity. Within this environment investigators can interact with the data/information displayed.  \r\nThe instrument services many groups, including visual computing, virtual and augmented reality, human computer interfaces, computer vision and image processing, data mining, physics, scientific computing, chemistry, marine and atmospheric sciences, climate and weather modeling, material science, etc.\r\nCollaborating scientist's applications will be ported to the RealityDeck, including applications in nanoelectronics, climate and weather modeling, biotoxin simulations, microtomography, astronomy, atmospheric science, G-pixel camera for intelligence gathering, architectural design and disaster simulations, smart energy grid, and many others.\r\nA unique assembly of displays, GPU cluster, sensors, communication/networking, computer vision and human computer interaction technologies, RealityDeck is an engineering feat with user studies to deliver a holistic system with a significant societal and research value. It is a one-of-a-kind pioneering G-pixel display approaching the limits of visual cognition that provides functionalities to a diverse user base. Its resolution at the eye's visual acuity and its field of view will always exceed that of a human user (wherever a human chooses to look), satisfying visual queries into the data in a very intuitive way. This visual interaction is tightly coupled with physical navigation.\r\nThis surround virtual environment consists of inertial sensors and six cameras mounted around the top corners of the RealityDeck room to allow interaction with the displays. The display system is driven by a cluster of about 80 high-end computer nodes, each equipped with two high end GPUs. A small-scale video-wall has already been constructed as an experimental platform for the RealityDeck consisting of 9 high-resolution 30 LCD panels in a 3\u00d73 configuration. \r\nBroader Impacts: \r\nThe instrument will be used for research, education, and outreach across many departments at the institution, the University of Maryland, and Brookhaven National Laboratory (BNL). It fosters collaborations across disciplines attracting faculty, researchers, and students. RealityDeck significantly enriches the quality of visual thinking and data exploration. It substantially enhances the infrastructure of research and education and has the potential to alter the way computer graphicists, engineers, and scientists work and/or conduct scientific discoveries.",
 "awd_arra_amount": 1400000.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Arie",
   "pi_last_name": "Kaufman",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Arie E Kaufman",
   "pi_email_addr": "ari@cs.stonybrook.edu",
   "nsf_id": "000266809",
   "pi_start_date": "2010-04-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Amitabh",
   "pi_last_name": "Varshney",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Amitabh Varshney",
   "pi_email_addr": "varshney@cs.umd.edu",
   "nsf_id": "000253793",
   "pi_start_date": "2010-04-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Hong",
   "pi_last_name": "Qin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hong Qin",
   "pi_email_addr": "qin@cs.sunysb.edu",
   "nsf_id": "000254447",
   "pi_start_date": "2010-04-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Dimitrios",
   "pi_last_name": "Samaras",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dimitrios Samaras",
   "pi_email_addr": "samaras@cs.sunysb.edu",
   "nsf_id": "000096125",
   "pi_start_date": "2010-04-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Klaus",
   "pi_last_name": "Mueller",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Klaus Mueller",
   "pi_email_addr": "mueller@cs.stonybrook.edu",
   "nsf_id": "000735898",
   "pi_start_date": "2010-04-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "perf_city_name": "STONY BROOK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117940001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "118900",
   "pgm_ele_name": "Major Research Instrumentation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6890",
   "pgm_ref_txt": "RECOVERY ACT ACTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "01R9",
   "app_name": "RRA RECOVERY ACT",
   "app_symb_id": "040101",
   "fund_code": "01R00910DB",
   "fund_name": "RRA RECOVERY ACT",
   "fund_symb_id": "040101"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 1400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><br /><br /></p>\n<p><strong>Project Title: Development of an Immersive Giga-pixel Display </strong></p>\n<p><strong>&nbsp;</strong></p>\n<p><strong>Project Outcomes Report for the General Public </strong><strong>Introduction</strong></p>\n<p>The goal of<br />this Major Research Instrumentation (MRI) project was the design, engineering<br />and implementation of a unique super high resolution visualization facility, termed&nbsp;<em>Reality Deck</em>, targeted at the display of big data. Past platforms<br />targeted at big-data visualization extended to approximately 300 megapixels resolution. Nowadays however, it is trivial to acquire datasets (ie.g., high resolution imagery) that spans multiple gigapixels in size.</p>\n<p>Constructed to answer the challenge<br />of big data visualization in large immersive display environments, the Reality<br />Deck is housed in a&nbsp; 40'x30' lab where 416 LCD monitors are tiled and mounted<br />in a 4-wall arrangement. Total work space enclosed by the monitors is<br />33'x19'. Overall, the Reality Deck provides an aggregate resolution of more<br />than 1.5 gigapixels.&nbsp; Additionally, it offers full<br />horizontal immersion by means of its four walls and mechanized door. This means&nbsp;data with a panoramic component can be very naturally mapped to the display and users can explore it just by physical navigation, without the need to \"pan\" the visualization using a controller. The facility size and<br />form factor invite users to walk around, examining different aspects of the<br />visualized data by approaching different sections of the display space. We leverage<br />this characteristic of the facility in several research contributions outlined<br />below.</p>\n<p><strong>&nbsp;</strong></p>\n<p><strong>Construction</strong></p>\n<p>Similarl to other room-sized displays, the Reality Deck is constructed by tiling multiple LCD monitors in precise fashion. In the Reality Deck case, we<br />utilize commodity, off-shelf, hardware with cost-efficient modifications<br />to drive construction costs down and enable ease of maintenance. Each<br />Samsung S27A850D monitor used&nbsp; was modified to reduce bezel<br />size and reroute all distracting electronics to its rear.</p>\n<p>Images and 3D visuals displayed in the Reality Deck are generated by a cluster of 20 workstation-class computers, each utilizing 4 GPUs (Graphics Processing Units).&nbsp; For most cluster nodes, each GPU is connected to 6 monitors for a total of 24 monitors per node. The visualization cluster is connected to the Reality Deck using active fiber-optic DisplayPort extender cables. 7 miles of cables are utilized throughout the Reality Deck.</p>\n<p>The facility is equipped with numerous interaction peripherals. A 24 infra-red camera tracking system provides positional information for people and objects while anambisonic sound system allows for audio queues to be tied into the visualization.&nbsp;A touch-enabled table computer is available in the<br />middle of the facility, enabling natural user interactions.</p>\n<p>Design process and challenges behind the construction of the Reality Deck have been document and available for future system builders [3, 5].</p>\n<p><strong>&nbsp;</strong></p>\n<p><strong>Visualization and Interaction Techniques</strong></p>\n<p>Visualization software for the Reality Deck provides support for visualization of multiple data formats (videos, 3D models, gigapixel images, geospatial data, medical volumes, etc.). We have also developed several&nbsp;visualization and interaction techniques that enable natural interfacing with<br />data and improve system performance.</p>\n<p>The Infinite<br />Canvas [4] is a walking-based interface that allows users to explore data that<br />extends arbitrarily along one dimension. Our novel frameless visualization<br />scheme [8] allows reconstruction of high resolution and high frame-rate<br />images from multi-t...",
  "por_txt_cntn": "\n\n\n\n\nProject Title: Development of an Immersive Giga-pixel Display \n\n \n\nProject Outcomes Report for the General Public Introduction\n\nThe goal of\nthis Major Research Instrumentation (MRI) project was the design, engineering\nand implementation of a unique super high resolution visualization facility, termed Reality Deck, targeted at the display of big data. Past platforms\ntargeted at big-data visualization extended to approximately 300 megapixels resolution. Nowadays however, it is trivial to acquire datasets (ie.g., high resolution imagery) that spans multiple gigapixels in size.\n\nConstructed to answer the challenge\nof big data visualization in large immersive display environments, the Reality\nDeck is housed in a  40'x30' lab where 416 LCD monitors are tiled and mounted\nin a 4-wall arrangement. Total work space enclosed by the monitors is\n33'x19'. Overall, the Reality Deck provides an aggregate resolution of more\nthan 1.5 gigapixels.  Additionally, it offers full\nhorizontal immersion by means of its four walls and mechanized door. This means data with a panoramic component can be very naturally mapped to the display and users can explore it just by physical navigation, without the need to \"pan\" the visualization using a controller. The facility size and\nform factor invite users to walk around, examining different aspects of the\nvisualized data by approaching different sections of the display space. We leverage\nthis characteristic of the facility in several research contributions outlined\nbelow.\n\n \n\nConstruction\n\nSimilarl to other room-sized displays, the Reality Deck is constructed by tiling multiple LCD monitors in precise fashion. In the Reality Deck case, we\nutilize commodity, off-shelf, hardware with cost-efficient modifications\nto drive construction costs down and enable ease of maintenance. Each\nSamsung S27A850D monitor used  was modified to reduce bezel\nsize and reroute all distracting electronics to its rear.\n\nImages and 3D visuals displayed in the Reality Deck are generated by a cluster of 20 workstation-class computers, each utilizing 4 GPUs (Graphics Processing Units).  For most cluster nodes, each GPU is connected to 6 monitors for a total of 24 monitors per node. The visualization cluster is connected to the Reality Deck using active fiber-optic DisplayPort extender cables. 7 miles of cables are utilized throughout the Reality Deck.\n\nThe facility is equipped with numerous interaction peripherals. A 24 infra-red camera tracking system provides positional information for people and objects while anambisonic sound system allows for audio queues to be tied into the visualization. A touch-enabled table computer is available in the\nmiddle of the facility, enabling natural user interactions.\n\nDesign process and challenges behind the construction of the Reality Deck have been document and available for future system builders [3, 5].\n\n \n\nVisualization and Interaction Techniques\n\nVisualization software for the Reality Deck provides support for visualization of multiple data formats (videos, 3D models, gigapixel images, geospatial data, medical volumes, etc.). We have also developed several visualization and interaction techniques that enable natural interfacing with\ndata and improve system performance.\n\nThe Infinite\nCanvas [4] is a walking-based interface that allows users to explore data that\nextends arbitrarily along one dimension. Our novel frameless visualization\nscheme [8] allows reconstruction of high resolution and high frame-rate\nimages from multi-tiered stream of samples. Conformal Visualization [1]\nprovides shape-preserving retargeting for exploration of data, i.e, medical\ndata, in the Reality Deck and also permits the display of information that\nwould normally lie in missing floor and ceiling surfaces of the system. Our\nAcuity-Driven Gigapixel Visualization technology [2] improves streaming\nperformance for gigapixel imagery by utilizing a tracking system to\nadaptively select a level of detail required for correct ..."
 }
}