{
 "awd_id": "1007773",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Bayesian Analysis and Applications",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2010-06-01",
 "awd_exp_date": "2015-05-31",
 "tot_intn_awd_amt": 333000.0,
 "awd_amount": 333000.0,
 "awd_min_amd_letter_date": "2010-05-18",
 "awd_max_amd_letter_date": "2013-05-29",
 "awd_abstract_narration": "Five research areas in Bayesian analysis, involving theory, methodology and application, will be pursued: objective Bayesian analysis, multiplicity adjustment, search and approximations in model selection, analysis of complex computer models, and differences between Bayes and empirical Bayes analysis. Research in objective Bayesian analysis will focus on the development of objective priors, together with their computational implementation, in semi-invariant contexts, which include spatial problems and problems arising in psychiatry. The Bayesian approach to multiplicity correction has the attraction that it does not depend on the error structure of the data; multiplicity correction is done only through the prior probabilities assigned to models or other multiplicity features. Understanding which probability assignments do, and do not, adjust for multiplicity will be an important feature of this research. A focus of the research on model selection will be the development of a generalization of BIC which is much more widely applicable than the standard version, especially overcoming the major hurdle of defining effective sample size for a parameter. Advances in these areas will have application to research involving the analysis and use of complex computer models of processes. Also, surprising differences between Bayes and empirical Bayes analysis arise in several of the above settings, and better understanding of these differences will also be a focus of the research.\r\n\r\nObjective Bayesian analysis has existed for over 250 years, but interest in the field has increased markedly in recent years. A major reason is that many of the significant scientific problems today (such as much of climate change research) involve some type of assimilation of data and physical modeling, typically done by Bayesian methods. Many of today?s most challenging problems ? including microarray and other bioinformatic analyses, syndromic surveillance, high-throughput screening, and many others ? involve consideration of multiple-testing with a huge number of possible tests, and require major multiplicity adjustments. For instance, the work on multiplicity will be done in the context of subgroup analysis in clinical trials, providing major new insights into HIV vaccine trials, and in refining detection methodology in high-energy physics.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Berger",
   "pi_mid_init": "O",
   "pi_sufx_name": "",
   "pi_full_name": "James O Berger",
   "pi_email_addr": "berger@stat.duke.edu",
   "nsf_id": "000386956",
   "pi_start_date": "2010-05-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "2200 W MAIN ST",
  "perf_city_name": "DURHAM",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277054640",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 51050.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 105323.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 106739.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 69888.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The research focused on four research areas in Bayesian statistical analysis, involving theory, methodology and application: objective Bayesian analysis, adjustment for multiple testing, hypothesis testing and model selection, and analysis of complex computer models.</p>\n<p>Research in objective Bayesian analysis focused on the development of objective priors, together with their computational implementation. Application areas for these techniques included educational testing, with new procedures being developed for adaptive on-line testing. A nonparametric Bayes procedure was also developed for robustly computing distances to Cepheid variable stars. Objective Bayesian procedures were also developed for analysis and adaptive scheduling of exoplanet observations.</p>\n<p>Many of today&rsquo;s most challenging problems &ndash; including microarray and other bioinformatic analyses, syndromic surveillance, high-throughput screening for drug discovery, and many others &ndash; involve consideration of multiple-testing with a huge number of possible tests, and require major multiplicity adjustments. A major part of this research project was studying the Bayesian approach to multiplicity correction, for two reasons. First, the Bayesian approach retains full power for discovery, even when the test statistics of the multiple tests are highly dependent, as is common in many problems such as subgroup analysis (detecting a subgroup of a population that, e.g., exhibits a treatment effect); in contrast standard non-Bayesian multiplicity correction techniques lose most of their detection power in the face of test statistic dependency. The second attraction of the Bayesian approach is that differing probability assignments can be made which allow extra weight to be given to hypotheses that are viewed as being scientifically more likely to be true. &nbsp;</p>\n<p>The specific work done in multiple testing focused first on subgroup analysis, primarily in the context of pharmaceutical clinical trials. The first fully Bayesian subgroup analysis was implemented, and the effect of apriori favoring certain subgroups was considered. A major surprise was that the Bayesian approach also provided the probabilities that individuals would experience a treatment effect, a key need if the promise of personalized medicine is to be realized. &nbsp;Additional multiple testing work focused on theory, establishing in particular contexts that the Bayesian multiple testing procedures exhibit strong frequentist multiplicity control.</p>\n<p>The work on hypothesis testing and model selection focused on developing optimal default Bayesian methodology for hypothesis testing and variable selection. The hypothesis testing work provided major new insights into HIV vaccine trials. The variable selection work lead to the first general (and automatic) procedure which satisfies all the desirable desiderata for procedures for variable selection.</p>\n<p>Many of the significant scientific problems today (such as much of climate change research) involve some type of assimilation of data and physical modeling. This interface, called Uncertainty Quantification, was a major focus of the research project. In particular, the research focused on emulation (approximation) of expensive-to-run computer models of processes, and remarkably improved emulators were obtained. This work is of direct use in prediction of probabilistic hazards of pyroclastic flow.</p>\n<p>Under the research project there was also significant development of researchers in statistics and data science more generally. The Ph.D. students involved with the project have extensively developed their skills in research through the project. Most have also been heavily involved with interdisciplinary research &ndash; three with geophysicists, one with psychologists, and one with pharmaceuticals. Five undergraduate students did senior theses on topics from the researc...",
  "por_txt_cntn": "\nThe research focused on four research areas in Bayesian statistical analysis, involving theory, methodology and application: objective Bayesian analysis, adjustment for multiple testing, hypothesis testing and model selection, and analysis of complex computer models.\n\nResearch in objective Bayesian analysis focused on the development of objective priors, together with their computational implementation. Application areas for these techniques included educational testing, with new procedures being developed for adaptive on-line testing. A nonparametric Bayes procedure was also developed for robustly computing distances to Cepheid variable stars. Objective Bayesian procedures were also developed for analysis and adaptive scheduling of exoplanet observations.\n\nMany of today\u00c6s most challenging problems &ndash; including microarray and other bioinformatic analyses, syndromic surveillance, high-throughput screening for drug discovery, and many others &ndash; involve consideration of multiple-testing with a huge number of possible tests, and require major multiplicity adjustments. A major part of this research project was studying the Bayesian approach to multiplicity correction, for two reasons. First, the Bayesian approach retains full power for discovery, even when the test statistics of the multiple tests are highly dependent, as is common in many problems such as subgroup analysis (detecting a subgroup of a population that, e.g., exhibits a treatment effect); in contrast standard non-Bayesian multiplicity correction techniques lose most of their detection power in the face of test statistic dependency. The second attraction of the Bayesian approach is that differing probability assignments can be made which allow extra weight to be given to hypotheses that are viewed as being scientifically more likely to be true.  \n\nThe specific work done in multiple testing focused first on subgroup analysis, primarily in the context of pharmaceutical clinical trials. The first fully Bayesian subgroup analysis was implemented, and the effect of apriori favoring certain subgroups was considered. A major surprise was that the Bayesian approach also provided the probabilities that individuals would experience a treatment effect, a key need if the promise of personalized medicine is to be realized.  Additional multiple testing work focused on theory, establishing in particular contexts that the Bayesian multiple testing procedures exhibit strong frequentist multiplicity control.\n\nThe work on hypothesis testing and model selection focused on developing optimal default Bayesian methodology for hypothesis testing and variable selection. The hypothesis testing work provided major new insights into HIV vaccine trials. The variable selection work lead to the first general (and automatic) procedure which satisfies all the desirable desiderata for procedures for variable selection.\n\nMany of the significant scientific problems today (such as much of climate change research) involve some type of assimilation of data and physical modeling. This interface, called Uncertainty Quantification, was a major focus of the research project. In particular, the research focused on emulation (approximation) of expensive-to-run computer models of processes, and remarkably improved emulators were obtained. This work is of direct use in prediction of probabilistic hazards of pyroclastic flow.\n\nUnder the research project there was also significant development of researchers in statistics and data science more generally. The Ph.D. students involved with the project have extensively developed their skills in research through the project. Most have also been heavily involved with interdisciplinary research &ndash; three with geophysicists, one with psychologists, and one with pharmaceuticals. Five undergraduate students did senior theses on topics from the research project &ndash; one on objective Bayesian methodology for educational testing, two on subgroup analysis, one on ..."
 }
}