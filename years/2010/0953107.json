{
 "awd_id": "0953107",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Brain-Tongue-Computer Interfacing",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2010-03-01",
 "awd_exp_date": "2018-02-28",
 "tot_intn_awd_amt": 516298.0,
 "awd_amount": 548298.0,
 "awd_min_amd_letter_date": "2010-03-29",
 "awd_max_amd_letter_date": "2016-12-01",
 "awd_abstract_narration": "The PI's long-term research plans involve exploring new pathways to the human central nervous system (CNS) in order to expand our knowledge about this highly complex system and understand how it works, and developing innovative technologies and research tools that will enable direct or indirect communication with the CNS through such pathways.  In particular, he is keen to utilize and evaluate new interfacing technologies in devices that will help individuals who suffer from chronic disabilities and neurological diseases, such as blindness, deafness, and paralysis to improve and extend their quality of life.  With these general goals in mind, the PI will in this project focus on exploring the use of voluntary tongue motion as a substitute for some of the functions traditionally performed by the arms and hands in personal environmental control.  This has not been possible in the past absent access to tongue motion without impeding the tongue's key roles in swallowing, respiration, and speech.  The PI has previously developed and successfully tested a new wireless, unobtrusive, and wearable technology he calls the Tongue Drive System (TDS), to indicate tongue position in real time within certain user-defined locations in the oral space.  Building upon the TDS prototype, he will explore whether the inherent characteristics of the tongue and its rich motor capabilities can be harnessed as an intermediary pathway to the human brain.  In other words, he will seek to create a Brain-Tongue-Computer Interface (BTCI) by enhancing the functionality of the TDS hardware, signal processing algorithms, and GUI software to support a large number of choices that will be simultaneously available to users, in addition to the proportional control capability that is currently employed to facilitate navigation and computer access.  The PI will conduct experiments to evaluate the performance, usability, and acceptability of the BCTI platform, and will employ it to achieve a fundamental understanding of human factors associated with voluntary tongue motions.  Finally, the PI will combine his real time 3-D tongue tracking technology with multi-channel wireless neural recording to explore the relationship between unconstrained tongue movements and whole muscle/single motor unit activities in speech, respiration, and swallowing without any bodily restraints.\r\n\r\nBroader Impacts:  Individuals who are severely disabled as a result of various causes from spinal cord injuries to stroke, cerebral palsy, and ALS find it extremely difficult to carry out everyday tasks without continuous help.  This research will ultimately transform the lives of many persons with severe disabilities, by helping them live active, self-supportive, and productive lives.  Solutions such as the BTCI may also help reduce healthcare and assisted-living costs by relieving the burden on family members and dedicated caregivers.  Utilization of the tongue's motion as an untapped human motor modality in command, control, and navigation tasks involves costs and benefits which are at present unknown; quantitative analysis of human performance in concurrently conducted sensory, motor, and cognitive tasks, both in the presence and absence of tongue motions, is likely to bring about new scientific discoveries in human system integration.  The PI's 3-D tongue tracking technology will also impact speech/language therapy, as well as the treatment of communication and sleep disorders that involve tongue motion.  The PI will explore use of the BTCI technology in educational settings for children with special needs through programs such as Tools for Life, and will also conduct outreach efforts to expose K-12 students to facts about the CNS, its associated impairments, and different ways to address those problems with engineering solutions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maysam",
   "pi_last_name": "Ghovanloo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maysam Ghovanloo",
   "pi_email_addr": "mgh@getech.edu",
   "nsf_id": "000320172",
   "pi_start_date": "2010-03-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 NORTH AVE NW",
  "perf_city_name": "ATLANTA",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 86884.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 121290.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 105775.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 125031.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 109318.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span><span style=\"font-size: small;\">This CAREER award helped build Dr. Ghovanloo&rsquo;s (PI) academic career along his long-term professional objective, which is inventing, exploring, and evaluating new technologies for improving the quality of life of people with severe disabilities, such as blindness, deafness, and paralysis. To this end, his research plan involves exploring new pathways to the human nervous system to expand the knowledge about this highly complex, efficient, and capable system, as well as developing innovative technologies to enable direct or indirect communication with the brain through such pathways.</span></span></p>\n<p><span><span style=\"font-size: small;\">In this project, we tapped into the amazing capabilities of the human tongue by creating a Brain-Tongue-Computer Interface (BTCI) based on a wireless, unobtrusive, and wearable assistive technology (AT), known as the Tongue Drive System (TDS), invented by the PI. Tongue and other muscles in the mouth are directly connected to the brain through a cranial nerve, which means that even the worst types of spinal cord injury, which result in the paralysis of the entire body, do not affect the voluntary tongue motion. Tongue is also one of the last parts of the body to be affected by many neurological diseases, such as ALS. At the same time, because a large area in the motor cortex of the brain is dedicated to the tongue, we can move our tongues very rapidly and precisely without requiring training or concentration. The tongue is also readily accessible without any invasive procedure or surgery.</span></span></p>\n<p><span><span style=\"font-size: small;\">In this project, we were able to take the TDS from an early stage prototype, created by the PI and his team, thanks to an earlier NSF-SGER grant, to a fully functional system with all the necessary hardware, signal processing algorithms, and user interfacing software to be used in two rounds of clinical trials, which were conducted at the Shepherd Center in Atlanta, GA, and Ability Lab (formerly known as Rehabilitation Institute of Chicago) in Chicago, IL, with additional support from the NIH-NIBIB. In a series of studies with both able-bodied volunteers and individuals with tetraplegia (paralysis of both hands and legs) we were able to explore the use of voluntary tongue motion as a substitute for some of the functions normally performed by the arms and hands in accessing computers/smartphones, driving powered wheelchairs, and controlling the environment. We compared the performance of individuals with tetraplegia in using the TDS with that of the Sip-and-Puff (SnP), one of the most popular ATs in the market. The results showed that even though participants had prior experience with SnP but completely new to TDS, they completed the tasks 3 times faster with TDS compared with SnP, at the same level of accuracy. We also evaluated the performance, usability, and acceptability of the TDS to achieve a fundamental understanding of human factors associated with voluntary tongue motions. The results, published in more than 40 peer-reviewed conference and journal publications, indicate that the tongue is indeed a suitable control surface for individuals with upper limb paralysis. These results were also picked up by the largest media outlets all across the world, and created significant interest and attention among the public.</span></span></p>\n<p><span><span style=\"font-size: small;\">Using a period of no-cost extension, we continued our efforts in further advancing the TDS technology, and going beyond what was originally proposed by designing and developing a multimodal TDS (mTDS). The mTDS not only offers all the advantages of the TDS (discrete), but also tracks the user head motion (continuous) using inertial sensors built into the headset. It is also equipped with a microphone to capture the user&rsquo;s voice and convert it to text, using a speech recognition software, such as Siri. Our experiments on the mTDS show that a multimodal AT that offers both discrete and continuous control capabilities has significant advantages over a single-mode device in more complex computer access tasks.<span> &nbsp;</span><span> </span><span>&nbsp;</span><span> &nbsp;&nbsp;</span></span></span></p>\n<p><span><span style=\"font-size: small;\">In terms of broader impacts, we added more magnetic sensors near the mouth, and developed an algorithm to track the tongue motion within the 3D oral space with high accuracy in real time. We have used this information to capture the tongue motion during speech along with lip gestures and voice to develop a Multimodal Speech Capture System (MSCS), which can be used to accelerate the rate of speech rehabilitation in patients with speech impairments due to brain damage or stroke, for instance. Yet another broader application of the TDS that resulted from this award is a combination of TDS and exoskeletons, allowing stroke survivors to move their hands beyond their active range-of-motion, utilizing their voluntary tongue movements.&nbsp;</span></span></p>\n<p><span><span style=\"font-size: small;\">The PI gave numerous presentations and demonstrations in various research centers, universities, and rehabilitation hospitals. This project was a major part of three PhD theses. Three post-doctoral fellows, more than 25 graduate students, and more than 20 undergraduate students contributed to this project and also learned from it over the entire award lifetime.</span></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/05/2018<br>\n\t\t\t\t\tModified by: Maysam&nbsp;Ghovanloo</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/0953107/0953107_10014479_1528236597395_TDS1_JD_MGH_July11--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/0953107/0953107_10014479_1528236597395_TDS1_JD_MGH_July11--rgov-800width.jpg\" title=\"PI and one of the participants in the TDS clinical trial\"><img src=\"/por/images/Reports/POR/2018/0953107/0953107_10014479_1528236597395_TDS1_JD_MGH_July11--rgov-66x44.jpg\" alt=\"PI and one of the participants in the TDS clinical trial\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">PI and one of the participants in the TDS clinical trial.</div>\n<div class=\"imageCredit\">Gary Meek</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maysam&nbsp;Ghovanloo</div>\n<div class=\"imageTitle\">PI and one of the participants in the TDS clinical trial</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/0953107/0953107_10014479_1528236490510_TDS_iPhone--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/0953107/0953107_10014479_1528236490510_TDS_iPhone--rgov-800width.jpg\" title=\"Tongue Drive System and Smartphone\"><img src=\"/por/images/Reports/POR/2018/0953107/0953107_10014479_1528236490510_TDS_iPhone--rgov-66x44.jpg\" alt=\"Tongue Drive System and Smartphone\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Major components of the Tongue Drive System</div>\n<div class=\"imageCredit\">Gary Meek</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maysam&nbsp;Ghovanloo</div>\n<div class=\"imageTitle\">Tongue Drive System and Smartphone</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/0953107/0953107_10014479_1528236386938_TDS_External_Block_Diagram--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/0953107/0953107_10014479_1528236386938_TDS_External_Block_Diagram--rgov-800width.jpg\" title=\"TDS Block Diagram\"><img src=\"/por/images/Reports/POR/2018/0953107/0953107_10014479_1528236386938_TDS_External_Block_Diagram--rgov-66x44.jpg\" alt=\"TDS Block Diagram\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A rendered block diagram of the Tongue Drive System</div>\n<div class=\"imageCredit\">Maysam Ghovanloo</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maysam&nbsp;Ghovanloo</div>\n<div class=\"imageTitle\">TDS Block Diagram</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis CAREER award helped build Dr. Ghovanloo?s (PI) academic career along his long-term professional objective, which is inventing, exploring, and evaluating new technologies for improving the quality of life of people with severe disabilities, such as blindness, deafness, and paralysis. To this end, his research plan involves exploring new pathways to the human nervous system to expand the knowledge about this highly complex, efficient, and capable system, as well as developing innovative technologies to enable direct or indirect communication with the brain through such pathways.\n\nIn this project, we tapped into the amazing capabilities of the human tongue by creating a Brain-Tongue-Computer Interface (BTCI) based on a wireless, unobtrusive, and wearable assistive technology (AT), known as the Tongue Drive System (TDS), invented by the PI. Tongue and other muscles in the mouth are directly connected to the brain through a cranial nerve, which means that even the worst types of spinal cord injury, which result in the paralysis of the entire body, do not affect the voluntary tongue motion. Tongue is also one of the last parts of the body to be affected by many neurological diseases, such as ALS. At the same time, because a large area in the motor cortex of the brain is dedicated to the tongue, we can move our tongues very rapidly and precisely without requiring training or concentration. The tongue is also readily accessible without any invasive procedure or surgery.\n\nIn this project, we were able to take the TDS from an early stage prototype, created by the PI and his team, thanks to an earlier NSF-SGER grant, to a fully functional system with all the necessary hardware, signal processing algorithms, and user interfacing software to be used in two rounds of clinical trials, which were conducted at the Shepherd Center in Atlanta, GA, and Ability Lab (formerly known as Rehabilitation Institute of Chicago) in Chicago, IL, with additional support from the NIH-NIBIB. In a series of studies with both able-bodied volunteers and individuals with tetraplegia (paralysis of both hands and legs) we were able to explore the use of voluntary tongue motion as a substitute for some of the functions normally performed by the arms and hands in accessing computers/smartphones, driving powered wheelchairs, and controlling the environment. We compared the performance of individuals with tetraplegia in using the TDS with that of the Sip-and-Puff (SnP), one of the most popular ATs in the market. The results showed that even though participants had prior experience with SnP but completely new to TDS, they completed the tasks 3 times faster with TDS compared with SnP, at the same level of accuracy. We also evaluated the performance, usability, and acceptability of the TDS to achieve a fundamental understanding of human factors associated with voluntary tongue motions. The results, published in more than 40 peer-reviewed conference and journal publications, indicate that the tongue is indeed a suitable control surface for individuals with upper limb paralysis. These results were also picked up by the largest media outlets all across the world, and created significant interest and attention among the public.\n\nUsing a period of no-cost extension, we continued our efforts in further advancing the TDS technology, and going beyond what was originally proposed by designing and developing a multimodal TDS (mTDS). The mTDS not only offers all the advantages of the TDS (discrete), but also tracks the user head motion (continuous) using inertial sensors built into the headset. It is also equipped with a microphone to capture the user?s voice and convert it to text, using a speech recognition software, such as Siri. Our experiments on the mTDS show that a multimodal AT that offers both discrete and continuous control capabilities has significant advantages over a single-mode device in more complex computer access tasks.       \n\nIn terms of broader impacts, we added more magnetic sensors near the mouth, and developed an algorithm to track the tongue motion within the 3D oral space with high accuracy in real time. We have used this information to capture the tongue motion during speech along with lip gestures and voice to develop a Multimodal Speech Capture System (MSCS), which can be used to accelerate the rate of speech rehabilitation in patients with speech impairments due to brain damage or stroke, for instance. Yet another broader application of the TDS that resulted from this award is a combination of TDS and exoskeletons, allowing stroke survivors to move their hands beyond their active range-of-motion, utilizing their voluntary tongue movements. \n\nThe PI gave numerous presentations and demonstrations in various research centers, universities, and rehabilitation hospitals. This project was a major part of three PhD theses. Three post-doctoral fellows, more than 25 graduate students, and more than 20 undergraduate students contributed to this project and also learned from it over the entire award lifetime.\n\n\t\t\t\t\tLast Modified: 06/05/2018\n\n\t\t\t\t\tSubmitted by: Maysam Ghovanloo"
 }
}