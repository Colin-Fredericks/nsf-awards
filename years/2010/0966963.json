{
 "awd_id": "0966963",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Intent Seeking Algorithms for New Human-Machine Interface",
 "cfda_num": "47.041",
 "org_code": "07020000",
 "po_phone": "7032922633",
 "po_email": "aleoness@nsf.gov",
 "po_sign_block_name": "Alex Leonessa",
 "awd_eff_date": "2010-08-01",
 "awd_exp_date": "2015-07-31",
 "tot_intn_awd_amt": 283362.0,
 "awd_amount": 283362.0,
 "awd_min_amd_letter_date": "2010-07-27",
 "awd_max_amd_letter_date": "2010-07-27",
 "awd_abstract_narration": "PI: Joshi, Sanjay S.\r\nProposal Number: 0966963\r\n\r\nProject Summary: We have created a novel human-machine interface (HMI) technology for paralyzed persons which uses the surface electromyography (sEMG) signal of a single, facial muscle for simultaneous multidimensional control of external devices. Our new controller has the potential to significantly increase the quality of life for its users. Unlike many existing humancomputer interfaces for this population, our interface is: unobtrusive & inconspicuous, noninterfering with eyes/mouth/tongue, continuously available when needed, multifunctional, easy-to-use in almost any head position, and portable. We have recently discovered that humans can learn how to simultaneously manipulate power levels in two separate frequency-bands of a sEMG power spectrum (simply by contracting the muscle). Each frequency band becomes a separate control channel, which can simultaneously control different aspects of a device. Thus, we may exploit a single muscle?s natural electrical signals in far more complex ways than previously known. Using this underlying discovery, we have developed a new user interface that relies on a single head muscle?s surface EMG signal, which is easy to obtain and restricted to a small non-descript area near the ear. Our system is somewhat similar to some electroencephalographic (EEG) based brain-computer interfaces (BCI) in which a person learns to ?guide? a cursor to certain positions on a computer screen. These positions on the screen could be virtual buttons that open computer applications (human-computer interfaces), turn on/off lights (environmental control units), or control wheelchairs (mobility applications). Two central challenges in all ?cursor-guided? HMI systems are 1) intent (how does the computer know where the user intended to place the cursor?), and 2) speed at which the cursor can achieve the intended position. These two questions are intertwined in that earlier knowledge of intent can lead to faster systems. We propose to develop new ?intent-seeking? algorithms that could make our HMI much faster than our currently instantiated system. In addition, in order to conduct evaluation studies on subjects with disabilities who cannot leave either home or hospital, we will develop a new smaller mobile version of our hardware that is very easy to transport, setup, and use anywhere.\r\nIntellectual Merit: The use of a single sEMG signal for simultaneous multidimensional control in human-computer interfaces is potentially transformative. The notion of predicting the future location of a target (in this case a computer cursor) arises in many different applications (e.g. aerospace engineering, robotics, brain-computer interfaces). These applications employ a combination of mathematical and computer-science techniques including statistical decision making, optimal filtering, and artificial intelligence. We intend to draw from these fields to develop accurate, fast algorithms for our human-computer interface application. From a hardware perspective, entire new classes of computing devices are appearing that can perform complex computations and run graphics-intensive applications from a hand-held (or smaller) footprint.\r\nDesigning our interface around these operating platforms will advance the area of highly portable and easy-to-use assistive interfaces.\r\nBroader Impact: A recent study initiated by the Reeve Foundation (2009) estimates that more than 5.5 million people live with paralysis in the United States. Many of the most severely paralyzed use ventilators to breathe, and are confined to certain head/body positions at different times during the day. Our goal is for severely paralyzed persons to regain some control of their surroundings and some basic independence. We are committed to including disabled persons in our research, not only as subjects but also as researchers themselves. As such, our work will create an additional broader impact in terms of research inclusiveness. In terms of intellectual broader impact, our new intent-seeking algorithms could have applications for many computer operating systems/programs for which disabled or non-disabled persons use various devices to guide cursors on a screen.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CBET",
 "org_div_long_name": "Division of Chemical, Bioengineering, Environmental, and Transport Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanjay",
   "pi_last_name": "Joshi",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Sanjay S Joshi",
   "pi_email_addr": "maejoshi@ucdavis.edu",
   "nsf_id": "000186022",
   "pi_start_date": "2010-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Davis",
  "perf_str_addr": "1850 RESEARCH PARK DR STE 300",
  "perf_city_name": "DAVIS",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956186153",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "534200",
   "pgm_ele_name": "Disability & Rehab Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "010E",
   "pgm_ref_txt": "DISABILITY RES & HOMECARE TECH"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 283362.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>A human computer interface (HCI) is a device which allows a person to control machines in their environment, such as a computer or a television. HCIs are especially important to paralyzed persons, many of whom have limited options to control devices. A severely paralyzed person may lose control over much of their body, but many medical conditions allow them to still use their head muscles (e.g. high spinal cord injury, as head muscles are controlled by the brain stem and not the spinal cord).&nbsp; Persons with severe paralysis must rely on 24-hr care to perform daily functions. An HCI that can be used independently by a paralyzed person for even small tasks can be immensely helpful. Using this grant, we developed a new HCI that allows a severely paralyzed person to use just one head muscle to control objects in their environment.&nbsp;</p>\n<p>Muscles produce electrical signals (called electromyographic signals, a.k.a. EMG signals) which can be measured by placing a sensor on the skin covering the muscle. Our main goal for this grant was to develop new devices and software that could measure a single head muscle&rsquo;s electrical signal, and then translate that measured electrical signal into movement of a cursor on a computer screen. Once a person can move a cursor on a screen, they may select buttons that can operate a computer (such as opening email) or even command external objects (such as operating a television set).</p>\n<p>During the development of our device, we demonstrated that humans can manipulate their muscles&rsquo; electrical signals in ways that are very unusual but helpful. This is called neuromuscular plasticity. For our HCI, we required users to manipulate EMG signal power from one muscle site into two separate frequency bands.&nbsp; This allowed us to control two aspects of a device simultaneously (called 2-dimensional control) using just one muscle (for example, both the x-position and y-position of a computer cursor). This method then allowed us to use half as many sensors for our HCI than other HCIs.&nbsp; This is important as paralyzed persons want as few sensors on them as possible. In addition, the use of fewer sensors allows lower cost for the HCI.</p>\n<p>During the course of this grant, we developed a portable HCI by combining a smart phone and EMG sensor. The EMG signal is sent into the phone, and the computer inside the phone performs all the signal processing. The phone screen is used to show the buttons that can be activated by a user. We also studied several computer algorithms, including machine learning algorithms, which could translate the EMG signals generated at a muscle into cursor movement and selection on a screen. Furthermore, we took our devices into the community and tested several disabled persons including persons with spinal cord injury, spinal muscular atrophy, and Tetra-Amelia syndrome (born without arms and legs).</p>\n<p>We hope that the techniques and devices we have developed using this grant will eventually allow even severely paralyzed persons to gain some small levels of independence, thus improving their quality of life. It has especially been our honor to work with our disabled volunteers and their families.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/29/2015<br>\n\t\t\t\t\tModified by: Sanjay&nbsp;S&nbsp;Joshi</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2015/0966963/0966963_10019192_1446144244310_BMCIDescription-...",
  "por_txt_cntn": "\nA human computer interface (HCI) is a device which allows a person to control machines in their environment, such as a computer or a television. HCIs are especially important to paralyzed persons, many of whom have limited options to control devices. A severely paralyzed person may lose control over much of their body, but many medical conditions allow them to still use their head muscles (e.g. high spinal cord injury, as head muscles are controlled by the brain stem and not the spinal cord).  Persons with severe paralysis must rely on 24-hr care to perform daily functions. An HCI that can be used independently by a paralyzed person for even small tasks can be immensely helpful. Using this grant, we developed a new HCI that allows a severely paralyzed person to use just one head muscle to control objects in their environment. \n\nMuscles produce electrical signals (called electromyographic signals, a.k.a. EMG signals) which can be measured by placing a sensor on the skin covering the muscle. Our main goal for this grant was to develop new devices and software that could measure a single head muscle\u00c6s electrical signal, and then translate that measured electrical signal into movement of a cursor on a computer screen. Once a person can move a cursor on a screen, they may select buttons that can operate a computer (such as opening email) or even command external objects (such as operating a television set).\n\nDuring the development of our device, we demonstrated that humans can manipulate their muscles\u00c6 electrical signals in ways that are very unusual but helpful. This is called neuromuscular plasticity. For our HCI, we required users to manipulate EMG signal power from one muscle site into two separate frequency bands.  This allowed us to control two aspects of a device simultaneously (called 2-dimensional control) using just one muscle (for example, both the x-position and y-position of a computer cursor). This method then allowed us to use half as many sensors for our HCI than other HCIs.  This is important as paralyzed persons want as few sensors on them as possible. In addition, the use of fewer sensors allows lower cost for the HCI.\n\nDuring the course of this grant, we developed a portable HCI by combining a smart phone and EMG sensor. The EMG signal is sent into the phone, and the computer inside the phone performs all the signal processing. The phone screen is used to show the buttons that can be activated by a user. We also studied several computer algorithms, including machine learning algorithms, which could translate the EMG signals generated at a muscle into cursor movement and selection on a screen. Furthermore, we took our devices into the community and tested several disabled persons including persons with spinal cord injury, spinal muscular atrophy, and Tetra-Amelia syndrome (born without arms and legs).\n\nWe hope that the techniques and devices we have developed using this grant will eventually allow even severely paralyzed persons to gain some small levels of independence, thus improving their quality of life. It has especially been our honor to work with our disabled volunteers and their families.\n\n \n\n\t\t\t\t\tLast Modified: 10/29/2015\n\n\t\t\t\t\tSubmitted by: Sanjay S Joshi"
 }
}