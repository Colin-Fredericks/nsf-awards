{
 "awd_id": "0963185",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Advanced CyberInfrastructure for High Performance, Data Intensive Computing",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Irene D. Lombardo",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 1337272.0,
 "awd_amount": 1337272.0,
 "awd_min_amd_letter_date": "2010-08-24",
 "awd_max_amd_letter_date": "2012-03-05",
 "awd_abstract_narration": "This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). \r\n\r\nThis infrastructure project will renovate a data center in the Bloomberg Center on the Homewood Campus of Johns Hopkins University.  The data center space will be refurbished to provide a flexible, stable, energy efficient environment for the high density of computing equipment needed to support research and research training in the Krieger School of Arts and Sciences, Whiting School of Engineering and Sheridan Libraries. The power capacity will be increased by a factor of six and the network connections from the renovated space to the campus networking core and to Internet2 will be increased from 1 GigE to 10 GigE.\r\n\r\nThe renovated space will be used to assemble and house state-of-the art equipment that will transform the scale and types of calculations that can be performed, directly affecting research by 36 faculty from a dozen departments.  This will enable more sophisticated calculations that will advance understanding of materials, turbulence, astronomy, environmental science, climate, high-energy physics, and biological systems. \r\n\r\nThe renovated data center will provide an energy efficient facility for data intensive computing, with rapid network access for researchers across the Homewood Campus and beyond, serving as a focal point for interdisciplinary activities in computational science and engineering. The ten-fold increase in the speed of the Internet2 connection will benefit remote users of data repositories stored in the center, as well as researchers in the Schools of Public Health and Medicine. The renovated center will provide the space and network bandwidth needed to host databases and research programs of broad use and interest, including the Sloan Digital Sky Survey, the U. S. Virtual Astronomy Observatory, SkyQuery, Pan-STARRS, and the Data Conservancy.\r\n\r\nTraining students to use new computational tools and algorithms effectively will have an important impact on the nation's industries and on research in universities and in national laboratories.  The renovated research and training facility will be central to research training initiatives, exciting young students about possible careers in science and engineering and aiding in recruiting a diverse pool of interested students.  As an example, students in the JHU IGERT on modeling complex systems will use the expanded data center and the 100Teraflop Graphics Processor Laboratory, enabled by the renovation, to implement and apply new algorithms. JHU is committed to expanding participation in science and engineering activities, such as through the IGERT project, which is partnering with women?s colleges and other universities with a high percentage of students from underrepresented groups.",
 "awd_arra_amount": 1337272.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jonathan",
   "pi_last_name": "Bagger",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Jonathan A Bagger",
   "pi_email_addr": "bagger@aps.org",
   "nsf_id": "000194302",
   "pi_start_date": "2010-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Alexander",
   "pi_last_name": "Szalay",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Alexander S Szalay",
   "pi_email_addr": "aszalay1@jhu.edu",
   "nsf_id": "000472256",
   "pi_start_date": "2010-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Robbins",
   "pi_mid_init": "O",
   "pi_sufx_name": "",
   "pi_full_name": "Mark O Robbins",
   "pi_email_addr": "mr@pha.jhu.edu",
   "nsf_id": "000093379",
   "pi_start_date": "2010-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Charles",
   "pi_last_name": "Meneveau",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Charles V Meneveau",
   "pi_email_addr": "meneveau@jhu.edu",
   "nsf_id": "000113441",
   "pi_start_date": "2010-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Golam",
   "pi_last_name": "Choudhury",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Golam S Choudhury",
   "pi_email_addr": "sayeedc@cmu.edu",
   "nsf_id": "000252360",
   "pi_start_date": "2010-08-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "3400 N CHARLES ST",
  "perf_city_name": "BALTIMORE",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182608",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "915500",
   "pgm_ele_name": "ACADEMIC RESEARCH INFRASTRUCTU"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6890",
   "pgm_ref_txt": "RECOVERY ACT ACTION"
  },
  {
   "pgm_ref_code": "9155",
   "pgm_ref_txt": "ACADEMIC RESEARCH INFRASTRUCTU"
  }
 ],
 "app_fund": [
  {
   "app_code": "01R9",
   "app_name": "RRA RECOVERY ACT",
   "app_symb_id": "040101",
   "fund_code": "01R00910DB",
   "fund_name": "RRA RECOVERY ACT",
   "fund_symb_id": "040101"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 1337272.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This award funded a renovation to provide a flexible, stable, and energy efficient environment for high performance computing equipment in support of research and research training on the Homewood Campus of the Johns Hopkins University.&nbsp; Consolidating equipment into a single room enables a tightly coupled networking of large, heterogeneous clusters that include compute, data, and GPU components, allowing computational science to be done in new ways.</p>\n<p>The Homewood High Performance Cluster (HHPC) is housed in the renovated facility.&nbsp; HHPC is a commodity compute cluster with Intel processors and an Infiniband network.&nbsp; The center serves as a focal point for interdisciplinary activities in computational science and engineering. The ten-fold increase in the speed provided by the Internet2 connection has benefited remote users of data repositories stored in the renovated facility, as well as researchers from our schools of public health and medicine on our East Baltimore campus, who share the connection.</p>\n<p>The data center allows for fast connections between the HHPC and two more specialized clusters, the Graphics Processor Laboratory and Data-Scope. &nbsp;Research groups move their projects between these clusters to take advantage of the unique capabilities that each offers. &nbsp;The system has been in continuous use since the spring of 2013. &nbsp;Largely because of these clusters and the GPU related research done on them, JHU became a CUDA Center of Excellence.</p>\n<p>The data center also hosts the servers for the Sloan Digital Sky Survey archive, the world&rsquo;s most used astronomy facility today, as well as the storage system used by the NSF DataNet-funded Data Conservatory for curation of the Sloan Digital Sky Survey data and the Johns Hopkins University Data Management Services (JHUDMS). &nbsp;</p>\n<p>JHUDMS has been a critical component of research, development, prototyping and implementation of the Sheridan Libraries&rsquo; data management program. &nbsp;Lessons learned from the curation of the Sloan Digital Sky Data are being tracked at the following web site: https://wikilibrary.jhu.edu/x/eY1XAQ. The wiki space has been noted within social media and various conferences as an exemplar for sharing lessons learned related to data curation of a large-scale data collection. &nbsp;The storage system was also the foundation for a series of capstone projects with the Carey Business School.</p>\n<p>The Institute for Data Intensive Engineering and Science (IDIES) is responsible for managing the data center.&nbsp; More information can be found on their website:&nbsp; <a href=\"http://idies.jhu.edu/Resources\">http://idies.jhu.edu/Resources</a>.&nbsp; IDIES is incubator for creating, curating, and publishing new data sets.&nbsp; IDIES research centers around the generation and analysis of very large scientific databases. &nbsp;Several public online databases have been developed, including the JHU Turbulence Database Cluster (TDC) site at: <a href=\"http://turbulence.pha.jhu.edu\">http://turbulence.pha.jhu.edu</a>. This is a web site that enables access to multi-Terabyte turbulence databases. &nbsp;The data reside on several nodes and disks on our database computer and are stored in small 3D subcubes. &nbsp;Another online database, the Sloan Digital Sky Survey II &ndash; SkyServer DR10, presents data that cover a large part of the universe. &nbsp;The purpose is to show the beauty of the universe, and to share the excitement as the largest map in the history of the world is built.</p>\n<p>The existence of this renovated data center is allowing JHU researchers to spark new exchanges between remote collaborators, and to exploit the complexity of scientific data that will change the way computing and research is done.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/25/2013<br>\n\t\t\t\t\tModified by: Jonathan&nbsp;A&nbsp;Bagger</p>\n</div>\n<div class=\"porSideCol\"></div...",
  "por_txt_cntn": "\nThis award funded a renovation to provide a flexible, stable, and energy efficient environment for high performance computing equipment in support of research and research training on the Homewood Campus of the Johns Hopkins University.  Consolidating equipment into a single room enables a tightly coupled networking of large, heterogeneous clusters that include compute, data, and GPU components, allowing computational science to be done in new ways.\n\nThe Homewood High Performance Cluster (HHPC) is housed in the renovated facility.  HHPC is a commodity compute cluster with Intel processors and an Infiniband network.  The center serves as a focal point for interdisciplinary activities in computational science and engineering. The ten-fold increase in the speed provided by the Internet2 connection has benefited remote users of data repositories stored in the renovated facility, as well as researchers from our schools of public health and medicine on our East Baltimore campus, who share the connection.\n\nThe data center allows for fast connections between the HHPC and two more specialized clusters, the Graphics Processor Laboratory and Data-Scope.  Research groups move their projects between these clusters to take advantage of the unique capabilities that each offers.  The system has been in continuous use since the spring of 2013.  Largely because of these clusters and the GPU related research done on them, JHU became a CUDA Center of Excellence.\n\nThe data center also hosts the servers for the Sloan Digital Sky Survey archive, the world\u00c6s most used astronomy facility today, as well as the storage system used by the NSF DataNet-funded Data Conservatory for curation of the Sloan Digital Sky Survey data and the Johns Hopkins University Data Management Services (JHUDMS).  \n\nJHUDMS has been a critical component of research, development, prototyping and implementation of the Sheridan Libraries\u00c6 data management program.  Lessons learned from the curation of the Sloan Digital Sky Data are being tracked at the following web site: https://wikilibrary.jhu.edu/x/eY1XAQ. The wiki space has been noted within social media and various conferences as an exemplar for sharing lessons learned related to data curation of a large-scale data collection.  The storage system was also the foundation for a series of capstone projects with the Carey Business School.\n\nThe Institute for Data Intensive Engineering and Science (IDIES) is responsible for managing the data center.  More information can be found on their website:  http://idies.jhu.edu/Resources.  IDIES is incubator for creating, curating, and publishing new data sets.  IDIES research centers around the generation and analysis of very large scientific databases.  Several public online databases have been developed, including the JHU Turbulence Database Cluster (TDC) site at: http://turbulence.pha.jhu.edu. This is a web site that enables access to multi-Terabyte turbulence databases.  The data reside on several nodes and disks on our database computer and are stored in small 3D subcubes.  Another online database, the Sloan Digital Sky Survey II &ndash; SkyServer DR10, presents data that cover a large part of the universe.  The purpose is to show the beauty of the universe, and to share the excitement as the largest map in the history of the world is built.\n\nThe existence of this renovated data center is allowing JHU researchers to spark new exchanges between remote collaborators, and to exploit the complexity of scientific data that will change the way computing and research is done.\n\n\t\t\t\t\tLast Modified: 11/25/2013\n\n\t\t\t\t\tSubmitted by: Jonathan A Bagger"
 }
}