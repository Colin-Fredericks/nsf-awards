{
 "awd_id": "0960529",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Iterative Models in Figure-Ground Perception: Tests and Challenges",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Anne Cleary",
 "awd_eff_date": "2010-06-15",
 "awd_exp_date": "2014-05-31",
 "tot_intn_awd_amt": 444193.0,
 "awd_amount": 444193.0,
 "awd_min_amd_letter_date": "2010-06-12",
 "awd_max_amd_letter_date": "2010-06-12",
 "awd_abstract_narration": "Visual perception seems trivially easy. Nevertheless, it has long withstood the attempts of both computer scientists and vision scientists to crack its code, most likely because past theories were based predominantly on conscious vision. In order for perceivers to experience a coherent visual world, perceptual input must be organized into separate objects, or \"figures.\" As part of this process, the brain decides where a figure lies with respect to every border between two contiguous regions of space. Consider a vertical border, for instance. The brain decides whether that border is a boundary for a figure lying on the left or the right. When the border is perceived as a boundary of a figure lying on the left, the region on the right seems simply to continue behind the figure at the border; no shape is perceived there. These \"figure-ground\" decisions are made outside of conscious awareness. Because of this, it is extremely difficult to investigate the mechanisms that produce figure-ground perception. An important, unanswered, question is whether figure-ground perception is accomplished via fast, feed-forward mechanisms or whether iterative mechanisms involving feedback from higher processing levels are involved. In feed-forward models, the input is processed in successive stages until a coherent percept emerges.  In iterative models, feed-forward processing is not sufficient; feedback from higher to lower levels is necessary to create the percept.\r\n\r\nMary Peterson and her colleagues at the University of Arizona have designed visual displays that allow them to investigate this question. One display type is a small symmetric, bounded silhouette lying on a larger ground. Portions of familiar shapes are hidden along the groundside of the silhouette's border; these shapes are not perceived consciously, only the shape of the enclosed silhouette is perceived consciously. (The classic \"face-vase illusion\" is an example of this.) Previous experiments have shown that the shape of the hidden object is suppressed when it is not perceived, supporting the view that figure-ground perception results from inhibitory competition between shapes that might be seen on opposite sides of a border; the winner is perceived as the shaped figure, whereas the loser is suppressed and the portion of space where it might have been seen is perceived as a shapeless ground. These displays are designed to isolate competition at the shape processing stage. Dr. Peterson and colleagues will also conduct a series of experiments which test whether suppression can be observed at lower levels where individual parts are represented and at higher levels where shape descriptions (\"semantics\") are represented.  According to a feed-forward account, suppression of the losing shape would prevent access to its semantics; hence, no effects should be evident at higher levels. Without feedback, no effects should be evident at lower, part-processing, levels either. An iterative view could account for suppression at lower and/or higher levels by assuming that the outcome of the between-shape competition was relayed to higher and lower levels. Thus the proposed experiments will adjudicate between these competing views of how perception occurs.  The researchers will also attempt to identify the processes involved in segregating figures from grounds in crowded real-world scenes. The perception of these more complex displays constitutes a challenge to current iterative models of figure-ground perception.  The planned research will provide a foundation for neurophysiological experiments and formal computational models of vision and will contribute to our understanding of the temporal and spatial dynamics of shape perception.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mary",
   "pi_last_name": "Peterson",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Mary A Peterson",
   "pi_email_addr": "mapeters@u.arizona.edu",
   "nsf_id": "000165530",
   "pi_start_date": "2010-06-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Arizona",
  "inst_street_address": "845 N PARK AVE RM 538",
  "inst_street_address_2": "",
  "inst_city_name": "TUCSON",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "5206266000",
  "inst_zip_code": "85721",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "AZ07",
  "org_lgl_bus_name": "UNIVERSITY OF ARIZONA",
  "org_prnt_uei_num": "",
  "org_uei_num": "ED44Y3W6P7B9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Arizona",
  "perf_str_addr": "845 N PARK AVE RM 538",
  "perf_city_name": "TUCSON",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "85721",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "AZ07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 444193.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Most people assume that visual perception requires only a pair of eyes with acuity sufficient to identify the letters in line 6 of the optometrist&rsquo;s chart. But, the eyes are insufficient for vision; the brain plays a huge role. The brain finds the best way to interpret the light received by the eyes as objects and scenes.</p>\n<p>&nbsp;</p>\n<p>What do you see in Figure 1? Most people see an unfamiliar black object on a white background.</p>\n<p>&nbsp;</p>\n<p>Insert Figure 1 about here</p>\n<p>&nbsp;</p>\n<p>Yet if you look at the white regions close to the left and right sides, you can see portions of familiar objects &mdash; white seahorses in profile. Pictures like this allow us to investigate a critical question regarding visual perception: Is visual perception best understood as a sequential process in which light received by the eye is processed in a one-way street in the brain from low to high levels until, at some high level, perception occurs and conceptual knowledge is accessed? Or, does visual perception involve a two-way street with communication between levels occurring in a backward direction as well as a forward direction?</p>\n<p>&nbsp;</p>\n<p>According to the one-way street hypothesis, there is no reason for the brain to process the areas on the outside of black silhouettes like the one in Figure 1; an object will not ultimately be perceived there, so it is wasteful to expend processing resources evaluating what might be there. In contrast, the two-way street hypothesis posits that the brain evaluates all objects that might be present and selects the best interpretation for the scene; the selection process involves backward communication from high to low levels as well as forward communication from low to high levels.</p>\n<p>&nbsp;</p>\n<p>By testing people with pictures like Figure 1 during this award period, my students and I found that before you see objects, your brain considers alternatives and then decides what you will see. These alternatives compete outside of conscious awareness, and the viewer is aware only of the object that wins the competition. For the image in Figure 1, the brain considers white seahorses as well as the unfamiliar black object. Conceptual knowledge about the white seahorses &ndash;that they are natural objects rather than artificial objects, for instance &ndash; is also activated earl in the course of perceptual processing. However, the black object tends to win the competition, and that is the object observers perceive. Observers tend to remain unaware of the seahorses; they are even unaware that there might be an alternative interpretation.</p>\n<p>&nbsp;</p>\n<p>We found that similar processes occur for whole scenes, and measured the time required to resolve scene-wide competition, even in displays that seem unambiguous because the vast majority of observers perceive the same thing. These results support the two-way street hypothesis.</p>\n<p>&nbsp;</p>\n<p><strong>Intellectual Merit. </strong>My students and I are the first to find evidence that conceptual knowledge is activated before the brain determines whether to perceive a object on the inside or the outside of silhouettes like those in Figure 1. We are also the first to show that the visual system considers alternative interpretations of scenes that are unambiguous by perceptual report. These findings are difficult to explain on the prevailing one-way processing models. In challenging those models, our results advance the frontiers of knowledge.</p>\n<p><strong>&nbsp;</strong></p>\n<p><strong>Broader Impacts</strong>. In the course of conducting this research, five graduate students in my laboratory were exposed to cutting-edge research, and were trained in theoretical thinking, in careful experimental design, in data analysis and interpretation, as well as in how to present their research in professional as well as public settings. Together we have disseminated th...",
  "por_txt_cntn": "\nMost people assume that visual perception requires only a pair of eyes with acuity sufficient to identify the letters in line 6 of the optometrist\u00c6s chart. But, the eyes are insufficient for vision; the brain plays a huge role. The brain finds the best way to interpret the light received by the eyes as objects and scenes.\n\n \n\nWhat do you see in Figure 1? Most people see an unfamiliar black object on a white background.\n\n \n\nInsert Figure 1 about here\n\n \n\nYet if you look at the white regions close to the left and right sides, you can see portions of familiar objects &mdash; white seahorses in profile. Pictures like this allow us to investigate a critical question regarding visual perception: Is visual perception best understood as a sequential process in which light received by the eye is processed in a one-way street in the brain from low to high levels until, at some high level, perception occurs and conceptual knowledge is accessed? Or, does visual perception involve a two-way street with communication between levels occurring in a backward direction as well as a forward direction?\n\n \n\nAccording to the one-way street hypothesis, there is no reason for the brain to process the areas on the outside of black silhouettes like the one in Figure 1; an object will not ultimately be perceived there, so it is wasteful to expend processing resources evaluating what might be there. In contrast, the two-way street hypothesis posits that the brain evaluates all objects that might be present and selects the best interpretation for the scene; the selection process involves backward communication from high to low levels as well as forward communication from low to high levels.\n\n \n\nBy testing people with pictures like Figure 1 during this award period, my students and I found that before you see objects, your brain considers alternatives and then decides what you will see. These alternatives compete outside of conscious awareness, and the viewer is aware only of the object that wins the competition. For the image in Figure 1, the brain considers white seahorses as well as the unfamiliar black object. Conceptual knowledge about the white seahorses &ndash;that they are natural objects rather than artificial objects, for instance &ndash; is also activated earl in the course of perceptual processing. However, the black object tends to win the competition, and that is the object observers perceive. Observers tend to remain unaware of the seahorses; they are even unaware that there might be an alternative interpretation.\n\n \n\nWe found that similar processes occur for whole scenes, and measured the time required to resolve scene-wide competition, even in displays that seem unambiguous because the vast majority of observers perceive the same thing. These results support the two-way street hypothesis.\n\n \n\nIntellectual Merit. My students and I are the first to find evidence that conceptual knowledge is activated before the brain determines whether to perceive a object on the inside or the outside of silhouettes like those in Figure 1. We are also the first to show that the visual system considers alternative interpretations of scenes that are unambiguous by perceptual report. These findings are difficult to explain on the prevailing one-way processing models. In challenging those models, our results advance the frontiers of knowledge.\n\n \n\nBroader Impacts. In the course of conducting this research, five graduate students in my laboratory were exposed to cutting-edge research, and were trained in theoretical thinking, in careful experimental design, in data analysis and interpretation, as well as in how to present their research in professional as well as public settings. Together we have disseminated the research broadly, via 19 publications (and another 4 under review), and 64 national and international conference presentations during the award period.\n\n \n\nBecause the University of Arizona is located in the southwest United States, it attracts graduate..."
 }
}