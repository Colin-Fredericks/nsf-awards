{
 "awd_id": "1055290",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: The Exploration of Memory Hierarchy Design and Optimization for Multi-core Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 190603.0,
 "awd_amount": 190603.0,
 "awd_min_amd_letter_date": "2010-08-26",
 "awd_max_amd_letter_date": "2010-08-26",
 "awd_abstract_narration": "Recently, there has been a growing disparity between processor and memory speeds; this disparity is called the ?memory wall? problem. Memory performance has a dominating effect on overall system performance, especially for the data-dominated applications. Also, memory usually occupies half of the surface of the integrated chip of the multi-core system; the total amount of memory required is also a main contributor of the manufacturing cost and the chip size of the multi-core CPU. Memory also dictates the power consumption, since memories and buses consume large quantities of energy. The ?memory wall? problem becomes even more serious when throughput in the processor part is propelled by multi-core architectures.\r\n\r\nIn this proposal, the PI is carrying out research to address the ?memory wall? problem and to develop potentially transformative approaches for memory hierarchy design and configuration in multi-core systems. Different memory architectures can lead to different solutions with different costs and with different performances. Memory size, memory configuration, and memory architecture will be optimized simultaneously for multi-core architectures in order to effectively and efficiently achieve higher performance.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Meilin",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Meilin Liu",
   "pi_email_addr": "meilin.liu@wright.edu",
   "nsf_id": "000502977",
   "pi_start_date": "2010-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Wright State University",
  "inst_street_address": "3640 COLONEL GLENN HWY",
  "inst_street_address_2": "",
  "inst_city_name": "DAYTON",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "9377752425",
  "inst_zip_code": "454350002",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "OH10",
  "org_lgl_bus_name": "WRIGHT STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPT2UNTNHJZ1"
 },
 "perf_inst": {
  "perf_inst_name": "Wright State University",
  "perf_str_addr": "3640 COLONEL GLENN HWY",
  "perf_city_name": "DAYTON",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "454350002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "OH10",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 190603.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>1.&nbsp; Proposed a new thread scheduling technique that can take advantage of data locality both among nearby warps and in the same warp to optimize the scientific applications on the GP-GPU systems. By analyzing the memory access patterns of the scientific applications, we try to find the regularities in the data access pattern of the scientific applications.&nbsp; Then we propose a new thread scheduling technique that can take advantage of data locality both among nearby warps and in the same warp to optimize the scientific applications on the GP-GPU systems. The simulation results validated our proposed thread scheduling technique and showed that significant improvements have been achieved.<br /><br />2.&nbsp; Proposed a dynamic warp scheduling algorithm considering both inter-warp and intra-warp locality to increase the global memory access throughput and L1 cache efficiency.<br /><br />3. Proposed and investigated a scheme to compute the memory cost of a basic block and a loop nest based on the data dependency distance. Use the memory cost model as the guidance for the scheduling techniques.<br /><br />4. Developed new memory allocation algorithms using&nbsp; the memory cost model. <br /><br />5.&nbsp; Developed new cache partitioning algorithm for specific hardware architectures, including multicore systems, and embedded systems.<br /><br />6. Developed a new graduate level course, CS4370/6370, \"Parallel Programming for manycore GPUs\". The graduate studens and undergraduate student who took the class will learn about new many-core GPU architecture, CUDA programming model, memory hierarchy design, parallel programming concepts, and compiling techniques to improve parallelism.&nbsp; Students who took the class will also learn how to develop scalable parallel programs to achieve high performance on GPUs.<br /><br />7. Teaching proposal &ldquo; Building a CUDA Teaching Center Laboratory at Wright State University,&rdquo; is currently awarded by Nvidia with matching funds ($9000) and equipment donation ($3940.18).</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/31/2013<br>\n\t\t\t\t\tModified by: Meilin&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n1.  Proposed a new thread scheduling technique that can take advantage of data locality both among nearby warps and in the same warp to optimize the scientific applications on the GP-GPU systems. By analyzing the memory access patterns of the scientific applications, we try to find the regularities in the data access pattern of the scientific applications.  Then we propose a new thread scheduling technique that can take advantage of data locality both among nearby warps and in the same warp to optimize the scientific applications on the GP-GPU systems. The simulation results validated our proposed thread scheduling technique and showed that significant improvements have been achieved.\n\n2.  Proposed a dynamic warp scheduling algorithm considering both inter-warp and intra-warp locality to increase the global memory access throughput and L1 cache efficiency.\n\n3. Proposed and investigated a scheme to compute the memory cost of a basic block and a loop nest based on the data dependency distance. Use the memory cost model as the guidance for the scheduling techniques.\n\n4. Developed new memory allocation algorithms using  the memory cost model. \n\n5.  Developed new cache partitioning algorithm for specific hardware architectures, including multicore systems, and embedded systems.\n\n6. Developed a new graduate level course, CS4370/6370, \"Parallel Programming for manycore GPUs\". The graduate studens and undergraduate student who took the class will learn about new many-core GPU architecture, CUDA programming model, memory hierarchy design, parallel programming concepts, and compiling techniques to improve parallelism.  Students who took the class will also learn how to develop scalable parallel programs to achieve high performance on GPUs.\n\n7. Teaching proposal \" Building a CUDA Teaching Center Laboratory at Wright State University,\" is currently awarded by Nvidia with matching funds ($9000) and equipment donation ($3940.18).\n\n\t\t\t\t\tLast Modified: 08/31/2013\n\n\t\t\t\t\tSubmitted by: Meilin Liu"
 }
}