{
 "awd_id": "1016018",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CIF:  Small:  Visual Recognition and Restoration In Concert",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Cozzens",
 "awd_eff_date": "2010-08-01",
 "awd_exp_date": "2013-07-31",
 "tot_intn_awd_amt": 443957.0,
 "awd_amount": 443957.0,
 "awd_min_amd_letter_date": "2010-07-20",
 "awd_max_amd_letter_date": "2012-05-14",
 "awd_abstract_narration": "Project Abstract for NSF Proposal 1016018\r\n          Visual Recognition and Restoration In Concert\r\n\t\t\tPeyman Milanfar\r\n\t\t  Electrical Engineering Department\r\n\t\tUniversity of California at Santa Cruz\r\n\r\nIn this research effort a central challenge in computer vision is addressed: Namely, to recognize and enhance objects in complex visual scenes given imperfect images, and more generally, video data. This effort strengthens the theoretical and practical foundations for generic visual object recognition systems that can deal with significant variations in visual appearance, a large number of categories, and stochastically and systematically degraded data. Data imperfections can include random noise, blur, and environmental degradations. The approach has transformative potential for a broad range of practical applications such as scalable image search and retrieval, automatic annotation, surveillance and security, video forensics, and medical image analysis for computer-aided\r\ndiagnosis.\r\n\r\nThe research advances the state-of-the-art in two important ways: (a) a unified and robust framework is derived for both (2-D) object and (3-D) action recognition, even when the data is subject to significant distortions, and (b) recognition and restoration from degraded data are treated in a common, statistically optimal setting. Traditionally, recognition and restoration have been addressed with limited awareness of each other?s techniques and of potential commonalities in approach. By improving, generalizing, and refining previously separate approaches to recognition with degraded data in an adaptive, non-parametric setting, for both 2-D and 3-D, this project contributes to the technical foundations and toolkits that can connect computer vision and image processing\r\nintelligently.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peyman",
   "pi_last_name": "Milanfar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Peyman Milanfar",
   "pi_email_addr": "milanfar@ee.ucsc.edu",
   "nsf_id": "000465013",
   "pi_start_date": "2010-07-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Cruz",
  "inst_street_address": "1156 HIGH ST",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA CRUZ",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8314595278",
  "inst_zip_code": "950641077",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "CA19",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA SANTA CRUZ",
  "org_prnt_uei_num": "",
  "org_uei_num": "VXUFPE4MCZH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Cruz",
  "perf_str_addr": "1156 HIGH ST",
  "perf_city_name": "SANTA CRUZ",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "950641077",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "CA19",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  },
  {
   "pgm_ele_code": "793600",
   "pgm_ele_name": "SIGNAL PROCESSING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 141257.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 147840.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 154860.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div>During the last year of the project, despite the PI being on leave of absence, the research team has made excellent progress supported by this grant. In total, 4 full length journal and 4 conference papers were published in the highest quality venues. It is also important to note that software for all work performed during this grant were made freely available to the research community. Here is a summary of accomplishments:</div>\n<div>*&nbsp;Estimating the amount of blur in a given image is important for computer vision applications. More speci?cally,the spatially varying defocus point-spread-functions over an image reveal geometric information of the scene, and theirestimate can also be used to recover an all-in-focus image. APSF for a defocus blur can be speci?ed by a single parameterindicating its scale. Most existing algorithms can only selectan optimal blur from a ?nite set of candidate PSFs for eachpixel. Some of those methods require a coded aperture ?lterinserted in the camera. We derived an algorithm estimating a defocus scale map from a single image, which is applicable to conventional cameras. This method is capable of measuring the probability of local defocus scale in the continuousdomain. It also takes smoothness and color edge informationinto consideration to generate a coherent blur map indicatingthe amount of blur at each pixel.&nbsp;</div>\n<div>*&nbsp;We studied a general class of nonlinear and shift-varying smoothing ?lters that operate based onaveraging. This important class of ?lters includes many well-known examples such as the bilateral?lter, nonlocal means, general adaptive moving average ?lters, and more. (Many linear ?lters suchas linear minimum mean-squared error smoothing ?lters, Savitzky&ndash;Golay ?lters, smoothing splines,and wavelet smoothers can be considered special cases.) They are frequently used in both signal andimage processing as they are elegant, computationally simple, and high performing. The operatorsthat implement such ?lters, however, are not symmetric in general. The main contribution was to provide a provably stable method for symmetrizing the smoothing operators. Speci?cally,we propose a novel approximation of smoothing operators by symmetric doubly stochastic matricesand show that this approximation is stable and accurate, even more so in higher dimensions. Wedemonstrate that there are several important advantages to this symmetrization, particularly inimage processing/?ltering applications such as denoising. In particular, (1) doubly stochastic ?ltersgenerally lead to improved performance over the baseline smoothing procedure; (2) when the ?ltersare applied iteratively, the symmetric ones can be guaranteed to lead to stable algorithms; and (3) symmetric smoothers allow an orthonormal eigendecomposition which enables us to peer into the complex behavior of such nonlinear and shift-varying ?lters in a locally adapted orthogonal basis.</div>\n<div>*&nbsp;The human visual system possesses the remarkable ability to pick out salient objects in images. Even more impressiveis its ability to do the very same in the presence of disturbances. In particular, the ability persists despite the presenceof noise, poor weather, and other impediments to perfect vision. Meanwhile, noise can signi?cantly degrade the accuracyof automated computational saliency detection algorithms. We set out to remedy this shortcoming. We proposed a novel and statistically sound method forestimating saliency based on a non-parametric regression framework, and investigate the stability of saliency models fornoisy images and analyze how state-of-the-art computational models respond to noisy visual stimuli. The proposed modelof saliency at a pixel of interest is a data-dependent weighted average of dissimilarities between a center patch around thatpixel and other patches. Our method consistently outperforms six other state-of-the-art models</div>\n<div>J...",
  "por_txt_cntn": "During the last year of the project, despite the PI being on leave of absence, the research team has made excellent progress supported by this grant. In total, 4 full length journal and 4 conference papers were published in the highest quality venues. It is also important to note that software for all work performed during this grant were made freely available to the research community. Here is a summary of accomplishments:\n* Estimating the amount of blur in a given image is important for computer vision applications. More speci?cally,the spatially varying defocus point-spread-functions over an image reveal geometric information of the scene, and theirestimate can also be used to recover an all-in-focus image. APSF for a defocus blur can be speci?ed by a single parameterindicating its scale. Most existing algorithms can only selectan optimal blur from a ?nite set of candidate PSFs for eachpixel. Some of those methods require a coded aperture ?lterinserted in the camera. We derived an algorithm estimating a defocus scale map from a single image, which is applicable to conventional cameras. This method is capable of measuring the probability of local defocus scale in the continuousdomain. It also takes smoothness and color edge informationinto consideration to generate a coherent blur map indicatingthe amount of blur at each pixel. \n* We studied a general class of nonlinear and shift-varying smoothing ?lters that operate based onaveraging. This important class of ?lters includes many well-known examples such as the bilateral?lter, nonlocal means, general adaptive moving average ?lters, and more. (Many linear ?lters suchas linear minimum mean-squared error smoothing ?lters, Savitzky&ndash;Golay ?lters, smoothing splines,and wavelet smoothers can be considered special cases.) They are frequently used in both signal andimage processing as they are elegant, computationally simple, and high performing. The operatorsthat implement such ?lters, however, are not symmetric in general. The main contribution was to provide a provably stable method for symmetrizing the smoothing operators. Speci?cally,we propose a novel approximation of smoothing operators by symmetric doubly stochastic matricesand show that this approximation is stable and accurate, even more so in higher dimensions. Wedemonstrate that there are several important advantages to this symmetrization, particularly inimage processing/?ltering applications such as denoising. In particular, (1) doubly stochastic ?ltersgenerally lead to improved performance over the baseline smoothing procedure; (2) when the ?ltersare applied iteratively, the symmetric ones can be guaranteed to lead to stable algorithms; and (3) symmetric smoothers allow an orthonormal eigendecomposition which enables us to peer into the complex behavior of such nonlinear and shift-varying ?lters in a locally adapted orthogonal basis.\n* The human visual system possesses the remarkable ability to pick out salient objects in images. Even more impressiveis its ability to do the very same in the presence of disturbances. In particular, the ability persists despite the presenceof noise, poor weather, and other impediments to perfect vision. Meanwhile, noise can signi?cantly degrade the accuracyof automated computational saliency detection algorithms. We set out to remedy this shortcoming. We proposed a novel and statistically sound method forestimating saliency based on a non-parametric regression framework, and investigate the stability of saliency models fornoisy images and analyze how state-of-the-art computational models respond to noisy visual stimuli. The proposed modelof saliency at a pixel of interest is a data-dependent weighted average of dissimilarities between a center patch around thatpixel and other patches. Our method consistently outperforms six other state-of-the-art models\nJournal publications during the final year: \n\nX. Zhu, S. Cohen, S. Schiller, and P. Milanfar, \" Estimating Spatially Varying Defoc..."
 }
}