{
 "awd_id": "0968878",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER:  Perfect sampling techniques for high dimensional integration",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032924885",
 "po_email": "tbartosz@nsf.gov",
 "po_sign_block_name": "Tomek Bartoszynski",
 "awd_eff_date": "2009-09-01",
 "awd_exp_date": "2011-12-31",
 "tot_intn_awd_amt": 119272.0,
 "awd_amount": 119272.0,
 "awd_min_amd_letter_date": "2009-10-14",
 "awd_max_amd_letter_date": "2010-02-24",
 "awd_abstract_narration": "This project will develop and analyze new computational methodologies for generating random variates from high dimensional distributions where the normalizing constant is unknown.  These random variates are then used to obtain approximations for problems involving high dimensional integrations.  Algorithms employing random variates are known as Monte Carlo methods.  Direct methods often suffer from  running times that are exponential in the dimension of the problem, whereas Monte Carlo approaches can have a polynomial or even linear running time.  Applications include estimate of parameters arising from probabilistic models, approximation of exact p-values in statistics, and efficient algorithms for approximate solutions to NP complete and \\#P complete problems.  The new algorithms are in a class of methods known as perfect sampling algorithms.  Existing perfect samplers such as Coupling From the Past have made an impact on Monte Carlo methods, but suffer from certain flaws that limit their applicability.  Here new methodologies such as the Randomness Recycler and other modifications and generalizations of acceptance rejection approaches will be used to solve these problems.  As part of this project, new classes will be developed and undergraduates and graduate students will have opportunities to work on problems arising in this area.\r\n\r\nToday our data collection abilities are better than at any point in history, but the time needed to analyze data can grow exponentially in the amount collected.  The use of randomness in designing algorithms for analysis of data can result in enormous benefits in speed and accuracy.  These techniques have been a cornerstone of computational methodology for the last fifty years.  Statistics, finance, signal processing, physics, and genetics are but some of the areas that have benefited from the injection of randomness into the design of algorithms.  However, existing methods are not without difficulties.  A new class of algorithms called perfect sampling methods solves many of these problems in specific cases, but their applicability is limited.  The goal of this project is to extend the reach of these  methods by introducing new types of perfect sampling algorithms.  The result will be faster, more accurate algorithms of the type used by practitioners every day in a wide variety of fields.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Huber",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Mark L Huber",
   "pi_email_addr": "mhuber@cmc.edu",
   "nsf_id": "000382347",
   "pi_start_date": "2009-10-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Claremont McKenna College",
  "inst_street_address": "500 E 9TH ST",
  "inst_street_address_2": "",
  "inst_city_name": "CLAREMONT",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9096077085",
  "inst_zip_code": "917115929",
  "inst_country_name": "United States",
  "cong_dist_code": "28",
  "st_cong_dist_code": "CA28",
  "org_lgl_bus_name": "CLAREMONT MCKENNA COLLEGE",
  "org_prnt_uei_num": "L45FLFHWMGQ9",
  "org_uei_num": "L45FLFHWMGQ9"
 },
 "perf_inst": {
  "perf_inst_name": "Claremont McKenna College",
  "perf_str_addr": "500 E 9TH ST",
  "perf_city_name": "CLAREMONT",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "917115929",
  "perf_ctry_code": "US",
  "perf_cong_dist": "28",
  "perf_st_cong_dist": "CA28",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126300",
   "pgm_ele_name": "PROBABILITY"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 12196.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 53886.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 53190.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Modern methods of statistical analysis require the ability to integrate complex functions over a large number of dimensions.&nbsp; For low dimensions of five or below, direct numerical methods can be used to approximate these integrals.&nbsp; But in many applications, the dimension of integration is the number of data points taken, resulting in integrals over dimensions ranging from a hundred to millions.</p>\n<p>This project developed new techniques for approximating high dimensional integrals, with an eye towards using methods for statistical analysis.&nbsp; For mathematical models such a perpetuities, matchings, overdispersed point processes, and restricted rankings, this project developed new algorithms.&nbsp; For most of these problems, it was possible to mathematically prove that the new algorithms are faster than the old ones.</p>\n<p>&nbsp;As an example, consider the following simple, but powerful, model of&nbsp;city formation.&nbsp; At some time in the past, a&nbsp;city is founded.&nbsp; This town sweeps out a radius.&nbsp; As new cities are built, they appear outside of the radius of existing cities.&nbsp; This model is simple, but can capture some of the behavior seen in real data sets of city locations.</p>\n<p>In order to fit parameters of this model (the rate of town formation and the radius of influence) using the maximum likelihood estimator, one of these high dimensional integrals needs to be approximated.&nbsp; The dimension of the integral equals the number of cities in the data set.&nbsp; Because of the algorithms developed in this project, it is now possible to build maximum likelihood estimates for this model for real data sets, a first.</p>\n<p>This project also helped to train the next generation of mathematicians.&nbsp; Two women graduate students worked on this project, one of whom now has her PhD.&nbsp; Four men and three women undergraduates also participated in the research, many of whom have now planning to go on to graduate school in mathematics.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/07/2012<br>\n\t\t\t\t\tModified by: Mark&nbsp;L&nbsp;Huber</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nModern methods of statistical analysis require the ability to integrate complex functions over a large number of dimensions.  For low dimensions of five or below, direct numerical methods can be used to approximate these integrals.  But in many applications, the dimension of integration is the number of data points taken, resulting in integrals over dimensions ranging from a hundred to millions.\n\nThis project developed new techniques for approximating high dimensional integrals, with an eye towards using methods for statistical analysis.  For mathematical models such a perpetuities, matchings, overdispersed point processes, and restricted rankings, this project developed new algorithms.  For most of these problems, it was possible to mathematically prove that the new algorithms are faster than the old ones.\n\n As an example, consider the following simple, but powerful, model of city formation.  At some time in the past, a city is founded.  This town sweeps out a radius.  As new cities are built, they appear outside of the radius of existing cities.  This model is simple, but can capture some of the behavior seen in real data sets of city locations.\n\nIn order to fit parameters of this model (the rate of town formation and the radius of influence) using the maximum likelihood estimator, one of these high dimensional integrals needs to be approximated.  The dimension of the integral equals the number of cities in the data set.  Because of the algorithms developed in this project, it is now possible to build maximum likelihood estimates for this model for real data sets, a first.\n\nThis project also helped to train the next generation of mathematicians.  Two women graduate students worked on this project, one of whom now has her PhD.  Four men and three women undergraduates also participated in the research, many of whom have now planning to go on to graduate school in mathematics.\n\n\t\t\t\t\tLast Modified: 05/07/2012\n\n\t\t\t\t\tSubmitted by: Mark L Huber"
 }
}