{
 "awd_id": "1016793",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Towards Realizing Cloud HPC: An Adaptive Programming Model for Accelerator-based Clusters",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2010-08-01",
 "awd_exp_date": "2014-07-31",
 "tot_intn_awd_amt": 409781.0,
 "awd_amount": 441781.0,
 "awd_min_amd_letter_date": "2010-07-21",
 "awd_max_amd_letter_date": "2012-04-18",
 "awd_abstract_narration": "High-End Computing systems, such as cloud computing setups, are increasingly employing many-core compute resources and computational accelerators, e.g., GPUs and IBM Cell processors, for high performance.  However, the use of such components results in a performance and communication mismatch, which in turn makes large-scale systems with heterogeneous resources difficult to design, build and program.  Moreover, the increased data demand of modern advanced applications, coupled with the asymmetry between computation speed and data transmission speed, threaten the benefits of employing accelerators in such setups.\r\n\r\nThis project addresses the above problems by designing a flexible, scalable, and easy-to-use programming model, AMOCA.  AMOCA supports innovative workload distribution techniques, which enables it to be used toward scaling modern scientific and enterprise applications on high-end asymmetric clouds comprising heterogeneous accelerator-type compute nodes. Moreover, AMOCA utilizes component-capability matching and adaptive inter-component data transfers for parallel programming models, automatically handles heterogeneous resources, and auto-tunes the model parameters to the specific instance of resources on which it is run.\r\n\r\nAMOCA lays the foundation for adapting the cloud computing paradigm for HPC, creates open source and transformative technologies for scalable any-core system architectures, and is expected to improve the efficiency and performance of advanced applications in a broad range of disciplines that perform simulation-based experimentation including computational physics, biology, and chemistry. AMOCA employs an integrated research and education approach for training both undergraduate and graduate researchers, especially from underrepresented groups. The training will instill critical system development skills and increase the use of accelerator-based clouds in HPC.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ali",
   "pi_last_name": "Butt",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Ali R Butt",
   "pi_email_addr": "butta@cs.vt.edu",
   "nsf_id": "000288467",
   "pi_start_date": "2010-07-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Polytechnic Institute and State University",
  "inst_street_address": "300 TURNER ST NW",
  "inst_street_address_2": "STE 4200",
  "inst_city_name": "BLACKSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "5402315281",
  "inst_zip_code": "240603359",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "VA09",
  "org_lgl_bus_name": "VIRGINIA POLYTECHNIC INSTITUTE & STATE UNIVERSITY",
  "org_prnt_uei_num": "X6KEFGLHSJX7",
  "org_uei_num": "QDE5UHE5XD16"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Polytechnic Institute and State University",
  "perf_str_addr": "300 TURNER ST NW",
  "perf_city_name": "BLACKSBURG",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "240603359",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "VA09",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 409781.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-5dcfa504-a625-4d4f-09a9-f6fcdecf685a\" style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 9pt; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Modern scientific and enterprise High Performance Computing (HPC) applications have varying behavior. Such variations can benefit from the opportunities presented by the increasing degree of heterogeneity in underlying computing infrastructure, especially in systems that support the emerging cloud computing model. For example, GPUs can be used to speed up compute-intensive tasks while large number of cores and adaptive data placement can help I/O operations. In this project, we designed and developed an </span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">A</span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">daptive programming </span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">MO</span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">del for </span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">C</span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">lusters of </span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">A</span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">ccelerators (AMOCA), a software substrate optimized for scaling applications on </span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">H</span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">igh-</span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">E</span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">nd </span><span style=\"font-size: 16px; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: normal; fo...",
  "por_txt_cntn": "Modern scientific and enterprise High Performance Computing (HPC) applications have varying behavior. Such variations can benefit from the opportunities presented by the increasing degree of heterogeneity in underlying computing infrastructure, especially in systems that support the emerging cloud computing model. For example, GPUs can be used to speed up compute-intensive tasks while large number of cores and adaptive data placement can help I/O operations. In this project, we designed and developed an Adaptive programming MOdel for Clusters of Accelerators (AMOCA), a software substrate optimized for scaling applications on High-End Asymmetric Clouds (HEACs). AMOCA offers a flexible, scalable, and easy-to-use programming model that automatically handles component asymmetry and adapts to the varying capabilities of the system resources on which the applications are executed.\nWe extended the MapReduce programming framework to program asymmetric clusters comprising traditional multicores and specialized accelerators such as Cell and GPU. For this purpose, we designed a custom easy-to-use lightweight library that is unique to the target architecture. We further fine-tuned our implementation to improve the slow I/O operations using techniques such as multiple buffers to overlap I/O latencies with computations. This yielded an efficient model that users can leverage to utilize asymmetric clusters in HPC using cloud-based programming techniques. Our investigation showed that our framework scales well with the number of different compute nodes. Furthermore, it runs simultaneously on different types of accelerators, successfully adapts to the resource capabilities, and performs 26.9% better on average for representative applications than a static execution approach.\nNext, we designed a workflow scheduler for the widespread Hadoop framework, which is aware of the execution behavior of the applications and schedules tasks based on application-hardware affinity. The scheduler is targeted at modern datacenters that may have several clusters each boasting different characteristics. Extant workflow schedulers are not aware of such heterogeneity, and thus cannot ensure high performance in terms of execution time and resource consumption. Similarly, the Hadoop Distributed File System (HDFS) that forms the storage substrate for several large cluster deployments is unable to exploit heterogeneity in the storage stack. To this end, we adopted a quantitative approach where we first studied detailed behavior of various representative Hadoop applications running on different hardware configurations. Next, we incorporated this information into our hardware-aware scheduler to improve the resource-application match. Evaluation of our approach shows that our optimized task placement performs 18.7% faster, on average, than hardware oblivious schedulers. We also designed Heterogeneity-Aware Tiered Storage (hatS), which is a novel redesign of HDFS into a multi-tiered storage system that seamlessly integrates heterogeneous storage technologies into the Hadoop ecosystem. Our evaluation showed that, hatS improves I/O performance by 36% on average, which results in up to 26% improvement in the overall job completion time.\nIn the next phase, we optimized the HEACs I/O stack using GPUs available at nodes and locality-aware scheduling. We designed a system that uses GPUs to support RAID in Lustre file system used in HPC centers. We observed that our system can reduce the cost of HPC I/O systems and improve their overall efficiency. We also designed a cloud scheduler to better place HPC workload virtual machines (VM) in a distributed cloud setting. The goal was to place a VM close to the data it needs, and to adapt the placement via migration as the application progresses and its characteristics or needs change. We employed a min-flow based graph optimizer for this purpose, and achieved high performance gains. Evaluation of our approach, using both real deploymen..."
 }
}