{
 "awd_id": "0917417",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small:  Learnability, Randomness, and Lower Bounds",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2010-05-15",
 "awd_exp_date": "2015-04-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2010-05-19",
 "awd_max_amd_letter_date": "2010-05-19",
 "awd_abstract_narration": "This project is motivated by new connections between the research fields of computational complexity theory and machine learning theory.  Computational complexity theory aims to understand which problems can be solved efficiently on a computer by determining the amounts of computational resources such as CPU time, memory space, or circuit area that are required to solve problems.  At the center of this field is the famous P vs. NP question which impacts virtually every scientific and engineering discipline, given the thousands of diverse NP-complete problems that have been discovered.  Machine learning theory studies the extent to which computers can learn from data and their ability to make future predictions and classifications based on what has been learned.  Some powerful learning algorithms have been discovered, but whether computers can be programmed to accomplish many learning tasks remains an open question.\r\n\r\nBoth computational complexity and machine learning aim to understand the capabilities and limitations of computation, but the two fields study different types of problems and use different kinds of techniques.  This research will employ techniques and ideas from each of these two fields to impact the other field, specifically with the goal of proving \"lower bound\" results.  This research will be accomplished by making use of a new vantage point provided by algorithmic randomness to relate complexity and learning problems.  Learning algorithms will be utilized to establish lower bounds on the computational resources required to solve problems in computational complexity.  The converse direction will be investigated to apply techniques and ideas from computational complexity to show that \"attribute-efficient\" learning algorithms do not exist for certain concept classes.  Algorithmic randomness and Kolmogorov complexity will be used to improve our understanding of the capabilities and limitations of learning algorithms.\r\n\r\nThis research will improve our understanding of computational complexity, which is informative to many areas of science and engineering where computation plays a role.  This project aims to better understand what learning tasks can be accomplished efficiently by computers, which has applications to the foundations of artificial intelligence.  In particular, this research will identify new obstacles that must be overcome in order to design successful automatic learning systems.  A greater synergy will be developed between computational complexity theory and machine learning theory, with the benefit of laying a foundation for future collaboration and interdisciplinary work across these fields.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Hitchcock",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "John M Hitchcock",
   "pi_email_addr": "jhitchco@uwyo.edu",
   "nsf_id": "000392588",
   "pi_start_date": "2010-05-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wyoming",
  "inst_street_address": "1000 E UNIVERSITY AVE",
  "inst_street_address_2": "",
  "inst_city_name": "LARAMIE",
  "inst_state_code": "WY",
  "inst_state_name": "Wyoming",
  "inst_phone_num": "3077665320",
  "inst_zip_code": "820712000",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "WY00",
  "org_lgl_bus_name": "UNIVERSITY OF WYOMING",
  "org_prnt_uei_num": "FDR5YF2K32X5",
  "org_uei_num": "FDR5YF2K32X5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wyoming",
  "perf_str_addr": "1000 E UNIVERSITY AVE",
  "perf_city_name": "LARAMIE",
  "perf_st_code": "WY",
  "perf_st_name": "Wyoming",
  "perf_zip_code": "820712000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "WY00",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "792700",
   "pgm_ele_name": "COMPLEXITY & CRYPTOGRAPHY"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9217",
   "pgm_ref_txt": "NATNL RESERCH & EDUCAT NETWORK"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project was motivated by the interplay between the subfields computational complexity, computational learning, and algorithmic randomness of theoretical computer science. Computational complexity theory studies the resources required to solve problems by algorithms on a computer. Computational learning theory studies the capability of algorithms to learn from examples and experience. Algorithmic randomness theory studies the interaction between computation and randomness. This research results of this projected have been disseminated in ten conference and journal publications, one M.S. thesis, and one Ph.D. dissertation. Here were summarize a few of the main themes.</p>\n<p>Much of research in the project centered around questions related to the famous P vs. NP question, one of the most fundamental questions inall of computer science. This question is important because of the many optimization problems in engineering and science that are NP-complete.</p>\n<p>We used learning algorithms to study the complexity of NP-complete sets, obtaining new theorems on whether sparse sets and linear threshold circuits may be NP-complete. We also used learning algorithms to study the complexity of sets of Kolmogorov random strings.</p>\n<p>The Berman-Hartmanis conjecture states that all NP-complete sets are isomorphic. In relation to this conjecture, we studied whether NP-complete sets are complete under length-increasing reductions.&nbsp;</p>\n<p>We established a stronger connection between the existence of exact learning algorithms and circuit lower bounds. This has possible implications for derandomization of probablistic algorithms and for cryptography.</p>\n<p>We studied the complexity of the Minimum Circuit Size Problem (MCSP). This fundamental problem is unusual because it is NP but not known to be NP-complete. We established new limitations on our abilityto prove that this problem is NP-complete, giving evidence that MCSP is an NP-intermediate problem.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/03/2015<br>\n\t\t\t\t\tModified by: John&nbsp;M&nbsp;Hitchcock</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project was motivated by the interplay between the subfields computational complexity, computational learning, and algorithmic randomness of theoretical computer science. Computational complexity theory studies the resources required to solve problems by algorithms on a computer. Computational learning theory studies the capability of algorithms to learn from examples and experience. Algorithmic randomness theory studies the interaction between computation and randomness. This research results of this projected have been disseminated in ten conference and journal publications, one M.S. thesis, and one Ph.D. dissertation. Here were summarize a few of the main themes.\n\nMuch of research in the project centered around questions related to the famous P vs. NP question, one of the most fundamental questions inall of computer science. This question is important because of the many optimization problems in engineering and science that are NP-complete.\n\nWe used learning algorithms to study the complexity of NP-complete sets, obtaining new theorems on whether sparse sets and linear threshold circuits may be NP-complete. We also used learning algorithms to study the complexity of sets of Kolmogorov random strings.\n\nThe Berman-Hartmanis conjecture states that all NP-complete sets are isomorphic. In relation to this conjecture, we studied whether NP-complete sets are complete under length-increasing reductions. \n\nWe established a stronger connection between the existence of exact learning algorithms and circuit lower bounds. This has possible implications for derandomization of probablistic algorithms and for cryptography.\n\nWe studied the complexity of the Minimum Circuit Size Problem (MCSP). This fundamental problem is unusual because it is NP but not known to be NP-complete. We established new limitations on our abilityto prove that this problem is NP-complete, giving evidence that MCSP is an NP-intermediate problem.\n\n\t\t\t\t\tLast Modified: 09/03/2015\n\n\t\t\t\t\tSubmitted by: John M Hitchcock"
 }
}