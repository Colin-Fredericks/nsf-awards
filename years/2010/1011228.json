{
 "awd_id": "1011228",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Large: Collaborative Research:  Compact Representations and Efficient Algorithms for Distributed Geometric Data",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 432364.0,
 "awd_amount": 432364.0,
 "awd_min_amd_letter_date": "2010-08-22",
 "awd_max_amd_letter_date": "2010-08-22",
 "awd_abstract_narration": "Across many fields of science, engineering, and business, massive data sets are being generated at unprecedented rate by high-bandwidth sensors and cameras, large-scale simulations, or web-enabled large scale data collection.  Much of this data has a geometric character, either directly or indirectly.   For example, second generation LiDARs can map the earth's surface at 15-20 cm resolution; the Large Synoptic Telescope is set to produce about 30 terabytes of data each night; thirteen hours of video are uploaded to YouTube every minute; Facebook manages over 40 billion photos requiring more than one petabyte of data.\r\n\r\nThese data sets provide tremendous opportunities to enable novel capabilities that were unimaginable a few years ago.  Capitalizing on these opportunities, however, and transforming these massive amounts of heterogeneous data into useful information for vastly different types of applications and users requires solving challenging algorithmic problems.  An effective way of addressing this challenge is by designing efficient methods for producing informative yet succinct summaries of such geometric data sets.  These summaries must work at multiple scales, and allow a wide variety of queries to be answered approximately but efficiently.  The goal of this project is to study the theoretical underpinnings of compact representations and efficient algorithms for organizing, summarizing, cross-correlating, interlinking, and querying large distributed geometric data sets.\r\n\r\nThis project will design methods for computing summaries of many kinds of flavors, all with provable properties.  Summaries can be combinatorial and metric (core sets and kernels), algebraic (linear sketches), topological (persistence diagrams), feature-based, and structural (encoding self-similarities in the data).  The properties they aim to capture extend from low-level metric attributes, such as the diameter or width of a point set, to higher-level attributes revealing the internal structure of the data, as in the detection of symmetries and repeated patterns.  This processing must be done in the presence of uncertainty in data coming from sensors, and optimize multiple performance measures, including communication cost for data distributed across multiple locations in a network.  Another key aspect of this project is that it aims to understand not individual data sets in isolation but rather the inter-relationships and correspondences among different data sets, and to do so by communicating only summary information, without even having all the data in one place. \r\n\r\nThis work touches upon many topics in theoretical computer science and applied mathematics including low-distortion embeddings, compressive sensing, transportation metrics, spectral graph theory or harmonic analysis, machine learning, and computational topology.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Leonidas",
   "pi_last_name": "Guibas",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Leonidas J Guibas",
   "pi_email_addr": "guibas@cs.stanford.edu",
   "nsf_id": "000467730",
   "pi_start_date": "2010-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "450 JANE STANFORD WAY",
  "perf_city_name": "STANFORD",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943052004",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "792900",
   "pgm_ele_name": "COMPUTATIONAL GEOMETRY"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 432364.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has developed methods for the joint analysis of large collections of correlated geometric data sets, including 3D models, 3D scans, and GPS traces. In each case, the context provided by many related data sets allows us to perform better operations on individual data sets, benefitting from the &ldquo;wisdom of the crowd.&rdquo; In some cases, this context also allows us to correct errors or supply missing information. The same applies to inferring the relationships between the data sets &mdash; computing maps and finding correspondences among them. Since such data sets can be both large and geographically distributed, we have investigated how to minimize the communication needed in order to perform this type of joint analysis.</p>\n<p>For the case of collections of related 3D models we gave algorithms that take initial noisy maps and correspondences between the shapes and greatly improve them by enforcing cycle-consistency, i.e. that ideally composite maps along cycles must approximate the identity map. We also demonstrated how these ideas vastly improve the fine-grained labeling of shape collections, by effectively allows us to understand where in the geometry of each label is the support for each label (e.g., what makes a rocking chair a rocking chair).</p>\n<p>In the case of 3D scans we have shown howto&nbsp; acquire indoor environments exploiting the symmetries and repetitions invariably present (e.g., an office area in a building is likely to have multiple of the same pieces of furniture). By using libraries to common objects we were able to help the scanning operator (whether robotic or human) to assess the completeness of the scan in real time and provided guidance on how to scan further to complete the acquisition. By further understanding the part structure of 3D models in a given class as well as their symmetries, we were able to complete imperfect scans even when significant portions of any objects when not been seen due to self-occlusions or occlusions by other objects.</p>\n<p>Finally, in the case of GPS traces, we demonstrated how, by joint analysis trajectory, can be effectively denoised and smoothed.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/22/2015<br>\n\t\t\t\t\tModified by: Leonidas&nbsp;J&nbsp;Guibas</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project has developed methods for the joint analysis of large collections of correlated geometric data sets, including 3D models, 3D scans, and GPS traces. In each case, the context provided by many related data sets allows us to perform better operations on individual data sets, benefitting from the \"wisdom of the crowd.\" In some cases, this context also allows us to correct errors or supply missing information. The same applies to inferring the relationships between the data sets &mdash; computing maps and finding correspondences among them. Since such data sets can be both large and geographically distributed, we have investigated how to minimize the communication needed in order to perform this type of joint analysis.\n\nFor the case of collections of related 3D models we gave algorithms that take initial noisy maps and correspondences between the shapes and greatly improve them by enforcing cycle-consistency, i.e. that ideally composite maps along cycles must approximate the identity map. We also demonstrated how these ideas vastly improve the fine-grained labeling of shape collections, by effectively allows us to understand where in the geometry of each label is the support for each label (e.g., what makes a rocking chair a rocking chair).\n\nIn the case of 3D scans we have shown howto  acquire indoor environments exploiting the symmetries and repetitions invariably present (e.g., an office area in a building is likely to have multiple of the same pieces of furniture). By using libraries to common objects we were able to help the scanning operator (whether robotic or human) to assess the completeness of the scan in real time and provided guidance on how to scan further to complete the acquisition. By further understanding the part structure of 3D models in a given class as well as their symmetries, we were able to complete imperfect scans even when significant portions of any objects when not been seen due to self-occlusions or occlusions by other objects.\n\nFinally, in the case of GPS traces, we demonstrated how, by joint analysis trajectory, can be effectively denoised and smoothed.\n\n\t\t\t\t\tLast Modified: 09/22/2015\n\n\t\t\t\t\tSubmitted by: Leonidas J Guibas"
 }
}