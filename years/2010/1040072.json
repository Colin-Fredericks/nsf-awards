{
 "awd_id": "1040072",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FIA: Collaborative Research: Architecting for Innovation",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2010-10-01",
 "awd_exp_date": "2013-09-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2010-09-22",
 "awd_max_amd_letter_date": "2010-09-22",
 "awd_abstract_narration": "A Platform for Internet Innovation\r\n\r\nThe architectural stability of the Internet was crucial in fostering the development of new applications and networking technologies by giving the former a stable base upon which to build and giving the latter a fixed set of requirements to support. However, in recent years this architectural stability has become a liability, as there are areas of increasing importance ? most notably inadequate support of security and availability, lack of adequate mechanisms for privacy, mobility, middleboxes, and data-oriented functionality ? where the original Internet architecture falls short.  The persistence of the Internet's architectural deficiencies is not because they are intellectually intractable, but because they are beyond the reach of incrementally deployable changes.  Based on this observation, the research team takes a different approach than recent clean-slate designs, focusing not on a new fixed architecture but instead on providing a platform to enable architectural innovation through incrementally deployable changes, without massive disruption in the infrastructure.\r\n   \r\nIn this research project, the research team focuses on the ?hardware-defined functionality? challenge and proposes a ?platform for innovation? that allows the network infrastructure to support new architectures without changes to the underlying hardware. In particular, this approach will enable forwarding hardware to support a wide range of alternative designs.  In addition, so that changes can be introduced alongside the current design, hardware will also be able to support multiple designs simultaneously. \r\n \r\nThe proposed platform will use a newly developed paradigm called Software-Defined Networks (SDN), currently embodied in the OpenFlow and NOX projects. OpenFlow is an open hardware forwarding interface. NOX is an open-source software platform that provides global abstractions to network management software and in turn communicates the decisions made by this software to the individual forwarding boxes.  This effort will provide a solid foundation for more general SDN designs that are open, comprehensive and can meet long-term needs. \r\n\r\nThe research team will also explore and demonstrate applicability of the SDN approach including abstractions and programming model for different domains of network use. These include enterprise, WAN, home, and wireless. To demonstrate the ability of the proposed platform to support innovation in radically new network mechanisms, the research team will deploy prototype novel architectures on SDN. \r\n\r\nIf successful, the proposed approach would allow the use of known approaches and design proposals currently available in the literature to address many of the Internet's current problems, as these solutions would be incrementally deployable, without major disruption to the underlying infrastructure. Furthermore, current commercial efforts to address Internet?s deficiencies are disjointed, proprietary, and tailored for short-term needs. The next generation of SDN technology provides a solid basis for coordinated, long-term efforts to address critical needs in areas of security, mobility and support of content-centric application and services. More importantly, the proposed approach would allow the Internet to meet future requirements as they arise through incrementally deployable modifications, relieving network designers of the burden of predicting what these future requirements might be.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hari",
   "pi_last_name": "Balakrishnan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hari Balakrishnan",
   "pi_email_addr": "hari@csail.mit.edu",
   "nsf_id": "000489957",
   "pi_start_date": "2010-09-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 MASSACHUSETTS AVE",
  "perf_city_name": "CAMBRIDGE",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7363",
   "pgm_ref_txt": "RES IN NETWORKING TECH & SYS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project was to investigate and develop ways in which architectural innovation could be accommodated effectively in the Internet. We made three significant contributions:</p>\n<p>1. TCP ex Machina</p>\n<p>Is it possible for a computer to \"discover\" the right rules for congestion control (i.e., how fast and when to send data) in networks? Should computers, rather than humans, be tasked with developing congestion control methods? &nbsp;And just how well can computers perform this task? We investigated these questions and found that computers can design schemes that in some cases surpass the best human-designed methods to date. We probed the limits of these machine-generated protocols, and showed how this style of transport-layer protocol design can give more freedom to network architects.</p>\n<p>Without the ability to adapt its congestion-control algorithms to new scenarios, TCP's inflexibility constrains architectural evolution. New network technologies are typically evaluated based on how well TCP performs over them. &nbsp;This scorecard can lead to perverse behavior, because TCP's network model is limited. For example, because TCP assumes that packet losses are due to congestion and reduces its transmission rate, some subnetworks work hard to hide losses. This often simply adds intolerably long packet delays. One may argue that such designs are misguided, but the difficulties presented by \"too-reliable\" link layers have been a perennial challenge for 25 years and show no signs of abating. With the rise of widespread cellular connectivity, these behaviors are common and deeply embedded in deployed infrastructure.</p>\n<p>We have developed an optimization tool called Remy that takes models of the network and workloads as input, and designs a congestion-control algorithm that tries to maximize the total expected value of a specified objective function. The resulting pre-calculated, optimized algorithm is then run on endpoints.</p>\n<p>For networks broadly consistent with the assumptions provided to Remy at design time, the machine-generated algorithms dramatically outperform existing methods, including Cubic, Compound, and Vegas. Comparing Remy's algorithms with schemes that require modifications to network gateways, including Cubic-over-sfqCoDel and XCP, Remy generally matched or surpassed these schemes, despite being entirely end-to-end. Please see http://mit.edu/remy.</p>\n<p>2. Extending software-defined networking (SDN) to the data plane.</p>\n<p>The Internet's \"data plane\" is in a continuous state of flux. Every few months, researchers publish the design of a new high-performance queueing or scheduling scheme that runs inside the networkfabric. Many such schemes have been queen for a day, only to besurpassed soon after as methods --- or evaluation metrics --- evolve.&nbsp;The lesson, in our view: there will never be a conclusive victor to govern queue management and scheduling inside network hardware. We provided quantitative evidence by demonstrating bidirectional cyclic preferences among three popular contemporary queueing and scheduling configurations.</p>\n<p>We posited that the way forward requires carefully extending SDN to control the fast-path scheduling and queueing behavior of a switch.To this end, we propose adding a small FPGA to switches. &nbsp;We have synthesized, placed, and routed hardware implementations of CoDel and RED. These schemes require only a few thousand FPGA \"slices\" to run at 10 Gbps or more---a minuscule fraction of current low-end FPGAs---demonstrating the feasibility and economy of our approach.</p>\n<p>3. Mosh, the mobile shell.</p>\n<p>Remote terminal applications are almost as old as the Internet. The most popular such application today is the SSH, which runs inside a terminal emulator. Unfortunately, SSH has two major weaknesses that make it unsuitable for mobile use. First, because it runs over TCP, SSH does not suppor...",
  "por_txt_cntn": "\nThe goal of this project was to investigate and develop ways in which architectural innovation could be accommodated effectively in the Internet. We made three significant contributions:\n\n1. TCP ex Machina\n\nIs it possible for a computer to \"discover\" the right rules for congestion control (i.e., how fast and when to send data) in networks? Should computers, rather than humans, be tasked with developing congestion control methods?  And just how well can computers perform this task? We investigated these questions and found that computers can design schemes that in some cases surpass the best human-designed methods to date. We probed the limits of these machine-generated protocols, and showed how this style of transport-layer protocol design can give more freedom to network architects.\n\nWithout the ability to adapt its congestion-control algorithms to new scenarios, TCP's inflexibility constrains architectural evolution. New network technologies are typically evaluated based on how well TCP performs over them.  This scorecard can lead to perverse behavior, because TCP's network model is limited. For example, because TCP assumes that packet losses are due to congestion and reduces its transmission rate, some subnetworks work hard to hide losses. This often simply adds intolerably long packet delays. One may argue that such designs are misguided, but the difficulties presented by \"too-reliable\" link layers have been a perennial challenge for 25 years and show no signs of abating. With the rise of widespread cellular connectivity, these behaviors are common and deeply embedded in deployed infrastructure.\n\nWe have developed an optimization tool called Remy that takes models of the network and workloads as input, and designs a congestion-control algorithm that tries to maximize the total expected value of a specified objective function. The resulting pre-calculated, optimized algorithm is then run on endpoints.\n\nFor networks broadly consistent with the assumptions provided to Remy at design time, the machine-generated algorithms dramatically outperform existing methods, including Cubic, Compound, and Vegas. Comparing Remy's algorithms with schemes that require modifications to network gateways, including Cubic-over-sfqCoDel and XCP, Remy generally matched or surpassed these schemes, despite being entirely end-to-end. Please see http://mit.edu/remy.\n\n2. Extending software-defined networking (SDN) to the data plane.\n\nThe Internet's \"data plane\" is in a continuous state of flux. Every few months, researchers publish the design of a new high-performance queueing or scheduling scheme that runs inside the networkfabric. Many such schemes have been queen for a day, only to besurpassed soon after as methods --- or evaluation metrics --- evolve. The lesson, in our view: there will never be a conclusive victor to govern queue management and scheduling inside network hardware. We provided quantitative evidence by demonstrating bidirectional cyclic preferences among three popular contemporary queueing and scheduling configurations.\n\nWe posited that the way forward requires carefully extending SDN to control the fast-path scheduling and queueing behavior of a switch.To this end, we propose adding a small FPGA to switches.  We have synthesized, placed, and routed hardware implementations of CoDel and RED. These schemes require only a few thousand FPGA \"slices\" to run at 10 Gbps or more---a minuscule fraction of current low-end FPGAs---demonstrating the feasibility and economy of our approach.\n\n3. Mosh, the mobile shell.\n\nRemote terminal applications are almost as old as the Internet. The most popular such application today is the SSH, which runs inside a terminal emulator. Unfortunately, SSH has two major weaknesses that make it unsuitable for mobile use. First, because it runs over TCP, SSH does not support roaming among IP addresses, orcope with intermittent connectivity while data is pending, and is almost unusable over marginal paths with non..."
 }
}