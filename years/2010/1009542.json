{
 "awd_id": "1009542",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Text, Neuroimaging, and Memory: Unified Models of Corpora and Cognition",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Aude Oliva",
 "awd_eff_date": "2010-08-01",
 "awd_exp_date": "2015-12-31",
 "tot_intn_awd_amt": 732296.0,
 "awd_amount": 732296.0,
 "awd_min_amd_letter_date": "2010-08-04",
 "awd_max_amd_letter_date": "2015-06-19",
 "awd_abstract_narration": "The PIs will develop new machine learning algorithms to explore how meaning is represented in the brain and how meaning representations shape human memory.  Current neuroscientific theories of memory posit that forming a memory for a particular event involves associating the details of that event with the person's current mental context, i.e., everything else that she is thinking about at the time.  When trying to remember the event, the person can access stored details by reinstating the mental context that was present when the memory was formed. This fits with the intuition that forgotten details (e.g., the location of misplaced house keys) can be retrieved by mentally \"re-tracing steps\", i.e., trying to reinstate the mindset that was present at the time of the original event.  With these theories in mind, the goal of this work is to develop machine learning algorithms that make it possible to track, based on fMRI brain data and behavioral memory data, the process of \"mentally re-tracing steps\"---the proposed algorithms will be able to decode the state of a person's mental context as she forms memories and (later) as she searches for these memories.\r\n\r\nThe proposed work uses two fundamental ideas about memory and meaning: The first idea is that mental context is shaped by the meanings of recently encountered stimuli.  The second idea is that semantic relationships between concepts in the brain mirror statistical relationships between words in naturally occurring language. The developed algorithms will bring together data from three sources---behavioral data from subjects performing memory recall tasks, fMRI neuroimaging data collected while subjects performed these tasks, and large collections of documents---to discover a latent meaning space that can simultaneously describe all three types of information.  Each point in this space describes a mental context. Thus the core of the proposed work is to develop latent variable models and algorithms that can infer from data how the mental context moves through meaning space as a person stores and searches for memories.\r\n\r\nThe proposed work will lead to fundamental advances in machine learning (new algorithms for inferring hidden variables based on multiple, heterogeneous data types) and neuroscience (more refined theories of how memory search is accomplished in the brain). Furthermore, this work will catalyze the development of new technologies for diagnosing and remediating memory problems, by making it possible to track how the contextual reinstatement process is going awry in people experiencing memory retrieval failure.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Blei",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Blei",
   "pi_email_addr": "david.blei@columbia.edu",
   "nsf_id": "000114130",
   "pi_start_date": "2010-08-04",
   "pi_end_date": "2014-06-04"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kenneth",
   "pi_last_name": "Norman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kenneth Norman",
   "pi_email_addr": "knorman@princeton.edu",
   "nsf_id": "000226762",
   "pi_start_date": "2015-06-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Kenneth",
   "pi_last_name": "Norman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kenneth Norman",
   "pi_email_addr": "knorman@princeton.edu",
   "nsf_id": "000226762",
   "pi_start_date": "2010-08-04",
   "pi_end_date": "2014-06-04"
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "1 NASSAU HALL",
  "perf_city_name": "PRINCETON",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "534500",
   "pgm_ele_name": "Engineering of Biomed Systems"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "004E",
   "pgm_ref_txt": "BIOMEDICAL ENG AND DIAGNOSTICS"
  },
  {
   "pgm_ref_code": "7327",
   "pgm_ref_txt": "CRCNS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 732296.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Functional Magnetic Resonance Imaging (fMRI) has revolutionized the field of cognitive neuroscience by allowing researchers to take high-resolution snapshots of brain activity approximately once per second throughout an experiment. Each voxel (the 3D analog of a pixel in a digital photograph) in a brain image reflects, roughly, the degree to which the corresponding brain location was activated at the time the image was acquired. FMRI images comprise tens of thousands of voxels, and hundreds of images may be collected during a single experimental testing session. The images provide insight into the brain structures activated during an experiment, the computations those brain structures carry out, and the interactions between the brain structures.</p>\n<p>Analyzing fMRI data poses a challenging &ldquo;big data&rdquo; problem: Looking for signatures of people&rsquo;s thoughts in these massive datasets is like looking for a small needle in an enormous haystack. This problem is even more difficult when we consider that brain regions do not act alone: They interact with each other as part of dynamic networks. If we consider the interactions between every pair of brain regions, this requires computing on the order of 100,000^2 (ten billion) correlations, all of which can change depending on what the person is thinking in each moment.</p>\n<p>To make sense of these measurements, we need some way of reducing this complexity (&ldquo;making the haystack smaller&rdquo;). The goal of our project was to simplify these complex patterns. &nbsp;Specifically, we sought to re-describe fMRI images in a simpler, more compact form that preserves information in the fMRI data about people&rsquo;s thoughts, while (at the same time) eliminating redundancies and filtering out noise. There are many off-the-shelf algorithms that can be used for dimensionality reduction, but none of these algorithms were designed with fMRI data in mind. In our work, we sought to leverage two ideas about how people&rsquo;s thoughts are expressed in fMRI data. &nbsp;First, a given thought should be sparsely realized in the brain (i.e., not all brain regions will be involved in expressing that thought). &nbsp;Second, brain activations should be spatially structured (i.e., the fMRI signature of a thought should consist of multiple spatially-localized &ldquo;clumps&rdquo; of activity). Keeping these ideas in mind, we built a new algorithm called Hierarchical Topographic Factor Analysis (hTFA) that re-represents each fMRI image as a weighted combination of localized spheres of activity. &nbsp;HTFA works by taking fMRI data from multiple people (who all did the same experiment), choosing an appropriate number of spheres, and then determining where to place those spheres and how big to make them in order to best reflect the original brain activity measured from those people. By setting the number of spheres to be lower than the original number of voxels in the image, we can greatly simplify the representation of the data, making it easier to subsequently analyze.</p>\n<p>Determining how to best place the spheres is a complex problem. To address this problem, we used cutting-edge Bayesian probabilistic modeling methods that make it possible to infer &ldquo;hidden&rdquo; features of data (here, the best locations of the spheres, their sizes, and their moment-by-moment activations) based on a limited number of noisy observations. Simply getting the algorithm to find a solution required the development of new machine learning methods. &nbsp;Then we faced the problem of getting the algorithm to run quickly enough to be useful; initial versions of the algorithm took a week to analyze a dataset, on a large computing cluster. Over the course of the project, we worked to optimize the algorithm, speeding it up by several orders of magnitude. With the current version of the hTFA code, it is possible to analyze changing patterns of w...",
  "por_txt_cntn": "\nFunctional Magnetic Resonance Imaging (fMRI) has revolutionized the field of cognitive neuroscience by allowing researchers to take high-resolution snapshots of brain activity approximately once per second throughout an experiment. Each voxel (the 3D analog of a pixel in a digital photograph) in a brain image reflects, roughly, the degree to which the corresponding brain location was activated at the time the image was acquired. FMRI images comprise tens of thousands of voxels, and hundreds of images may be collected during a single experimental testing session. The images provide insight into the brain structures activated during an experiment, the computations those brain structures carry out, and the interactions between the brain structures.\n\nAnalyzing fMRI data poses a challenging \"big data\" problem: Looking for signatures of people\u00c6s thoughts in these massive datasets is like looking for a small needle in an enormous haystack. This problem is even more difficult when we consider that brain regions do not act alone: They interact with each other as part of dynamic networks. If we consider the interactions between every pair of brain regions, this requires computing on the order of 100,000^2 (ten billion) correlations, all of which can change depending on what the person is thinking in each moment.\n\nTo make sense of these measurements, we need some way of reducing this complexity (\"making the haystack smaller\"). The goal of our project was to simplify these complex patterns.  Specifically, we sought to re-describe fMRI images in a simpler, more compact form that preserves information in the fMRI data about people\u00c6s thoughts, while (at the same time) eliminating redundancies and filtering out noise. There are many off-the-shelf algorithms that can be used for dimensionality reduction, but none of these algorithms were designed with fMRI data in mind. In our work, we sought to leverage two ideas about how people\u00c6s thoughts are expressed in fMRI data.  First, a given thought should be sparsely realized in the brain (i.e., not all brain regions will be involved in expressing that thought).  Second, brain activations should be spatially structured (i.e., the fMRI signature of a thought should consist of multiple spatially-localized \"clumps\" of activity). Keeping these ideas in mind, we built a new algorithm called Hierarchical Topographic Factor Analysis (hTFA) that re-represents each fMRI image as a weighted combination of localized spheres of activity.  HTFA works by taking fMRI data from multiple people (who all did the same experiment), choosing an appropriate number of spheres, and then determining where to place those spheres and how big to make them in order to best reflect the original brain activity measured from those people. By setting the number of spheres to be lower than the original number of voxels in the image, we can greatly simplify the representation of the data, making it easier to subsequently analyze.\n\nDetermining how to best place the spheres is a complex problem. To address this problem, we used cutting-edge Bayesian probabilistic modeling methods that make it possible to infer \"hidden\" features of data (here, the best locations of the spheres, their sizes, and their moment-by-moment activations) based on a limited number of noisy observations. Simply getting the algorithm to find a solution required the development of new machine learning methods.  Then we faced the problem of getting the algorithm to run quickly enough to be useful; initial versions of the algorithm took a week to analyze a dataset, on a large computing cluster. Over the course of the project, we worked to optimize the algorithm, speeding it up by several orders of magnitude. With the current version of the hTFA code, it is possible to analyze changing patterns of whole-brain network interactions on a full-scale dataset in a matter of hours on standard computing hardware (e.g., a laptop). We plan to release an open-source version of ..."
 }
}