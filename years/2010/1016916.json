{
 "awd_id": "1016916",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Collaborative Research: Exploiting Information Graphics in a Digital Library",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 395056.0,
 "awd_amount": 419056.0,
 "awd_min_amd_letter_date": "2010-08-31",
 "awd_max_amd_letter_date": "2013-05-13",
 "awd_abstract_narration": "This project is a collaborative effort between the University of Delaware and Millersville University. Information graphics (non-pictorial graphics such as bar charts and line graphs) occur frequently in popular media such as newspapers and magazines. Not only is the knowledge conveyed by these graphics very often not included in the article's text, but (in contrast with scientific documents) the article's text most often does not even explicitly refer to the graphics. Information retrieval research has focused on the text of documents, and their information graphics have largely been ignored. Yet, the graphic designer considered the graphic's message important enough to warrant designing a graphic to convey it. This project's goal is a novel methodology for retrieving relevant information graphics from a digital library in response to user queries.\r\n\r\nInformation graphics in popular media generally have a communicative goal or message that they are intended to convey. This message encapsulates the high-level knowledge contained in the graphic. The approach of the project is a language model that treats the relevance of a graphic to a query as a mixture of three components: a graphic's intended message, other textual components of the graphic such as its caption and additional textual description augmenting the caption, and the text of the document containing the graphic. Challenges that are being addressed include identifying the portion of the article that is relevant to the graphic, associating query terms with the intended messages of graphics in the document library, expanding the abbreviated captions and additional textual descriptions of graphics to more fully capture their content, and appropriately weighting the contribution of individual components of the mixture model. In addition, some kinds of graphics, such as grouped bar charts, have both a primary intended message and a secondary message. The impact of the secondary message on retrieval when an ideal graphic is unavailable is also being addressed. Evaluation of the graph retrieval methodology consists of experiments in which human subjects rate the relevance of retrieved graphics to user queries.\r\n\r\nThe goal of this project is to produce a system for retrieving relevant information graphics, thereby expanding the utility of digital libraries. Together with the SIGHT system, which conveys the content of information graphics via speech, the project will extend the information resources available to individuals with sight-impairments. The project will also produce a corpus of information graphics and their XML representations that can be used by other researchers. Corpora and research results will be disseminated on the project web site (http://www.cis.udel.edu/~carberry/Graph-Retrieval). In addition to significantly increasing the resources accessible from a digital library, the research will lay the foundation for expanding research on question-answering to take into account information graphics. The project will contribute to the development of future scientists by educating graduate students, providing research opportunities for undergraduates at a predominantly undergraduate institution, and enhancing the mentoring skills of graduate students as they work on a team that includes undergraduates.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mary",
   "pi_last_name": "Carberry",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Mary S Carberry",
   "pi_email_addr": "carberry@cis.udel.edu",
   "nsf_id": "000315445",
   "pi_start_date": "2010-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Delaware",
  "inst_street_address": "550 S COLLEGE AVE",
  "inst_street_address_2": "",
  "inst_city_name": "NEWARK",
  "inst_state_code": "DE",
  "inst_state_name": "Delaware",
  "inst_phone_num": "3028312136",
  "inst_zip_code": "197131324",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DE00",
  "org_lgl_bus_name": "UNIVERSITY OF DELAWARE",
  "org_prnt_uei_num": "",
  "org_uei_num": "T72NHKM259N3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Delaware",
  "perf_str_addr": "550 S COLLEGE AVE",
  "perf_city_name": "NEWARK",
  "perf_st_code": "DE",
  "perf_st_name": "Delaware",
  "perf_zip_code": "197131324",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DE00",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 395056.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Information graphics (infographics) are non-pictorial graphics such as bar charts and line graphs.&nbsp; Designers of such graphics generally construct them using well-known communicative signals (e.g., coloring a bar differently from other bars in order to draw attention to it) to convey a high-level intended message.&nbsp; Although much research has addressed the problems of retrieving text documents and pictorial images, little attention has been given to the retrieval of information graphics.&nbsp; Conventional search engines rely on the document text that contains the infographic, including the infographic's file name, the image tag from the webpage html source file, and words in the accompanying article that contains the infographic.<br /><br />This project investigated a novel methodology for infographics retrieval that takes into account how well the structure and message content of candidate infographics match the requisite structure and message content requested by a user query.&nbsp; <br /><br />The research assumes that the user inputs a full sentence, grammatically correct, interrogative query.&nbsp; It also assumes that infographics are stored in a digital library along with an XML representation that captures the intended message of the graphic and sufficient information about the graphic so that it could be redrawn.<br /><br />Given a new query, it is analyzed to determine the desired characteristics of relevant graphs: what is expected on the independent and dependent axes, the type of preferred intended message, and whether there should be a focused entity emphasized in the graph.&nbsp; First, the query is parsed by a CCG parser developed by Clark and Curran and trained specifically for questions.&nbsp; From the parse tree, a set of candidate entities are extracted that might represent the requisite content of the axes and a set of linguistic attributes are identified for each query-entity pair.&nbsp; These are input to a learned decision tree that determines whether an entity represents content of the independent axis, the dependent axis, or neither.&nbsp; The hypothesized content of the axes is input to a second decision tree that identifies the category of intended message (such as a Ranking of entities) requested by the user's query.&nbsp; A third decision tree decides whether the query suggests that a particular entity should be focused in a relevant graphic.<br /><br />Once the query has been analyzed, infographics must be ranked in terms of relevance to the user query by considering not only the words in the query but also the requisite structure and message content identified from the query.&nbsp; Two methodologies for estimating relevance were investigated.&nbsp; The first is a mixture model that measures relevance as a linear combination of structural relevance (the independent and dependent axes), message relevance (intended message and focused entities), and word similarity.&nbsp; The mixture model was implemented in SOLR and is available for experiments by other users; the link to the SOLR interface can be found on the project web site at www.cis.udel.edu/~carberry/Graph-Retrieval.&nbsp; The second method uses a learning to rank algorithm on a wide range of features (including structural and content features) to produce a model for ranking infographics in terms of relevance to a user query.&nbsp; <br /><br />Both retrieval methodologies were implemented and tested on a corpus of infographics and user queries, and shown to significantly outperform a baseline approach that treats queries and graphics as bags of words. Thus the research demonstrated not only the success of the new retrieval methodologies but also the importance of taking an infographic's structure and message content into account when doing graph retrieval.&nbsp; Future work will extend this research to more complex infographics and other kinds of graphics such as maps.<...",
  "por_txt_cntn": "\nInformation graphics (infographics) are non-pictorial graphics such as bar charts and line graphs.  Designers of such graphics generally construct them using well-known communicative signals (e.g., coloring a bar differently from other bars in order to draw attention to it) to convey a high-level intended message.  Although much research has addressed the problems of retrieving text documents and pictorial images, little attention has been given to the retrieval of information graphics.  Conventional search engines rely on the document text that contains the infographic, including the infographic's file name, the image tag from the webpage html source file, and words in the accompanying article that contains the infographic.\n\nThis project investigated a novel methodology for infographics retrieval that takes into account how well the structure and message content of candidate infographics match the requisite structure and message content requested by a user query.  \n\nThe research assumes that the user inputs a full sentence, grammatically correct, interrogative query.  It also assumes that infographics are stored in a digital library along with an XML representation that captures the intended message of the graphic and sufficient information about the graphic so that it could be redrawn.\n\nGiven a new query, it is analyzed to determine the desired characteristics of relevant graphs: what is expected on the independent and dependent axes, the type of preferred intended message, and whether there should be a focused entity emphasized in the graph.  First, the query is parsed by a CCG parser developed by Clark and Curran and trained specifically for questions.  From the parse tree, a set of candidate entities are extracted that might represent the requisite content of the axes and a set of linguistic attributes are identified for each query-entity pair.  These are input to a learned decision tree that determines whether an entity represents content of the independent axis, the dependent axis, or neither.  The hypothesized content of the axes is input to a second decision tree that identifies the category of intended message (such as a Ranking of entities) requested by the user's query.  A third decision tree decides whether the query suggests that a particular entity should be focused in a relevant graphic.\n\nOnce the query has been analyzed, infographics must be ranked in terms of relevance to the user query by considering not only the words in the query but also the requisite structure and message content identified from the query.  Two methodologies for estimating relevance were investigated.  The first is a mixture model that measures relevance as a linear combination of structural relevance (the independent and dependent axes), message relevance (intended message and focused entities), and word similarity.  The mixture model was implemented in SOLR and is available for experiments by other users; the link to the SOLR interface can be found on the project web site at www.cis.udel.edu/~carberry/Graph-Retrieval.  The second method uses a learning to rank algorithm on a wide range of features (including structural and content features) to produce a model for ranking infographics in terms of relevance to a user query.  \n\nBoth retrieval methodologies were implemented and tested on a corpus of infographics and user queries, and shown to significantly outperform a baseline approach that treats queries and graphics as bags of words. Thus the research demonstrated not only the success of the new retrieval methodologies but also the importance of taking an infographic's structure and message content into account when doing graph retrieval.  Future work will extend this research to more complex infographics and other kinds of graphics such as maps.\n\nThe project also produced a corpus of queries and information graphics that are available for use by other researchers.  In addition, the project contributed to the development of human resou..."
 }
}