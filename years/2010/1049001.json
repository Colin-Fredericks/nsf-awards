{
 "awd_id": "1049001",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER:  Visual, Tactile, and Acoustic Signal Analysis and Perception for Tactile-Acoustic Display",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2010-08-15",
 "awd_exp_date": "2012-07-31",
 "tot_intn_awd_amt": 60000.0,
 "awd_amount": 60000.0,
 "awd_min_amd_letter_date": "2010-08-08",
 "awd_max_amd_letter_date": "2010-08-08",
 "awd_abstract_narration": "The world is increasingly dominated by multimedia technology for communication, commerce, entertainment, art, education, and medicine.  Since modern electronic media are rich in graphical and pictorial information, it has been hard for the population of visually impaired people to keep up.  While some of this information can also be presented as speech or Braille text, the ability to directly present graphical and pictorial information in tactile form, in combination with auditory signals, would dramatically increase the amount of information that can be made available to the members of this large community, and would also drive advances in interfaces for diverse applications such as virtual reality and medicine.  Although the tactile sense has to date received relatively little attention due to the lack of versatile devices, recent advances in tactile display technology provide impetus for new research.  While existing tactile devices are mostly static, there is great promise for dynamic devices based on emerging technologies such as electro-active polymers, pneumatics, and MEMs.  Dynamic devices would make it possible to generate and display arbitrary tactile patterns, but to estimate the capabilities of different device configurations it is important to understand and model the device characteristics and how they relate to human perception.  It has been shown that the relevant characteristics (material, surface shape) can be simulated using accurate static physical models.  This sets the stage for potentially transformative research to enable the presentation of graphical and pictorial information in tactile-acoustic form, by exploiting the capabilities of tactile display devices in combination with the abilities of human tactile and auditory perception.  To reach that goal will require the investigation of fundamental issues in tactile perception as it relates to existing devices or the design of new ones, and the study of fundamental relationships among visual, tactile, and auditory perception.  The PI's objective in this exploratory project is to conduct preliminary work along these lines in order to establish the feasibility of the approach.  To this end, he will develop mathematical models for tactile devices and perception, and conduct experiments to validate them.  Research subtasks will include development of algorithms for synthesizing tactile textures, development of structural similarity metrics for visual, tactile, and acoustic textures, and quantitative description of perceptual dimensions of visual, tactile, and acoustic textures.  Tests with sighted (visually blocked) and visually-impaired people will measure our ability to discriminate among tactile patterns with and without acoustic feedback, identify dimensions of tactile texture perception (e.g., roughness, directionality), establish that pattern labels can be learned with and without acoustic cues, and explore the brain's ability to integrate tactile information into a scene.\r\n\r\nBroader Impacts:  This research will contribute to fundamental advances in sense substitution and the use of touch for human-computer interaction.  It will address fundamental problems in visual, tactile, and acoustic texture analysis and perception, and the use of touch for communication of graphical and pictorial information.  Project outcomes will contribute to a deeper understanding of the sense of touch and its relation to vision.  In addition to ultimately enabling visually impaired people to access pictorial information, the research will have an impact on a number of other areas, including virtual reality, interfaces with tactile feedback, product design, and medical applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thrasyvoulos",
   "pi_last_name": "Pappas",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Thrasyvoulos N Pappas",
   "pi_email_addr": "pappas@eecs.northwestern.edu",
   "nsf_id": "000107857",
   "pi_start_date": "2010-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "633 CLARK ST",
  "perf_city_name": "EVANSTON",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602080001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 60000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The world is increasingly dominated by multimedia technology for communication, commerce, entertainment, art, education, and medicine.&nbsp; Since modern electronic media is rich in graphical and pictorial information, it has been hard for the population of visually impaired people to keep up.<br /><br />In this exploratory project we conducted preliminary research that establishes the feasibility of the presentation of graphical and pictorial information in tactile-acoustic form, by exploiting the capabilities of tactile display devices in combination with the abilities of human tactile and auditory perception.&nbsp; While some of this information can also be presented as speech or Braille text, the direct presentation of graphical and pictorial information in tactile-acoustic form will dramatically increase the amount of information that can be made available to the visually impaired segment of the population.&nbsp; Moreover, advances in the tactile modality and its relation to and interactions with vision and hearing will impact the development of intuitive and natural interfaces for a number of other applications, including virtual reality, multimodal interfaces, and medicine. <br /><br />During this project, we developed mathematical models for tactile devices and perception, as well as algorithms for synthesizing tactile textures.&nbsp; Subjective experiments with with sighted (visually blocked) and visually-impaired people measured the discriminability of tactile and acoustic patterns and explored the brain's ability to perceive simple shapes and simple spatial layout information by integrating tactile and acoustic signals presented on a touch screen.<br /><br /><strong>Intellectual Merit:</strong> This research contributes to fundamental advances in sense substitution, and the use of touch and sound for human-computer interaction.&nbsp; It addresses fundamental problems in visual, tactile, and acoustic texture analysis and perception, and the use of touch for communication of graphical and pictorial information.&nbsp; It contributes to a deeper understanding of the sense of touch and its relation to vision.<br /><br /><strong>Broader Impact:</strong> In addition to enabling visually impaired people to access pictorial information, this project will have an impact on a number of other areas, including virtual reality, interfaces with tactile feedback, product design, and medical applications.&nbsp;&nbsp; This project has given the opportunity to both graduate and undergraduates to perform research in this area and has had a strong impact on the maturity and the research, presentation, and<br />communication skills of the students.&nbsp;&nbsp; Finally, research findings have been incorporated in the \"Human Perception and Electronic Media\" course that the PI teaches at Northwestern University.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/30/2012<br>\n\t\t\t\t\tModified by: Thrasyvoulos&nbsp;N&nbsp;Pappas</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2012/1049001/1049001_10019996_1346343522357_ultimate--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2012/1049001/1049001_10019996_1346343522357_ultimate--rgov-800width.jpg\" title=\"Tactile-Acoustic Representation of Visual Signals\"><img src=\"/por/images/Reports/POR/2012/1049001/1049001_10019996_1346343522357_ultimate--rgov-66x44.jpg\" alt=\"Tactile-Acoustic Representation of Visual Signals\"></a>\n<div class=\"imageCaptionContainer\">\n<di...",
  "por_txt_cntn": "\nThe world is increasingly dominated by multimedia technology for communication, commerce, entertainment, art, education, and medicine.  Since modern electronic media is rich in graphical and pictorial information, it has been hard for the population of visually impaired people to keep up.\n\nIn this exploratory project we conducted preliminary research that establishes the feasibility of the presentation of graphical and pictorial information in tactile-acoustic form, by exploiting the capabilities of tactile display devices in combination with the abilities of human tactile and auditory perception.  While some of this information can also be presented as speech or Braille text, the direct presentation of graphical and pictorial information in tactile-acoustic form will dramatically increase the amount of information that can be made available to the visually impaired segment of the population.  Moreover, advances in the tactile modality and its relation to and interactions with vision and hearing will impact the development of intuitive and natural interfaces for a number of other applications, including virtual reality, multimodal interfaces, and medicine. \n\nDuring this project, we developed mathematical models for tactile devices and perception, as well as algorithms for synthesizing tactile textures.  Subjective experiments with with sighted (visually blocked) and visually-impaired people measured the discriminability of tactile and acoustic patterns and explored the brain's ability to perceive simple shapes and simple spatial layout information by integrating tactile and acoustic signals presented on a touch screen.\n\nIntellectual Merit: This research contributes to fundamental advances in sense substitution, and the use of touch and sound for human-computer interaction.  It addresses fundamental problems in visual, tactile, and acoustic texture analysis and perception, and the use of touch for communication of graphical and pictorial information.  It contributes to a deeper understanding of the sense of touch and its relation to vision.\n\nBroader Impact: In addition to enabling visually impaired people to access pictorial information, this project will have an impact on a number of other areas, including virtual reality, interfaces with tactile feedback, product design, and medical applications.   This project has given the opportunity to both graduate and undergraduates to perform research in this area and has had a strong impact on the maturity and the research, presentation, and\ncommunication skills of the students.   Finally, research findings have been incorporated in the \"Human Perception and Electronic Media\" course that the PI teaches at Northwestern University.\n\n\t\t\t\t\tLast Modified: 08/30/2012\n\n\t\t\t\t\tSubmitted by: Thrasyvoulos N Pappas"
 }
}