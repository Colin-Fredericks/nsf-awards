{
 "awd_id": "1029325",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Workshop on Federating Computational Resources",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Darleen Fisher",
 "awd_eff_date": "2010-05-01",
 "awd_exp_date": "2011-04-30",
 "tot_intn_awd_amt": 34593.0,
 "awd_amount": 34593.0,
 "awd_min_amd_letter_date": "2010-02-23",
 "awd_max_amd_letter_date": "2010-02-23",
 "awd_abstract_narration": "There is increasing demand among researchers and production system architects to combine (federate) compute, storage, and network resources from multiple sources (e.g., the organization?s own resources, their partners? resources, commercial and academic clouds, programmable network substrates). Various proprietary and experimental systems have taken the first steps to demonstrate the potential effectiveness of such federations, but substantial concerns remain about security, interoperability and management. In many ways, the situation resembles what emerging networks faced at the dawn of the Internet. Consolidation seems certain, but there is a lack the right architectural framework, where new models must contend with a quickly growing base of incompatible production systems. Against this backdrop, this workshop focuses on issues related to federating resources from multiple autonomous organizations into a seamless/ubiquitous resource pool, thereby giving users standard interfaces for accessing the widely distributed and diverse collection of resources they need. This workshop brings together leading network researchers and network research infrastructure developers to discuss specifics of federate (combine) compute, storage, and network resources from multiple sources. The concept for the workshop follows from multiple discussions in the GENI and FIRE initiatives to build federated network test-beds. The workshop expects to develop a common understanding of what it means for autonomous organizations to federate their resources into a seamless/ubiquitous resource pool.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Larry",
   "pi_last_name": "Peterson",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Larry L Peterson",
   "pi_email_addr": "llp@cs.princeton.edu",
   "nsf_id": "000406115",
   "pi_start_date": "2010-02-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "1 NASSAU HALL",
  "perf_city_name": "PRINCETON",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 34593.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>There is increasing demand in the research community for access to compute, storage, and network resources from many sources: the organization's own resources, collaboratoring partner resources, commercial and academic clouds, and national testbeds. As a consequence of this demand, there is increasing interest in the interfaces and mechanisms needed to federate computational resources from multiple autonomous organizations, thereby forming a seamless and ubiquitous resourse pool.</p>\n<p>To this end, this workshop brought together computer scientists from across the country to develop a common understanding of what it means for autonomous organizations to federate their compute, storage, and network resources, define relevant terminology, establish universal design principles, and identify candidate federation strategies.</p>\n<p>As a result of the two-day workshop (held May 11-12 2010 at Princeton University), the participants converged on an architectural design document that defines the minimal set of interfaces and data types that enable a federation of slice-based compute/storage/network resources to interoperate. (The term \"slice\" refers to the fact that the federated resources can be shared, with many users assigned a \"slice\" of the of the composite resource pool.)</p>\n<p>At its core, the architecture supports four key types of entities:<em></em></p>\n<p style=\"padding-left: 30px;\"><em>Owners</em> of parts of the computational substrate, who are therefore responsible for the externally visible behavior of their equipment, and who establish the high-level policies for how their portion of the substrate is utilized. <em></em></p>\n<p style=\"padding-left: 30px;\"><em>Operators</em> of parts of the computational substrate, often working for owners, whose job it is to keep the platform running, provide a service to researchers, and prevent malicious or otherwise damaging activity exploiting the platform. <em></em></p>\n<p style=\"padding-left: 30px;\"><em>Researchers</em> (and <em>developers</em>) employing the computational substrate, for running experiments, deploying experimental services, measuring aspects of the platform, and so on. <em></em></p>\n<p style=\"padding-left: 30px;\"><em>Identity anchors </em>drive authorization by asserting attributes (or roles) of other entities. These anchors are sometimes called <em>Identity Providers</em>, for example, a research organization that asserts a given user is a <em>Principal Investigator (PI</em>) representing the organization, and therefore is authorize to access the substrate.</p>\n<p>Starting with this foundation, the architecture defines a set of abstraction objects, and the operations that can be performed on those objects to advertise, acquire, use, monitor, and release resources from the federation.</p>\n<p>Susequent to this workshop, this architecture was adopted by an NSF-funded initiative, called GENI (Global Environment for Network Innovation), and now forms the basis for an emerging collection of independently owned and operated compute, storage, and network resources.</p>\n<ul>\n</ul><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/14/2011<br>\n\t\t\t\t\tModified by: Larry&nbsp;L&nbsp;Peterson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThere is increasing demand in the research community for access to compute, storage, and network resources from many sources: the organization's own resources, collaboratoring partner resources, commercial and academic clouds, and national testbeds. As a consequence of this demand, there is increasing interest in the interfaces and mechanisms needed to federate computational resources from multiple autonomous organizations, thereby forming a seamless and ubiquitous resourse pool.\n\nTo this end, this workshop brought together computer scientists from across the country to develop a common understanding of what it means for autonomous organizations to federate their compute, storage, and network resources, define relevant terminology, establish universal design principles, and identify candidate federation strategies.\n\nAs a result of the two-day workshop (held May 11-12 2010 at Princeton University), the participants converged on an architectural design document that defines the minimal set of interfaces and data types that enable a federation of slice-based compute/storage/network resources to interoperate. (The term \"slice\" refers to the fact that the federated resources can be shared, with many users assigned a \"slice\" of the of the composite resource pool.)\n\nAt its core, the architecture supports four key types of entities:\nOwners of parts of the computational substrate, who are therefore responsible for the externally visible behavior of their equipment, and who establish the high-level policies for how their portion of the substrate is utilized. \nOperators of parts of the computational substrate, often working for owners, whose job it is to keep the platform running, provide a service to researchers, and prevent malicious or otherwise damaging activity exploiting the platform. \nResearchers (and developers) employing the computational substrate, for running experiments, deploying experimental services, measuring aspects of the platform, and so on. \nIdentity anchors drive authorization by asserting attributes (or roles) of other entities. These anchors are sometimes called Identity Providers, for example, a research organization that asserts a given user is a Principal Investigator (PI) representing the organization, and therefore is authorize to access the substrate.\n\nStarting with this foundation, the architecture defines a set of abstraction objects, and the operations that can be performed on those objects to advertise, acquire, use, monitor, and release resources from the federation.\n\nSusequent to this workshop, this architecture was adopted by an NSF-funded initiative, called GENI (Global Environment for Network Innovation), and now forms the basis for an emerging collection of independently owned and operated compute, storage, and network resources.\n\n\n\n\t\t\t\t\tLast Modified: 08/14/2011\n\n\t\t\t\t\tSubmitted by: Larry L Peterson"
 }
}