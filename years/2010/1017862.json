{
 "awd_id": "1017862",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI:  Small: High Resolution Tactile Sensing.",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2010-09-03",
 "awd_max_amd_letter_date": "2010-09-03",
 "awd_abstract_narration": "This project seeks to develop tactile sensing technology that emulates many qualities of human skin. The goal is a sensor that can determine the texture and shape of objects that it touches, as well as the forces distributed across the surface. The new sensor is made of a block of clear elastomer, with a compliance similar to that of the human fingertip, covered with a flexible reflective skin. A small light source and a camera are embedded in the device. When an object contacts the skin, the surface is distorted, leading to a change in the reflected light pattern. Machine vision techniques convert the patterns into estimates of the forces on the skin. The project is testing a number of optical and mechanical designs, and is developing the corresponding image analysis techniques, in order to characterize and optimize the performance. Because the sensor is compliant, it can be built into a human-like robotic finger, providing gripping surfaces that are mechanically stable as well as highly sensitive. The new technology may also be useful in medical applications such as minimally invasive surgery, where it is important for the surgeon to sense the mechanical properties of the tissues that are being explored.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Edward",
   "pi_last_name": "Adelson",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Edward H Adelson",
   "pi_email_addr": "adelson@csail.mit.edu",
   "nsf_id": "000332297",
   "pi_start_date": "2010-09-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mandayam",
   "pi_last_name": "Srinivasan",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Mandayam A Srinivasan",
   "pi_email_addr": "srini@mit.edu",
   "nsf_id": "000116428",
   "pi_start_date": "2010-09-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 MASSACHUSETTS AVE",
  "perf_city_name": "CAMBRIDGE",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The purpose of this project was to develop improved touch sensors for robotic fingertips. For many applications, the ideal fingertip should have these characteristics: It should be soft like a human finger, so that the robot can manipulate objects of various shapes; it should be sensitive to small forces; it should have high spatial resolution, so it can discriminate different geometries and textures. Current sensors fall short of the human fingertip in various ways. The new type of sensor developed in this project uses a technology called &ldquo;GelSight&rdquo; that can match the human fingertip in many ways, and has spatial resolution far higher than that of human skin.&nbsp; A GelSight sensor is made of a clear elastomer covered by an opaque reflective membrane. A camera and an illumination system are situated inside the finger, and they look through the elastomer at the membrane. When the fingertip contacts an object, the shape of the membrane is distorted, and the camera measures the distortion using methods from machine vision. By using a technique called photometric stereo, it is possible to resolve the membrane&rsquo;s shape in great detail, resolving features finer than a human hair. The sensor is also able to detect small variations in the distortion pattern, and this allows its use in lump detection (such as in detecting tumors).&nbsp; The sensor can detect lumps with a sensitivity exceeding that of a human fingertip. Another important capability is measuring tangential forces, also called shear forces, since they arise from the friction between the fingertip and the object being grasped or manipulated. The pattern of shear forces allows the robot to tell when an object is about to slip from the grasp; the robot can respond by tightening the grip to prevent the slip. Most touch sensors are unable to measure these forces, but by tracking an array of markers on the membrane surface, the GelSight sensor can measure the distribution shear forces across the surface of the fingertip. The sensor also supports the task of recognition and alignment of object shapes. This helps the robot plan and execute movements requiring accurate knowledge of the grasped objecct&rsquo;s position and orientation</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/04/2015<br>\n\t\t\t\t\tModified by: Edward&nbsp;H&nbsp;Adelson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe purpose of this project was to develop improved touch sensors for robotic fingertips. For many applications, the ideal fingertip should have these characteristics: It should be soft like a human finger, so that the robot can manipulate objects of various shapes; it should be sensitive to small forces; it should have high spatial resolution, so it can discriminate different geometries and textures. Current sensors fall short of the human fingertip in various ways. The new type of sensor developed in this project uses a technology called \"GelSight\" that can match the human fingertip in many ways, and has spatial resolution far higher than that of human skin.  A GelSight sensor is made of a clear elastomer covered by an opaque reflective membrane. A camera and an illumination system are situated inside the finger, and they look through the elastomer at the membrane. When the fingertip contacts an object, the shape of the membrane is distorted, and the camera measures the distortion using methods from machine vision. By using a technique called photometric stereo, it is possible to resolve the membrane\u00c6s shape in great detail, resolving features finer than a human hair. The sensor is also able to detect small variations in the distortion pattern, and this allows its use in lump detection (such as in detecting tumors).  The sensor can detect lumps with a sensitivity exceeding that of a human fingertip. Another important capability is measuring tangential forces, also called shear forces, since they arise from the friction between the fingertip and the object being grasped or manipulated. The pattern of shear forces allows the robot to tell when an object is about to slip from the grasp; the robot can respond by tightening the grip to prevent the slip. Most touch sensors are unable to measure these forces, but by tracking an array of markers on the membrane surface, the GelSight sensor can measure the distribution shear forces across the surface of the fingertip. The sensor also supports the task of recognition and alignment of object shapes. This helps the robot plan and execute movements requiring accurate knowledge of the grasped objecct\u00c6s position and orientation\n\n\t\t\t\t\tLast Modified: 01/04/2015\n\n\t\t\t\t\tSubmitted by: Edward H Adelson"
 }
}