{
 "awd_id": "1017156",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NeTS: Small: Distributed Solutions to Smart Camera Networks",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Thyagarajan Nandagopal",
 "awd_eff_date": "2010-07-01",
 "awd_exp_date": "2014-06-30",
 "tot_intn_awd_amt": 395000.0,
 "awd_amount": 411000.0,
 "awd_min_amd_letter_date": "2010-07-07",
 "awd_max_amd_letter_date": "2011-06-07",
 "awd_abstract_narration": "Smart camera networks (SCNs) merge computer vision, distributed\r\nprocessing, and sensor network disciplines to solve problems in\r\nmulti-camera applications by providing valuable information through\r\ndistributed sensing and collaborative in-network processing.\r\nCollaboration in sensor networks is necessary not only to compensate\r\nfor the processing, sensing, energy, and bandwidth limitations of each\r\nsensor node but also to improve the accuracy and robustness of the\r\nnetwork. Collaborative processing in SCNs is more challenging than in\r\nconventional scalar sensor networks (SSNs) because of three unique\r\nfeatures of cameras, including the extremely higher data rate, the\r\ndirectional sensing characteristics with limited field of view (FOV),\r\nand the existence of visual occlusion. An integrated research is\r\ncarried out to tackle the unique challenges presented by SCNs where\r\ncollaboration is the key. Three aspects of collaborative processing\r\nare investigated, 1) coverage estimation in the presence of visual\r\nocclusions to provide adequate redundancy in sensing coverage, and to\r\nenable collaboration where the statistics of visual coverage blends\r\nthe statistics of camera nodes and targets, 2) clustering to\r\nschedule an efficient sleep-wakeup pattern among neighbor nodes formed\r\nby image comparison-based semantic neighbor selection algorithm for\r\nmore efficient collaboration, and 3) distributed optimization, for\r\nin-network data processing that concerns how to effectively obtain\r\nrobust and accurate integration results from multiple distributed\r\nsensors for challenging vision tasks like target detection,\r\nlocalization, and tracking in crowds.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hairong",
   "pi_last_name": "Qi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hairong Qi",
   "pi_email_addr": "hqi@utk.edu",
   "nsf_id": "000253946",
   "pi_start_date": "2010-07-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Charles",
   "pi_last_name": "Cao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Charles Cao",
   "pi_email_addr": "cao@utk.edu",
   "nsf_id": "000537804",
   "pi_start_date": "2010-07-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Tennessee Knoxville",
  "inst_street_address": "201 ANDY HOLT TOWER",
  "inst_street_address_2": "",
  "inst_city_name": "KNOXVILLE",
  "inst_state_code": "TN",
  "inst_state_name": "Tennessee",
  "inst_phone_num": "8659743466",
  "inst_zip_code": "379960001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "TN02",
  "org_lgl_bus_name": "UNIVERSITY OF TENNESSEE",
  "org_prnt_uei_num": "LXG4F9K8YZK5",
  "org_uei_num": "FN2YCS2YAUW3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Tennessee Knoxville",
  "perf_str_addr": "201 ANDY HOLT TOWER",
  "perf_city_name": "KNOXVILLE",
  "perf_st_code": "TN",
  "perf_st_name": "Tennessee",
  "perf_zip_code": "379960001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "TN02",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7363",
   "pgm_ref_txt": "RES IN NETWORKING TECH & SYS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 395000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Although vision is perhaps the most powerful of the human senses, conventional scalar sensor networks have not been able to exploit its potential due to the extremely constrained resources aside in the network.</p>\n<p>Smart camera networks (SCNs) merge computer vision, distributed processing, and sensor network disciplines to solve problems in multi-camera applications by providing valuable information through distributed sensing and collaborative in-network processing. Collaboration in sensor networks is necessary not only to compensate for the processing, sensing, energy, and bandwidth limitations of each sensor node but also to improve the accuracy and robustness of the network.</p>\n<p>Generally speaking, cameras, as a more complex sensing modality, possess three unique features that could hinder the practical deployment of any SCN applications, including the extremely higher data rate, the directional sensing characteristics with limited field of view (FOV), and the existence of visual occlusion. These unique features have brought up new challenging issues, including, for example, the challenges on bandwidth requirement in distributed computing, the challenges on designing light-weight algorithms for improved energy efficiency, and the challenges on fault-tolerance and collaborative processing.</p>\n<p>This project conducts comprehensive studies on the capabilities and limitations of smart camera networks. We have performed some groundbreaking works that help advance the development of SCNs to a great extent.</p>\n<p>The project studies the essential issue of visual coverage. Because of the presence of visual occlusions, the statistics of visual coverage blends the statistics of camera nodes and targets, and are extremely difficult to derive. For the first time, we are able to derive a closed-form solution to visual coverage estimation (i.e., estimate the probability that an arbitrary target in the field is visually covered by at least K sensor nodes). With the estimated coverage statistics, we can provide a more accurate estimation of the minimum node density that suffices to ensure a <strong>K</strong>-coverage across the field.</p>\n<p>In addition, we were able to provide theoretical bounds to practically solve the K-coverage problem in a barrier coverage context through the deployment of a hybrid sensor network where both static and mobile sensors are involved.</p>\n<p>The project also studies the issue of distributed optimization for &ldquo;in-network&rdquo; data processing among a subset of sensors. We tackle the challenging problem of target detection and localization in crowds through the discovery of a new target model as compared to existing schemes, where we resolve the certainty of target nonexistence instead of the traditional resolution of the uncertainty of target existence. This approach is lightweight, energy-efficient, and robust where not only each camera node transmits a very limited amount of data, but that a limited number of camera nodes is used.</p>\n<p>Finally, a suite of auxiliary services has been developed to facilitate the deployment of applications in smart camera networks. For example, Uno is the first distributed storage system that explicitly addresses the challenges to store privacy sensitive data of users; LIPS represents the first piece of work that exploits state-based models for link prediction in sensor networks; and EDAL presents a highly energy efficient data collection protocol in wireless sensor networks, where it generates routes that connect all source nodes with minimal total path cost, under the constraints of packet delay requirements and load balancing needs.</p>\n<p>In summary, the project has addressed the fundamental challenges on the capability of SCNs on coverage estimation, and provide pragmatic guidance in the design of distributed algorithms for performing various vision tasks.</p><br>\n<p>\n\t\t\t\t      \tLast Modif...",
  "por_txt_cntn": "\nAlthough vision is perhaps the most powerful of the human senses, conventional scalar sensor networks have not been able to exploit its potential due to the extremely constrained resources aside in the network.\n\nSmart camera networks (SCNs) merge computer vision, distributed processing, and sensor network disciplines to solve problems in multi-camera applications by providing valuable information through distributed sensing and collaborative in-network processing. Collaboration in sensor networks is necessary not only to compensate for the processing, sensing, energy, and bandwidth limitations of each sensor node but also to improve the accuracy and robustness of the network.\n\nGenerally speaking, cameras, as a more complex sensing modality, possess three unique features that could hinder the practical deployment of any SCN applications, including the extremely higher data rate, the directional sensing characteristics with limited field of view (FOV), and the existence of visual occlusion. These unique features have brought up new challenging issues, including, for example, the challenges on bandwidth requirement in distributed computing, the challenges on designing light-weight algorithms for improved energy efficiency, and the challenges on fault-tolerance and collaborative processing.\n\nThis project conducts comprehensive studies on the capabilities and limitations of smart camera networks. We have performed some groundbreaking works that help advance the development of SCNs to a great extent.\n\nThe project studies the essential issue of visual coverage. Because of the presence of visual occlusions, the statistics of visual coverage blends the statistics of camera nodes and targets, and are extremely difficult to derive. For the first time, we are able to derive a closed-form solution to visual coverage estimation (i.e., estimate the probability that an arbitrary target in the field is visually covered by at least K sensor nodes). With the estimated coverage statistics, we can provide a more accurate estimation of the minimum node density that suffices to ensure a K-coverage across the field.\n\nIn addition, we were able to provide theoretical bounds to practically solve the K-coverage problem in a barrier coverage context through the deployment of a hybrid sensor network where both static and mobile sensors are involved.\n\nThe project also studies the issue of distributed optimization for \"in-network\" data processing among a subset of sensors. We tackle the challenging problem of target detection and localization in crowds through the discovery of a new target model as compared to existing schemes, where we resolve the certainty of target nonexistence instead of the traditional resolution of the uncertainty of target existence. This approach is lightweight, energy-efficient, and robust where not only each camera node transmits a very limited amount of data, but that a limited number of camera nodes is used.\n\nFinally, a suite of auxiliary services has been developed to facilitate the deployment of applications in smart camera networks. For example, Uno is the first distributed storage system that explicitly addresses the challenges to store privacy sensitive data of users; LIPS represents the first piece of work that exploits state-based models for link prediction in sensor networks; and EDAL presents a highly energy efficient data collection protocol in wireless sensor networks, where it generates routes that connect all source nodes with minimal total path cost, under the constraints of packet delay requirements and load balancing needs.\n\nIn summary, the project has addressed the fundamental challenges on the capability of SCNs on coverage estimation, and provide pragmatic guidance in the design of distributed algorithms for performing various vision tasks.\n\n\t\t\t\t\tLast Modified: 11/07/2014\n\n\t\t\t\t\tSubmitted by: Hairong Qi"
 }
}