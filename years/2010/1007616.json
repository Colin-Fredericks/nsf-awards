{
 "awd_id": "1007616",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Estimation for non-linear processes with long memory",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2010-05-15",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 324999.0,
 "awd_amount": 324999.0,
 "awd_min_amd_letter_date": "2010-05-12",
 "awd_max_amd_letter_date": "2012-02-02",
 "awd_abstract_narration": "Long-memory is characterized by a covariance function which decreases\r\n slowly to zero as the lag increases.  The decrease is so slow that the\r\n corresponding spectral density blows up at very low frequencies, a\r\n phenomenon also known as ``long-range dependence'' or ``1/f noise''.\r\n Because wavelets are associated with scaling, it is natural to\r\n attempt to use wavelets in order to estimate the intensity of long\r\n memory in time series. The advantage of wavelets on Fourier methods\r\n is that there is no need to difference the time series if these are\r\n not stationary.  Fourier and wavelet techniques have been applied to\r\n processes with long memory that are Gaussian or linear.  This study\r\n focuses instead on non-linear processes with long memory, for\r\n example, outputs of non-linear filters with Gaussian or with linear\r\n inputs.  The goal is to derive effective techniques to estimate the\r\n exponents which characterize the intensity of long-memory, in these\r\n more realistic contexts.\r\n\r\nTime series are a collection of data points collected through time,\r\n for instance income or temperature. The dependence between these data\r\n points may be weak or strong. When this dependence is strong the time\r\n series is said to have long memory. Time series with long memory\r\n appear in a number of applications, for example, in economics\r\n and in the analysis of traffic in computer  networks.\r\n The goal of this study is to understand their properties\r\n and how to estimate them.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Murad",
   "pi_last_name": "Taqqu",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Murad S Taqqu",
   "pi_email_addr": "murad@math.bu.edu",
   "nsf_id": "000229142",
   "pi_start_date": "2010-05-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Trustees of Boston University",
  "inst_street_address": "1 SILBER WAY",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173534365",
  "inst_zip_code": "022151703",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "TRUSTEES OF BOSTON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "THL6A6JLE1S7"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of Boston University",
  "perf_str_addr": "1 SILBER WAY",
  "perf_city_name": "BOSTON",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "022151703",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 88495.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 111072.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 125432.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Time series with long memory have been the focus of much attention. They appear in a number of applications, for example, in economics and in the analysis of traffic in computer networks. Concerning estimation, the main emphasis so far, has been in the context of Gaussian or linear time series, that is, time series defined as weighted sums of independent and identically distributed innovations.</p>\n<p>Long-memory is characterized by a covariance function which decreases slowly to 0 as the lag increases. The decrease is so slow that the corresponding spectral density blows up at very low frequencies, a phenomenon also known as \"long-range dependence\" or 1/f noise\".</p>\n<p>There are many empirical procedures which are graphical in nature to detect and measure the intensity of long memory, but rigorous estimation procedures are few. Because wavelets are associated with scaling, it is natural to attempt to use wavelets in order to estimate the intensity of long memory. Wavelets have been successfully used as an alternative to the regression on the logarithm of the periodogram. The advantage of wavelets on Fourier is that there is no need to difference the time series if these are not stationary. These approaches have been applied to processes with long memory that are Gaussian or linear.</p>\n<p>In this project, which started May 15, 2010, we have focused on non-linear processes with long memory, more specifically, outputs of non-linear filters with Gaussian or with linear inputs. The goal was to derive effective techniques to estimate the exponents which characterize the intensity of long-memory, in these more realistic contexts. The non-linear setup is challenging. We have succeeded in describing the property of the estimator in many asymptotic situations. Sometimes the asymptotic limit is Gaussian but sometimes it is not.&nbsp; The limits can be described in terms of&nbsp; Wiener-Ito integrals. We have also studied other problems related to long memory, such as the use of various statistics, the detection of change of regimes, the study of asymptotic behavior of various dependence measurements.&nbsp;</p>\n<p>This project&nbsp; resulted in 34 articles and a book. The book describes the Wiener chaos, which is a way to characterize some forms of non-linearity. The goal &nbsp;was to render this subject more accessible. This was done in a in a number of ways. &nbsp;Many examples to illustrate the theory were provided&nbsp; and &nbsp;also&nbsp; many of the formulas were implemented in the computer language <em>Mathematica</em>, so that the user can acquire a concrete feeling for the subject.</p>\n<p>Intellectual merit: This project develops&nbsp; rigorous estimation procedures for long memory and furthers our understanding of such dependence structures. It is part of an on-going effort by the P.I. to develop the probabilistic and statistical features of long memory, heavy tails and related notions and to bridge the gap between theory and applications. The project has also supported a graduate student who is the main co-author on a number of papers.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/16/2014<br>\n\t\t\t\t\tModified by: Murad&nbsp;S&nbsp;Taqqu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nTime series with long memory have been the focus of much attention. They appear in a number of applications, for example, in economics and in the analysis of traffic in computer networks. Concerning estimation, the main emphasis so far, has been in the context of Gaussian or linear time series, that is, time series defined as weighted sums of independent and identically distributed innovations.\n\nLong-memory is characterized by a covariance function which decreases slowly to 0 as the lag increases. The decrease is so slow that the corresponding spectral density blows up at very low frequencies, a phenomenon also known as \"long-range dependence\" or 1/f noise\".\n\nThere are many empirical procedures which are graphical in nature to detect and measure the intensity of long memory, but rigorous estimation procedures are few. Because wavelets are associated with scaling, it is natural to attempt to use wavelets in order to estimate the intensity of long memory. Wavelets have been successfully used as an alternative to the regression on the logarithm of the periodogram. The advantage of wavelets on Fourier is that there is no need to difference the time series if these are not stationary. These approaches have been applied to processes with long memory that are Gaussian or linear.\n\nIn this project, which started May 15, 2010, we have focused on non-linear processes with long memory, more specifically, outputs of non-linear filters with Gaussian or with linear inputs. The goal was to derive effective techniques to estimate the exponents which characterize the intensity of long-memory, in these more realistic contexts. The non-linear setup is challenging. We have succeeded in describing the property of the estimator in many asymptotic situations. Sometimes the asymptotic limit is Gaussian but sometimes it is not.  The limits can be described in terms of  Wiener-Ito integrals. We have also studied other problems related to long memory, such as the use of various statistics, the detection of change of regimes, the study of asymptotic behavior of various dependence measurements. \n\nThis project  resulted in 34 articles and a book. The book describes the Wiener chaos, which is a way to characterize some forms of non-linearity. The goal  was to render this subject more accessible. This was done in a in a number of ways.  Many examples to illustrate the theory were provided  and  also  many of the formulas were implemented in the computer language Mathematica, so that the user can acquire a concrete feeling for the subject.\n\nIntellectual merit: This project develops  rigorous estimation procedures for long memory and furthers our understanding of such dependence structures. It is part of an on-going effort by the P.I. to develop the probabilistic and statistical features of long memory, heavy tails and related notions and to bridge the gap between theory and applications. The project has also supported a graduate student who is the main co-author on a number of papers.\n\n\t\t\t\t\tLast Modified: 09/16/2014\n\n\t\t\t\t\tSubmitted by: Murad S Taqqu"
 }
}