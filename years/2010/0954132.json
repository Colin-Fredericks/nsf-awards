{
 "awd_id": "0954132",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Advanced Decision Procedures forWords, Trees and Lists",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2010-03-15",
 "awd_exp_date": "2017-02-28",
 "tot_intn_awd_amt": 499612.0,
 "awd_amount": 499612.0,
 "awd_min_amd_letter_date": "2010-03-08",
 "awd_max_amd_letter_date": "2016-03-22",
 "awd_abstract_narration": "As complex computer systems become ever more pervasive in our society, especially with the increasing deployment of multi-core processors and clusters of servers in the nation's cyber infrastructure, the demand to advance techniques on program analysis and verification has ever been more intensive. Logic-based reasoning techniques have played a fundamental role in assurance of correctness, reliability and security of computer systems. These techniques divide into two categories: general-purpose theorem proving and specialized decision algorithms. Theorem provers, enjoying a high degree of inference completeness, can prove sophisticated properties but require human guidance in general. On the other hand, decision algorithms, though confined within specialized domains, can automatically discharge a large amount of constraints. It has long been a challenge to combine the merits of the two kinds of techniques to produce a new generation of analysis tools that can handle a wide range of constraints with a high degree of automation. This research is to answer this challenge by building powerful decision theories as well as practical tools for reasoning about high-level data structures that are widely used in advanced programming languages and algorithms. The results would have wide and immediate applications in system analysis, improving the precision and scope of static and runtime analysis techniques.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gianfranco",
   "pi_last_name": "Ciardo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gianfranco Ciardo",
   "pi_email_addr": "ciardo@iastate.edu",
   "nsf_id": "000254304",
   "pi_start_date": "2015-01-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Ting",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ting Zhang",
   "pi_email_addr": "tingz@cs.iastate.edu",
   "nsf_id": "000530685",
   "pi_start_date": "2010-03-08",
   "pi_end_date": "2015-01-20"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andrew",
   "pi_last_name": "Miner",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Andrew S Miner",
   "pi_email_addr": "asminer@iastate.edu",
   "nsf_id": "000232634",
   "pi_start_date": "2015-01-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Samik",
   "pi_last_name": "Basu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Samik Basu",
   "pi_email_addr": "sbasu@cs.iastate.edu",
   "nsf_id": "000150686",
   "pi_start_date": "2015-01-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Iowa State University",
  "inst_street_address": "1350 BEARDSHEAR HALL",
  "inst_street_address_2": "515 MORRILL ROAD",
  "inst_city_name": "AMES",
  "inst_state_code": "IA",
  "inst_state_name": "Iowa",
  "inst_phone_num": "5152945225",
  "inst_zip_code": "500112103",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IA04",
  "org_lgl_bus_name": "IOWA STATE UNIVERSITY OF SCIENCE AND TECHNOLOGY",
  "org_prnt_uei_num": "DQDBM7FGJPC5",
  "org_uei_num": "DQDBM7FGJPC5"
 },
 "perf_inst": {
  "perf_inst_name": "Iowa State University",
  "perf_str_addr": "1350 BEARDSHEAR HALL",
  "perf_city_name": "AMES",
  "perf_st_code": "IA",
  "perf_st_name": "Iowa",
  "perf_zip_code": "500112103",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IA04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "794400",
   "pgm_ele_name": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 200558.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 97020.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 99900.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 102134.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main goal of the project was to develop algorithms to verify the correctness of complex hardware/software systems.&nbsp; This is an important problem, because design errors or software bugs can be catastrophic.&nbsp; It is also a difficult problem, because the state space (the set of possible states that the system can reach) grows exponentially large, especially for systems described compositionally (i.e., by composing smaller subsystems in a hierarchical manner, which is how complex systems are usually designed).<br /><br />A conceptually simple but practically very time-and-memory-intensive initial analysis step is state-space generation.&nbsp; Once the state space is known, simple properties can be immediately verified (e.g., can the system reach a state where no further progress is possible?).&nbsp; More intricated \"temporal logic\" queries about complex behaviors (e.g., is it true that the system will always eventually satisfy a high-priority request, even if there many low-priority requests in the queue?) require more specialized \"model checking\" algorithms, but still are based upon knowledge of the state space. <br /><br />One contribution from this project relates to advanced algorithms based on \"decision diagrams\" to generate, encode, and operate on very large state spaces.<br /><br />(1) We have improved the efficiency of this data structure by providing several alternatives for storing decision diagram nodes, resulting in lower memory requirements (the main bottleneck in decision diagram algorithms) and reduced runtimes.&nbsp; This allows users of our software library, MEDDLY, and of our tool, SMART, to tackle larger problems.<br /><br />(2) We have developed new algorithms to more efficiently generate the state space and to dynamically change the order of the decision diagram variables.&nbsp; The collection of these variables describes the state of the system, and it is well-known that the order in which they are considered in the decision diagram definition can greatly affect its size, but finding an optimal order is an \"NP-hard\" problem, so we proposed heuristics that tend to do well but are of course not guaranteed to be optimal.<br /><br />(3) We have designed algorithms than can find minimal \"counterexamples\" to arbitrarily nested CTL properties (a particular class of temporal logic queries).&nbsp; This is important because, when a model checking tool finds an error, it is not enough to simply raise an alarm; rather, an explanation of what is wrong with the system, in the form of a complex path describing how things can go wrong starting from the initial state, must be provided to the user, who can then debug and fix the system.&nbsp; This counterexample is essentially a sequence of events demonstrating how the undesirable behavior may happen;&nbsp; since this sequence can contain hundreds or even thousands of steps that must be examined manually by the user, it is desirable that the model checking tool provide a short, ideally minimal, counterexample, among the many possible counterexamples.<br /><br />The second class of contributions relates to the analysis of parallel or concurrent software.&nbsp; Most large software systems developed nowadays are multi-threaded (i.e., they contain multiple tasks running in parallel and occasionally interacting, either indirectly by simply writing and reading shared variables, or directly via the exchange of messages.&nbsp; Debugging either class of parallel program is exceedingly difficult because humans are naturally biased towards sequential thinking, while most errors are due to an unforeseen (and rare) interleaving of steps taken in a particularly unfortunate order by two or more otherwise independent tasks.<br /><br />(1) Traditional \"concrete\"&nbsp; testing is just unable to explore all the possible interactions between parallel tasks, so the likelihood it discovers a rare error is very low.&nbsp; More advanced \"symbolic\" testing explores all the possible evolutions, so it is in principle able to find all errors; however, in practice, it usually fails because the number of possible combinations for the values of the variables in each task is enormous.&nbsp; So-called \"concolic\" testing attempts to combine concrete and symbolic approaches, focusing on a concrete execution while symbolically exploring alternates, while employing some technique to exclude executions that appear possible but are not.&nbsp; We defined a similarly light-weight testing approach that focuses on just a single class of errors, failure to terminate, due to the interleaving of multiple tasks.<br /><br />(2) The automated verification of parallel systems where tasks interact via message-passing is undecidable (i.e., no algorithm can exist to answer this question), even if the tasks are represented as finite-state machines, the simplest form of automata.&nbsp; We showed that even just verifying that all messages sent are eventually consumed is undecidable as well.&nbsp; However, we demonstrated a subclass of systems where verification is decidable: those where each task communicates with only one component.&nbsp; This results is important because several systems of practical relevance fall into this subclass.<br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/02/2017<br>\n\t\t\t\t\tModified by: Gianfranco&nbsp;Ciardo</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe main goal of the project was to develop algorithms to verify the correctness of complex hardware/software systems.  This is an important problem, because design errors or software bugs can be catastrophic.  It is also a difficult problem, because the state space (the set of possible states that the system can reach) grows exponentially large, especially for systems described compositionally (i.e., by composing smaller subsystems in a hierarchical manner, which is how complex systems are usually designed).\n\nA conceptually simple but practically very time-and-memory-intensive initial analysis step is state-space generation.  Once the state space is known, simple properties can be immediately verified (e.g., can the system reach a state where no further progress is possible?).  More intricated \"temporal logic\" queries about complex behaviors (e.g., is it true that the system will always eventually satisfy a high-priority request, even if there many low-priority requests in the queue?) require more specialized \"model checking\" algorithms, but still are based upon knowledge of the state space. \n\nOne contribution from this project relates to advanced algorithms based on \"decision diagrams\" to generate, encode, and operate on very large state spaces.\n\n(1) We have improved the efficiency of this data structure by providing several alternatives for storing decision diagram nodes, resulting in lower memory requirements (the main bottleneck in decision diagram algorithms) and reduced runtimes.  This allows users of our software library, MEDDLY, and of our tool, SMART, to tackle larger problems.\n\n(2) We have developed new algorithms to more efficiently generate the state space and to dynamically change the order of the decision diagram variables.  The collection of these variables describes the state of the system, and it is well-known that the order in which they are considered in the decision diagram definition can greatly affect its size, but finding an optimal order is an \"NP-hard\" problem, so we proposed heuristics that tend to do well but are of course not guaranteed to be optimal.\n\n(3) We have designed algorithms than can find minimal \"counterexamples\" to arbitrarily nested CTL properties (a particular class of temporal logic queries).  This is important because, when a model checking tool finds an error, it is not enough to simply raise an alarm; rather, an explanation of what is wrong with the system, in the form of a complex path describing how things can go wrong starting from the initial state, must be provided to the user, who can then debug and fix the system.  This counterexample is essentially a sequence of events demonstrating how the undesirable behavior may happen;  since this sequence can contain hundreds or even thousands of steps that must be examined manually by the user, it is desirable that the model checking tool provide a short, ideally minimal, counterexample, among the many possible counterexamples.\n\nThe second class of contributions relates to the analysis of parallel or concurrent software.  Most large software systems developed nowadays are multi-threaded (i.e., they contain multiple tasks running in parallel and occasionally interacting, either indirectly by simply writing and reading shared variables, or directly via the exchange of messages.  Debugging either class of parallel program is exceedingly difficult because humans are naturally biased towards sequential thinking, while most errors are due to an unforeseen (and rare) interleaving of steps taken in a particularly unfortunate order by two or more otherwise independent tasks.\n\n(1) Traditional \"concrete\"  testing is just unable to explore all the possible interactions between parallel tasks, so the likelihood it discovers a rare error is very low.  More advanced \"symbolic\" testing explores all the possible evolutions, so it is in principle able to find all errors; however, in practice, it usually fails because the number of possible combinations for the values of the variables in each task is enormous.  So-called \"concolic\" testing attempts to combine concrete and symbolic approaches, focusing on a concrete execution while symbolically exploring alternates, while employing some technique to exclude executions that appear possible but are not.  We defined a similarly light-weight testing approach that focuses on just a single class of errors, failure to terminate, due to the interleaving of multiple tasks.\n\n(2) The automated verification of parallel systems where tasks interact via message-passing is undecidable (i.e., no algorithm can exist to answer this question), even if the tasks are represented as finite-state machines, the simplest form of automata.  We showed that even just verifying that all messages sent are eventually consumed is undecidable as well.  However, we demonstrated a subclass of systems where verification is decidable: those where each task communicates with only one component.  This results is important because several systems of practical relevance fall into this subclass.\n\n\n\n\t\t\t\t\tLast Modified: 06/02/2017\n\n\t\t\t\t\tSubmitted by: Gianfranco Ciardo"
 }
}