{
 "awd_id": "1018544",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "DC: Small: A Programming Model for Distributed Data Fusion",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2010-09-15",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 380000.0,
 "awd_amount": 380000.0,
 "awd_min_amd_letter_date": "2010-09-15",
 "awd_max_amd_letter_date": "2010-09-15",
 "awd_abstract_narration": "Data is being generated everywhere in real-time since the scope of sensors has extended to smartphones that continually capture and/or transmit a varied type of data. A lot of data comes in different semantic forms that needs to be distinguished. For example, tweets and instant messages carry different types of information although both are based on text. Such distributed data carries rich semantics that need to be captured and processed for determining the state of the information in near real time and this poses many challenges. This work proposes a language-based (Java) approach along with a mobile agent based system to capture important properties such as timeliness, currency, incompleteness, consistency, and autonomy of data utilizing the properties of their sources. Moreover, since the data sources are quite autonomous, information flow policies dictate access control of the non-local data. Policies pose constraints on data access and movement and multiple processing possibilities exist in such a scenario. Performing such data fusion in real-time is very challenging and it is envisioned to use Java mobile agents framework. The role of compiler analysis is critical to make the runtime smart to  reduce undue overhead to get distributed real time processing needs under control. It is proposed to test this software infrastructure on several applications from the domains such as the  transportation, and the navigation systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Santosh",
   "pi_last_name": "Pande",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Santosh Pande",
   "pi_email_addr": "santosh@cc.gatech.edu",
   "nsf_id": "000253802",
   "pi_start_date": "2010-09-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Nate",
   "pi_last_name": "Clark",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nate Clark",
   "pi_email_addr": "ntclark@cc.gatech.edu",
   "nsf_id": "000502635",
   "pi_start_date": "2010-09-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 NORTH AVE NW",
  "perf_city_name": "ATLANTA",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779300",
   "pgm_ele_name": "DATA-INTENSIVE COMPUTING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7793",
   "pgm_ref_txt": "DATA-INTENSIVE COMPUTING"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 380000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The sources and diversity of &nbsp;distributed data are growing by leaps and bounds. The success of data driven analytics and control becomes critically dependent on programmar productivity involved in writing such applications - namely, the ability to reason about the data which is distributed across trust boundaries. The goal of this work is to develop a programming model that allows one to model the properties of trust, sharing, ownership, and timeliness for distributed data in a simple, intuitive manner and to develop the underlying implementation for its efficient fusion.</p>\n<p>In this project, first, simple extensions are developed to Java to model the above properties through annotations, thus, the underlying programming model used for this purpose is : SPMD (single program multiple data). Under this model, the same Java program executes in a distributed sense and localizes and evaluates to the data owned at respective sources. The model is based on Java Aglets: data sharing is dictated by the annotations. The data can be fetched from remote processing node if the data owner allows so under the sharing annotations. If not, the computation migrates to the node that owns the data and executes an aglet (a modification of remote procedure call) under the trusted execution environment of the data owner. In this work, data sharing annotations are developed that form a superset of real world policies such as used in instagram or snapchat. For example, a data may be shared with a friend but a friend is not allowed to share it further with anyone or is allowed provided the transitive relation satisfies a constraint. Moreover, once the data is consumed (read or operated upon per algebra surrounding ownership policies), it is destroyed or morphed permanently in a non-reversible form. &nbsp; The policies of data ownership are composable and can be modeled through a simple type system. One of the key contributions of this work is the development of data annotations and an underlying &nbsp;simple type system useful for its consistency checking.&nbsp;</p>\n<p>The next step is the efficient implementation of the programming model. &nbsp;One of the key issues faced is the repeated migrations of the Java Aglets to data sources to enforce the trust constraints. Optimizations are developed to transform the program order to minimize the number of migrations. In an orthogonal manner, data movement and caching optimizations are developed to move the live data from respective data sources to &nbsp;other nodes so that the cost of migrations can be amortized. A major contribution of this work is the development of aglet migration transformations and data caching/movement techniques to reduce the runtime overhead. Apart from overhead reduction, one of the key optimizations focussed on timeliness property. Modeling of the context under which one can live with stale data opens up optimization space above and the project successfully demonstrated an &nbsp;initial exploration of this key idea. &nbsp;</p>\n<p>The results of the above work are published in several key conferences. The final paper on this work is presented in HICSS 2015, a systems conference which also embraces business applications that &nbsp;involve distributed data processing. The paper was a runner up for best paper award. The framework is demonstrated and successfully evaluated on modeling several distributed data processing scenarios including: mobile friends discovery, snapchat, instagram and complex pictures and video sharing applications built using real world \"friends\" relations. Currently, the framework is being tested for robustness for open source release.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/23/2016<br>\n\t\t\t\t\tModified by: Santosh&nbsp;Pande</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe sources and diversity of  distributed data are growing by leaps and bounds. The success of data driven analytics and control becomes critically dependent on programmar productivity involved in writing such applications - namely, the ability to reason about the data which is distributed across trust boundaries. The goal of this work is to develop a programming model that allows one to model the properties of trust, sharing, ownership, and timeliness for distributed data in a simple, intuitive manner and to develop the underlying implementation for its efficient fusion.\n\nIn this project, first, simple extensions are developed to Java to model the above properties through annotations, thus, the underlying programming model used for this purpose is : SPMD (single program multiple data). Under this model, the same Java program executes in a distributed sense and localizes and evaluates to the data owned at respective sources. The model is based on Java Aglets: data sharing is dictated by the annotations. The data can be fetched from remote processing node if the data owner allows so under the sharing annotations. If not, the computation migrates to the node that owns the data and executes an aglet (a modification of remote procedure call) under the trusted execution environment of the data owner. In this work, data sharing annotations are developed that form a superset of real world policies such as used in instagram or snapchat. For example, a data may be shared with a friend but a friend is not allowed to share it further with anyone or is allowed provided the transitive relation satisfies a constraint. Moreover, once the data is consumed (read or operated upon per algebra surrounding ownership policies), it is destroyed or morphed permanently in a non-reversible form.   The policies of data ownership are composable and can be modeled through a simple type system. One of the key contributions of this work is the development of data annotations and an underlying  simple type system useful for its consistency checking. \n\nThe next step is the efficient implementation of the programming model.  One of the key issues faced is the repeated migrations of the Java Aglets to data sources to enforce the trust constraints. Optimizations are developed to transform the program order to minimize the number of migrations. In an orthogonal manner, data movement and caching optimizations are developed to move the live data from respective data sources to  other nodes so that the cost of migrations can be amortized. A major contribution of this work is the development of aglet migration transformations and data caching/movement techniques to reduce the runtime overhead. Apart from overhead reduction, one of the key optimizations focussed on timeliness property. Modeling of the context under which one can live with stale data opens up optimization space above and the project successfully demonstrated an  initial exploration of this key idea.  \n\nThe results of the above work are published in several key conferences. The final paper on this work is presented in HICSS 2015, a systems conference which also embraces business applications that  involve distributed data processing. The paper was a runner up for best paper award. The framework is demonstrated and successfully evaluated on modeling several distributed data processing scenarios including: mobile friends discovery, snapchat, instagram and complex pictures and video sharing applications built using real world \"friends\" relations. Currently, the framework is being tested for robustness for open source release. \n\n\t\t\t\t\tLast Modified: 09/23/2016\n\n\t\t\t\t\tSubmitted by: Santosh Pande"
 }
}