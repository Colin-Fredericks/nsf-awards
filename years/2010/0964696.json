{
 "awd_id": "0964696",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "AF: Medium:  A Fair Prescription for Partial Synchrony",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Balasubramanian Kalyanasundaram",
 "awd_eff_date": "2010-06-01",
 "awd_exp_date": "2015-05-31",
 "tot_intn_awd_amt": 737656.0,
 "awd_amount": 889094.0,
 "awd_min_amd_letter_date": "2010-05-24",
 "awd_max_amd_letter_date": "2013-08-22",
 "awd_abstract_narration": "Partial synchrony refers to computing environments where timing bounds exist for communication delays and processing speeds, but knowledge of these bounds may be limited or unknown. Although such bounds are only implicit, they can still be used to advantage for building reliable distributed systems in the presence of message loss and crashed processors. The central problem however, is how timing parameters for partial synchrony should be modeled, measured, and denominated.\r\n\r\nSince its inception some 25 years ago, the prevailing paradigm of chronometry-based models has invoked real-time as a formal basis for modeling temporal bounds on message delays and process speeds. Unfortunately, such models are intrinsically limited (and even flawed) as descriptions of empirical distributed systems, because the characteristic property of partial synchrony is not chronometric timeliness, but rather chronological fairness.\r\n\r\nThis project is developing a fundamental theory of partial synchrony  based on the notion of chronological fairness. The key technical innovation is that system failures can be detected in executions that are unfair, rather than untimely. This approach leads to greater generality because many untimely executions are still fair. Theoretical results codify a hierarchy of fairness properties, including technical limitations, expressivity, and reducibility to oracular models. Practical results extract fairness models from empirical systems. An integrated critique of chronometric models  helps to initiate a broader shift in research trends to focus on fairness-based paradigms of partial synchrony.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jennifer",
   "pi_last_name": "Welch",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Jennifer L Welch",
   "pi_email_addr": "welch@cse.tamu.edu",
   "nsf_id": "000365769",
   "pi_start_date": "2010-05-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Scott",
   "pi_last_name": "Pike",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Scott M Pike",
   "pi_email_addr": "pike@cse.tamu.edu",
   "nsf_id": "000282987",
   "pi_start_date": "2010-05-24",
   "pi_end_date": "2013-08-22"
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M Engineering Experiment Station",
  "perf_str_addr": "3124 TAMU",
  "perf_city_name": "COLLEGE STATION",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433124",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "793400",
   "pgm_ele_name": "PARAL/DISTRIBUTED ALGORITHMS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 586218.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 151438.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 151438.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Distributed computing systems are all around us, ranging from multiple<br />cores in a cell phone to the Internet itself.&nbsp; Developing software for<br />distributed systems that is correct and efficient is challenging due<br />to complications caused by concurrency, component failures, and<br />variable communication delays.&nbsp; This project takes a principled<br />approach, based on rigorous mathematical reasoning, to find<br />distributed algorithms for some fundamental problems that underlie<br />distributed applications.<br /><br />Most distributed systems are partially synchronous, i.e., they exhibit<br />some level of coordination concerning relative times when the<br />computing processes take steps and how long communication between the<br />processes takes.&nbsp; Partial synchrony has commonly been defined with<br />real time: for example, some event happened at 4:00 and another event<br />happened at 4:10.&nbsp; This project has explored a new approach to<br />defining partial synchrony, using the notion of \"fairness\": for<br />example, in between two steps of one process, another process takes at<br />most ten steps, regardless of the real times at which these events<br />occur.<br /><br />(1) Systems that are both asynchronous and subject to (undetectable)<br />process crashes make it difficult, and sometimes impossible, for<br />processes to coordinate with each other.&nbsp; A common mechanism for<br />overcoming this obstacle is a system service called a failure<br />detector, which provides processes with some level of information<br />about crashes.&nbsp; We proved that it is sufficient (as well as necessary)<br />for a failure detector mechanism to ensure bounds on the relative<br />occurrences of events, regardless of the real times when these events<br />occur.&nbsp; Our results further the shift in the direction of research on<br />how to construct good failure detectors away from traditional<br />real-time notions, which require knowledge of events outside the<br />system, and towards fairness-based partial synchrony, which can be<br />understood solely with respect to other events that are internal to<br />the system.&nbsp; Our results suggest that fairness is the appropriate way<br />to understand crash tolerance.<br /><br />(2) The \"link reversal\" approach has been exploited in distributed<br />algorithms for numerous problems, including resource allocation,<br />mutual exclusion, routing, and leader election in the past several<br />decades.&nbsp; In the link reversal approach, a virtual direction is<br />imposed on the link between two processes in the system (modeled as a<br />graph), where the direction indicates which process of the two has<br />precedence to take some action.&nbsp; By reversing the direction of the<br />link, the precedence changes, thus providing some level of fairness to<br />the actions of the processes.&nbsp; Our work provided exact formulas for<br />the work and time performance, as well as tradeoffs between work and<br />time, of two well-known routing algorithms based on link reversal.&nbsp; As<br />a result, we are now able to select which routing algorithm is best<br />depending on the pattern of connections between processes and whether<br />work performance or time performance is more important.<br /><br />(3) Distributed storage, or shared data, is a vital mechanism for<br />communication among processors in distributed systems (for example,<br />note the escalation of cloud computing), and facilitates the<br />development of higher-quality applications.&nbsp; Although shared data is a<br />convenient abstraction, it is not generally provided in large-scale<br />distributed systems.&nbsp; Instead, processors keep individual copies of<br />the data, and communicate by sending messages to keep the replicas<br />consistent.&nbsp; It is known that providing shared objects of many<br />\"classic\" data types...",
  "por_txt_cntn": "\nDistributed computing systems are all around us, ranging from multiple\ncores in a cell phone to the Internet itself.  Developing software for\ndistributed systems that is correct and efficient is challenging due\nto complications caused by concurrency, component failures, and\nvariable communication delays.  This project takes a principled\napproach, based on rigorous mathematical reasoning, to find\ndistributed algorithms for some fundamental problems that underlie\ndistributed applications.\n\nMost distributed systems are partially synchronous, i.e., they exhibit\nsome level of coordination concerning relative times when the\ncomputing processes take steps and how long communication between the\nprocesses takes.  Partial synchrony has commonly been defined with\nreal time: for example, some event happened at 4:00 and another event\nhappened at 4:10.  This project has explored a new approach to\ndefining partial synchrony, using the notion of \"fairness\": for\nexample, in between two steps of one process, another process takes at\nmost ten steps, regardless of the real times at which these events\noccur.\n\n(1) Systems that are both asynchronous and subject to (undetectable)\nprocess crashes make it difficult, and sometimes impossible, for\nprocesses to coordinate with each other.  A common mechanism for\novercoming this obstacle is a system service called a failure\ndetector, which provides processes with some level of information\nabout crashes.  We proved that it is sufficient (as well as necessary)\nfor a failure detector mechanism to ensure bounds on the relative\noccurrences of events, regardless of the real times when these events\noccur.  Our results further the shift in the direction of research on\nhow to construct good failure detectors away from traditional\nreal-time notions, which require knowledge of events outside the\nsystem, and towards fairness-based partial synchrony, which can be\nunderstood solely with respect to other events that are internal to\nthe system.  Our results suggest that fairness is the appropriate way\nto understand crash tolerance.\n\n(2) The \"link reversal\" approach has been exploited in distributed\nalgorithms for numerous problems, including resource allocation,\nmutual exclusion, routing, and leader election in the past several\ndecades.  In the link reversal approach, a virtual direction is\nimposed on the link between two processes in the system (modeled as a\ngraph), where the direction indicates which process of the two has\nprecedence to take some action.  By reversing the direction of the\nlink, the precedence changes, thus providing some level of fairness to\nthe actions of the processes.  Our work provided exact formulas for\nthe work and time performance, as well as tradeoffs between work and\ntime, of two well-known routing algorithms based on link reversal.  As\na result, we are now able to select which routing algorithm is best\ndepending on the pattern of connections between processes and whether\nwork performance or time performance is more important.\n\n(3) Distributed storage, or shared data, is a vital mechanism for\ncommunication among processors in distributed systems (for example,\nnote the escalation of cloud computing), and facilitates the\ndevelopment of higher-quality applications.  Although shared data is a\nconvenient abstraction, it is not generally provided in large-scale\ndistributed systems.  Instead, processors keep individual copies of\nthe data, and communicate by sending messages to keep the replicas\nconsistent.  It is known that providing shared objects of many\n\"classic\" data types with strong guarantees on how consistent the data\nis can be expensive, in particular, the operations on the data can\ntake a long time to complete.  This fact has fueled interest in more\nrelaxed versions of the data types, in the hopes that they can be\nimplemented faster.  Our research provided the first analysis for\nmessage-passing implementations of relaxed queues (a common data\ntype), in which an element removed by a dequeue ..."
 }
}