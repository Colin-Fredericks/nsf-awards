{
 "awd_id": "1012147",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "HCC: Large: Collaborative Research:  Beyond Flat Images:  Acquiring, Processing, and Fabricating Visually Rich Material Appearance",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2010-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 498105.0,
 "awd_amount": 498105.0,
 "awd_min_amd_letter_date": "2010-08-20",
 "awd_max_amd_letter_date": "2010-08-20",
 "awd_abstract_narration": "Despite revolutionary advances in how images are recorded, manipulated, and reproduced, our ability to re-create the visual experience remains remarkably limited.  Few realistic computer models exist for the characteristic appearance of natural materials such as marble, wood, coral, or skin, or man-made ones such as color-shifting automotive paints.  Digitizing and creating realistic images of these substances involves reproducing their interaction with light:  the way light is reflected from surfaces, or scattered and absorbed within the materials.  Full reproducibility also involves \"printing\" a material as a real, physical object that modulates the light around us. However, it is currently impossible to output complex appearance the way we print color on a paper with fixed gloss, or create shapes using a 3D printer. This project encompasses a comprehensive, collaborative research agenda in computer graphics and related areas, to develop an end-to-end framework for acquiring, representing, and fabricating complex appearance, as well as to understand how it is perceived by the human visual system.\r\n\r\nThe enabling technical idea of the project is to treat materials as thin three-dimensional volumes populated with general scattering sites. This is a radical departure from the hitherto standard approach in computer graphics, which has studied materials purely as surfaces.  The volumetric representation subsumes and generalizes the diverse set of conventional representations that currently exist in graphics, including surface-based notions such as bidirectional reflectance (BRDF), spatially varying BRDF, and subsurface scattering distributions (BSSRDF).  Moreover, it enables fundamentally improved approaches to efficient yet general acquisition, fast and realistic rendering, and fabrication of objects exhibiting phenomena beyond simple surface reflectance and spatially homogeneous subsurface scattering.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Szymon",
   "pi_last_name": "Rusinkiewicz",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Szymon M Rusinkiewicz",
   "pi_email_addr": "smr@princeton.edu",
   "nsf_id": "000379377",
   "pi_start_date": "2010-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "1 NASSAU HALL",
  "perf_city_name": "PRINCETON",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 498105.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Just as an integrated visual computing pipeline has revolutionized the way our experiences of the world are documented and communicated in images and videos (&ldquo;flat&rdquo; images), the goal of this large collaborative NSF project was to define a new digital pipeline for rich visual appearance, using computer graphics. The key components are a new unifying representations of reflectance and scattering, new acquisition methodologies, techniques for editing and rendering, considerations of perception, and fabrication of complex<br />materials.</p>\n<p>The project was a multi-PI, multi-institution collaboration, and this report focuses on work done at Princeton by PI Rusinkiewicz and colleagues.</p>\n<p>One of the main challenges addressed by the project was capturing the complex appearance of human hair.&nbsp; Because hair consists of a very large number of strands, each with a very distinctive way it reflects light, it had traditionally been very difficult to build complete and realistic models of a full head of hair.&nbsp; Our work used multiple cameras along with a comprehensive model of how strands \"flow\" from scalp to tip in order to build realistic models of complex hairstyles.&nbsp; This work served as the foundation for research in other groups, eventually culminating in systems that can build 3D models of hair at sufficiently high quality to be used in movie special effects.</p>\n<p>The other main thrust of the research performed under the auspices of this project was 3D printing, and more general computer-controlled fabrication, of surfaces and objects with complex appearance.&nbsp; Essentially, we were interested in how to use modern 3D printers and computer-controlled 3D milling devices to produce output that those devices were never intended for.&nbsp; The key was the *combination* of these devices with sophisticated computation: by modeling exactly what the appearance would be of sending a given set of instructions to the 3D printer, we could \"reverse engineer\" the process and figure out how to get those devices to manufacture surfaces with effects such as holography, caustics, spatially-varying reflectance, fiber optics, and surfaces with embedded metal \"flakes\" that provide fine control over appearance.&nbsp; Among the artifacts we were able to produce are:</p>\n<ul>\n<li>a clear acrylic plate with \"scratches\" in it that provides a 3D hologram-like illusion</li>\n<li>a plate with a set of small lenses machined in it, which focus light into the pattern of an image</li>\n<li>an exact reproduction of a previously-scanned paper document with multiple inks carefully positioned to control gloss and metallic highlights</li>\n<li>objects (such as a human head) with embedded fiber optics, allowing light cast by a projector to be routed from the base to the curved surface, creating a \"shaped display\"</li>\n<li>a flat surface with embedded flakes whose orientation is carefully controlled to give the appearance of an \"embossed\", bumpy surface</li>\n</ul>\n<p>All of these investigations of 3D printing and controllable appearance have enriched our concept of what kinds of optical effects are possible with 3D printing, and should pave the way for 3D printed objects that not only have the desired shape, but also the desired appearance.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/23/2016<br>\n\t\t\t\t\tModified by: Szymon&nbsp;M&nbsp;Rusinkiewicz</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nJust as an integrated visual computing pipeline has revolutionized the way our experiences of the world are documented and communicated in images and videos (\"flat\" images), the goal of this large collaborative NSF project was to define a new digital pipeline for rich visual appearance, using computer graphics. The key components are a new unifying representations of reflectance and scattering, new acquisition methodologies, techniques for editing and rendering, considerations of perception, and fabrication of complex\nmaterials.\n\nThe project was a multi-PI, multi-institution collaboration, and this report focuses on work done at Princeton by PI Rusinkiewicz and colleagues.\n\nOne of the main challenges addressed by the project was capturing the complex appearance of human hair.  Because hair consists of a very large number of strands, each with a very distinctive way it reflects light, it had traditionally been very difficult to build complete and realistic models of a full head of hair.  Our work used multiple cameras along with a comprehensive model of how strands \"flow\" from scalp to tip in order to build realistic models of complex hairstyles.  This work served as the foundation for research in other groups, eventually culminating in systems that can build 3D models of hair at sufficiently high quality to be used in movie special effects.\n\nThe other main thrust of the research performed under the auspices of this project was 3D printing, and more general computer-controlled fabrication, of surfaces and objects with complex appearance.  Essentially, we were interested in how to use modern 3D printers and computer-controlled 3D milling devices to produce output that those devices were never intended for.  The key was the *combination* of these devices with sophisticated computation: by modeling exactly what the appearance would be of sending a given set of instructions to the 3D printer, we could \"reverse engineer\" the process and figure out how to get those devices to manufacture surfaces with effects such as holography, caustics, spatially-varying reflectance, fiber optics, and surfaces with embedded metal \"flakes\" that provide fine control over appearance.  Among the artifacts we were able to produce are:\n\na clear acrylic plate with \"scratches\" in it that provides a 3D hologram-like illusion\na plate with a set of small lenses machined in it, which focus light into the pattern of an image\nan exact reproduction of a previously-scanned paper document with multiple inks carefully positioned to control gloss and metallic highlights\nobjects (such as a human head) with embedded fiber optics, allowing light cast by a projector to be routed from the base to the curved surface, creating a \"shaped display\"\na flat surface with embedded flakes whose orientation is carefully controlled to give the appearance of an \"embossed\", bumpy surface\n\n\nAll of these investigations of 3D printing and controllable appearance have enriched our concept of what kinds of optical effects are possible with 3D printing, and should pave the way for 3D printed objects that not only have the desired shape, but also the desired appearance.\n\n\t\t\t\t\tLast Modified: 05/23/2016\n\n\t\t\t\t\tSubmitted by: Szymon M Rusinkiewicz"
 }
}