{
 "awd_id": "1018490",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small:  Grounding Probabilistic Event Logic in a Hierarchy of Video Segmentation Tubes",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2010-09-15",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 449984.0,
 "awd_amount": 465984.0,
 "awd_min_amd_letter_date": "2010-08-18",
 "awd_max_amd_letter_date": "2012-03-13",
 "awd_abstract_narration": "The project addresses the fundamental challenge of grounding high-level semantic concepts about events into low-level video data. The key innovations include:  (1) Representing events via probabilistic event logic (PEL) along with corresponding inference and learning algorithms, (2) Video segmentation into a hierarchy of space-time tubes, and (3) Robustly grounding PEL into space-time tubes via AND-OR grammars. Space-time tubes are extracted by tracking candidate object boundaries across frames, where both boundary detection and tracking are learned from training videos. PEL allows for arbitrary, probabilistic, spatiotemporal constraints among events, including the traditional compositional rules, Allen relations between time intervals, and correlations among different events. Unlike existing work, the logical nature of PEL allows humans, even non-experts, to easily inject their own knowledge into the system. PEL conducts joint, holistic inference to find the globally best parse over all events, which is grounded in an AND-OR grammar of primitive events. The AND-OR grammar uses robust graph matching of video tubes for handling uncertainty in low-level visual processing. \r\nFor evaluation, two video datasets of American football and a building?s atrium are compiled, with fully annotated event labels, object tracks, and spatiotemporal segmentations. \r\n\r\nTraining is provided for graduate and undergraduate students, including those from under-represented groups. The project is expected to: (a) advance the state of the art which typically focuses only on video classification; (b) make the two datasets public; (c) generate workshops/tutorials on the related topics; and (d) produce publications in the highest-impact journals/conferences.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sinisa",
   "pi_last_name": "Todorovic",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sinisa Todorovic",
   "pi_email_addr": "sinisa@eecs.oregonstate.edu",
   "nsf_id": "000514889",
   "pi_start_date": "2010-08-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Alan",
   "pi_last_name": "Fern",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alan Fern",
   "pi_email_addr": "afern@eecs.oregonstate.edu",
   "nsf_id": "000088242",
   "pi_start_date": "2010-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Oregon State University",
  "inst_street_address": "1500 SW JEFFERSON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CORVALLIS",
  "inst_state_code": "OR",
  "inst_state_name": "Oregon",
  "inst_phone_num": "5417374933",
  "inst_zip_code": "973318655",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "OR04",
  "org_lgl_bus_name": "OREGON STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "MZ4DYXE1SL98"
 },
 "perf_inst": {
  "perf_inst_name": "Oregon State University",
  "perf_str_addr": "1500 SW JEFFERSON AVE",
  "perf_city_name": "CORVALLIS",
  "perf_st_code": "OR",
  "perf_st_name": "Oregon",
  "perf_zip_code": "973318655",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "OR04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 449984.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project addressed one of the basic problems in computer vision, that of detecting human actions and identifying their spatiotemporal extents in video. The key outcomes include: 1) Formulation of representation, 2) Learning algorithms, and 3) Inference algorithms for parsing human actions in video using the probabilistic event logic (PEL) grounded onto a hierarchy of video segments. PEL parses the video by identifying video segments occupied by events of interest, such that the resulting parse respects compositional, force-dynamic, and the Allen temporal relations between time intervals encoded in the PEL knowledge base. Our major outcomes include the following:</p>\n<p>1) An efficient algorithm for compiling PEL to its equivalent Conjunctive Normal Form (CNF) form, and the corresponding inference algorithm for PEL-CNF.</p>\n<p>2) An algorithm for learning both the formulas and formula weights of PEL knowledge base in an unsupervised manner, and an algorithm for learning weights of user-specified formulas in PEL knowledge base.</p>\n<p>3) Two new video datasets of basketball and volleyball games were collected and manually annotated with event labels, object tracks, and spatiotemporal segmentations.</p>\n<p>Extensive experimental evaluation on this project demonstrated that PEL brought the internal computer&rsquo;s representation of high-level concepts closer to terms that a human could easily interact with, enabling even non-experts to naturally inject their own knowledge into the system.</p>\n<p>Training was provided for a number of graduate and undergraduate students, including those from under-represented groups. The project provided research material for: 4 M.S. theses, 2 Ph.D. dissertations, 2 Ph.D. preliminary examination presentations, and 2 Ph.D. qualifier examination presentations in the School of Electrical Engineering and Computer Science, at Oregon State University.</p>\n<p>The project results were widely disseminated in peer-reviewed publications, and invited talks by the principal investigators at top computer vision conferences.</p>\n<p>The project enabled the principal investigators to explore new research domains -- specifically, large-scale analysis of real-world videos of American football games.</p>\n<p>The project results, datasets, and list of all publications are summarized at the following website: http://blogs.oregonstate.edu/osupel/</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/04/2014<br>\n\t\t\t\t\tModified by: Sinisa&nbsp;Todorovic</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project addressed one of the basic problems in computer vision, that of detecting human actions and identifying their spatiotemporal extents in video. The key outcomes include: 1) Formulation of representation, 2) Learning algorithms, and 3) Inference algorithms for parsing human actions in video using the probabilistic event logic (PEL) grounded onto a hierarchy of video segments. PEL parses the video by identifying video segments occupied by events of interest, such that the resulting parse respects compositional, force-dynamic, and the Allen temporal relations between time intervals encoded in the PEL knowledge base. Our major outcomes include the following:\n\n1) An efficient algorithm for compiling PEL to its equivalent Conjunctive Normal Form (CNF) form, and the corresponding inference algorithm for PEL-CNF.\n\n2) An algorithm for learning both the formulas and formula weights of PEL knowledge base in an unsupervised manner, and an algorithm for learning weights of user-specified formulas in PEL knowledge base.\n\n3) Two new video datasets of basketball and volleyball games were collected and manually annotated with event labels, object tracks, and spatiotemporal segmentations.\n\nExtensive experimental evaluation on this project demonstrated that PEL brought the internal computer\u00c6s representation of high-level concepts closer to terms that a human could easily interact with, enabling even non-experts to naturally inject their own knowledge into the system.\n\nTraining was provided for a number of graduate and undergraduate students, including those from under-represented groups. The project provided research material for: 4 M.S. theses, 2 Ph.D. dissertations, 2 Ph.D. preliminary examination presentations, and 2 Ph.D. qualifier examination presentations in the School of Electrical Engineering and Computer Science, at Oregon State University.\n\nThe project results were widely disseminated in peer-reviewed publications, and invited talks by the principal investigators at top computer vision conferences.\n\nThe project enabled the principal investigators to explore new research domains -- specifically, large-scale analysis of real-world videos of American football games.\n\nThe project results, datasets, and list of all publications are summarized at the following website: http://blogs.oregonstate.edu/osupel/\n\n \n\n\t\t\t\t\tLast Modified: 11/04/2014\n\n\t\t\t\t\tSubmitted by: Sinisa Todorovic"
 }
}