{
 "awd_id": "1017077",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF:  Small:  Run-Time Program Generation and Empirical Optimization",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2010-08-01",
 "awd_exp_date": "2014-07-31",
 "tot_intn_awd_amt": 486850.0,
 "awd_amount": 486850.0,
 "awd_min_amd_letter_date": "2010-07-22",
 "awd_max_amd_letter_date": "2013-06-13",
 "awd_abstract_narration": "In programming computers, \"knowledge is power\" -  the more that is known about the data on which a program is to operate, and the machine on which it is to execute, the greater the efficiency that can be obtained.  However, programs are written to process all input data and run on many different machines.  Run-time program generation (RTPG) is a technique in which the programmer writes a program whose purpose is to write another program at run time when the input data (or some part of it) and machine are known.  This idea and its potential to produce dramatic efficiency improvements has been known for many years, but various technical problems have hampered its adoption.  Recent software research and developments in computer hardware enable us to address those problems.  This research develops tools and techniques for RTPG; applies them some important problems; and demonstrates the practicality of the technique.\r\n\r\nThis work explores several critical problems in the application of RTPG. Most programs of practical interest operate on large data sets, which pose special challenges for RTPG.  Further, since large data sets exacerbate the well-known problem of program generation cost, the PIs address that issue  in several novel ways.  The PIs design an object language for program generation that allows for compile-time preprocessing of fragments to facilitate run-time optimizations.  The PIs design optimizations expressly for computer-generated programs (which have different characteristics from ordinary, programmer-written codes).  Above all, the PIs employ the technique of auto-tuning, in which relevant characteristics of a target computer are determined at install time, and used to guide the run-time program generation process.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Samuel",
   "pi_last_name": "Kamin",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Samuel N Kamin",
   "pi_email_addr": "kamin@illinois.edu",
   "nsf_id": "000183498",
   "pi_start_date": "2010-07-22",
   "pi_end_date": "2013-06-13"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maria",
   "pi_last_name": "Garzaran",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Maria J Garzaran",
   "pi_email_addr": "garzaran@cs.uiuc.edu",
   "nsf_id": "000297030",
   "pi_start_date": "2013-06-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Vikram",
   "pi_last_name": "Adve",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Vikram S Adve",
   "pi_email_addr": "vadve@cs.uiuc.edu",
   "nsf_id": "000334755",
   "pi_start_date": "2010-07-22",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Maria",
   "pi_last_name": "Garzaran",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Maria J Garzaran",
   "pi_email_addr": "garzaran@cs.uiuc.edu",
   "nsf_id": "000297030",
   "pi_start_date": "2010-07-22",
   "pi_end_date": "2013-06-13"
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "506 S WRIGHT ST",
  "perf_city_name": "URBANA",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "732900",
   "pgm_ele_name": "COMPILERS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 486850.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Runtime specialization optimizes programs based on partial information available only at runtime. It is applicable when some input data is used repeatedly while other input data varies. This technique has the potential of generating highly efficient codes.</p>\n<p>In this project, we have explored the potential for obtaining speedups for sparse matrix-dense vector multiplication using runtime specialization, in the case where a single matrix is to be multiplied by many vectors. We experiment with five methods involving runtime specialization, comparing them to state of the art methods that do not, such as INTEL MKL library.</p>\n<p>Our experiments using matrices from the Matrix Market and Florida collections and running on different architectures show that in most cases the specialized code runs faster than any version without specialization, between 1.46 to 1.78 on the average for 23 matrices and five different platforms. Among the evaluated methods, we have found that one of our methods can produce significant speedups when the number of distinct values is small. This is important, as this can be common in matrices that are derived from graphs.</p>\n<p>We have also found that the best method depends on the matrix and machine, as no method is the best for all matrices and machines. Thus, we have identified the main input characteristics that impact the performance and used machine learning techniques to predict among all the methods the one that will deliver the highest performance. We can also generate at runtime codes that ran as fast or sometimes even faster than the codes generated using an offline compiler, although in this case the matrix has to run for enough iterations to amortize the cost of runtime code generation.</p>\n<p>Overall, those matrices where the location of non-zeros is known way ahead of time can directly benefit from our results. For matrices whose shape is only known at runtime, our machine learning techniques together with runtime code generation will be useful if run for enough iterations.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/04/2014<br>\n\t\t\t\t\tModified by: Maria&nbsp;J&nbsp;Garzaran</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nRuntime specialization optimizes programs based on partial information available only at runtime. It is applicable when some input data is used repeatedly while other input data varies. This technique has the potential of generating highly efficient codes.\n\nIn this project, we have explored the potential for obtaining speedups for sparse matrix-dense vector multiplication using runtime specialization, in the case where a single matrix is to be multiplied by many vectors. We experiment with five methods involving runtime specialization, comparing them to state of the art methods that do not, such as INTEL MKL library.\n\nOur experiments using matrices from the Matrix Market and Florida collections and running on different architectures show that in most cases the specialized code runs faster than any version without specialization, between 1.46 to 1.78 on the average for 23 matrices and five different platforms. Among the evaluated methods, we have found that one of our methods can produce significant speedups when the number of distinct values is small. This is important, as this can be common in matrices that are derived from graphs.\n\nWe have also found that the best method depends on the matrix and machine, as no method is the best for all matrices and machines. Thus, we have identified the main input characteristics that impact the performance and used machine learning techniques to predict among all the methods the one that will deliver the highest performance. We can also generate at runtime codes that ran as fast or sometimes even faster than the codes generated using an offline compiler, although in this case the matrix has to run for enough iterations to amortize the cost of runtime code generation.\n\nOverall, those matrices where the location of non-zeros is known way ahead of time can directly benefit from our results. For matrices whose shape is only known at runtime, our machine learning techniques together with runtime code generation will be useful if run for enough iterations. \n\n \n\n\t\t\t\t\tLast Modified: 11/04/2014\n\n\t\t\t\t\tSubmitted by: Maria J Garzaran"
 }
}