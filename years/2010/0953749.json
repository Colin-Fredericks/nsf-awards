{
 "awd_id": "0953749",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER:  Examining Users' Collective Privacy Management for Online Social Networks",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "wenjing lou",
 "awd_eff_date": "2010-06-01",
 "awd_exp_date": "2016-09-30",
 "tot_intn_awd_amt": 478606.0,
 "awd_amount": 394642.0,
 "awd_min_amd_letter_date": "2010-05-26",
 "awd_max_amd_letter_date": "2016-09-23",
 "awd_abstract_narration": "To better articulate privacy as a dynamic and dialectic phenomenon in a Web 2.0 world, this project proposes a set of basic empirical research activities to investigate three aspects of privacy in online social networks: conceptualization, intervention, and awareness. The goals of this CAREER award are to: 1) improve the theoretical understanding of information privacy in the context of online social networks in an interdisciplinary manner; 2) assess the efficacy of various privacy intervention strategies developed or proposed by the technologists and regulators; and 3) develop and enhance the persuasiveness of privacy and security awareness and training programs. The main contribution of this research is the generation of an interdisciplinary privacy research framework, with extensive grounding in a range of multidisciplinary privacy literatures in behavioral sciences, computer science, information systems, communication, and social psychology. This research takes a holistic view of privacy compared to the large amount of work focusing strictly on data privacy aspects. Thus, it recognizes the critical importance of user perceptions and behaviors when evaluating and developing privacy protection approaches. The proposed three tasks are greatly needed to better connect the social analysis of user privacy behaviors with the technical design of privacy enhancing technologies. The work should contribute to basic science-the underpinnings of user perceptions and actions around privacy management-as well as the findings generated for informing the design of privacy enhancing techniques. The research findings can enable technology-oriented researchers to develop more feasible privacy enhancing techniques that are embedded into the design specifications of systems, as well as aligned with organizational practices and user behaviors. This project will adopt various empirical research methods (experiments, large-scale survey, focus group and social network analysis) to test the behavioral hypotheses underlying user privacy behaviors in the context of online social networks. Well executed surveys and field experiments will contribute substantially to our understanding of how the actual users of online social networks behave and what interventions (in terms of technologies, regulations and trainings) may change their privacy decisions and behaviors.\r\n\r\nOne of the three major research thrusts is to develop a privacy awareness and training program for users of online social networks. The findings could potentially have a large impact on promoting privacy and security awareness in the user community. The project also has impacts on guideline creation for industry regulators and government agencies.  The PI aims to transform the repository of knowledge on the dynamic and dialectic nature of privacy assurance into a number of educational activities in her academic home at Penn State. The educational plan describes the development of new courses and course modules on privacy assurance at both undergraduate and graduate levels, bringing research into classrooms, outreach to students in underrepresented groups, and training of undergraduate and graduate student researchers in interdisciplinary methods.  The PI has transformed her science into a privacy workshop for high-school girls and their parents to teach about on-line privacy issues and practices. She proposes to continue such efforts to promote privacy and security awareness among high-school girls, as well as to attract more female students into the program of security and risk analysis at Penn State. The PI will also work with a professional society, the Association for Information Systems, to create a privacy research chapter and a privacy pedagogy section to extend the Information Systems research agenda and curriculum into this important area nationally.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peng",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Peng Liu",
   "pi_email_addr": "pliu@ist.psu.edu",
   "nsf_id": "000240285",
   "pi_start_date": "2013-08-22",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Heng",
   "pi_last_name": "Xu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Heng Xu",
   "pi_email_addr": "heng.xu@ufl.edu",
   "nsf_id": "000204693",
   "pi_start_date": "2010-05-26",
   "pi_end_date": "2013-08-22"
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "201 OLD MAIN",
  "perf_city_name": "UNIVERSITY PARK",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168021503",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "PA15",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "779500",
   "pgm_ele_name": "TRUSTWORTHY COMPUTING"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7795",
   "pgm_ref_txt": "TRUSTWORTHY COMPUTING"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 378642.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Social networking sites (SNSs) brought users' voluntary disclosure of personal data to the mainstream, making privacy concerns particularly salient in recent years. The extensive display of personal information by users of SNSs requires greater stress on sociotechnical research in information privacy. Different from other online contexts such as e-commerce, individuals on SNSs not only disclose information of themselves, but also share information concerning others (e.g., daily schedules with co-workers, group photos with friends, interesting anecdotes of family members, and so forth) inside and outside of their social networks. Likewise, they also have to face the situations where their personal data are disclosed by their co-workers, friends or family members without their knowledge.</p>\n<p>Given that shared content is co-constructed by self and others, and that boundaries between different social groups are often blurred, SNSs bring unprecedented challenges for understanding and managing information privacy. Our research identified the incomprehensiveness of purely studying privacy from the self-management model in the context of SNSs. Instead, we suggested considering a community governance model of privacy management, which differs from a self-management model because of its change of agency (from the self to a collective such as a group), its inclusion of interactional privacy decision making, and its collective domain where users and their social groups share responsibilities for keeping their shared data safe and private. In a series of empirical studies with human subjects, we demonstrated that there was such a thing as a collective level of privacy, and there needed to be ways to define privacy from a community governance perspective so shared data can be managed collaboratively among community members.</p>\n<p>In another series of studies, we explored the notion of collaborative privacy management as collaborative tools and approaches that allow individuals to protect online privacy as a member of a community (such as a social group) by harnessing other members&rsquo; collective privacy knowledge and preferences to make informed privacy decisions. We experimented different design ideas to enable collaborative privacy management. One idea, inspired by the conceptual framework of social transluscence, was to design social nudges that keep members informed about interdependent data collection, aggregation and use to ensure collective privacy awareness and accountability. Another was to using automated context detection to infer when social/online/physical circumstances have changed enough to require new privacy decision-making.</p>\n<p>From the standpoint of intellectual merit, this research aimed at advancing the scientific understanding of what makes collective privacy decision making uniquely different from, and sometimes more difficult than, individual privacy decision making. In terms of broader impact, this research may inform the work of privacy technologists, providing insights that go beyond the current technical data privacy solutions, to revisit the individualistic assumptions underlying those solutions.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/22/2016<br>\n\t\t\t\t\tModified by: Peng&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSocial networking sites (SNSs) brought users' voluntary disclosure of personal data to the mainstream, making privacy concerns particularly salient in recent years. The extensive display of personal information by users of SNSs requires greater stress on sociotechnical research in information privacy. Different from other online contexts such as e-commerce, individuals on SNSs not only disclose information of themselves, but also share information concerning others (e.g., daily schedules with co-workers, group photos with friends, interesting anecdotes of family members, and so forth) inside and outside of their social networks. Likewise, they also have to face the situations where their personal data are disclosed by their co-workers, friends or family members without their knowledge.\n\nGiven that shared content is co-constructed by self and others, and that boundaries between different social groups are often blurred, SNSs bring unprecedented challenges for understanding and managing information privacy. Our research identified the incomprehensiveness of purely studying privacy from the self-management model in the context of SNSs. Instead, we suggested considering a community governance model of privacy management, which differs from a self-management model because of its change of agency (from the self to a collective such as a group), its inclusion of interactional privacy decision making, and its collective domain where users and their social groups share responsibilities for keeping their shared data safe and private. In a series of empirical studies with human subjects, we demonstrated that there was such a thing as a collective level of privacy, and there needed to be ways to define privacy from a community governance perspective so shared data can be managed collaboratively among community members.\n\nIn another series of studies, we explored the notion of collaborative privacy management as collaborative tools and approaches that allow individuals to protect online privacy as a member of a community (such as a social group) by harnessing other members? collective privacy knowledge and preferences to make informed privacy decisions. We experimented different design ideas to enable collaborative privacy management. One idea, inspired by the conceptual framework of social transluscence, was to design social nudges that keep members informed about interdependent data collection, aggregation and use to ensure collective privacy awareness and accountability. Another was to using automated context detection to infer when social/online/physical circumstances have changed enough to require new privacy decision-making.\n\nFrom the standpoint of intellectual merit, this research aimed at advancing the scientific understanding of what makes collective privacy decision making uniquely different from, and sometimes more difficult than, individual privacy decision making. In terms of broader impact, this research may inform the work of privacy technologists, providing insights that go beyond the current technical data privacy solutions, to revisit the individualistic assumptions underlying those solutions. \n\n\t\t\t\t\tLast Modified: 12/22/2016\n\n\t\t\t\t\tSubmitted by: Peng Liu"
 }
}