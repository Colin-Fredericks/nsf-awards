{
 "awd_id": "1007457",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Sampling from Distributions with Intractable Integrals",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2010-08-01",
 "awd_exp_date": "2013-07-31",
 "tot_intn_awd_amt": 100000.0,
 "awd_amount": 100000.0,
 "awd_min_amd_letter_date": "2010-07-19",
 "awd_max_amd_letter_date": "2012-05-07",
 "awd_abstract_narration": "During the past five decades, Markov chain Monte Carlo (MCMC) methods have been developed as a versatile and powerful tool for scientific computing.  However, as known by many researchers, conventional MCMC methods suffer from the inability to sample from distributions with intractable integrals. The goal of this project is to develop some innovative Monte Carlo algorithms which are capable of sampling from distributions with intractable integrals. To achieve this goal, the PI proposes a new population Monte Carlo algorithm---Monte Carlo dynamically weighted importance sampling (MCDWIS). In simulations, MCDWIS replaces the ratio of intractable integrals by its Monte Carlo estimate, and the bias introduced thereby is counterbalanced by giving different weights to new samples produced. MCDWIS allows for the use of Monte Carlo estimates in MCMC simulations, while leaving the target distribution invariant with respect to important weights. Unlike auxiliary variable MCMC methods, MCDWIS avoids the requirement for perfect samples, and thus can be applied to many statistical models for which perfect sampling is unavailable or very expensive. As discussed in the proposal, MCDWIS can also be used to sample from incomplete posterior distributions for missing data and random effects-related models (e.g., generalized linear mixed models), which are traditionally treated with the expectation-maximization (EM) or Monte Carlo EM algorithms. In addition to providing a fully Bayesian analysis for these models, the MCDWIS can potentially overcome, due to its self-adjusting mechanism, the local-trap problem suffered by the EM and Monte Carlo EM algorithms. In this proposal, the PI also proposes an importance sampling-targeted stochastic approximation Monte Carlo algorithm, the so-called importance stochastic approximation Monte Carlo algorithm, which can be used for Bayesian inference for the models with intractable normalizing constants.\r\n\r\nThe intellectual merit of this project is to provide some innovative computational methods, which are expected to play a major role in statistical inference for an important class of scientific models, including random graph models used in social network analysis, autonormal models used in spatial data analysis, autologistic models used in disease mapping, and generalized linear mixed models used in biomedical data analysis, among others. Successful inferences of the models will enhance people's underderstanding to the underlying natural, social, or biological systems. This project will have broader impacts in both communities of statistical methodology and scientific computing. The research results will be disseminated to these communities via direct collaboration with researchers in other disciplines, conference presentations, books, and papers to be published in academic journals.  The project will have also significant impacts on education through direct involvement of graduate students in the project and incorporation of results into undergraduate and graduate courses.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Faming",
   "pi_last_name": "Liang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Faming Liang",
   "pi_email_addr": "fmliang@purdue.edu",
   "nsf_id": "000490214",
   "pi_start_date": "2010-07-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Research Foundation",
  "inst_street_address": "400 HARVEY MITCHELL PKWY S STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778454375",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A & M RESEARCH FOUNDATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "EQH8NQ4AXFT7"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M University",
  "perf_str_addr": "400 HARVEY MITCHELL PKY S STE 300",
  "perf_city_name": "COLLEGE STATION",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778454375",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 28456.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 29143.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 42401.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;</p>\n<p style=\"text-align: left;\">During the past several decades, Markov chain Monte Carlo (MCMC) methods have been developed as a versatile and powerful tool for scientific computing. However, as known by many researchers, conventional MCMC methods, such as the Metropolis-Hastings (MH) algorithm and the Gibbs sampler,&nbsp; cannot be applied to sample from distributions with intractable normalizing constants. The goal of this project is to develop some innovative Monte Carlo algorithms to tackle this problem. During the past three years, a few such a kind of Monte Carlo algorithms have been developed by the PI and his co-authors, which are described in sequel as follows.</p>\n<p style=\"text-align: left;\">In Liang (2010), the PI proposed the so-called double Metropolis-Hastings (DMH) algorithm, where , at each iteration, an appropriate auxiliary variable is drawn via running a short Markov chain and the normalizing constants are then canceled&nbsp; by augmenting the auxiliary variable to the proposal distribution. This algorithm is getting more and more popular due to its simplicity and high efficiency.</p>\n<p style=\"text-align: left;\">In Liang and Jin (2013), the authors proposed the so-called Monte Carlo Metropolis-Hastings (MCMH) algorithm, which is to approximate, at each iteration, the normalizing constant ratio in the MH acceptance probability using the samples simulated from an appropriate distribution via a short Markov chain. This algorithm has a lot of implications, as it allows a random quantity to be included in the MH acceptance probability. Based on it, the PI has recently developed some advanced Monte Carlo algorithms for big data analysis.</p>\n<p style=\"text-align: left;\">In Jin and Liang (2013a), the authors proposed the so-called Bayesian stochastic approximation Monte Carlo (BSAMC) algorithm. This algorithm works by sampling from a sequence of approximate distributions with their average converging to the target distribution, where the approximate distributions can be achieved using the stochastic approximation Monte Carlo algorithm, a former work by the PI and his co-authors. A strong law of large numbers is established for the BSAMC estimator under mild conditions.</p>\n<p style=\"text-align: left;\">Very recently, the PI and his co-authors proposed the so-called&nbsp; adaptive exchange (AEX) algorithm (Liang et al., 2013). AEX can be viewed as a MCMC extension of the exchange algorithm that was originally developed by Murray, Ghahramani and MacKay (2006, <em>Proc. 22nd Ann. Conf.&nbsp; on UAI</em>). In AEX, the auxiliary variables are generated via an importance sampling procedure from an auxiliary Markov chain running in parallel. The convergence of the algorithm is established under mild conditions. Compared to the exchange algorithm,&nbsp; AEX removes the requirement that the auxiliary variables must be drawn using a perfect sampler, and thus can be applied to many models for which the perfect sampler is not available or very expensive.</p>\n<p style=\"text-align: left;\">In addition to the above Monte Carlo algorithms targeted at distribution sampling, the PI and his co-authors have proposed to use the varying truncation stochastic approximation MCMC algorithm for finding the maximum likelihood estimate for the distributions with intractable normalizing constants (Jin and Liang, 2013b). The proposed method has been successfully applied to the exponential random graph model, one of the most popular models used in social network analysis.</p>\n<p style=\"text-align: left;\">The PI and his co-authors have also successfully applied the proposed algorithms to solve some real problems, such as social network modeling (Jin, Yuan, Liang, 2013) and gene-environment interaction analysis (Yu et al., 2012).</p>\n<p style=\"text-align: left;\">This project has broader impacts in both communities of statistical methodology and scientific computing. The resear...",
  "por_txt_cntn": "\n \nDuring the past several decades, Markov chain Monte Carlo (MCMC) methods have been developed as a versatile and powerful tool for scientific computing. However, as known by many researchers, conventional MCMC methods, such as the Metropolis-Hastings (MH) algorithm and the Gibbs sampler,  cannot be applied to sample from distributions with intractable normalizing constants. The goal of this project is to develop some innovative Monte Carlo algorithms to tackle this problem. During the past three years, a few such a kind of Monte Carlo algorithms have been developed by the PI and his co-authors, which are described in sequel as follows.\nIn Liang (2010), the PI proposed the so-called double Metropolis-Hastings (DMH) algorithm, where , at each iteration, an appropriate auxiliary variable is drawn via running a short Markov chain and the normalizing constants are then canceled  by augmenting the auxiliary variable to the proposal distribution. This algorithm is getting more and more popular due to its simplicity and high efficiency.\nIn Liang and Jin (2013), the authors proposed the so-called Monte Carlo Metropolis-Hastings (MCMH) algorithm, which is to approximate, at each iteration, the normalizing constant ratio in the MH acceptance probability using the samples simulated from an appropriate distribution via a short Markov chain. This algorithm has a lot of implications, as it allows a random quantity to be included in the MH acceptance probability. Based on it, the PI has recently developed some advanced Monte Carlo algorithms for big data analysis.\nIn Jin and Liang (2013a), the authors proposed the so-called Bayesian stochastic approximation Monte Carlo (BSAMC) algorithm. This algorithm works by sampling from a sequence of approximate distributions with their average converging to the target distribution, where the approximate distributions can be achieved using the stochastic approximation Monte Carlo algorithm, a former work by the PI and his co-authors. A strong law of large numbers is established for the BSAMC estimator under mild conditions.\nVery recently, the PI and his co-authors proposed the so-called  adaptive exchange (AEX) algorithm (Liang et al., 2013). AEX can be viewed as a MCMC extension of the exchange algorithm that was originally developed by Murray, Ghahramani and MacKay (2006, Proc. 22nd Ann. Conf.  on UAI). In AEX, the auxiliary variables are generated via an importance sampling procedure from an auxiliary Markov chain running in parallel. The convergence of the algorithm is established under mild conditions. Compared to the exchange algorithm,  AEX removes the requirement that the auxiliary variables must be drawn using a perfect sampler, and thus can be applied to many models for which the perfect sampler is not available or very expensive.\nIn addition to the above Monte Carlo algorithms targeted at distribution sampling, the PI and his co-authors have proposed to use the varying truncation stochastic approximation MCMC algorithm for finding the maximum likelihood estimate for the distributions with intractable normalizing constants (Jin and Liang, 2013b). The proposed method has been successfully applied to the exponential random graph model, one of the most popular models used in social network analysis.\nThe PI and his co-authors have also successfully applied the proposed algorithms to solve some real problems, such as social network modeling (Jin, Yuan, Liang, 2013) and gene-environment interaction analysis (Yu et al., 2012).\nThis project has broader impacts in both communities of statistical methodology and scientific computing. The research results  have been disseminated to these communities via direct collaboration with researchers in other disciplines and publications in academic journals.  The project  has also significant impacts on education through direct involvement of graduate students, such as I.K. Jin and Q. Song,  in the project and incorporation of the results into a graduate course ..."
 }
}