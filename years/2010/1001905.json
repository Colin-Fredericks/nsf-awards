{
 "awd_id": "1001905",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Deterministic analogues of random processes",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032924885",
 "po_email": "tbartosz@nsf.gov",
 "po_sign_block_name": "Tomek Bartoszynski",
 "awd_eff_date": "2010-08-15",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2010-08-03",
 "awd_max_amd_letter_date": "2015-06-10",
 "awd_abstract_narration": "The PI's work concerns deterministic systems whose small-scale behavior is designed to mimic the average case behavior of random systems.  In many cases the large-scale behavior of such \"quasirandom\" systems reproduces interesting aspects of the large-scale behavior of the random systems they mimic.  At the same time, quasirandom systems exhibit many rich and complex patterns specific to the deterministic context, and these patterns demand explanation.\r\n\r\nOne reason for studying quasirandom systems is that they may have applications to Monte Carlo simulation: it could be that for many random systems of interest to scientists, the best way to get statistical information about the system is to replace it by a quasirandom analogue.  But in the longer run the real significance of the PI's work may be the way it shows that many of the theorems of probability theory remain true when they are recast as statements about discrepancy, with no mention of probability at all.  Such a radical revision of probability theory seems necessary if we are ever to understand how non-random mathematical objects (like the digits of pi) behave \"as if they were random\".",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Propp",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "James G Propp",
   "pi_email_addr": "JamesPropp@gmail.com",
   "nsf_id": "000175480",
   "pi_start_date": "2010-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Lowell",
  "inst_street_address": "220 PAWTUCKET ST STE 400",
  "inst_street_address_2": "",
  "inst_city_name": "LOWELL",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "9789344170",
  "inst_zip_code": "018543573",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "MA03",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS LOWELL",
  "org_prnt_uei_num": "",
  "org_uei_num": "LTNVSTJ3R6D5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Lowell",
  "perf_str_addr": "220 PAWTUCKET ST STE 400",
  "perf_city_name": "LOWELL",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "018543573",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "MA03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126300",
   "pgm_ele_name": "PROBABILITY"
  },
  {
   "pgm_ele_code": "797000",
   "pgm_ele_name": "Combinatorics"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>What are the computational powers of large networks of simple agents? This is a new question but also an old one: back in the 1970s, long before the era of nanocomputing, computer scientist Arthur Engel devised a way for extremely simple processors, linked in a network, to answer questions about the mathematical properties of the selfsame network. In Engel's protocol, there is no synchronization of the processors; different processors may work at different speeds, but when all the communicating processors have finished their work, the network will contain the answer to the question that was asked. Lately this has become a paradigm for the \"abelian processors\" model of computation, invented by physicist Deepak Dhar and investigated by mathematician Lionel Levine and others.&nbsp; (Here the word \"abelian\" signifies that the order in which the processors perform their respective work will not affect the final outcome.)</p>\n<p>During the funded period, the PI published three papers on Engel's \"chip-firing\" machines and the PI's own (related) \"rotor-routing\" machines. One paper showed that rotor-routing has many of the same properties as chip-firing. Specifically, if you want to study the properties of random walk (or a similar random process) on a graph, create a network of processors that mimics the topology of the graph, and if the processors are properly designed, the network will compute properties of the graph. The PI's second paper, published in the interdisciplinary journal \"Chaos\", situated this work at the border between computer science, mathematics, and physics, by showing how such algorithms can be seen as a form of \"discrete analogue computing\", and how their behavior can be understood using \"invariants\" that are analogous to the dynamically conserved quantities of physics. The third paper showed that if the processors in a network have a certain symmetry property, the behavior of the network as a whole reproduces that symmetry; this is part of a general vision that dictates that many \"global\" properties of a computation can be derived as a consequence of the \"local\" properties of the computation.</p>\n<p>The work is based on a view that blurs the usual boundaries between random processes and deterministic processes. When we want to study a random process, we can replace it by an analogous non-random process that, in a deterministic way, reproduces crucial features of the random process. For example, for some purposes, a derandomized analogue of a fair coin is a process that simply alternates between Heads and Tails; both processes have the property of showing each of two outcomes equally often. Although processors that mindlessly alternate between Heads and Tails might seem too simple to be useful, a network of such processors, properly communicating with one another, can mimic the random counterpart of the network and compute useful things about it.</p>\n<p>The intellectual merit of the work lies in its contribution to the study of emergent behavior in complex systems made of simple components, and the possibility of harnessing this behavior for purposes of computation. In particular, the abelian processors paradigm gives us a chance to see what sorts of computations are possible when there is no central controller synchronizing different parts of a computation. While the work has no ongoing or envisaged applications to specific tasks, the framework may prove useful. For example, negative theoretical results that assert that abelian networks cannot perform certain computational tasks could be useful, by showing us where in a computation some global synchronization is needed.</p>\n<p>The broader impact of the PI's work lies mostly in its educational component. Engel's networks, repurposed by the PI and repackaged by James Tanton, have been turned into a visually appealing approach to huge swaths of the K-12 curriculum; this \"Exploding Dots\" pedagogy, which was inspired by the PI's work on chip-firing, will be the centerpiece of the Global Math Project's \"week of math\" in 2017. Although the PI's NSF grant has expired, the PI plans to spend the coming year creating pedagogical materials that will bridge the gap between Engel's \"probabilistic abacus\" and Tanton's exploding dots.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/31/2016<br>\n\t\t\t\t\tModified by: James&nbsp;G&nbsp;Propp</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2016/1001905/1001905_10019640_1477441514016_z2-e--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1001905/1001905_10019640_1477441514016_z2-e--rgov-800width.jpg\" title=\"Emergent order in a rotor-router network\"><img src=\"/por/images/Reports/POR/2016/1001905/1001905_10019640_1477441514016_z2-e--rgov-66x44.jpg\" alt=\"Emergent order in a rotor-router network\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This figure shows how a network of simple processors can create an intriguing fractal pattern. Complex global behavior emerges from simple local rules.</div>\n<div class=\"imageCredit\">Lionel Levine</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">James&nbsp;G&nbsp;Propp</div>\n<div class=\"imageTitle\">Emergent order in a rotor-router network</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nWhat are the computational powers of large networks of simple agents? This is a new question but also an old one: back in the 1970s, long before the era of nanocomputing, computer scientist Arthur Engel devised a way for extremely simple processors, linked in a network, to answer questions about the mathematical properties of the selfsame network. In Engel's protocol, there is no synchronization of the processors; different processors may work at different speeds, but when all the communicating processors have finished their work, the network will contain the answer to the question that was asked. Lately this has become a paradigm for the \"abelian processors\" model of computation, invented by physicist Deepak Dhar and investigated by mathematician Lionel Levine and others.  (Here the word \"abelian\" signifies that the order in which the processors perform their respective work will not affect the final outcome.)\n\nDuring the funded period, the PI published three papers on Engel's \"chip-firing\" machines and the PI's own (related) \"rotor-routing\" machines. One paper showed that rotor-routing has many of the same properties as chip-firing. Specifically, if you want to study the properties of random walk (or a similar random process) on a graph, create a network of processors that mimics the topology of the graph, and if the processors are properly designed, the network will compute properties of the graph. The PI's second paper, published in the interdisciplinary journal \"Chaos\", situated this work at the border between computer science, mathematics, and physics, by showing how such algorithms can be seen as a form of \"discrete analogue computing\", and how their behavior can be understood using \"invariants\" that are analogous to the dynamically conserved quantities of physics. The third paper showed that if the processors in a network have a certain symmetry property, the behavior of the network as a whole reproduces that symmetry; this is part of a general vision that dictates that many \"global\" properties of a computation can be derived as a consequence of the \"local\" properties of the computation.\n\nThe work is based on a view that blurs the usual boundaries between random processes and deterministic processes. When we want to study a random process, we can replace it by an analogous non-random process that, in a deterministic way, reproduces crucial features of the random process. For example, for some purposes, a derandomized analogue of a fair coin is a process that simply alternates between Heads and Tails; both processes have the property of showing each of two outcomes equally often. Although processors that mindlessly alternate between Heads and Tails might seem too simple to be useful, a network of such processors, properly communicating with one another, can mimic the random counterpart of the network and compute useful things about it.\n\nThe intellectual merit of the work lies in its contribution to the study of emergent behavior in complex systems made of simple components, and the possibility of harnessing this behavior for purposes of computation. In particular, the abelian processors paradigm gives us a chance to see what sorts of computations are possible when there is no central controller synchronizing different parts of a computation. While the work has no ongoing or envisaged applications to specific tasks, the framework may prove useful. For example, negative theoretical results that assert that abelian networks cannot perform certain computational tasks could be useful, by showing us where in a computation some global synchronization is needed.\n\nThe broader impact of the PI's work lies mostly in its educational component. Engel's networks, repurposed by the PI and repackaged by James Tanton, have been turned into a visually appealing approach to huge swaths of the K-12 curriculum; this \"Exploding Dots\" pedagogy, which was inspired by the PI's work on chip-firing, will be the centerpiece of the Global Math Project's \"week of math\" in 2017. Although the PI's NSF grant has expired, the PI plans to spend the coming year creating pedagogical materials that will bridge the gap between Engel's \"probabilistic abacus\" and Tanton's exploding dots.\n\n\t\t\t\t\tLast Modified: 10/31/2016\n\n\t\t\t\t\tSubmitted by: James G Propp"
 }
}