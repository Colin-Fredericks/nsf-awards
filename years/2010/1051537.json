{
 "awd_id": "1051537",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Workshop: Accelerators for Data Intensive Applications; A Workshop to Engage the Science and Engineering Community - Arlington, VA - Fall 2010",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Irene Qualters",
 "awd_eff_date": "2010-08-15",
 "awd_exp_date": "2011-07-31",
 "tot_intn_awd_amt": 37837.0,
 "awd_amount": 37837.0,
 "awd_min_amd_letter_date": "2010-08-24",
 "awd_max_amd_letter_date": "2010-08-24",
 "awd_abstract_narration": "We will hold workshop in early Fall 2010 to promote understanding of, through collaboration around, issues required to utilize accelerator enhanced systems efficiently for solving challenging problems in several application domains. Working through these issues together will advance understanding in application domains and computer science.  This will launch productive collaborations between computer scientists and application developers to enable efficient and early use of accelerator computing resources as they come online and foster the discussion of a potential Software Infrastructure Center organization.   We will use application requirements from several important science and engineering disciplines to drive innovations in future computing technologies such as manycore processor architectures and application accelerators.\r\n\r\nThe workshop will promote meaningful information exchange between the application developers and computer scientists and engineers.  It will be structured as a tutorial; application scientists will describe their applications along with the computational challenges they present; computer scientists will describe their methods and tools for improving application performance and capability. There will be concrete actions identified out of the workshop, such as collaborative development of a center scale proposal for algorithm and model development and software for the community based on these abstractions which will be included in the workshop report. The objective is that investigators in both fields are to become better positioned to use emerging application accelerators.\r\n\r\nThe workshop will be used to facilitate an unprecedented exploration of important science problems at great scale and fidelity and enabling a broad set of science and engineering applications to productively employ parallelism and accelerators to tackle data- and compute- intensive problems. Collaborations between domain experts and computer scientists thus have the potential to improve U.S. economic competitiveness, improve understanding of emerging processor architectures, and keep the U.S. pre-eminent in this important promising technology.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Bader",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "David A Bader",
   "pi_email_addr": "bader@njit.edu",
   "nsf_id": "000206826",
   "pi_start_date": "2010-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Viktor",
   "pi_last_name": "Prasanna",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Viktor K Prasanna",
   "pi_email_addr": "prasanna@usc.edu",
   "nsf_id": "000209825",
   "pi_start_date": "2010-08-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3720 S FLOWER ST FL 3",
  "perf_city_name": "LOS ANGELES",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "90033",
  "perf_ctry_code": "US",
  "perf_cong_dist": "34",
  "perf_st_cong_dist": "CA34",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "800400",
   "pgm_ele_name": "Software Institutes"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 37837.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"Standard\"><em>&nbsp;</em></p>\n<p>&nbsp;</p>\n<p class=\"Standard\">A <em>Planning meeting for Center Scale Activities related to Accelerators for Data Intensive Applications</em>, was held<em> </em>at Arlington, VA, on October 14-15, 2010. It was supported by the National Science Foundation (NSF) as part of the Call for Exploratory Workshop Proposals on Scientific Software Innovation Institutes (S2I2) [NSF 10-050]. The workshop, chaired by Viktor K. Prasanna, University of Southern California, and David A. Bader, Georgia Institute of Technology, invited domain scientists from the application areas of biology, computational social science, and security, and computer science researchers from the technology areas of multi-core processors, general-purpose graphics processing units (GPGPU), and field programmable gate arrays (FPGA). The workshop included over 25 participants, with broad representation from academia and industry.</p>\n<h2>1.1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Recommendation on Center Organization, Goals and Sustainability</h2>\n<p class=\"Standard\">The S2I2 center&rsquo;s operational model must balance research, development, and integration activities to best achieve the overall goal of software creation, maintenance, and sustainability. The center is best organized through a strong management model headed by a center director with academic credentials and management experience. The primary goal of the center must be to investigate, build, distribute, and maintain software that will spur innovation in scientific computing over an extended period of time. A strong software design and development team should build and maintain reliable, usable, and extensible software that are created organically and contributed by user, developer, and business communities.</p>\n<p class=\"Standard\">A sustainable software infrastructure requires building the &ldquo;software right&rdquo;. The workshop participants recommend that a center should adopt portable, open, extensible software development frameworks and practices to allow easy intake, sharing, and sustained maintenance of code. Software should be modular, with stakeholders associated with each module. Growth of new software must be encouraged while balancing the need to maintain the existing codebase. The center must actively plan for the lifecycle of software, transitioning from management to maintenance and even to deprecation. Maintaining and evaluating an evolving set of benchmarks and &ldquo;hero&rdquo; codes is important to the community. There is also agreement that any center-maintained software must include and enforce guidelines for code contribution.</p>\n<p class=\"Standard\">Documentation of both software and best practices for specific domains and applications are essential. Availability of trained technical writers in the center would be of immediate value to the community.</p>\n<h2>1.2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Motivation for a Center on Software for Accelerators</h2>\n<p class=\"Standard\">Data-intensive computational kernels in biology, network security, and social sciences exemplify emerging and future workloads and represent challenging cases that can benefit from high performance accelerators. For example, next generation DNA sequencing instruments flood individual investigators with terabytes and community projects with petabytes of data. High-throughput instrumentation is also making a presence in other areas, such as materials science where atomic-scale images are provided by Atom Problem Tomography (APT). The workshop participants identified a combination of multi-core processors, and accelerator technologies such as GPUs and FPGAs as providing a more affordable and accessible alternative to large clusters and supercomputers. Another application for accelerators is the area of high throughput malware scanning, matching large ...",
  "por_txt_cntn": "\n\n \nA Planning meeting for Center Scale Activities related to Accelerators for Data Intensive Applications, was held at Arlington, VA, on October 14-15, 2010. It was supported by the National Science Foundation (NSF) as part of the Call for Exploratory Workshop Proposals on Scientific Software Innovation Institutes (S2I2) [NSF 10-050]. The workshop, chaired by Viktor K. Prasanna, University of Southern California, and David A. Bader, Georgia Institute of Technology, invited domain scientists from the application areas of biology, computational social science, and security, and computer science researchers from the technology areas of multi-core processors, general-purpose graphics processing units (GPGPU), and field programmable gate arrays (FPGA). The workshop included over 25 participants, with broad representation from academia and industry.\n1.1.            Recommendation on Center Organization, Goals and Sustainability\nThe S2I2 center\u00c6s operational model must balance research, development, and integration activities to best achieve the overall goal of software creation, maintenance, and sustainability. The center is best organized through a strong management model headed by a center director with academic credentials and management experience. The primary goal of the center must be to investigate, build, distribute, and maintain software that will spur innovation in scientific computing over an extended period of time. A strong software design and development team should build and maintain reliable, usable, and extensible software that are created organically and contributed by user, developer, and business communities.\nA sustainable software infrastructure requires building the \"software right\". The workshop participants recommend that a center should adopt portable, open, extensible software development frameworks and practices to allow easy intake, sharing, and sustained maintenance of code. Software should be modular, with stakeholders associated with each module. Growth of new software must be encouraged while balancing the need to maintain the existing codebase. The center must actively plan for the lifecycle of software, transitioning from management to maintenance and even to deprecation. Maintaining and evaluating an evolving set of benchmarks and \"hero\" codes is important to the community. There is also agreement that any center-maintained software must include and enforce guidelines for code contribution.\nDocumentation of both software and best practices for specific domains and applications are essential. Availability of trained technical writers in the center would be of immediate value to the community.\n1.2.            Motivation for a Center on Software for Accelerators\nData-intensive computational kernels in biology, network security, and social sciences exemplify emerging and future workloads and represent challenging cases that can benefit from high performance accelerators. For example, next generation DNA sequencing instruments flood individual investigators with terabytes and community projects with petabytes of data. High-throughput instrumentation is also making a presence in other areas, such as materials science where atomic-scale images are provided by Atom Problem Tomography (APT). The workshop participants identified a combination of multi-core processors, and accelerator technologies such as GPUs and FPGAs as providing a more affordable and accessible alternative to large clusters and supercomputers. Another application for accelerators is the area of high throughput malware scanning, matching large data quickly against sophisticated malware signatures. Compute-intensive numerical methods, such as the molecular dynamics and Fast Multi-pole Methods, can also benefit from accelerator-driven parallelization.\nWorking through practical details of how applications can take advantage of such accelerators will enable breakthroughs in these domains. An iterative development process is required to under..."
 }
}