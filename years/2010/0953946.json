{
 "awd_id": "0953946",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Data-Intensive HPC Analytics: A Systems Approach Through Extended Interfaces, Data Restructuring and Data-centric Scheduling",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2010-03-15",
 "awd_exp_date": "2017-02-28",
 "tot_intn_awd_amt": 438909.0,
 "awd_amount": 454909.0,
 "awd_min_amd_letter_date": "2010-03-08",
 "awd_max_amd_letter_date": "2013-12-18",
 "awd_abstract_narration": "With the advent of emerging e-Science applications, today's scientific research increasingly relies on petascale-and-beyond computing over large data sets with petabyte-and-beyond sizes. Representatives include analytics- and simulation- driven applications such as the human vision simulation, astrophysics data analysis, earthquake modeling, climate modeling using ensemble runs, etc. In many of the above-mentioned fields, scientists are dealing with large amounts of data and analyzing them to explore new concepts and ideas. These applications make up data-intensive HPC analytics, which lies at the intersection of current HPC and Data-Intensive Scalable Computing (DISC).\r\nWhen HPC systems use traditional configurations to support data-intensive HPC analytics, data is copied from a large remote storage system to diskless compute nodes for processing. Copying data back and forth is an expensive and time consuming process. These data-intensive applications do not require compute intensive resources, but rather moderate compute power machines with the capability of local storage so that data can be processed in-place. One such example of this configuration is the Hadoop framework. However, there are currently limitations in this framework which must be overcome in order to make Hadoop an effective HPC tool. The investigator is leveraging the Hadoop framework to process large amount of patterned data in HPC. This research program includes three thrusts. It is developing the MapReduce API to support a wider range of I/O access patterns, various data restructuring schemes to improve I/O performance for these access patterns, and an efficient scheduling scheme considering multiple chunk locations and data transfer latencies over the network. The research is integrated into several educational activities, such as the development of data-intensive HPC curricula.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jun",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jun Wang",
   "pi_email_addr": "Jun.Wang@ucf.edu",
   "nsf_id": "000277527",
   "pi_start_date": "2010-03-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "The University of Central Florida Board of Trustees",
  "inst_street_address": "4000 CENTRAL FLORIDA BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "ORLANDO",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "4078230387",
  "inst_zip_code": "328168005",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "FL10",
  "org_lgl_bus_name": "THE UNIVERSITY OF CENTRAL FLORIDA BOARD OF TRUSTEES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RD7MXJV7DKT9"
 },
 "perf_inst": {
  "perf_inst_name": "The University of Central Florida Board of Trustees",
  "perf_str_addr": "4000 CENTRAL FLORIDA BLVD",
  "perf_city_name": "ORLANDO",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "328168005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "FL10",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "104500",
   "pgm_ele_name": "CAREER: FACULTY EARLY CAR DEV"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 101659.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 125864.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 112365.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 115021.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 11.0px Helvetica} -->\n<p class=\"p1\">This CAREER project makes it major research contribution by defining a new computing paradigm for high-performance computing scientists and engineers to better handle the onslaught of data towards scientific inquiry in today&rsquo;s big data era. Rather than moving data to the demanding applications, we develop a data-centric computing platform to prepare data ahead of time, distribute data appropriately at target computers, and launch big data applications from desirable place where we like to go. This is among the first to develop a unified big data and big compute framework to accelerate HPC big data analytics. We develop a new big data computing framework which provides a suite of open-source software tools for many interdisciplinary scientists and big data analysts in a wide variety of disciplines (e.g., bioinformatics, life science, high energy physicists, astrophysics) to conduct their data analyses in a fast and cost-effective fashion. Both times and amount of big data movement taking place in anywhere and anytime has been significantly reduced. In addition, we port our data intensive computing framework to both Windows and Amazon two different cloud computing platforms, which enables scientists to perform fast big data analysis at any time, and in any place.</p>\n<p class=\"p1\">Regarding the broad impact, our new interdisciplinary research framework in support of data-intensive HPC analytics enables many bioinformatics and astrophysics scientists and engineers to conduct data analyses in comprehensive access patterns by a super faster and easier way compared with the state-of-the-art solutions. We estimate it can not only save millions of dollars of physicists&rsquo; labor cost in national lab, but also significantly shorten the development cycle of analyses programs.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/11/2017<br>\n\t\t\t\t\tModified by: Jun&nbsp;Wang</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/0953946/0953946_10013915_1489266178825_nsf_figure_2017--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/0953946/0953946_10013915_1489266178825_nsf_figure_2017--rgov-800width.jpg\" title=\"Big Data Express\"><img src=\"/por/images/Reports/POR/2017/0953946/0953946_10013915_1489266178825_nsf_figure_2017--rgov-66x44.jpg\" alt=\"Big Data Express\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Accelerating Big Data Processing</div>\n<div class=\"imageCredit\">Mr. Dan Huang and Dr. Jun Wang</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Jun&nbsp;Wang</div>\n<div class=\"imageTitle\">Big Data Express</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis CAREER project makes it major research contribution by defining a new computing paradigm for high-performance computing scientists and engineers to better handle the onslaught of data towards scientific inquiry in today?s big data era. Rather than moving data to the demanding applications, we develop a data-centric computing platform to prepare data ahead of time, distribute data appropriately at target computers, and launch big data applications from desirable place where we like to go. This is among the first to develop a unified big data and big compute framework to accelerate HPC big data analytics. We develop a new big data computing framework which provides a suite of open-source software tools for many interdisciplinary scientists and big data analysts in a wide variety of disciplines (e.g., bioinformatics, life science, high energy physicists, astrophysics) to conduct their data analyses in a fast and cost-effective fashion. Both times and amount of big data movement taking place in anywhere and anytime has been significantly reduced. In addition, we port our data intensive computing framework to both Windows and Amazon two different cloud computing platforms, which enables scientists to perform fast big data analysis at any time, and in any place.\nRegarding the broad impact, our new interdisciplinary research framework in support of data-intensive HPC analytics enables many bioinformatics and astrophysics scientists and engineers to conduct data analyses in comprehensive access patterns by a super faster and easier way compared with the state-of-the-art solutions. We estimate it can not only save millions of dollars of physicists? labor cost in national lab, but also significantly shorten the development cycle of analyses programs.\n\n \n\n\t\t\t\t\tLast Modified: 03/11/2017\n\n\t\t\t\t\tSubmitted by: Jun Wang"
 }
}