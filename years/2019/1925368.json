{
 "awd_id": "1925368",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: INT: COLLAB: Leveraging Environmental Monitoring UAS in Rainforests",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928950",
 "po_email": "rwachter@nsf.gov",
 "po_sign_block_name": "Ralph Wachter",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 722804.0,
 "awd_amount": 722804.0,
 "awd_min_amd_letter_date": "2019-09-04",
 "awd_max_amd_letter_date": "2019-09-04",
 "awd_abstract_narration": "Rainforest canopies are important ecosystems for diverse plant and animal life, however validating predictions for scientific decisions about these environments is difficult due to a lack of efficient data collection methods. Access is limited due to remoteness, dense foliage, and venomous wildlife, which constrain research to trails and vegetation near the forest floor. Currently, most data is collected within 50 meters of trails and 5 meters from the ground due to these limitations. Unmanned Aerial Systems (UASs) have been used for sensor deployment and monitoring, but only recently has the ability to collect soil samples at precise locations in the ground been developed by the project team. The proposed work will contribute transformative soil, water, and leaf sampling technologies as part of a UAS sampling system to expand the reach of scientists in challenging environments. It will increase the perception abilities of the robots in challenging terrains and the ability for people to interact with and control the UASs. This effort has the potential to benefit a range of organizations that monitor sensitive environmental regions by providing complementary technologies that fulfill a gap through capabilities to sample previously inaccessible areas at a resolution not previously possible while reducing risk to both humans and the environment. \r\n\r\nThis proposal presents a vision aimed at advancing heterogeneous multi-UAS technologies, practices, and understanding to increase the reach of human sensing in challenging, hard-to-access environments. The proposed work will advance the NRI 2.0 Co-Robotic agenda by focusing on scalability of both systems and teams, inspired in the context of UAS-based forest canopy monitoring. The vision addresses key goals in co-robotic system development with regards to the available attention of the humans involved, site selection for complementary sampling, and improvements in robot design and decision making for sample collection. These goals will be developed in local, well-understood environments before being refined in yearly tests in the harsh, cluttered forest contexts, all while contributing to progress in fundamental co-robotic challenges. The proposed activities will result in: 1) Timing rules and motion-based communications for conveying multi-UAS intention and knowledge to end-users, 2) Perception algorithms that map the environmental knowledge and domain expertise of a scientist into a fleet of vehicles to support semi-autonomous collection of samples above and below the canopy, 3) Platform innovations to improve mechanisms and algorithms for sample collection in new contexts, and 4) Improved data collection in forest canopies to advance the science of plant hydraulics and streamflow generation.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Brittany",
   "pi_last_name": "Duncan",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Brittany A Duncan",
   "pi_email_addr": "bduncan@unl.edu",
   "nsf_id": "000703906",
   "pi_start_date": "2019-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Carrick",
   "pi_last_name": "Detweiler",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Carrick Detweiler",
   "pi_email_addr": "carrick@cse.unl.edu",
   "nsf_id": "000580669",
   "pi_start_date": "2019-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Nebraska-Lincoln",
  "inst_street_address": "2200 VINE ST # 830861",
  "inst_street_address_2": "",
  "inst_city_name": "LINCOLN",
  "inst_state_code": "NE",
  "inst_state_name": "Nebraska",
  "inst_phone_num": "4024723171",
  "inst_zip_code": "685032427",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NE01",
  "org_lgl_bus_name": "BOARD OF REGENTS OF THE UNIVERSITY OF NEBRASKA",
  "org_prnt_uei_num": "",
  "org_uei_num": "HTQ6K6NJFHA6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Nebraska-Lincoln",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NE",
  "perf_st_name": "Nebraska",
  "perf_zip_code": "685880115",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NE01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 722804.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>This project </strong><strong>developed novel</strong><strong> systems and algorithms to allow Unmanned Aerial Systems (UAS) to </strong><strong>monitor critical rainforest ecosystems from </strong><strong>the air, leading to significant </strong><strong>improvements in spatial and temporal coverage of carbon-water data</strong><strong>. </strong><strong>The increased data resolution allowed demonstration of previously unobserved patterns of carbon-water uptake differences in old growth rainforest compared to new growth monoculture or commodity crop areas in the same geographic region. Samples such as those collected through this project are difficult to collect due to dangerous wildlife, potential risk to critical ecosystems, and difficulty of access. </strong><strong>While UASs have been used for </strong><strong>remote sensing in these environments</strong><strong>, this project addressed several fundamental challenges in robotics to allow the UAS to </strong><strong>collect samples safely</strong><strong>.</strong></p>\r\n<p>&nbsp;</p>\r\n<p><strong>The intellectual merit of this project spanned robotics, computer science, and </strong><strong>ecohydrology</strong><strong>. To </strong><strong>improve adoption of UAS by scientists, we developed a short (10 hour) training program which demonstrated a minimum level of proficiency in operation, allowed us to probe user mental model development to suggest indicators of proficiency without necessitating operation, and better understand novice interactions to system failures</strong><strong>. We </strong><strong>also extended prior work in drone gesture capabilities to overcome challenges from multiple viewing angles, viewing distances, and visual noise in the background</strong><strong>. In addition, we developed </strong><strong>monocular depth estimation algorithms to allow the onboard camera to estimate altitude at the edge, overcoming limitations in prior datasets and algorithms</strong><strong>. We </strong><strong>also developed novel mechanisms and controllers to allow close interactions with the environment (facilitated by the new vision algorithms) to collect both leaf and soil samples as complementary datapoints for the aerial carbon-water cycle measurements</strong><strong>.&nbsp;</strong></p>\r\n<p>&nbsp;</p>\r\n<p><strong>The broader impact of this project has benefited a range of organizations and stakeholders by providing complementary technologies that fill a gap in </strong><strong>scientific application of drone technologies. </strong><strong>We evaluated and demonstrated the technologies developed with </strong><strong>scientists</strong><strong> </strong><strong>over three field campaigns spanning hundreds of flights in Costa Rica, </strong><strong>and </strong><strong>hosted training</strong><strong> workshops </strong><strong>at</strong><strong> conferences</strong><strong> to interface with additional scientists</strong><strong>. </strong><strong>Additional impacts include training over 20 undergraduate students on the challenges and opportunities in field robotics, getting to see their projects collect data in field environments, and fourteen graduate students across three institutions many of whom have graduated and moved into industry and faculty positions across the United States.</strong></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 04/25/2025<br>\nModified by: Brittany&nbsp;A&nbsp;Duncan</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/1925368/1925368_10639902_1745554753776_IMG_7232--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2025/1925368/1925368_10639902_1745554753776_IMG_7232--rgov-800width.jpg\" title=\"UAS for Carbon-Water Monitoring in Costa Rican Rainforest\"><img src=\"/por/images/Reports/POR/2025/1925368/1925368_10639902_1745554753776_IMG_7232--rgov-66x44.jpg\" alt=\"UAS for Carbon-Water Monitoring in Costa Rican Rainforest\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Flight of University of Nebraska UAS for carbon-water monitoring at the Texas A&M Soltis Center in Costa Rica.</div>\n<div class=\"imageCredit\">Carrick Detweiler</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Brittany&nbsp;A&nbsp;Duncan\n<div class=\"imageTitle\">UAS for Carbon-Water Monitoring in Costa Rican Rainforest</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1925368/1925368_10639902_1745555010894_IMG_7778--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2025/1925368/1925368_10639902_1745555010894_IMG_7778--rgov-800width.jpg\" title=\"First Successful Leaf Sample at Soltis\"><img src=\"/por/images/Reports/POR/2025/1925368/1925368_10639902_1745555010894_IMG_7778--rgov-66x44.jpg\" alt=\"First Successful Leaf Sample at Soltis\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">First successful leaf sample at Texas A&M Soltis Center by University of Nebraska UAS.</div>\n<div class=\"imageCredit\">Carrick Detweiler</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Brittany&nbsp;A&nbsp;Duncan\n<div class=\"imageTitle\">First Successful Leaf Sample at Soltis</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1925368/1925368_10639902_1745554903965_IMG_7368--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2025/1925368/1925368_10639902_1745554903965_IMG_7368--rgov-800width.jpg\" title=\"UAS Sampling Leaves at Soltis Center\"><img src=\"/por/images/Reports/POR/2025/1925368/1925368_10639902_1745554903965_IMG_7368--rgov-66x44.jpg\" alt=\"UAS Sampling Leaves at Soltis Center\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">UAS from University of Nebraska sampling leaves at the Texas A&M Soltis Center.</div>\n<div class=\"imageCredit\">Carrick Detweiler</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Brittany&nbsp;A&nbsp;Duncan\n<div class=\"imageTitle\">UAS Sampling Leaves at Soltis Center</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project developed novel systems and algorithms to allow Unmanned Aerial Systems (UAS) to monitor critical rainforest ecosystems from the air, leading to significant improvements in spatial and temporal coverage of carbon-water data. The increased data resolution allowed demonstration of previously unobserved patterns of carbon-water uptake differences in old growth rainforest compared to new growth monoculture or commodity crop areas in the same geographic region. Samples such as those collected through this project are difficult to collect due to dangerous wildlife, potential risk to critical ecosystems, and difficulty of access. While UASs have been used for remote sensing in these environments, this project addressed several fundamental challenges in robotics to allow the UAS to collect samples safely.\r\n\n\n\r\n\n\nThe intellectual merit of this project spanned robotics, computer science, and ecohydrology. To improve adoption of UAS by scientists, we developed a short (10 hour) training program which demonstrated a minimum level of proficiency in operation, allowed us to probe user mental model development to suggest indicators of proficiency without necessitating operation, and better understand novice interactions to system failures. We also extended prior work in drone gesture capabilities to overcome challenges from multiple viewing angles, viewing distances, and visual noise in the background. In addition, we developed monocular depth estimation algorithms to allow the onboard camera to estimate altitude at the edge, overcoming limitations in prior datasets and algorithms. We also developed novel mechanisms and controllers to allow close interactions with the environment (facilitated by the new vision algorithms) to collect both leaf and soil samples as complementary datapoints for the aerial carbon-water cycle measurements.\r\n\n\n\r\n\n\nThe broader impact of this project has benefited a range of organizations and stakeholders by providing complementary technologies that fill a gap in scientific application of drone technologies. We evaluated and demonstrated the technologies developed with scientists over three field campaigns spanning hundreds of flights in Costa Rica, and hosted training workshops at conferences to interface with additional scientists. Additional impacts include training over 20 undergraduate students on the challenges and opportunities in field robotics, getting to see their projects collect data in field environments, and fourteen graduate students across three institutions many of whom have graduated and moved into industry and faculty positions across the United States.\r\n\n\n\t\t\t\t\tLast Modified: 04/25/2025\n\n\t\t\t\t\tSubmitted by: BrittanyADuncan\n"
 }
}