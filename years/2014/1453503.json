{
 "awd_id": "1453503",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: EAGER: Prototype of an Image-Based Ecological Information System (IBEIS)",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 126592.0,
 "awd_amount": 164092.0,
 "awd_min_amd_letter_date": "2014-08-27",
 "awd_max_amd_letter_date": "2016-02-22",
 "awd_abstract_narration": "Images are rapidly becoming the most abundant, widely available, and cheapest source of information about the natural world. Images taken by field scientists, tourists, and incidental photographers, and gathered from camera traps and autonomous vehicles provide rich data with the promise of addressing big ecological questions at high resolution and at fine-grained scale. Realizing this potential requires building a large autonomous computational system that starts from image collections and progresses all the way to answering ecological queries, such as population sizes, species distributions and interactions, and movement patterns. The system must have methods of extracting the relevant ecological information from the images and of integrating with other ecological data sources, with minimal human interaction, using state-of-the art information management, computer vision, and data analytics technologies. Such a system will advance computer systems and simultaneously enable ecology to develop as a science of connections across spatial, temporal, and biological scales, as well as provide data- and scientifically-grounded support for ecological decisions. \r\n\r\nThis work aims to build a prototype of an Image-Based Ecological Information Software System (IBEIS) that relies on a proliferation of images collected daily on a single facility from many different sources, both human and automatic, to determine both the species as well as recognition of distinct individuals. The system will allow for tracking location and movement while providing a data management system that will allow scientists to better understand, and at finer granularity, behaviors and motivations. The system will include: (1) an infrastructure and a mechanism for collecting images from tourists and other sources; (2) a (cloud) infrastructure and a data management system for storing, accessing, and manipulating the images and the derived data; (3) computer vision techniques for extracting information from the images about the identity of individual units, as well as techniques for combining that information with other relevant data to derive information about meaningful ecological units; and (4) statistical techniques and query structures to support ecological queries of the data, such as population sizes and dynamics, movement history and home ranges, and species interactions. \r\n\r\nThis work will advance computer systems including information management, computer vision, and data analytics technologies, all the while increasing public engagement in science and ecology.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Charles",
   "pi_last_name": "Stewart",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Charles V Stewart",
   "pi_email_addr": "stewart@cs.rpi.edu",
   "nsf_id": "000307751",
   "pi_start_date": "2014-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rensselaer Polytechnic Institute",
  "inst_street_address": "110 8TH ST",
  "inst_street_address_2": "",
  "inst_city_name": "TROY",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5182766000",
  "inst_zip_code": "121803590",
  "inst_country_name": "United States",
  "cong_dist_code": "20",
  "st_cong_dist_code": "NY20",
  "org_lgl_bus_name": "RENSSELAER POLYTECHNIC INSTITUTE",
  "org_prnt_uei_num": "",
  "org_uei_num": "U5WBFKEBLMX3"
 },
 "perf_inst": {
  "perf_inst_name": "Rensselaer Polytechnic Institute",
  "perf_str_addr": "110 8th Street",
  "perf_city_name": "Troy",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "121803522",
  "perf_ctry_code": "US",
  "perf_cong_dist": "20",
  "perf_st_cong_dist": "NY20",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1714",
   "pgm_ref_txt": "SPECIAL PROJECTS - CISE"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 126592.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 21500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-f668c09f-d0bc-0ee1-2812-4237d87beccd\"> </span></p>\n<p dir=\"ltr\"><span>According to a July 2017 study in the Proceedings of the National Academy of Sciences, a &ldquo;sixth mass extinction&rdquo; is underway, a trend signalled by widespread vertebrate losses that &ldquo;will have negative cascading consequences on ecosystem functioning and services vital to sustaining civilization.&rdquo; &nbsp;This study represents a growing awareness in the wildlife research community that more rapid assessment, response, and review are needed to understand and counter this decline. Unfortunately, t</span><span>he collection and management of wildlife data remains a largely ad hoc and academic exercise focused on moving small data sets into local, custom population studies for &ldquo;one-off&rdquo; analyses without long-term data curation or collaboration across borders and regions. Arriving at a critical mass of data for population analysis can take years (especially for rare or endangered species). Long required observation periods and manual data processing (e.g., matching photos &ldquo;by eye&rdquo;) can create multi-year lags between study initialization and scientific results, as well as create conclusions too coarse or slow for effective and optimizable conservation action. This limits the scope, scale, repeatability, continuity, and return-on-investment of the studies as they face the limits of their home-grown tools and IT capabilities. </span><span>Wildlife researchers lack a common yet customizable platform for collaboration and often don&rsquo;t have the technical experience to take advantage of advanced computing tools from the fields computer vision, machine learning and artificial intelligence.</span></p>\n<p dir=\"ltr\"><span>This NSF project took an important step toward solving this problem by developing a prototype of the Wildbook system that produces animal population analyses based on the ability to automatically identify individual animals and follow them across many images. &nbsp;These images, taken at different times and locations, may be </span><span>collected by scientists, field technicians, and the general public, or they may be </span><span>gathered through social media. Automatic identification is based on a pipeline of methods developed during this project to find the animals in the images, determine their species, and either recognize them individually if they have been seen before or determine that they are new, previously unseen animals. &nbsp;&nbsp;Recognition may be based on unique striped or spot patterns in the animals&rsquo; skin or fur, on their wrinkles, or on the outlines of their dorsal fins or flukes. This project developed a series of algorithms.</span></p>\n<p dir=\"ltr\"><span>The individual animals identities extract from each image, when put together with the image location and time the image was taken, become information about </span><span>who</span><span> the animals are, </span><span>where</span><span> they are, and </span><span>when</span><span> they were seen. &nbsp;This who/when/where information is stored in the Wildbook data management system that can be queried by scientists, by conservation managers, and in many cases by the general public to study many questions about the animals and the populations they are a part of, including how many animals there are, what are the age demographics, how the animals are behaving and who they are associating with, how they are using the land, and how are they responding to human and environmental pressures?</span></p>\n<p dir=\"ltr\"><span>This project also developed software and guidelines to support large-scale citizen science events, and we tested these at the Great Zebra and Giraffe Count in Nairobi National Park (NNP) in March 2015 and the Great Grevy&rsquo;s Rally &nbsp;(GGR) in an area throughout northern Kenya in January 2016.  The first was a prototype event to study the plains zebra and Masai giraffe populations in NNP and evaluate their long-term viability.  This involved over 150 volunteer photographers over two days, producing over 10,000 images, and a population estimates of 2,307 +/- 366 plain zebras and 119 +/- 48 Masai giraffes. The two-day GGR event involved over 45 cars, and 350 photographers, driving over 10,000 square miles, and covering the same ground on both days. Over 1900 Grevy&rsquo;s zebras were uniquely identified. &nbsp;Estimating the population size from resighting animals over two days produced a census estimate of 2350 individuals with confidence intervals of +/- 93.  This accuracy has led policy makers and Kenyan county governors to see for the first time that this iconic species is at risk.  Given that we were also able to show that the proportion of infants and juveniles has risen to a level where the population can sustain itself, the governors are committed to investing the time and money to change people&rsquo;s behavior to further remove threats to the Grevy&rsquo;s zebras&rsquo; existence.</span></p>\n<p dir=\"ltr\"><span>The demonstrated success of the prototype Wildbook system offers great hope for the development of a future Wildbook product that can be used by scientists to analyze the behavior of animals over time and space, at scales ranging from individuals, to groups, to herds and even to entire populations. &nbsp;The resulting data will allow conservation managers to make timely, data-driven plans and decisions in their efforts to combat the effects of the sixth great mass extinction.</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/05/2018<br>\n\t\t\t\t\tModified by: Charles&nbsp;V&nbsp;Stewart</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nAccording to a July 2017 study in the Proceedings of the National Academy of Sciences, a \"sixth mass extinction\" is underway, a trend signalled by widespread vertebrate losses that \"will have negative cascading consequences on ecosystem functioning and services vital to sustaining civilization.\"  This study represents a growing awareness in the wildlife research community that more rapid assessment, response, and review are needed to understand and counter this decline. Unfortunately, the collection and management of wildlife data remains a largely ad hoc and academic exercise focused on moving small data sets into local, custom population studies for \"one-off\" analyses without long-term data curation or collaboration across borders and regions. Arriving at a critical mass of data for population analysis can take years (especially for rare or endangered species). Long required observation periods and manual data processing (e.g., matching photos \"by eye\") can create multi-year lags between study initialization and scientific results, as well as create conclusions too coarse or slow for effective and optimizable conservation action. This limits the scope, scale, repeatability, continuity, and return-on-investment of the studies as they face the limits of their home-grown tools and IT capabilities. Wildlife researchers lack a common yet customizable platform for collaboration and often don?t have the technical experience to take advantage of advanced computing tools from the fields computer vision, machine learning and artificial intelligence.\nThis NSF project took an important step toward solving this problem by developing a prototype of the Wildbook system that produces animal population analyses based on the ability to automatically identify individual animals and follow them across many images.  These images, taken at different times and locations, may be collected by scientists, field technicians, and the general public, or they may be gathered through social media. Automatic identification is based on a pipeline of methods developed during this project to find the animals in the images, determine their species, and either recognize them individually if they have been seen before or determine that they are new, previously unseen animals.   Recognition may be based on unique striped or spot patterns in the animals? skin or fur, on their wrinkles, or on the outlines of their dorsal fins or flukes. This project developed a series of algorithms.\nThe individual animals identities extract from each image, when put together with the image location and time the image was taken, become information about who the animals are, where they are, and when they were seen.  This who/when/where information is stored in the Wildbook data management system that can be queried by scientists, by conservation managers, and in many cases by the general public to study many questions about the animals and the populations they are a part of, including how many animals there are, what are the age demographics, how the animals are behaving and who they are associating with, how they are using the land, and how are they responding to human and environmental pressures?\nThis project also developed software and guidelines to support large-scale citizen science events, and we tested these at the Great Zebra and Giraffe Count in Nairobi National Park (NNP) in March 2015 and the Great Grevy?s Rally  (GGR) in an area throughout northern Kenya in January 2016.  The first was a prototype event to study the plains zebra and Masai giraffe populations in NNP and evaluate their long-term viability.  This involved over 150 volunteer photographers over two days, producing over 10,000 images, and a population estimates of 2,307 +/- 366 plain zebras and 119 +/- 48 Masai giraffes. The two-day GGR event involved over 45 cars, and 350 photographers, driving over 10,000 square miles, and covering the same ground on both days. Over 1900 Grevy?s zebras were uniquely identified.  Estimating the population size from resighting animals over two days produced a census estimate of 2350 individuals with confidence intervals of +/- 93.  This accuracy has led policy makers and Kenyan county governors to see for the first time that this iconic species is at risk.  Given that we were also able to show that the proportion of infants and juveniles has risen to a level where the population can sustain itself, the governors are committed to investing the time and money to change people?s behavior to further remove threats to the Grevy?s zebras? existence.\nThe demonstrated success of the prototype Wildbook system offers great hope for the development of a future Wildbook product that can be used by scientists to analyze the behavior of animals over time and space, at scales ranging from individuals, to groups, to herds and even to entire populations.  The resulting data will allow conservation managers to make timely, data-driven plans and decisions in their efforts to combat the effects of the sixth great mass extinction.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 06/05/2018\n\n\t\t\t\t\tSubmitted by: Charles V Stewart"
 }
}