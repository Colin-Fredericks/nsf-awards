{
 "awd_id": "1350670",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER: Sketching Algorithms for Massive Data",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2014-05-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 512818.0,
 "awd_amount": 512818.0,
 "awd_min_amd_letter_date": "2014-01-22",
 "awd_max_amd_letter_date": "2014-01-22",
 "awd_abstract_narration": "A sketch of a massive dataset is some compression of it which still allows for answering, sometimes only approximately, some pre-specified types of queries about the data. For many query types of interest, it turns out that sketches exist that provide exponentially smaller compressions. This feature has made sketching methods pervasive in coping with recent trends in data explosion to reduce both communication bandwidth and required storage capacity. Sketching has also been applied to obtain algorithmic speedup for certain high-dimensional problems such as nearest neighbor search, clustering, and low-rank approximation for large matrices, as well as to enable more efficient signal acquisition in a field that has come to be known as compressed sensing. This research plans to further the state of knowledge concerning three intertwined subtopics of sketching: streaming, dimensionality reduction, and compressed sensing.\r\n\r\nA fundamental question the PI will investigate is whether one can design sketches that are moderately \"universal\", in that the same sketch can be used to answer many different types of queries. Dimensionality reduction has been successfully used to circumvent the so-called \"curse of dimensionality\" in many problems, where the best known algorithms have running times that scale poorly with dimension. This research plans to study the tradeoffs between approximation quality, number of vectors in the data set, and target dimension, and to close gaps between known upper and lower bounds.  Compressed sensing has found applications in a diverse range of areas, such as magnetic resonance imaging and photography. This research plans to investigate more efficient compressed sensing schemes for providing various types of approximate recovery guarantees.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jelani",
   "pi_last_name": "Nelson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jelani Nelson",
   "pi_email_addr": "minilek@berkeley.edu",
   "nsf_id": "000644981",
   "pi_start_date": "2014-01-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University",
  "perf_str_addr": "33 Oxford Street, Maxwell Dworki",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021382933",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 512818.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project developed foundational results in the areas of dimensionality reduction, streaming algorithms, and compressed sensing. On the front of dimensionality reduction, it was shown that the 'random projection' method of Johnson and Lindenstrauss is optimal in the strongest sense possible; there are sets of high-dimensional data points that cannot be mapped in any way to much lower dimension than what the JL method guarantees while still preserving distances well.</p>\n<p>&nbsp;</p>\n<p>Regarding streaming and other algorithms for massive datasets, new algorithms and impossibliity results were shown for connectivity questions in graphs. For the 'heavy hitters' problem of finding frequent items in a stream of data (e.g. \"what word was recently frequently searched for on some search engine?\"), new algorithms were developed with better memory/speed guarantees, as well as fast such algorithms satisfying privacy constraints (e.g. if Apple wants to know \"what geolocations have our iPhone users been frequenting recently?\" in aggregate, without any individual user having their own privacy compromised).</p>\n<p>&nbsp;</p>\n<p>In the field of compressed sensing, a new lower bound was shown on the number of measurements one needs to take of a high-dimensional signal to obtain the type of measurement scheme known to be sufficient for good approximate recovery. Such questions are connected to, e.g. magnetic resonance imaging.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/27/2019<br>\n\t\t\t\t\tModified by: Jelani&nbsp;Nelson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project developed foundational results in the areas of dimensionality reduction, streaming algorithms, and compressed sensing. On the front of dimensionality reduction, it was shown that the 'random projection' method of Johnson and Lindenstrauss is optimal in the strongest sense possible; there are sets of high-dimensional data points that cannot be mapped in any way to much lower dimension than what the JL method guarantees while still preserving distances well.\n\n \n\nRegarding streaming and other algorithms for massive datasets, new algorithms and impossibliity results were shown for connectivity questions in graphs. For the 'heavy hitters' problem of finding frequent items in a stream of data (e.g. \"what word was recently frequently searched for on some search engine?\"), new algorithms were developed with better memory/speed guarantees, as well as fast such algorithms satisfying privacy constraints (e.g. if Apple wants to know \"what geolocations have our iPhone users been frequenting recently?\" in aggregate, without any individual user having their own privacy compromised).\n\n \n\nIn the field of compressed sensing, a new lower bound was shown on the number of measurements one needs to take of a high-dimensional signal to obtain the type of measurement scheme known to be sufficient for good approximate recovery. Such questions are connected to, e.g. magnetic resonance imaging. \n\n\t\t\t\t\tLast Modified: 11/27/2019\n\n\t\t\t\t\tSubmitted by: Jelani Nelson"
 }
}