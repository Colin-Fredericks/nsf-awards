{
 "awd_id": "1422224",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: The Role of Gesture in Word Learning",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Chalandra Bryant",
 "awd_eff_date": "2014-08-01",
 "awd_exp_date": "2018-07-31",
 "tot_intn_awd_amt": 339338.0,
 "awd_amount": 339338.0,
 "awd_min_amd_letter_date": "2014-07-24",
 "awd_max_amd_letter_date": "2014-07-24",
 "awd_abstract_narration": "When people talk, they gesture. Gesturing helps speakers to organize their thoughts and words, and also helps listeners to more fully understand the information being conveyed.  Instructional techniques have begun to incorporate use of speech-accompanying gestures to facilitate learning. However, it is unclear how and why gestures aid learning.  The goal of this research is to investigate whether, and if so how, observing gestures differs from observing actions performed on objects in facilitating young children's word learning. The research employs  both behavioral measures of learning and brain imaging techniques to address this issue. The research will ultimately help to optimize learning environments.\r\n\r\nThis project addresses the hypothesis that gesture's facilitative effect on learning is distinct from effects of observing actions because gestures are more abstract forms of representation, in that they highlight the important components of an action without being tied to a specific learning context. The project explores the ways in which gestures versus actions facilitate word learning in 4 to 5 year old children. The research goals include  (1) comparing the impact that learning a word through gesture, compared to action, has on the word's learning trajectory; (2) evaluating how well words are generalized and retained over time after they are learned through gesture or action; (3) exploring the neural mechanisms underlying each of these types of learning experiences. The results will clarify whether and how gesture promotes learning that goes beyond the particular, and extends over time.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Susan",
   "pi_last_name": "Goldin-Meadow",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Susan J Goldin-Meadow",
   "pi_email_addr": "sgm@uchicago.edu",
   "nsf_id": "000198358",
   "pi_start_date": "2014-07-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "The University of Chicago",
  "perf_str_addr": "5848 S. University Ave.",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606375418",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169800",
   "pgm_ele_name": "DS -Developmental Sciences"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1698",
   "pgm_ref_txt": "DS-Developmental Sciences"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "7298",
   "pgm_ref_txt": "COLLABORATIVE RESEARCH"
  },
  {
   "pgm_ref_code": "7956",
   "pgm_ref_txt": "SBE Interdisciplinary Research"
  },
  {
   "pgm_ref_code": "8605",
   "pgm_ref_txt": "SBE 2020"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 339338.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>When people talk, they gesture. Research has shown that gesture can play a role in changing how we think about the world and, as a result, contribute to learning. Gesture's facilitative effect on learning could stem from the fact that it itself is an action. But because gesture can highlight the important components of an action without being tied to a specific learning context, it has the potential to go beyond action in its effect on how we think about information and how we learn. Through a series of studies, our project explored the ways in which gesture's relation to action (its similarity and distinctiveness) facilitates word learning, and had 3 goals. (1) To compare the impact that learning a word through gesture, compared to action, has on the word's learning trajectory; (2) to determine how well words are generalized and retained over time after they are learned through gesture or action; (3) to explore the neural mechanisms underlying each of these types of learning experiences. The over-arching goal was to use both behavioral and neuroimaging measures to compare and contrast the effects that gesture vs. action has on learning, on the assumption that using both measures will lead to a deeper understanding of the mechanisms underlying these effects than using either measure alone.</p>\n<p>Through our work, we show that children are able to successfully learn novel words through action or gesture experience, whether these movements are performed by the child or experimenter. However, they learn words more quickly when <em>doing </em>movements than <em>seeing </em>movements, and also learn more quickly through action than gesture (Wakefield, Hall, James, &amp; Goldin-Meadow, 2016). But, we found that even though action may be an easier route by which to initially learn words, children are significantly more likely to <em>generalize</em> these words if they learned through gesture, rather than action (Wakefield, Hall, James, &amp; Goldin-Meadow, 2018). This finding suggests that children may struggle to learn verbs flexibly, at least in part, because action directly ties a child's experience with a novel word to a particular object, which encourages the learning to be object-focused. Our results corroborate work in other domains (mathematics), suggesting that gesture provides a teaching tool that facilitates more flexible learning than does action. But why do gesture and action show some similarities and some differences in how they help children learn? To answer this question, we used neuroimaging to understand how the networks children recruit when thinking about words learned through action versus gesture are similar and different. Analyses suggest that although children recruit some of the same regions to process verbs whether learned through action or gesture (such as regions associated with processing verbs related to motor movements), there are important differences as well. In particular, learning through gesture and action appears to shape how children pay attention to objects, and the importance they give to those objects in a learning context. This difference (detectable in neuroimaging) may contribute to the behavioral differences that emerge when children learn through action versus gesture. Together, our findings give new insight into how action and gesture affect children's understanding of verbs.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/29/2018<br>\n\t\t\t\t\tModified by: Susan&nbsp;J&nbsp;Goldin-Meadow</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhen people talk, they gesture. Research has shown that gesture can play a role in changing how we think about the world and, as a result, contribute to learning. Gesture's facilitative effect on learning could stem from the fact that it itself is an action. But because gesture can highlight the important components of an action without being tied to a specific learning context, it has the potential to go beyond action in its effect on how we think about information and how we learn. Through a series of studies, our project explored the ways in which gesture's relation to action (its similarity and distinctiveness) facilitates word learning, and had 3 goals. (1) To compare the impact that learning a word through gesture, compared to action, has on the word's learning trajectory; (2) to determine how well words are generalized and retained over time after they are learned through gesture or action; (3) to explore the neural mechanisms underlying each of these types of learning experiences. The over-arching goal was to use both behavioral and neuroimaging measures to compare and contrast the effects that gesture vs. action has on learning, on the assumption that using both measures will lead to a deeper understanding of the mechanisms underlying these effects than using either measure alone.\n\nThrough our work, we show that children are able to successfully learn novel words through action or gesture experience, whether these movements are performed by the child or experimenter. However, they learn words more quickly when doing movements than seeing movements, and also learn more quickly through action than gesture (Wakefield, Hall, James, &amp; Goldin-Meadow, 2016). But, we found that even though action may be an easier route by which to initially learn words, children are significantly more likely to generalize these words if they learned through gesture, rather than action (Wakefield, Hall, James, &amp; Goldin-Meadow, 2018). This finding suggests that children may struggle to learn verbs flexibly, at least in part, because action directly ties a child's experience with a novel word to a particular object, which encourages the learning to be object-focused. Our results corroborate work in other domains (mathematics), suggesting that gesture provides a teaching tool that facilitates more flexible learning than does action. But why do gesture and action show some similarities and some differences in how they help children learn? To answer this question, we used neuroimaging to understand how the networks children recruit when thinking about words learned through action versus gesture are similar and different. Analyses suggest that although children recruit some of the same regions to process verbs whether learned through action or gesture (such as regions associated with processing verbs related to motor movements), there are important differences as well. In particular, learning through gesture and action appears to shape how children pay attention to objects, and the importance they give to those objects in a learning context. This difference (detectable in neuroimaging) may contribute to the behavioral differences that emerge when children learn through action versus gesture. Together, our findings give new insight into how action and gesture affect children's understanding of verbs.\n\n\t\t\t\t\tLast Modified: 10/29/2018\n\n\t\t\t\t\tSubmitted by: Susan J Goldin-Meadow"
 }
}