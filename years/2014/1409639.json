{
 "awd_id": "1409639",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Medium: Adapting to Affect in Multimodal Dialogue-Rich Interaction with Middle School Students",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2014-08-01",
 "awd_exp_date": "2018-07-31",
 "tot_intn_awd_amt": 1184073.0,
 "awd_amount": 1200073.0,
 "awd_min_amd_letter_date": "2014-08-01",
 "awd_max_amd_letter_date": "2016-06-23",
 "awd_abstract_narration": "Affect, or emotion, profoundly shapes human experience. It influences how we perform tasks, how we build relationships with one another, and how we navigate the complexities of our daily lives. Affect is shaped and influenced by communication with other humans, experiences with the natural world, and interactions with machines. Affect plays a particularly prominent role in learning. During learning, a recurring subset of the broad range of human emotions such as confusion, frustration, boredom, anxiety, engagement, surprise, and delight appear regularly. Different emotions are best responded to in different ways. For example, task-based feedback and guidance is a helpful response to emotions of confusion and frustration, while empathetic feedback is more helpful for emotions of anger or excitement. Prior research has not answered the question of how affective adaptation can maximize the benefit to students as they interact with interactive computer-based learning environments. And yet the investigators on this project are now well positioned to address a central, unanswered question of how learning environments can adaptively respond to students' affect to create the most effective, engaging learning experiences while simultaneously promoting improved attitudes toward learning.\r\n\r\nThe project will provide important societal benefits by generating theoretical and practical advances across multiple disciplines. The project will lead to a deeper understanding of affect-rich learning; a set of broadly applicable affect adaptation principles; and a computational model of affective adaptation and dialogue that will be incorporated into a learning environment for science learning. The resulting affect-modeling technologies can serve as a foundation for the next generation of adaptive educational software that will promote learning through affect-rich adaptation. This will be broadly useful throughout education. The project will address issues of diversity by partnering with the highly diverse Dunn Middle School and Harnett Central Middle School, and through ongoing collaboration with the STARS Alliance for Broadening Participation in Computing. To ensure societal impact, the results will be disseminated to the public through middle school outreach programs, and to the scientific community through publication at scientific venues.\r\n\r\nThe three major scientific goals of the project are to: (1) Capture rich multimodal data of students' affective experiences while interacting with a fully instrumented learning environment with spoken dialogue. Observational studies will be conducted by having middle school students interact with an existing learning environment for science education called \"Crystal Island.\" Crystal Island was developed by the investigators on this project and has already been used by thousands of students in middle school classrooms to learn microbiology, but it does not currently support rich multimodal interaction or natural language dialogue. Crystal Island will be fully instrumented to collect rich, multimodal data including speech, facial expression, gaze, posture, skin conductance response, heart rate, and problem-solving actions. (2) Design, develop, and refine an affect-understanding model that integrates students' natural language, nonverbal behavior, physiological response, and task-action phenomena into a rich multi-dimensional stream of affective data. By utilizing this data collected from the observational studies, an affect-understanding model will be constructed using machine learned including hidden Markov modeling. This will be the first affect-understanding model for learning environments that integrates the full complement of affect signals of spoken language (including prosody, syntax, and semantics), nonverbal behavior (including gaze and posture), physiological data (including skin conductance response and heart rate), and task actions (including navigation and manipulation actions in the learning environment). (3) Design, develop, and refine an integrated affect and dialogue management model that adaptively responds to students' affective states in the course of their learning interactions. By utilizing the learning-interaction data collected in the observational studies, a Partially Observable Markov Decision Process (POMDP) affect adaptation policy will be acquired with reinforcement learning, integrating affect and dialogue management. The resulting adaptation policy will govern both when and how the system responds to students' affect as they solve problems. The computer-based mentor will provide problem-solving advice, encouragement, empathetic responses, and other support as is needed to improve the educational experience and outcome.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Lester",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "James C Lester",
   "pi_email_addr": "lester@csc.ncsu.edu",
   "nsf_id": "000365555",
   "pi_start_date": "2014-08-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Wiebe",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Eric N Wiebe",
   "pi_email_addr": "eric_wiebe@ncsu.edu",
   "nsf_id": "000303175",
   "pi_start_date": "2014-08-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Bradford",
   "pi_last_name": "Mott",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Bradford W Mott",
   "pi_email_addr": "bwmott@ncsu.edu",
   "nsf_id": "000534787",
   "pi_start_date": "2014-08-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Kristy",
   "pi_last_name": "Boyer",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Kristy E Boyer",
   "pi_email_addr": "keboyer@cise.ufl.edu",
   "nsf_id": "000591513",
   "pi_start_date": "2014-08-01",
   "pi_end_date": "2016-02-24"
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "CAMPUS BOX 7514",
  "perf_city_name": "Raleigh",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276958206",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 489443.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 357793.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 352837.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Affective adaptation holds great promise for promoting productive affective states that improve the learning experience. With a decade of research on affective computing that has yielded foundational results on affect and learning, we are now well positioned to address a central question in the field: How can we design learning environments that adaptively respond to students' affect to create the most effective, engaging learning experiences while simultaneously promoting improved attitudes toward learning? To answer this question, the research team designed, developed, and investigated affect adaptation models within a dialogue-rich multimodal learning environment for middle school students. The project investigated an affect adaptation framework that was designed to promote significant improvement in students' learning, problem solving, engagement, and attitudes toward learning. The research, which utilized a learning environment featuring a natural language dialogue interface that enabled students to express themselves freely during learning, was pursued via three central thrusts:<br /><br />1. Capturing rich multimodal data of students' affective experiences while interacting with the fully instrumented learning environment. We conducted a series of observational data collection studies with middle school students interacting with a learning environment for science education. The learning environment, Crystal Island, was designed in our laboratory and has been used by thousands of students in middle school classrooms to learn microbiology. Crystal Island, which did not previously support rich multimodal interaction or natural language dialogue, was instrumented to collect rich, multimodal data including text, facial expression, gaze, posture, skin conductance response, and problem-solving task actions. These naturalistic affect datasets contributed to a formulation of a semantically rich account of students' affective experiences during learning.<br /><br />2. Designing, developing, and iteratively refining an affect understanding model that integrates students' natural language, nonverbal behavior, physiological response, and task action phenomena. By utilizing rich multimodal affective data collected from the observational studies, we created machine-learned models of affect during game-based learning. Refined in an iterative process, these models constitute the first affect understanding models for learning environments that integrate the full complement of affect signals provided by natural language, nonverbal behavior, physiological data, and task actions. By jointly modeling affect streams alongside fine-grained measurements of task progress and natural language interpretation, the models support adaptation that is responsive to students' affective states (e.g., happiness, delight, frustration, boredom).<br /><br />3. Designing, developing, and iteratively refining an integrated affect and dialogue management model that adaptively responds to students' affective states in the course of their learning interactions. By utilizing interaction data collected in the observational studies, affect models and dialogue policies were acquired by combining machine learning techniques and a user-centered design approach to create and refine the affect-rich dialogue interactions. With the goal of creating effective, engaging learning experiences for each student, the resulting multimodal affect models can govern both when and how the system responds to students' affect as they solve problems. At runtime, the affect adaptation model can issue specifications for generating multimodal responses for a virtual learning companion who interacts with the student in the learning environment.&nbsp;<br /><br />The project made significant contributions to both human-computer interaction (multimodal affective computing) and advanced learning technologies (adaptive learning environments). Through a broad range of empirical findings on students' interactions with affect-informed learning environments, the project has yielded advances through four complementary sets of results. First, it saw the development of a dialogue act prediction model of humans' interactions with virtual learning companions. The model uses long short-term memory networks and conditional random fields to predict dialogue acts based on multimodal data streams, including facial action units and skin conductance response. Second, the project produced findings on gender effects with virtual learning companions, including results showing that girls were significantly more engaged than boys, particularly with a narrative-integrated agent, while boys reported higher mental demand with that agent. Notably, even when controlling for digital game experience and prior knowledge, the gender effects held. Third, the project produced a goal recognition model that automatically recognizes students' goals in problem-solving interactions in game-based learning environments. Utilizing a long short-term memory framework, the model outperformed baseline models, both with respect to predictive accuracy and the ability to make early predictions. This result holds significant promise for creating more effective dialogue management policies. Fourth, the project saw the creation of a model for utilizing affect indicators such as facial expression to predict student mental demand and student engagement in game-based learning environments. The findings show that automatically detected facial expressions such as those associated with joy, disgust, sadness, and surprise are significant predictors of students' self-reported engagement and mental demand at the conclusion of learning interactions. The results suggest that it is possible to create affect-based predictive student models that can enable proactively tailored problem-solving scenarios by anticipating student mental demand and engagement.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2018<br>\n\t\t\t\t\tModified by: James&nbsp;C&nbsp;Lester</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAffective adaptation holds great promise for promoting productive affective states that improve the learning experience. With a decade of research on affective computing that has yielded foundational results on affect and learning, we are now well positioned to address a central question in the field: How can we design learning environments that adaptively respond to students' affect to create the most effective, engaging learning experiences while simultaneously promoting improved attitudes toward learning? To answer this question, the research team designed, developed, and investigated affect adaptation models within a dialogue-rich multimodal learning environment for middle school students. The project investigated an affect adaptation framework that was designed to promote significant improvement in students' learning, problem solving, engagement, and attitudes toward learning. The research, which utilized a learning environment featuring a natural language dialogue interface that enabled students to express themselves freely during learning, was pursued via three central thrusts:\n\n1. Capturing rich multimodal data of students' affective experiences while interacting with the fully instrumented learning environment. We conducted a series of observational data collection studies with middle school students interacting with a learning environment for science education. The learning environment, Crystal Island, was designed in our laboratory and has been used by thousands of students in middle school classrooms to learn microbiology. Crystal Island, which did not previously support rich multimodal interaction or natural language dialogue, was instrumented to collect rich, multimodal data including text, facial expression, gaze, posture, skin conductance response, and problem-solving task actions. These naturalistic affect datasets contributed to a formulation of a semantically rich account of students' affective experiences during learning.\n\n2. Designing, developing, and iteratively refining an affect understanding model that integrates students' natural language, nonverbal behavior, physiological response, and task action phenomena. By utilizing rich multimodal affective data collected from the observational studies, we created machine-learned models of affect during game-based learning. Refined in an iterative process, these models constitute the first affect understanding models for learning environments that integrate the full complement of affect signals provided by natural language, nonverbal behavior, physiological data, and task actions. By jointly modeling affect streams alongside fine-grained measurements of task progress and natural language interpretation, the models support adaptation that is responsive to students' affective states (e.g., happiness, delight, frustration, boredom).\n\n3. Designing, developing, and iteratively refining an integrated affect and dialogue management model that adaptively responds to students' affective states in the course of their learning interactions. By utilizing interaction data collected in the observational studies, affect models and dialogue policies were acquired by combining machine learning techniques and a user-centered design approach to create and refine the affect-rich dialogue interactions. With the goal of creating effective, engaging learning experiences for each student, the resulting multimodal affect models can govern both when and how the system responds to students' affect as they solve problems. At runtime, the affect adaptation model can issue specifications for generating multimodal responses for a virtual learning companion who interacts with the student in the learning environment. \n\nThe project made significant contributions to both human-computer interaction (multimodal affective computing) and advanced learning technologies (adaptive learning environments). Through a broad range of empirical findings on students' interactions with affect-informed learning environments, the project has yielded advances through four complementary sets of results. First, it saw the development of a dialogue act prediction model of humans' interactions with virtual learning companions. The model uses long short-term memory networks and conditional random fields to predict dialogue acts based on multimodal data streams, including facial action units and skin conductance response. Second, the project produced findings on gender effects with virtual learning companions, including results showing that girls were significantly more engaged than boys, particularly with a narrative-integrated agent, while boys reported higher mental demand with that agent. Notably, even when controlling for digital game experience and prior knowledge, the gender effects held. Third, the project produced a goal recognition model that automatically recognizes students' goals in problem-solving interactions in game-based learning environments. Utilizing a long short-term memory framework, the model outperformed baseline models, both with respect to predictive accuracy and the ability to make early predictions. This result holds significant promise for creating more effective dialogue management policies. Fourth, the project saw the creation of a model for utilizing affect indicators such as facial expression to predict student mental demand and student engagement in game-based learning environments. The findings show that automatically detected facial expressions such as those associated with joy, disgust, sadness, and surprise are significant predictors of students' self-reported engagement and mental demand at the conclusion of learning interactions. The results suggest that it is possible to create affect-based predictive student models that can enable proactively tailored problem-solving scenarios by anticipating student mental demand and engagement.\n\n\t\t\t\t\tLast Modified: 11/30/2018\n\n\t\t\t\t\tSubmitted by: James C Lester"
 }
}