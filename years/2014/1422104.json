{
 "awd_id": "1422104",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Integrating Imaging Detectors",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Cozzens",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 297101.0,
 "awd_amount": 297101.0,
 "awd_min_amd_letter_date": "2014-06-18",
 "awd_max_amd_letter_date": "2014-06-18",
 "awd_abstract_narration": "The ubiquity of integrating detectors in scientific and engineering applications suggests that a variety of real-world measurements are high-dimensional count data. Count data, however, is usually an indirect means of measuring the underlying vector-valued signal of interest - whether it be light intensity in a pixel sensor, energy in charged gas particles, or energy in inelastic scattering detected by scanning electron microscope - that cannot be measured directly. The two dominating sources of heteroskedastic noise in an integrating detector are the Poisson process that describes the stochasticity in photon arrival and the Fano noise stemming from particle-to-electron conversion. As such, the estimation of this signal from the observed count data therefore plays a prominent role across diverse applications. \r\n\r\nThis research is comprised of four investigations. First is the classical task of estimating the raw signal value from the Poisson count data, for which an optimal wavelet transform-based denoising method is being developed. Second, the noise model is extended from the cannonical Poisson corruption to Fano noise - a challenging task since the distribution of Fano noise is not known exactly. Third is a study aimed at objectively valuating the visual information loss in noisy image sensor data, where the problems of image signal recovery and visual image quality are reasoned jointly. Fourth is an effort to make precise the trade offs between integrating detector resolution and noise, where the goal is to quantify the discernibility of information in signal rather than the raw signal values.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Keigo",
   "pi_last_name": "Hirakawa",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Keigo Hirakawa",
   "pi_email_addr": "khirakawa1@udayton.edu",
   "nsf_id": "000541314",
   "pi_start_date": "2014-06-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Dayton",
  "inst_street_address": "300 COLLEGE PARK AVE",
  "inst_street_address_2": "",
  "inst_city_name": "DAYTON",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "9372293232",
  "inst_zip_code": "454690001",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "OH10",
  "org_lgl_bus_name": "UNIVERSITY OF DAYTON",
  "org_prnt_uei_num": "V62NC51F7YV1",
  "org_uei_num": "V62NC51F7YV1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Dayton",
  "perf_str_addr": "300 College Park",
  "perf_city_name": "Dayton",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "454690104",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "OH10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 297101.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The ubiquity of integrating detectors in scientific and engineering applications suggests that a variety of real-world measurements are high-dimensional count data. Count data, however, is usually an indirect means of measuring the underlying vector-valued signal of interest&mdash;whether it be light intensity in a pixel sensor, energy in charged gas particles, or energy in inelastic scattering detected by scanning electron microscope&mdash;that cannot be measured directly. The two dominating sources of heteroskedastic noise in an integrating detector are the Poisson process that describes the stochasticity in photon arrival and the Fano noise stemming from particle-to-electron conversion.&nbsp; Hence the estimation of this signal from the observed count data plays a prominent role across diverse applications.</p>\n<p>&nbsp;</p>\n<p>We proposed novel approaches to making inferences on high-dimensional count data to recover the underlying signal or intensity. In our first study, we leveraged the fact that Skellam variability accurately models the heteroscedastic &ldquo;noise&rdquo; of count data in Haar wavelet domain, and developed an unbiased estimate of risk for Skellam mean estimator---a proxy for pixel domain denoising. We also solved for a shrinkage operator which minimizes this risk of signal recovery---the end result is a wavelet-based denoising technique that is &ldquo;best&rdquo; according to the predefined risk.</p>\n<p>&nbsp;</p>\n<p>In our second study, we carefully characterized the sensor noise distribution, and determined that additive Gaussian and Poisson variabilities do not entirely account for the uncertainties of the sensor data. Image denoising schemes developed with a mismatched noise model underperformed when using an actual image sensor. We proposed Poisson likelihood mixture model, aimed at adjusting the Poisson denoising schemes for real sensor outputs. The end result is a superior denoising performance for real-world detectors.</p>\n<p>&nbsp;</p>\n<p>In our third study, we leveraged multiscale multiplicative innovation (MMI) transform that describes the uncertainty of the Haar frame transformed Poisson-Fano count data. MMI also corresponds to the notion of &ldquo;contrast&rdquo;---an image feature that better matches the ways in which human vision interprets images. We developed an optimal recovery method for MMI coefficients, hence restoring the contrast of the underlying image.</p>\n<p>&nbsp;</p>\n<p>In our fourth study, we developed a novel technique for predicting the perceptual quality of the denoised images. In denoising, full reference image quality assessment (FRIQA) metric that quantifies the perceptual similarity (or dissimilarity) between the pristine image we are trying to recover (ideal reference) and the denoised image (target image) is preferred over no reference image quality assessment (NRIQA) that disregards the ideal reference we are trying to recover.&nbsp; However, ideal reference in FRIQA is not available in practice. We proposed a notion of corrupted reference image quality assessment (CRIQA) that predicts the FRIQA scores very accurately.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2017<br>\n\t\t\t\t\tModified by: Keigo&nbsp;Hirakawa</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1422104/1422104_10311480_1512009073386_Contrast--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1422104/1422104_10311480_1512009073386_Contrast--rgov-800width.jpg\" title=\"Optimal Denoising Of Image Contrast\"><img src=\"/por/images/Reports/POR/2017/1422104/1422104_10311480_1512009073386_Contrast--rgov-66x44.jpg\" alt=\"Optimal Denoising Of Image Contrast\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Optimal Denoising of Image Contrast</div>\n<div class=\"imageCredit\">University of Dayton</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">Keigo&nbsp;Hirakawa</div>\n<div class=\"imageTitle\">Optimal Denoising Of Image Contrast</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe ubiquity of integrating detectors in scientific and engineering applications suggests that a variety of real-world measurements are high-dimensional count data. Count data, however, is usually an indirect means of measuring the underlying vector-valued signal of interest&mdash;whether it be light intensity in a pixel sensor, energy in charged gas particles, or energy in inelastic scattering detected by scanning electron microscope&mdash;that cannot be measured directly. The two dominating sources of heteroskedastic noise in an integrating detector are the Poisson process that describes the stochasticity in photon arrival and the Fano noise stemming from particle-to-electron conversion.  Hence the estimation of this signal from the observed count data plays a prominent role across diverse applications.\n\n \n\nWe proposed novel approaches to making inferences on high-dimensional count data to recover the underlying signal or intensity. In our first study, we leveraged the fact that Skellam variability accurately models the heteroscedastic \"noise\" of count data in Haar wavelet domain, and developed an unbiased estimate of risk for Skellam mean estimator---a proxy for pixel domain denoising. We also solved for a shrinkage operator which minimizes this risk of signal recovery---the end result is a wavelet-based denoising technique that is \"best\" according to the predefined risk.\n\n \n\nIn our second study, we carefully characterized the sensor noise distribution, and determined that additive Gaussian and Poisson variabilities do not entirely account for the uncertainties of the sensor data. Image denoising schemes developed with a mismatched noise model underperformed when using an actual image sensor. We proposed Poisson likelihood mixture model, aimed at adjusting the Poisson denoising schemes for real sensor outputs. The end result is a superior denoising performance for real-world detectors.\n\n \n\nIn our third study, we leveraged multiscale multiplicative innovation (MMI) transform that describes the uncertainty of the Haar frame transformed Poisson-Fano count data. MMI also corresponds to the notion of \"contrast\"---an image feature that better matches the ways in which human vision interprets images. We developed an optimal recovery method for MMI coefficients, hence restoring the contrast of the underlying image.\n\n \n\nIn our fourth study, we developed a novel technique for predicting the perceptual quality of the denoised images. In denoising, full reference image quality assessment (FRIQA) metric that quantifies the perceptual similarity (or dissimilarity) between the pristine image we are trying to recover (ideal reference) and the denoised image (target image) is preferred over no reference image quality assessment (NRIQA) that disregards the ideal reference we are trying to recover.  However, ideal reference in FRIQA is not available in practice. We proposed a notion of corrupted reference image quality assessment (CRIQA) that predicts the FRIQA scores very accurately. \n\n \n\n\t\t\t\t\tLast Modified: 11/29/2017\n\n\t\t\t\t\tSubmitted by: Keigo Hirakawa"
 }
}