{
 "awd_id": "1461547",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Primitives and Policies for Complex Behavior in Human and Robotic Hands",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2014-07-01",
 "awd_exp_date": "2017-06-30",
 "tot_intn_awd_amt": 238863.0,
 "awd_amount": 238863.0,
 "awd_min_amd_letter_date": "2014-09-04",
 "awd_max_amd_letter_date": "2014-09-04",
 "awd_abstract_narration": "Each human fingertip has approximately 2000 tactile sensors.  Stimulation of these sensors triggers reactive grip responses that are mediated by the spine.  In comparison to the dexterous capabilities of the human hand, robotic manipulation capabilities in unstructured environments are crude.  When controlled by a human operator, robotic manipulators are further limited by restricted information flow (command and sensing) at the human-machine interface.  All human-machine systems, from telesurgery robots to neuroprostheses, must address the critical issue of communication delays which can range, depending upon the distance between the human and the machine, from less than a second to hours.  For artificial manipulation, even delays of one second can result in adverse events such as increased bleeding from an open incision or increased frustration and eventual disuse of an advanced prosthesis.  Taking a cue from biology, autonomous low-level reflexes that detect stimuli and implement a corrective response in robotic hands without a human in the loop could buy time for communication, information processing, and decision-making in human-machine systems.   A long-term research objective of the PI is to advance robotic manipulation with grip reflex algorithm primitives, artificial tactile sensors, and generalizable grasp policy algorithms inspired by the human hand.  In this project, she will focus on understanding what drives low-level reactive grip responses, how human-machine performance can benefit from the implementation of similar autonomous primitives, and what grasp policies can be learned by a robotic hand.  Contributions of this work will include characterization of the reactive grip responses in human hands, development of human-inspired grip reflex algorithm primitives and tactile sensors for robotic hands, and development of learning algorithms that autonomously extract general grasp policies for robotic hands.  Research outcomes will enhance our fundamental understanding of grasp primitives in human hands that provide a foundation for dexterous manipulation, and improve the functionality of robotic hands through grip reflex algorithm primitives and learning algorithms that extract grasp policies.\r\n\r\nBroader Impacts:  This research will transform artificial manipulation by enabling robotic grasp with dynamic control of adduction/abduction degrees-of-freedom and use of biomimetic tactile sensors, thereby revolutionizing robotic manipulators intended for unstructured, access-limited, or unsafe environments (including space, underwater, military, rescue, surgery, assistive, rehabilitative, and prosthetic) that require robustness in the face of uncertainty, control delays, or limited information flow at the human-machine interface.  In conjunction with her research the PI will work to engage students at an early age in the exploration of the rich field of robotics.  To that end, she will develop hands-on instructional modules for teaching elementary and middle school students about robotics using low-cost materials and deploy them locally for the benefit of students under-represented in science, technology, engineering, and mathematics fields.  She will also develop an interactive exhibit for a science museum on robotic hands deploy it locally for the benefit of school-aged children and the general public in the metropolitan Phoenix area.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Veronica",
   "pi_last_name": "Santos",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Veronica J Santos",
   "pi_email_addr": "vjsantos@ucla.edu",
   "nsf_id": "000521933",
   "pi_start_date": "2014-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900952000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 54577.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 87994.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 96292.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Intellectual Merit:&nbsp; </strong>The long-term research objective was to advance robotic manipulation with grip reflex algorithm primitives, artificial tactile sensors, and generalizable grasp policy algorithms inspired by the human hand. Research Goals: 1) Characterize reactive grip responses in human hands, 2) Develop human-inspired grip reflex algorithm primitives and tactile sensors for robotic hands, 3) Develop learning algorithms that autonomously extract general grasp policies for robotic hands.</p>\n<p><span style=\"text-decoration: underline;\">Toward Goal #1:</span> Researchers have shown that pulse-like increases in precision grip forces are elicited by unexpected translational perturbations of grasped objects. We showed similar grip responses to unexpected rotational perturbations induced by torques. The strength of the grip response scaled with the axis of rotation relative to the hand and slip conditions at the fingertips.</p>\n<p>We investigated individual digit contributions to a three-digit task in which an object was rotationally manipulated against gravity. Subjects poured fluid from containers having different shapes and center of mass locations. The thumb, index, and middle fingers acted in unison temporally, but contributed independently to grip forces and stabilizing moments during the dynamic, pouring task.</p>\n<p><span style=\"text-decoration: underline;\">Toward Goal #2:</span> Collaborating with an expert in microfluidics and soft lithography, we developed a flexible, capacitive microfluidic normal force sensor that can be conformally wrapped around curved surfaces. The sensor uses liquid metal-filled microfluidic channels to form capacitive plates and conductive interconnects that are not susceptible to cracking or fatigue.</p>\n<p>We developed a highly sensorized robot hand testbed called the &lsquo;BairClaw.&rsquo;&nbsp; A remote actuation system enables the modular control of tendon-driven hands. A proprioception system enables measurement of joint angles and tendon tensions while temperature, vibration, and skin deformation are provided by a commercially available, multimodal tactile sensor. Originally conceived for artificial grasp, manipulation, and haptic exploration, the anthropomorphic robot testbed could be used to study embodiment and neurorehabilitation of somatosensory disorders due to upper limb impairment or loss.</p>\n<p><span style=\"text-decoration: underline;\">Toward Goal #3:</span> Using a commercially available, deformable, multimodal tactile sensor, we developed an approach for the artificial haptic perception of salient geometric features such as edges, bumps, and pits. Human-inspired, haptic &lsquo;exploratory procedures&rsquo; were performed with the fingertip sensor. Support vector machines were used to develop offline models of geometric features by leveraging shape information encoded in asymmetric skin deformation.</p>\n<p>We developed an approach for real-time haptic perception and decision-making for a functional contour-following task: the closure of a ziplock bag. This task is challenging for robots because the bag is deformable, transparent, and visually occluded by fingertips. Collaborating with experts in reinforcement learning, we used a Contextual Multi-Armed Bandit algorithm to maximize cumulative rewards by balancing exploration versus exploitation of the state-action space in a finite time. This work emphasized the importance of developing reinforcement learning approaches that account for limited resources such as hardware life and researcher time.</p>\n<p><strong>Broader Impacts:</strong>&nbsp; Robotic manipulation in unstructured environments is crude compared to the dexterous capabilities of the human hand. While robotic solutions need not be anthropomorphic, human dexterity principles can be elucidated and used to inspire advances in robotics. Tactile sensors can be used to complement computer-vision based approaches and are indispensable when line-of-sight is unavailable. Artificial haptic perception can be used to advance semi-autonomous robots that support the high-level goals of human teleoperators. Human-machine systems ranging from neuroprostheses to wheelchair-mounted robot arms and robots for explosive ordnance disposal can benefit from such advances.</p>\n<p>This work conducted at Arizona State University and the University of California, Los Angeles has strengthened collaborations across countries, universities, disciplines, and between academia and industry. The project has produced seven journal articles, one book chapter, two conference proceedings articles, three doctoral dissertations, one Master&rsquo;s degree report, and one U.S. patent. Lab tours, exhibits, and elementary school visits have benefited hundreds of students (from preschoolers to graduate students), teachers, and members of the public. We developed hands-on instructional modules for teaching elementary school students about robotics using low-cost materials. Slides, videos, and activities for &lsquo;Robots Helping People&rsquo;-themed visits to elementary schools are provided at <a href=\"https://uclabiomechatronics.wordpress.com/outreach/\">https://uclabiomechatronics.wordpress.com/outreach/</a> for free use and adaptation. A graduate-level course on the &lsquo;Control of Robotic Systems&rsquo; was developed, which featured research supported by this grant.</p>\n<p>This project provided opportunities to educate the public on scientific approaches and the benefits of publicly funded research. Tactile sensor skin work was featured at the interactive &lsquo;skin wall&rsquo; in a permanent exhibit at the Arizona Science Center. Work with motion capture, tactile sensors, and robots was featured in a &lsquo;biomechanics&rsquo; episode of an educational television show called &lsquo;STEM Journals&rsquo; hosted by Geoff Notkin. Our work was featured in Science News and PCMag articles, and video segments for PBS NewsHour hosted by Miles O&rsquo;Brien, Voice of America (bilingual), NSF Science Nation (with podcast), an NSF video celebrating robots that work with people, and an upcoming documentary/ visual art piece called &lsquo;NEO&rsquo; that addresses how technology and humanity may intertwine in the future.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/22/2017<br>\n\t\t\t\t\tModified by: Veronica&nbsp;J&nbsp;Santos</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115992869_Figure6--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115992869_Figure6--rgov-800width.jpg\" title=\"Artificial haptic perception, decision-making, and reinforcement learning\"><img src=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115992869_Figure6--rgov-66x44.jpg\" alt=\"Artificial haptic perception, decision-making, and reinforcement learning\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We developed a method for real-time haptic perception and decision-making for a functional contour-following task: closing a ziplock bag. Collaborating with reinforcement learning experts, a Contextual Multi-Armed Bandit policy was tested on: a) empty bag, and b,c) with cereal.</div>\n<div class=\"imageCredit\">Hellman, R.B., Tekin, C., van der Schaar, M., and Santos, V.J. ?Functional contour-following via haptic perception and reinforcement learning,? IEEE Trans on Haptics, 2017. In press</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Veronica&nbsp;J&nbsp;Santos</div>\n<div class=\"imageTitle\">Artificial haptic perception, decision-making, and reinforcement learning</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115455492_Figure2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115455492_Figure2--rgov-800width.jpg\" title=\"Digit coordination during a pouring task\"><img src=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115455492_Figure2--rgov-66x44.jpg\" alt=\"Digit coordination during a pouring task\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We investigated individual digit contributions to a three-digit task in which an object was rotationally manipulated against gravity. Subjects poured fluid from containers having different shapes and center of mass locations into a narrow-necked receptacle to the left of the container.</div>\n<div class=\"imageCredit\">Manis, R. and Santos, V.J. ?Independent digit contributions to rotational manipulation in a three-digit pouring task requiring dynamic stability,? Exp Brain Res 2015:233(7):2195?2204. doi:10.1007/s00221-015-4289-6.</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Veronica&nbsp;J&nbsp;Santos</div>\n<div class=\"imageTitle\">Digit coordination during a pouring task</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115565217_Figure3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115565217_Figure3--rgov-800width.jpg\" title=\"Tactile sensor skin for normal force\"><img src=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115565217_Figure3--rgov-66x44.jpg\" alt=\"Tactile sensor skin for normal force\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Collaborating with microfluidics experts, we developed a flexible, microfluidic normal force sensor that can be wrapped around curved surfaces. The sensor uses liquid metal-filled channels to form capacitive plates and conductive interconnects that are not susceptible to cracking or fatigue.</div>\n<div class=\"imageCredit\">Ponce Wong, R.D., Posner, J.D., and Santos, V.J., ?Flexible microfluidic normal force sensor skin for tactile feedback,? Sensors and Actuators A: Physical 2012:179:62-69. doi: 10.1016/j.sna.2012.03.023</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Veronica&nbsp;J&nbsp;Santos</div>\n<div class=\"imageTitle\">Tactile sensor skin for normal force</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115691351_Figure4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115691351_Figure4--rgov-800width.jpg\" title=\"'BairClaw' sensorized robot hand testbed\"><img src=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115691351_Figure4--rgov-66x44.jpg\" alt=\"'BairClaw' sensorized robot hand testbed\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We developed a highly sensorized robot hand testbed called the ?BairClaw.? (A) Tap-and-hold experiment against an instrumented plate. (B) Joint angles, (C) tactile sensor internal fluid pressure and microvibration, (D) tactile sensor skin deformation, and (E) normal contact force data are shown.</div>\n<div class=\"imageCredit\">Hellman, R.B., Chang, E., Tanner, J., Helms Tillery, S.I., and Santos, V.J., ?A robot hand testbed designed for enhancing embodiment and functional neurorehabilitation of body schema in subjects with upper limb impairment or loss.? Front Hum Neurosci 2015:9(26):1-10. doi: 10.3389/fnhum.2015.00026.</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Veronica&nbsp;J&nbsp;Santos</div>\n<div class=\"imageTitle\">'BairClaw' sensorized robot hand testbed</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115852546_Figure5--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115852546_Figure5--rgov-800width.jpg\" title=\"Artificial haptic perception of edges\"><img src=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115852546_Figure5--rgov-66x44.jpg\" alt=\"Artificial haptic perception of edges\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Using a commercially available tactile sensor, we developed a method for the haptic perception of edges. Human-inspired, ?exploratory procedures? (EPs) were performed. (a) A constant fingertip contact angle was used. (b) static contact, (c, d) distal to proximal strokes, (e) radial to ulnar stroke.</div>\n<div class=\"imageCredit\">Ponce Wong, R.D., Hellman, R.B., and Santos, V.J. ?Spatial asymmetry in tactile sensor skin deformation aids perception of edge orientation during haptic exploration,? IEEE Trans on Haptics, Special Issue on ?Haptics in Rehabilitation and Neural Engineering,? 2014:7(2):191?202.</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Veronica&nbsp;J&nbsp;Santos</div>\n<div class=\"imageTitle\">Artificial haptic perception of edges</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115309255_Figure1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115309255_Figure1--rgov-800width.jpg\" title=\"Precision grip responses to unexpected rotational perturbations\"><img src=\"/por/images/Reports/POR/2017/1461547/1461547_10018363_1506115309255_Figure1--rgov-66x44.jpg\" alt=\"Precision grip responses to unexpected rotational perturbations\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We studied pulse-like increases in precision grip forces elicited by unexpected rotational perturbations induced by torques. (A) Radial view of the subject?s hand (B) View from the perspective of the subject of the object.</div>\n<div class=\"imageCredit\">De Gregorio, M. and Santos, V.J. ?Precision grip responses to unexpected rotational perturbations scale with axis of rotation,? J Biomechanics 2013:46(6):1098-1103.</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Veronica&nbsp;J&nbsp;Santos</div>\n<div class=\"imageTitle\">Precision grip responses to unexpected rotational perturbations</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nIntellectual Merit:  The long-term research objective was to advance robotic manipulation with grip reflex algorithm primitives, artificial tactile sensors, and generalizable grasp policy algorithms inspired by the human hand. Research Goals: 1) Characterize reactive grip responses in human hands, 2) Develop human-inspired grip reflex algorithm primitives and tactile sensors for robotic hands, 3) Develop learning algorithms that autonomously extract general grasp policies for robotic hands.\n\nToward Goal #1: Researchers have shown that pulse-like increases in precision grip forces are elicited by unexpected translational perturbations of grasped objects. We showed similar grip responses to unexpected rotational perturbations induced by torques. The strength of the grip response scaled with the axis of rotation relative to the hand and slip conditions at the fingertips.\n\nWe investigated individual digit contributions to a three-digit task in which an object was rotationally manipulated against gravity. Subjects poured fluid from containers having different shapes and center of mass locations. The thumb, index, and middle fingers acted in unison temporally, but contributed independently to grip forces and stabilizing moments during the dynamic, pouring task.\n\nToward Goal #2: Collaborating with an expert in microfluidics and soft lithography, we developed a flexible, capacitive microfluidic normal force sensor that can be conformally wrapped around curved surfaces. The sensor uses liquid metal-filled microfluidic channels to form capacitive plates and conductive interconnects that are not susceptible to cracking or fatigue.\n\nWe developed a highly sensorized robot hand testbed called the ?BairClaw.?  A remote actuation system enables the modular control of tendon-driven hands. A proprioception system enables measurement of joint angles and tendon tensions while temperature, vibration, and skin deformation are provided by a commercially available, multimodal tactile sensor. Originally conceived for artificial grasp, manipulation, and haptic exploration, the anthropomorphic robot testbed could be used to study embodiment and neurorehabilitation of somatosensory disorders due to upper limb impairment or loss.\n\nToward Goal #3: Using a commercially available, deformable, multimodal tactile sensor, we developed an approach for the artificial haptic perception of salient geometric features such as edges, bumps, and pits. Human-inspired, haptic ?exploratory procedures? were performed with the fingertip sensor. Support vector machines were used to develop offline models of geometric features by leveraging shape information encoded in asymmetric skin deformation.\n\nWe developed an approach for real-time haptic perception and decision-making for a functional contour-following task: the closure of a ziplock bag. This task is challenging for robots because the bag is deformable, transparent, and visually occluded by fingertips. Collaborating with experts in reinforcement learning, we used a Contextual Multi-Armed Bandit algorithm to maximize cumulative rewards by balancing exploration versus exploitation of the state-action space in a finite time. This work emphasized the importance of developing reinforcement learning approaches that account for limited resources such as hardware life and researcher time.\n\nBroader Impacts:  Robotic manipulation in unstructured environments is crude compared to the dexterous capabilities of the human hand. While robotic solutions need not be anthropomorphic, human dexterity principles can be elucidated and used to inspire advances in robotics. Tactile sensors can be used to complement computer-vision based approaches and are indispensable when line-of-sight is unavailable. Artificial haptic perception can be used to advance semi-autonomous robots that support the high-level goals of human teleoperators. Human-machine systems ranging from neuroprostheses to wheelchair-mounted robot arms and robots for explosive ordnance disposal can benefit from such advances.\n\nThis work conducted at Arizona State University and the University of California, Los Angeles has strengthened collaborations across countries, universities, disciplines, and between academia and industry. The project has produced seven journal articles, one book chapter, two conference proceedings articles, three doctoral dissertations, one Master?s degree report, and one U.S. patent. Lab tours, exhibits, and elementary school visits have benefited hundreds of students (from preschoolers to graduate students), teachers, and members of the public. We developed hands-on instructional modules for teaching elementary school students about robotics using low-cost materials. Slides, videos, and activities for ?Robots Helping People?-themed visits to elementary schools are provided at https://uclabiomechatronics.wordpress.com/outreach/ for free use and adaptation. A graduate-level course on the ?Control of Robotic Systems? was developed, which featured research supported by this grant.\n\nThis project provided opportunities to educate the public on scientific approaches and the benefits of publicly funded research. Tactile sensor skin work was featured at the interactive ?skin wall? in a permanent exhibit at the Arizona Science Center. Work with motion capture, tactile sensors, and robots was featured in a ?biomechanics? episode of an educational television show called ?STEM Journals? hosted by Geoff Notkin. Our work was featured in Science News and PCMag articles, and video segments for PBS NewsHour hosted by Miles O?Brien, Voice of America (bilingual), NSF Science Nation (with podcast), an NSF video celebrating robots that work with people, and an upcoming documentary/ visual art piece called ?NEO? that addresses how technology and humanity may intertwine in the future.\n\n\t\t\t\t\tLast Modified: 09/22/2017\n\n\t\t\t\t\tSubmitted by: Veronica J Santos"
 }
}