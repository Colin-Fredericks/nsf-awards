{
 "awd_id": "1408944",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC: Medium: Collaborative: Broker Leads for Privacy-Preserving Discovery in Health Information Exchange",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2014-10-01",
 "awd_exp_date": "2019-09-30",
 "tot_intn_awd_amt": 360000.0,
 "awd_amount": 360000.0,
 "awd_min_amd_letter_date": "2014-08-26",
 "awd_max_amd_letter_date": "2014-08-26",
 "awd_abstract_narration": "Support for research on distributed data sets is challenged by stakeholder requirements limiting sharing. Researchers need early stage access to determine whether data sets are likely to contain the data they need. The Broker Leads project is developing privacy-enhancing technologies adapted to this discovery phase of data-driven research. Its approach is inspired by health information exchanges that are based on a broker system where data are held by healthcare providers and collected in distributed queries managed by the broker. Such systems have potential to support public health and biomedical research.  The project targets \"similar patient queries\" where the query is a patient medical record and the response is information about similar patients. Such queries have value for many applications, including developing cohorts for finding institutions for further discussions about joint research.\r\n\r\nBroker Leads uses the concept of a \"lead\" in which data holders provide representative collections of non-identifiable real or synthetic data meeting strong privacy guarantees, e.g., differential privacy.  Even though such data may be unsuitable for clinical decision making and scientific discovery due to the transformations done for privacy protection, they guide a user of a broker lead system to the data sets very likely to be useful to addressing a given similar patient query. These data sets can then be used with other privacy-protecting strategies, such as secure multiparty computation or restrictive data use agreements ensuring adequate data protection.  In addition to providing practical and well-analyzed strategies for early stages of research on healthcare data, this project will provide new insights into practical issues with privacy technology in end-to-end applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Carl",
   "pi_last_name": "Gunter",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Carl A Gunter",
   "pi_email_addr": "cgunter@uiuc.edu",
   "nsf_id": "000361179",
   "pi_start_date": "2014-08-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "ChengXiang",
   "pi_last_name": "Zhai",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "ChengXiang Zhai",
   "pi_email_addr": "czhai@illinois.edu",
   "nsf_id": "000215468",
   "pi_start_date": "2014-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618207473",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 360000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-4261093a-7fff-7e5d-cab1-bcd5ec24d449\"> </span></p>\n<p dir=\"ltr\"><span>This project contributed models and techniques to protect the privacy of shared data. Many of the case studies were based on leads generated by brokers from biomedical data, but the results are applicable to all types of data and covered a wide range of techniques.</span></p>\n<p dir=\"ltr\"><span>A key area of investigation was the ability to support early stages of research, which are often characterized by a need for exploration in which researchers do not know the details of the hypotheses they will find most interesting. The project developed techniques for measuring the privacy protections of synthetic data that can be studied in a flexible manner while still being mathematically assured of protecting the privacy of the parties on which the synthetic data was based. One new technique developed in the project used &ldquo;seedbased&rdquo; synthetic generation that creates synthetic data based on a mixture of traits of subjects. Another new technique concerned how to measure membership privacy based on established privacy models and machine learning testing strategies.</span></p>\n<p dir=\"ltr\"><span>Machine learning is a fundamental component of modern data analytics on biomedical data.&nbsp; The project carried out the first investigation of distributed, collaborative learning from the data privacy perspective.&nbsp; This multi-year study showed that (a) modern machine learning models may reveal the sensitive data used to train them, and (b) this leakage is exacerbated in collaborative learning scenarios.&nbsp; The project also demonstrated that these potential privacy violations are rooted in how today&rsquo;s machine learning frameworks and pipelines operate on data, and proposed new methods for mitigating threats to individual privacy.&nbsp; These results open the road to secure, privacy-preserving, distributed machine learning.</span></p>\n<p dir=\"ltr\"><span>The project also studied various techniques to support broker lead based privacy-preserving data sharing and applied such protection to various biomedical data. More specifically, the project developed the techniques for secure similar patient query, using approximation to simplify complicated protecting tasks. The project demonstrated the weaknesses in the beacon-based sharing and built up more effective protection from leads by adding noise to achieve differential privacy in response to the queries from the data user. This more effective protection is shown to work on different kinds of biomedical data, not only human genomes but also DNA methylation data. It was also shown that the side effects introduced by the noise could be addressed using trusted execution environments, which offer an efficient and secure channel for evaluating the utility of data before sharing.&nbsp; The project demonstrated the great potential for lead-based secure data sharing by leveraging different confidential computing technologies. These results will continue to foster the community of biomedical data protection through the high-impact iDASH genome privacy competition.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/30/2019<br>\n\t\t\t\t\tModified by: Carl&nbsp;Gunter</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThis project contributed models and techniques to protect the privacy of shared data. Many of the case studies were based on leads generated by brokers from biomedical data, but the results are applicable to all types of data and covered a wide range of techniques.\nA key area of investigation was the ability to support early stages of research, which are often characterized by a need for exploration in which researchers do not know the details of the hypotheses they will find most interesting. The project developed techniques for measuring the privacy protections of synthetic data that can be studied in a flexible manner while still being mathematically assured of protecting the privacy of the parties on which the synthetic data was based. One new technique developed in the project used \"seedbased\" synthetic generation that creates synthetic data based on a mixture of traits of subjects. Another new technique concerned how to measure membership privacy based on established privacy models and machine learning testing strategies.\nMachine learning is a fundamental component of modern data analytics on biomedical data.  The project carried out the first investigation of distributed, collaborative learning from the data privacy perspective.  This multi-year study showed that (a) modern machine learning models may reveal the sensitive data used to train them, and (b) this leakage is exacerbated in collaborative learning scenarios.  The project also demonstrated that these potential privacy violations are rooted in how today\u2019s machine learning frameworks and pipelines operate on data, and proposed new methods for mitigating threats to individual privacy.  These results open the road to secure, privacy-preserving, distributed machine learning.\nThe project also studied various techniques to support broker lead based privacy-preserving data sharing and applied such protection to various biomedical data. More specifically, the project developed the techniques for secure similar patient query, using approximation to simplify complicated protecting tasks. The project demonstrated the weaknesses in the beacon-based sharing and built up more effective protection from leads by adding noise to achieve differential privacy in response to the queries from the data user. This more effective protection is shown to work on different kinds of biomedical data, not only human genomes but also DNA methylation data. It was also shown that the side effects introduced by the noise could be addressed using trusted execution environments, which offer an efficient and secure channel for evaluating the utility of data before sharing.  The project demonstrated the great potential for lead-based secure data sharing by leveraging different confidential computing technologies. These results will continue to foster the community of biomedical data protection through the high-impact iDASH genome privacy competition. \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/30/2019\n\n\t\t\t\t\tSubmitted by: Carl Gunter"
 }
}