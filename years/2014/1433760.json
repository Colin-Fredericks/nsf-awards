{
 "awd_id": "1433760",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Development and Application of a Multilevel Evaluation Procedure for Examining State and School Educational Contexts with NAEP",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Finbarr Sloane",
 "awd_eff_date": "2014-01-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 339916.0,
 "awd_amount": 339916.0,
 "awd_min_amd_letter_date": "2014-03-19",
 "awd_max_amd_letter_date": "2014-03-19",
 "awd_abstract_narration": "The National Assessment of Educational Progress (NAEP) mathematics exam renders aggregate scores based on the assumption that each test item measures a single underlying proficiency (e.g., an area of mathematics). Prior work of the investigators suggests that there may be more information that can be mined from the NAEP exam that may be used for policymaking at the instructional level, such as policymaking for schools). \r\n\r\nUsing the NAEP item response data, the investigators propose a two-fold goal: (1) to understand school and state influences on student mathematics achievement, and (2) to improve measurement and statistical analysis techniques for the evaluation of mathematics education.  A considerable portion of the research will focus on the creation of measurement and statistical techniques (goal two) that will be demonstrated in the advancement of goal one analyses.\r\n\r\nThe investigators will use Item Response Theory (IRT) and Hierarchical Linear Modeling (HLM) analyses to produce their own statistically-based classification of NAEP items that, when contrasted with the existing (official) NAEP conceptually-based classification system, should reveal information that can be attributed at the school and state levels simultaneously.  This will allow the researchers to use the data and their (error) variance--both in IRT and HLM--to examine how schools differ on any number of preselected, relevant policy characteristics.  To do this, however, requires that the investigators build new statistical tools and will require that this very premise be tested in the form of a hypothesis.  \r\n\r\nThus, the results of this feasibility study will determine if a test designed for assessing national (only) progress can be used to explain the relative mathematical strengths of schools. This approach could be used to evaluate policy initiatives focused at the school level using NAEP and potentially other large-scale assessment data.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gregory",
   "pi_last_name": "Camilli",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gregory Camilli",
   "pi_email_addr": "greg.camilli@gmail.com",
   "nsf_id": "000415665",
   "pi_start_date": "2014-03-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "089011183",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "762500",
   "pgm_ele_name": "REAL"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9177",
   "pgm_ref_txt": "ELEMENTARY/SECONDARY EDUCATION"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0411",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001112DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 339916.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>My work to date supported by NSF funding has focused on extracting more information from two large-scale assessments: the National Assessment of Educational Progress (NAEP), and the Trends in Mathematics and Science Study (TIMSS). These assessments consist of different types of test items in format, content, and complexity. Both assessment programs provide subscores to provide diagnostic information at the state or country level. However, these subscores are too highly correlated to discriminate between different mathematical proficiencies. My research is focused on producing more distinct subscores for these assessments in order to study educational policies regarding mathematics achievement. Subscores reported by sponsoring organizations are highly correlated at  r&nbsp;&gt;&nbsp;.9, while correlations between the empirical factors I develop  in my work are typically modest at about r = .5.</p>\n<p>This work has led to the discovery of multifactor solutions to the 2009 and 2011 NAEP mathematics data at grades four and eight. A two-factor solution is readily interpretable across 2009-2011. For both factors, state-level correlations are high across years. Multifactor solutions were also found for the TIMSS 2007 and 2011 mathematics assessments: three factors emerged at fourth grade (number competencies, algebra and fractions) and two at eighth grade. Obtaining factor solutions allows the examination of the empirical structure of test items, as opposed to theoretical structure, and computation of subscores consistent with those empirical structures. Factor analysis approaches demonstrate there are subscores that can be reported in a way to better reflect upon educational practices.</p>\n<p>Countries participating in TIMSS had profiles of achievement that provide clues to the effects of educational systems. For instance, in 2007 Singapore was ranked first in terms of fractions but former Russian republics were ranked highly in terms of algebra. For the fourth grade NAEP assessment, two highly interpretable factors were found on the NAEP assessment that generalized across 2009-2011. The first general factor was defined by cognitive behaviors best described as geometric or graphical reasoning containing a strong element of visual interpretation. This factor is highly correlated with the NAEP total score. This demonstrates that high NAEP scores reflect complex and abstract competency in mathematics. &nbsp;The second factor was defined by items requiring multidigit operations. States that scored highly on this factor appear to have stressed (at least until 2011) more traditional mathematics.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2016<br>\n\t\t\t\t\tModified by: Gregory&nbsp;Camilli</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMy work to date supported by NSF funding has focused on extracting more information from two large-scale assessments: the National Assessment of Educational Progress (NAEP), and the Trends in Mathematics and Science Study (TIMSS). These assessments consist of different types of test items in format, content, and complexity. Both assessment programs provide subscores to provide diagnostic information at the state or country level. However, these subscores are too highly correlated to discriminate between different mathematical proficiencies. My research is focused on producing more distinct subscores for these assessments in order to study educational policies regarding mathematics achievement. Subscores reported by sponsoring organizations are highly correlated at  r &gt; .9, while correlations between the empirical factors I develop  in my work are typically modest at about r = .5.\n\nThis work has led to the discovery of multifactor solutions to the 2009 and 2011 NAEP mathematics data at grades four and eight. A two-factor solution is readily interpretable across 2009-2011. For both factors, state-level correlations are high across years. Multifactor solutions were also found for the TIMSS 2007 and 2011 mathematics assessments: three factors emerged at fourth grade (number competencies, algebra and fractions) and two at eighth grade. Obtaining factor solutions allows the examination of the empirical structure of test items, as opposed to theoretical structure, and computation of subscores consistent with those empirical structures. Factor analysis approaches demonstrate there are subscores that can be reported in a way to better reflect upon educational practices.\n\nCountries participating in TIMSS had profiles of achievement that provide clues to the effects of educational systems. For instance, in 2007 Singapore was ranked first in terms of fractions but former Russian republics were ranked highly in terms of algebra. For the fourth grade NAEP assessment, two highly interpretable factors were found on the NAEP assessment that generalized across 2009-2011. The first general factor was defined by cognitive behaviors best described as geometric or graphical reasoning containing a strong element of visual interpretation. This factor is highly correlated with the NAEP total score. This demonstrates that high NAEP scores reflect complex and abstract competency in mathematics.  The second factor was defined by items requiring multidigit operations. States that scored highly on this factor appear to have stressed (at least until 2011) more traditional mathematics.\n\n\t\t\t\t\tLast Modified: 11/29/2016\n\n\t\t\t\t\tSubmitted by: Gregory Camilli"
 }
}