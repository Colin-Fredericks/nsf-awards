{
 "awd_id": "1447416",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: F: DKA: Usable Multiple Scale Big Data Analytics through Interactive Visualization",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 998912.0,
 "awd_amount": 998912.0,
 "awd_min_amd_letter_date": "2014-08-25",
 "awd_max_amd_letter_date": "2015-08-18",
 "awd_abstract_narration": "Gaining big insight from big data requires big analytics, which poses big usability problems.  Analyses of big data often rely on several computational and statistical models that operate on multiple levels of data scale to discover and characterize noteworthy patterns. The models work jointly or in sequence to filter, group, summarize, and visualize big data so that analysts may assess the data. As a simple example in big text analytics, massive text is first sampled for relevant or representative words, then further reduced by a complex form of modeling (e.g., topic modeling), then visualized by applying a dimension reduction algorithm. As the size of data increases, so does the number of models and, likewise, the need for human interaction in the analytical process. By interacting, humans include expert judgment into the analytical process, and efficiently explore and make sense of big data from varying perspectives. However, for a variety of reasons, interacting with any individual model is difficult, let alone a growing number of models.  Thus, current human-computer-interaction research is merged with complex statistical methods and fast computation to develop a usable, multi-model analytic framework for big data.  Wrapped in software, the framework will be accessible to both professional and student users alike; i.e., available to make new discoveries in current government and industrial big datasets, as well as, educate future analysts at the undergraduate and graduate levels given new teaching modules.  \r\n\r\nThe new analytic framework extends Visual-to-Parametric Interaction (V2PI) to Multi-scale V2PI (MV2PI). V2PI currently supports usable small-data analytics, and enables users to adjust model parameters by interacting directly with data in visualizations. That is, V2PI interprets visual interactions quantitatively to update underlying model parameters and produce new visualizations. MV2PI now links together several models that operate at multiple levels of data-scale in a unified interactive space. In MV2PI, small-scale data interactions in visualizations propagate to larger scale models (by inverting them and updating their parameters) and new visualizations are generated.  In the text analytics example, if users drag several data points together to hypothesize a cluster, the inverted dimension reduction model computes updated dimension weights, queries relevant new hits at the large scale, identifies changed topics, and updates the layout to show big-data support for the new cluster.  With MV2PI, users may interactively explore large-scale data and complex inter-relationships between models in real time, and in a usable fashion that directly supports their natural cognitive sensemaking process.  Development of MV2PI involves: (1) formulation of an explicitly stated framework ; (2) creation of new interactive models (e.g., Interactive K-means and Interactive Latent Dirichlet Allocation) that cover different levels of scale and support MV2PI model inversion; (3) implementation of computational methods to support high-performance, real-time model updates; and (4) evaluation of MV2PI software framework  for usability and effectiveness.  The project web site (http://www.apps.stat.vt.edu/bava/mv2pi.html) will include information on MV2PI development, access to software, datasets, educational materials, and publications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "North",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher L North",
   "pi_email_addr": "north@cs.vt.edu",
   "nsf_id": "000194960",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yong",
   "pi_last_name": "Cao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yong Cao",
   "pi_email_addr": "yongcao@vt.edu",
   "nsf_id": "000497125",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Leanna",
   "pi_last_name": "House",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Leanna L House",
   "pi_email_addr": "lhouse@vt.edu",
   "nsf_id": "000528517",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Scotland",
   "pi_last_name": "Leman",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Scotland C Leman",
   "pi_email_addr": "leman@vt.edu",
   "nsf_id": "000528899",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Polytechnic Institute and State University",
  "inst_street_address": "300 TURNER ST NW",
  "inst_street_address_2": "STE 4200",
  "inst_city_name": "BLACKSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "5402315281",
  "inst_zip_code": "240603359",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "VA09",
  "org_lgl_bus_name": "VIRGINIA POLYTECHNIC INSTITUTE & STATE UNIVERSITY",
  "org_prnt_uei_num": "X6KEFGLHSJX7",
  "org_uei_num": "QDE5UHE5XD16"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Polytechnic Institute and State University",
  "perf_str_addr": "",
  "perf_city_name": "Blacksburg",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "240610001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "VA09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 998912.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Challenges:&nbsp;</strong>Gaining big insight from big data requires big analytics, which poses big usability problems. Analyses of big data often rely on multiple computational models that operate at multiple levels of scale to discover and characterize valuable hidden insights within the data. The models filter, group, summarize, and visualize big data so that analysts may assess the data. As an example of big text analytics, large text collections are often first sampled for relevant words, then further clustered by modeling topics, then dimension reduced to visualize a set of 2D or 3D data points. As the size of data increases, so does the number of statistical models and, likewise, the amount of human interaction in the analytical process. By interacting with the models, human analysts can inject their expert judgment into the analytical process, and thus explore the big data from varying perspectives. For example, an analyst could identify multiple alternative perspectives of a historical event from a collection of documents about that event. However, because of complex low-level formal parameters of the models, interacting with any individual model is difficult, especially for non-experts. Furthermore, in big data analysis, there is a need to simultaneously interact with multiple models. This makes it very difficult to interactively analyze big data. The grand challenge is to enable effective communication between human intelligence and computational artificial intelligence models. To address this challenge, our interdisciplinary approach merged human-computer-interaction techniques with complex statistical methods and fast high-performance computation to make big data analytics accessible to both professional and student analysts.</p>\n<p><strong>Solutions:</strong>&nbsp;Our solution is a new framework called Multi-Scale Semantic Interaction (SI). SI enables users to adjust model parameters by interacting directly with data in a visualization. That is, SI interprets visual interactions quantitatively to update parameters and produce new visualizations. SI is a new interactive framework that links together multiple models operating at multiple levels of data scale in a unified interactive space. Model results are combined into a common visualization. Directly manipulating the small-scale data in the visualization propagates to larger scale models by inverting the models to update their parameters, ultimately producing a new output result. In the text analytics example, if the user drags several documents together to synthesize a cluster, an inverted dimension reduction model computes updated term weights, forages for relevant new documents at the large scale, identifies new topics, and updates the visualization to show additional evidence from the data that supports the new synthesized cluster. This approach enables users to interactively explore large-scale data and complex inter-relationships between models in real time, and in a usable fashion that directly supports their natural cognitive sensemaking process.</p>\n<p><strong>Intellectual Merits:&nbsp;</strong>In terms of&nbsp;<strong></strong>intellectual merits, this project made many novel contributions. First, this research created the conceptual SI pipeline and software architecture, and identified design alternatives for communication flow between models, visualizations, and interactions. The pipeline is bidirectional and composable, enabling developers to easily construct new analytic systems. Second, we designed several new interactive models, spanning multiple levels of data scale, that support the model inversion approach to machine learning and can operate within the new pipeline. These include dimension reduction, clustering, topic modeling, and information retrieval models.&nbsp;&nbsp;Third, we developed new high-performance computational methods that rapidly update models in support of real-time interaction with big data. Fourth, we designed novel visualizations and interactions that emphasize usability of the above methods, and support visualization of data objects, data attributes, and the uncertainty associated with the models. Fifth, we instantiated multiple applications of the pipeline to create several example applications, including Andromeda and Cosmos. Sixth, we evaluated the usability of these systems and measured their impact on human sensemaking in big data analytics. We found significant benefits for multi-dimensional data analytics and text analytics tasks. An example finding was that SI foraging enabled users to uncover a broader array of relevant documents, perhaps helping to overcome problems of confirmation bias. The project produced over 30 publications and 7 student theses and dissertations.</p>\n<p><strong>Broader Impacts:&nbsp;</strong>In terms of&nbsp;<strong></strong>broader impacts, this project met several major educational objectives. New educational modules using the web-based software developed in the project were designed to teach students about complex analytical concepts such as dimension reduction. These modules were applied in courses reaching over 1000 students. The modules were also broadly disseminated through training workshops for use at other universities. This work also directly contributed to the development of new curriculum for teaching data science to both STEM and non-STEM students, and the development of a degree minor in data science targeted to students from diverse disciplines to enable them to excel in a big data world. The project also contributed to the establishment of a new workshop on machine learning from user interaction in visualization, and helped to solidify the future research agenda of interactive AI.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/06/2018<br>\n\t\t\t\t\tModified by: Christopher&nbsp;L&nbsp;North</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544072040102_ScreenShot2017-10-27at2.27.26PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544072040102_ScreenShot2017-10-27at2.27.26PM--rgov-800width.jpg\" title=\"Interactive Clustering\"><img src=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544072040102_ScreenShot2017-10-27at2.27.26PM--rgov-66x44.jpg\" alt=\"Interactive Clustering\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Interactive Clustering</div>\n<div class=\"imageCredit\">Virginia Tech</div>\n<div class=\"imageSubmitted\">Christopher&nbsp;L&nbsp;North</div>\n<div class=\"imageTitle\">Interactive Clustering</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544072540197_ScreenShot2018-12-06at12.01.27AM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544072540197_ScreenShot2018-12-06at12.01.27AM--rgov-800width.jpg\" title=\"Table of sample models\"><img src=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544072540197_ScreenShot2018-12-06at12.01.27AM--rgov-66x44.jpg\" alt=\"Table of sample models\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Table of sample models</div>\n<div class=\"imageCredit\">Virginia Tech</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Christopher&nbsp;L&nbsp;North</div>\n<div class=\"imageTitle\">Table of sample models</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544072662119_ScreenShot2018-12-06at12.03.09AM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544072662119_ScreenShot2018-12-06at12.03.09AM--rgov-800width.jpg\" title=\"Andromeda online\"><img src=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544072662119_ScreenShot2018-12-06at12.03.09AM--rgov-66x44.jpg\" alt=\"Andromeda online\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Andromeda online</div>\n<div class=\"imageCredit\">Virginia Tech</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Christopher&nbsp;L&nbsp;North</div>\n<div class=\"imageTitle\">Andromeda online</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544073059027_ScreenShot2018-12-06at12.09.33AM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544073059027_ScreenShot2018-12-06at12.09.33AM--rgov-800width.jpg\" title=\"SIRIUS dual projections\"><img src=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544073059027_ScreenShot2018-12-06at12.09.33AM--rgov-66x44.jpg\" alt=\"SIRIUS dual projections\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">SIRIUS dual projections</div>\n<div class=\"imageCredit\">Virginia Tech</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Christopher&nbsp;L&nbsp;North</div>\n<div class=\"imageTitle\">SIRIUS dual projections</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544073285916_ScreenShot2018-12-06at12.13.23AM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544073285916_ScreenShot2018-12-06at12.13.23AM--rgov-800width.jpg\" title=\"Cosmos pipeline\"><img src=\"/por/images/Reports/POR/2018/1447416/1447416_10337708_1544073285916_ScreenShot2018-12-06at12.13.23AM--rgov-66x44.jpg\" alt=\"Cosmos pipeline\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Cosmos pipeline</div>\n<div class=\"imageCredit\">Virginia Tech</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Christopher&nbsp;L&nbsp;North</div>\n<div class=\"imageTitle\">Cosmos pipeline</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nChallenges: Gaining big insight from big data requires big analytics, which poses big usability problems. Analyses of big data often rely on multiple computational models that operate at multiple levels of scale to discover and characterize valuable hidden insights within the data. The models filter, group, summarize, and visualize big data so that analysts may assess the data. As an example of big text analytics, large text collections are often first sampled for relevant words, then further clustered by modeling topics, then dimension reduced to visualize a set of 2D or 3D data points. As the size of data increases, so does the number of statistical models and, likewise, the amount of human interaction in the analytical process. By interacting with the models, human analysts can inject their expert judgment into the analytical process, and thus explore the big data from varying perspectives. For example, an analyst could identify multiple alternative perspectives of a historical event from a collection of documents about that event. However, because of complex low-level formal parameters of the models, interacting with any individual model is difficult, especially for non-experts. Furthermore, in big data analysis, there is a need to simultaneously interact with multiple models. This makes it very difficult to interactively analyze big data. The grand challenge is to enable effective communication between human intelligence and computational artificial intelligence models. To address this challenge, our interdisciplinary approach merged human-computer-interaction techniques with complex statistical methods and fast high-performance computation to make big data analytics accessible to both professional and student analysts.\n\nSolutions: Our solution is a new framework called Multi-Scale Semantic Interaction (SI). SI enables users to adjust model parameters by interacting directly with data in a visualization. That is, SI interprets visual interactions quantitatively to update parameters and produce new visualizations. SI is a new interactive framework that links together multiple models operating at multiple levels of data scale in a unified interactive space. Model results are combined into a common visualization. Directly manipulating the small-scale data in the visualization propagates to larger scale models by inverting the models to update their parameters, ultimately producing a new output result. In the text analytics example, if the user drags several documents together to synthesize a cluster, an inverted dimension reduction model computes updated term weights, forages for relevant new documents at the large scale, identifies new topics, and updates the visualization to show additional evidence from the data that supports the new synthesized cluster. This approach enables users to interactively explore large-scale data and complex inter-relationships between models in real time, and in a usable fashion that directly supports their natural cognitive sensemaking process.\n\nIntellectual Merits: In terms of intellectual merits, this project made many novel contributions. First, this research created the conceptual SI pipeline and software architecture, and identified design alternatives for communication flow between models, visualizations, and interactions. The pipeline is bidirectional and composable, enabling developers to easily construct new analytic systems. Second, we designed several new interactive models, spanning multiple levels of data scale, that support the model inversion approach to machine learning and can operate within the new pipeline. These include dimension reduction, clustering, topic modeling, and information retrieval models.  Third, we developed new high-performance computational methods that rapidly update models in support of real-time interaction with big data. Fourth, we designed novel visualizations and interactions that emphasize usability of the above methods, and support visualization of data objects, data attributes, and the uncertainty associated with the models. Fifth, we instantiated multiple applications of the pipeline to create several example applications, including Andromeda and Cosmos. Sixth, we evaluated the usability of these systems and measured their impact on human sensemaking in big data analytics. We found significant benefits for multi-dimensional data analytics and text analytics tasks. An example finding was that SI foraging enabled users to uncover a broader array of relevant documents, perhaps helping to overcome problems of confirmation bias. The project produced over 30 publications and 7 student theses and dissertations.\n\nBroader Impacts: In terms of broader impacts, this project met several major educational objectives. New educational modules using the web-based software developed in the project were designed to teach students about complex analytical concepts such as dimension reduction. These modules were applied in courses reaching over 1000 students. The modules were also broadly disseminated through training workshops for use at other universities. This work also directly contributed to the development of new curriculum for teaching data science to both STEM and non-STEM students, and the development of a degree minor in data science targeted to students from diverse disciplines to enable them to excel in a big data world. The project also contributed to the establishment of a new workshop on machine learning from user interaction in visualization, and helped to solidify the future research agenda of interactive AI.\n\n\t\t\t\t\tLast Modified: 12/06/2018\n\n\t\t\t\t\tSubmitted by: Christopher L North"
 }
}