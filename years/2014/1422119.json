{
 "awd_id": "1422119",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Moving MapReduce into the Cloud: Flexibility, Efficiency, and Elasticity",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2014-10-01",
 "awd_exp_date": "2019-09-30",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2014-09-05",
 "awd_max_amd_letter_date": "2016-09-20",
 "awd_abstract_narration": "MapReduce, a parallel and distributed programming model on clusters of commodity hardware, has emerged as the de facto standard for processing large data sets. Although MapReduce provides a simple and generic interface for parallel programming, it incurs several problems when running in the cloud including low cluster resource utilization, suboptimal scalability and poor multi-tenancy support. This project explores and designs new techniques that let MapReduce fully exploit the benefits of flexible and elastic resource allocations in the cloud while addressing the overhead and issues caused by server virtualization. It broadens impact by allowing a flexible and cost-effective way to perform big data analytics. This project also involves industry collaboration, curriculum development, and provides more avenues to bring women, minority, and underrepresented students into research and graduate programs.\r\n\r\nRunning MapReduce in the cloud offers many benefits, including rapid deployment, high availability, on-demand elasticity and secure multi-tenancy. However, a simple migration of MapReduce to the cloud environment does not fully exploit these benefits. The semantic gap between MapReduce runtime and cloud resource management, and the lack of optimizations of MapReduce workloads in cloud hypervisors, together make it difficult to attain flexibility, efficiency and elasticity. This project develops a synergistic approach for coordinating MapReduce and the cloud. This research centers on two key designs: 1) para-virtualized MapReduce, an enhancement of MapReduce to actively adapt job execution to the cloud dynamics, including interference and hardware heterogeneity; 2) MapReduce cloud, a collection of optimizations for MapReduce-aware cloud resource allocation and scheduling. This project combines computer system experimentations with rigorous system design to improve the flexibility, efficiency and elasticity of MapReduce in the cloud. It emphasizes the adaptability of MapReduce in a heterogeneous and dynamic cloud environment, proposes cross-layer optimizations to unlock the potential of cloud systems, and ensures that optimizations for MapReduce workloads do not compromise the requirements for high resource utilization and multi-tenant fairness.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiaobo",
   "pi_last_name": "Zhou",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaobo Zhou",
   "pi_email_addr": "xzhou@uccs.edu",
   "nsf_id": "000330885",
   "pi_start_date": "2014-09-05",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jia",
   "pi_last_name": "Rao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jia Rao",
   "pi_email_addr": "jia.rao@uta.edu",
   "nsf_id": "000627435",
   "pi_start_date": "2014-09-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Colorado at Colorado Springs",
  "inst_street_address": "1420 AUSTIN BLUFFS PKWY",
  "inst_street_address_2": "",
  "inst_city_name": "COLORADO SPRINGS",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "7192553153",
  "inst_zip_code": "809183733",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "CO05",
  "org_lgl_bus_name": "THE REGENTS OF THE UNIVERSITY OF COLORADO",
  "org_prnt_uei_num": "",
  "org_uei_num": "RH87YDXC1AY5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Colorado at Colorado Springs",
  "perf_str_addr": "1420 Austin Bluffs Parkway",
  "perf_city_name": "Colorado Springs",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "809183733",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "CO05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>MapReduce, a parallel and distributed programming model on clusters of commodity hardware, has emerged as the de-facto-standard for processing large datasets. Although MapReduce provides a simple and generic interface for parallel programming, it incurs problems including low cluster resource utilization, suboptimal scalability and poor multi-tenancy support. In this project, we designed new techniques that let MapReduce fully exploit the benefits of flexible and elastic resource allocations in the cloud while addressing the overhead and issues caused by server virtualization. The research centers on two key designs: 1) para-virtualized MapReduce, an enhancement of MapReduce to actively adapt job execution to the cloud dynamics, including interference and hardware heterogeneity; 2) MapReduce cloud, a collection of optimizations for MapReduce-aware cloud resource scheduling. We made following outcomes in research deliverables, student training, and curricula integration.</p>\n<p>1) Para-virtualized MapReduce:</p>\n<p>MapReduce applications are commonly deployed in heterogeneous computing environments. The performance discrepancy due to hardware heterogeneity and interference present significant challenges to attain high job performance. We augmented MapReduce framework in task configuration and designed new techniques in task scheduling, data placement and troubleshooting for MapReduce in heterogeneous clouds. Specifically, we proposed FlexSlot, a user-transparent task slot management scheme that automatically identifies stragglers and resizes their slots to accelerate task execution. We designed <em>FlexMap</em>, a user-transparent approach that dynamically provisions tasks with different sizes to match distinct machine capacity in heterogeneous clusters. MapReduce increasingly executes iterative machine learning jobs that exhibit a non-linear relationship between the size of partitioned parameters and processing time within each iteration. We proposed FlexPara, a parameter partition approach that leverages the non-linear relationship and provisions adaptive tasks to match the distinct machine capacity so as to address the job skewness on clusters.</p>\n<p>Homogeneous configuration of tasks on heterogeneous nodes is an important source of load imbalance. We proposed an adaptive task tuning approach, Ant, that automatically finds the optimal settings for individual tasks running on different nodes. We also found that decoupling Hadoop per-node storage from its computation opens up opportunities for IO acceleration, locality improvement, and on-the-fly cluster resizing. We developed StoreApp, a shared storage appliance for virtual Hadoop worker nodes co-located on the same physical host. For a dynamic Hadoop cluster, we proposed RD<em>S</em>, a resource and deadline-aware Hadoop job scheduler that takes future resource availability into minimizing job deadline misses. Furthermore, we developed SDChecker, a tool that characterizes scheduling delay for low-latency MapReduce workloads, and LRTrace, a non-intrusive tracing tool for troubleshooting data-analytics applications in lightweight virtualized environments.</p>\n<p>2) MapReduce Cloud</p>\n<p>Clouds are evolving to host heterogeneous workloads on shared clusters to reduce the operational cost and achieve high resource utilization. However, it is challenging to schedule heterogeneous workloads with diverse resource requirements and QoS constraints. We proposed BIG-C, a container-based resource management framework for MapReduce clusters. The key design is to leverage lightweight containers to make tasks preemptable in cluster scheduling so as to achieve high resource efficiency and job performance. We designed PerfCloud, a middleware that utilizes system-level performance metrics for early detection of performance interference in a multi-tenant cloud, and provides non-invasive performance isolation. Out-of-memory errors and excessive garbage collection activities are common in data-intensive programs, which cause not only poor performance but also execution failures. We conducted a preliminary study Docker-MB, a simple approach to addressing memory pressure in data-parallel programs using lightweight virtualization.</p>\n<p>Our research was also extended to cluster support to iterative machine learning workloads. We designed an aggressive synchronization model A-BSP based on the convergent property of iterative machine learning algorithms, by allowing the algorithms to use the updates generated based on partial input data for agile synchronization. We also augmented parameter server architecture and delivered iBatch, a novel communication approach that batches parameter communication and forward computation for scalable deep learning training in clusters.</p>\n<p>Overall, this project combines system experimentation with rigorous design to improve the flexibility, efficiency and elasticity of MapReduce in the clouds. We emphasized the adaptability of MapReduce in a heterogeneous and dynamic cloud and made the core MapReduce components aware of these issues. We coordinated resource scheduling in MapReduce runtime and the cloud hypervisor, which greatly improves resource efficiency and performance scalability of MapReduce in the cloud.</p>\n<p>This project provided significant training and professional development for students. It supported four PhD students in conducting quality research. It also engages an undergraduate student in research experiences. One student obtained PhD in 2019 and joined Nvidia lab at Boulder as a research staff. Two students will defend their thesis in academic year 2019-20.</p>\n<p>The outcomes were disseminated to research communities by presentations in ACM/IEEE/USENIX conferences, keynote and outreach talks in domestic and oversea universities, publications in numerous IEEE Transactions, and open-source artifacts at GitHub. We integrated research results with curricula innovation by integrating some research results into one graduate-level course in Computer Communications.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/02/2019<br>\n\t\t\t\t\tModified by: Xiaobo&nbsp;Zhou</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMapReduce, a parallel and distributed programming model on clusters of commodity hardware, has emerged as the de-facto-standard for processing large datasets. Although MapReduce provides a simple and generic interface for parallel programming, it incurs problems including low cluster resource utilization, suboptimal scalability and poor multi-tenancy support. In this project, we designed new techniques that let MapReduce fully exploit the benefits of flexible and elastic resource allocations in the cloud while addressing the overhead and issues caused by server virtualization. The research centers on two key designs: 1) para-virtualized MapReduce, an enhancement of MapReduce to actively adapt job execution to the cloud dynamics, including interference and hardware heterogeneity; 2) MapReduce cloud, a collection of optimizations for MapReduce-aware cloud resource scheduling. We made following outcomes in research deliverables, student training, and curricula integration.\n\n1) Para-virtualized MapReduce:\n\nMapReduce applications are commonly deployed in heterogeneous computing environments. The performance discrepancy due to hardware heterogeneity and interference present significant challenges to attain high job performance. We augmented MapReduce framework in task configuration and designed new techniques in task scheduling, data placement and troubleshooting for MapReduce in heterogeneous clouds. Specifically, we proposed FlexSlot, a user-transparent task slot management scheme that automatically identifies stragglers and resizes their slots to accelerate task execution. We designed FlexMap, a user-transparent approach that dynamically provisions tasks with different sizes to match distinct machine capacity in heterogeneous clusters. MapReduce increasingly executes iterative machine learning jobs that exhibit a non-linear relationship between the size of partitioned parameters and processing time within each iteration. We proposed FlexPara, a parameter partition approach that leverages the non-linear relationship and provisions adaptive tasks to match the distinct machine capacity so as to address the job skewness on clusters.\n\nHomogeneous configuration of tasks on heterogeneous nodes is an important source of load imbalance. We proposed an adaptive task tuning approach, Ant, that automatically finds the optimal settings for individual tasks running on different nodes. We also found that decoupling Hadoop per-node storage from its computation opens up opportunities for IO acceleration, locality improvement, and on-the-fly cluster resizing. We developed StoreApp, a shared storage appliance for virtual Hadoop worker nodes co-located on the same physical host. For a dynamic Hadoop cluster, we proposed RDS, a resource and deadline-aware Hadoop job scheduler that takes future resource availability into minimizing job deadline misses. Furthermore, we developed SDChecker, a tool that characterizes scheduling delay for low-latency MapReduce workloads, and LRTrace, a non-intrusive tracing tool for troubleshooting data-analytics applications in lightweight virtualized environments.\n\n2) MapReduce Cloud\n\nClouds are evolving to host heterogeneous workloads on shared clusters to reduce the operational cost and achieve high resource utilization. However, it is challenging to schedule heterogeneous workloads with diverse resource requirements and QoS constraints. We proposed BIG-C, a container-based resource management framework for MapReduce clusters. The key design is to leverage lightweight containers to make tasks preemptable in cluster scheduling so as to achieve high resource efficiency and job performance. We designed PerfCloud, a middleware that utilizes system-level performance metrics for early detection of performance interference in a multi-tenant cloud, and provides non-invasive performance isolation. Out-of-memory errors and excessive garbage collection activities are common in data-intensive programs, which cause not only poor performance but also execution failures. We conducted a preliminary study Docker-MB, a simple approach to addressing memory pressure in data-parallel programs using lightweight virtualization.\n\nOur research was also extended to cluster support to iterative machine learning workloads. We designed an aggressive synchronization model A-BSP based on the convergent property of iterative machine learning algorithms, by allowing the algorithms to use the updates generated based on partial input data for agile synchronization. We also augmented parameter server architecture and delivered iBatch, a novel communication approach that batches parameter communication and forward computation for scalable deep learning training in clusters.\n\nOverall, this project combines system experimentation with rigorous design to improve the flexibility, efficiency and elasticity of MapReduce in the clouds. We emphasized the adaptability of MapReduce in a heterogeneous and dynamic cloud and made the core MapReduce components aware of these issues. We coordinated resource scheduling in MapReduce runtime and the cloud hypervisor, which greatly improves resource efficiency and performance scalability of MapReduce in the cloud.\n\nThis project provided significant training and professional development for students. It supported four PhD students in conducting quality research. It also engages an undergraduate student in research experiences. One student obtained PhD in 2019 and joined Nvidia lab at Boulder as a research staff. Two students will defend their thesis in academic year 2019-20.\n\nThe outcomes were disseminated to research communities by presentations in ACM/IEEE/USENIX conferences, keynote and outreach talks in domestic and oversea universities, publications in numerous IEEE Transactions, and open-source artifacts at GitHub. We integrated research results with curricula innovation by integrating some research results into one graduate-level course in Computer Communications.\n\n\t\t\t\t\tLast Modified: 10/02/2019\n\n\t\t\t\t\tSubmitted by: Xiaobo Zhou"
 }
}