{
 "awd_id": "1422477",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Collaborative Research: Stochastic Sampling for Rendering, Imaging, and Modeling",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 179664.0,
 "awd_amount": 179664.0,
 "awd_min_amd_letter_date": "2014-07-23",
 "awd_max_amd_letter_date": "2014-07-23",
 "awd_abstract_narration": "Stochastic sampling is a fundamental component in most computer graphics applications, including rendering, imaging, modeling, and simulation. For example, in rendering, stochastic sampling is crucial to efficiently solving complex integrals; in texture synthesis, it is the key to generate visually pleasing patterns; in geometry processing, it is used to characterize important geometry features. While much previous work has focused on planar samples with blue noise spectrum, little research has studied more general types of stochastic sampling. This research aims to advance the state of the art in general stochastic sampling, providing new theoretical insights, computational methods, and practical applications. The outcome benefits not only computer graphics and vision, but many other disciplines that rely on stochastic sampling techniques.\r\n\r\nThis project studies new methods for analyzing and synthesizing stochastic samples. On the analysis side, the research introduces new techniques, based on spatial statistics, to quantify the distribution properties of stochastic samples. On the synthesis side, the research presents computationally efficient methods to generate high-quality samples with desired distribution properties. Modern GPUs are employed to achieve parallel computation. These techniques in turn enable new applications. In rendering, the project answers fundamental questions such as the optimal sample patterns for anti-aliasing and half-toning. In computational photography, the project introduces novel scene-dependent coded patterns that allow a camera system to capture more details (spatially, temporally, and spectrally) in a single shot. In geometry processing, the project presents new technique to generate samples on surfaces, for remeshing, defining shape features, and performing shape matching.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jingyi",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jingyi Yu",
   "pi_email_addr": "yu@cis.udel.edu",
   "nsf_id": "000487324",
   "pi_start_date": "2014-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Delaware",
  "inst_street_address": "550 S COLLEGE AVE",
  "inst_street_address_2": "",
  "inst_city_name": "NEWARK",
  "inst_state_code": "DE",
  "inst_state_name": "Delaware",
  "inst_phone_num": "3028312136",
  "inst_zip_code": "197131324",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DE00",
  "org_lgl_bus_name": "UNIVERSITY OF DELAWARE",
  "org_prnt_uei_num": "",
  "org_uei_num": "T72NHKM259N3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Delaware",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "DE",
  "perf_st_name": "Delaware",
  "perf_zip_code": "197162553",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DE00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 179664.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Stochastic sampling, such as blue noise sampling, is a fundamental component in many graphics and vision applications, including rendering, imaging, modeling, simulation, and geometry processing. In these applications, the samples' distribution property and computation speed can critically influence the result quality and efficiency. While much previous work has focused on blue noise sampling for anti&shy;aliasing, half&shy;toning and texture synthesis, general stochastic sampling, including non&shy;Euclidean, anisotropic, and non&shy;blue noise sampling, has received relatively little attention until recently. From the analysis side, few methods exist to quantify the distribution property of general samples&#894; from the synthesis side, producing such samples is computationally expensive&#894; from the application side, many problems, particularly in rendering, imaging and computational photography, can greatly benefit from carefully designed samples with problem&shy;specific distribution properties, and yet these approaches have not been studied previously due to the lack of an effective sample synthesis method.</p>\n<p>&nbsp;</p>\n<p>During the course of this project, we investigated new techniques for analyzing and synthesizing stochastic samples. We contributed to not only advancing the theoretical foundations of stochastic sampling, but also enabling new applications by presenting novel algorithms and practical, applicable results. On the analysis side, we introduced new techniques to quantify and measure the distribution properties of general stochastic samples, providing a sound mathematical foundation for our work. On the synthesis side, we presented computationally efficient methods to generate high-quality samples that conform with desired distribution properties. On the application side, we leveraged our techniques to enable new applications that exploit application&shy;specific distribution properties, particularly in rendering, imaging and computational photography, and 3D shape analysis and synthesis.</p>\n<p>&nbsp;</p>\n<p>The PI's research resulted in a number of publications at top&shy;tier computer vision venues (e.g. 3DV and CVPR). Representative topics of these publications include: using specially designed pattern for handling ambient occlusions in photometric shape recovery, a novel light field sampling scheme based on a novel type of computational camera called the crossed-slit or XSlit camera, and new classes of shape reconstruction schemes based on multi-view reconstruction. Through this project, the PI also manages to establish extensive collaborations with ShanghaiTech, Microsoft Research, and PLEX-VR. Multiple partners have provided data for validating our algorithms, a vital component to success of this project.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/24/2019<br>\n\t\t\t\t\tModified by: Jingyi&nbsp;Yu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nStochastic sampling, such as blue noise sampling, is a fundamental component in many graphics and vision applications, including rendering, imaging, modeling, simulation, and geometry processing. In these applications, the samples' distribution property and computation speed can critically influence the result quality and efficiency. While much previous work has focused on blue noise sampling for anti&shy;aliasing, half&shy;toning and texture synthesis, general stochastic sampling, including non&shy;Euclidean, anisotropic, and non&shy;blue noise sampling, has received relatively little attention until recently. From the analysis side, few methods exist to quantify the distribution property of general samples&#894; from the synthesis side, producing such samples is computationally expensive&#894; from the application side, many problems, particularly in rendering, imaging and computational photography, can greatly benefit from carefully designed samples with problem&shy;specific distribution properties, and yet these approaches have not been studied previously due to the lack of an effective sample synthesis method.\n\n \n\nDuring the course of this project, we investigated new techniques for analyzing and synthesizing stochastic samples. We contributed to not only advancing the theoretical foundations of stochastic sampling, but also enabling new applications by presenting novel algorithms and practical, applicable results. On the analysis side, we introduced new techniques to quantify and measure the distribution properties of general stochastic samples, providing a sound mathematical foundation for our work. On the synthesis side, we presented computationally efficient methods to generate high-quality samples that conform with desired distribution properties. On the application side, we leveraged our techniques to enable new applications that exploit application&shy;specific distribution properties, particularly in rendering, imaging and computational photography, and 3D shape analysis and synthesis.\n\n \n\nThe PI's research resulted in a number of publications at top&shy;tier computer vision venues (e.g. 3DV and CVPR). Representative topics of these publications include: using specially designed pattern for handling ambient occlusions in photometric shape recovery, a novel light field sampling scheme based on a novel type of computational camera called the crossed-slit or XSlit camera, and new classes of shape reconstruction schemes based on multi-view reconstruction. Through this project, the PI also manages to establish extensive collaborations with ShanghaiTech, Microsoft Research, and PLEX-VR. Multiple partners have provided data for validating our algorithms, a vital component to success of this project. \n\n \n\n\t\t\t\t\tLast Modified: 09/24/2019\n\n\t\t\t\t\tSubmitted by: Jingyi Yu"
 }
}