{
 "awd_id": "1422179",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Small: Collaborative Research: Development of a Wearable 3D Integral Imaging Augmented Reality Display Technology",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2014-08-20",
 "awd_max_amd_letter_date": "2015-07-28",
 "awd_abstract_narration": "An augmented reality (AR) display which enables the ability to overlay 2D or 3D digital information on a person's real-world view has long been portrayed as a technology that will transform the way that people perceive and interact with digital information. Although several types of display devices have been explored for AR applications, the ideal display would be a lightweight and compact optical-see-through head-mounted-display (OST-HMD) which enables digital information to be optically superposed onto the direct view of the physical world, and which at the same time maintains a see-through view of the world. With recent advances in mobile computing, image sensors, and cloud computing, the single remaining barrier to realizing ubiquitous AR technology is the display technology. The lack of high-performance, compact, and low-cost AR displays limits the ability to explore its potential benefits. One of the specific display problems that has not yet been adequately addressed, and is thus a specific barrier to widespread use of AR technology, is the visual discomfort and fatigue experiences by users of OST-HMDs. Visual discomfort is a critical concern in applications where users need to work with AR displays for an extended period of time. One of the key factors causing visual discomfort is the accommodation-convergence cue mismatch between digital information rendered by the display and the real-world scene. This is a fundamental problem inherent to existing AR displays. This project will address the human factor issues that persist in existing AR displays by developing a compact, lightweight, glasses-style 3D AR display technology that integrates wearable AR display technology with a microscopic integral imaging method. 3D products will soon pervade daily activities in education, transportation, computers, medicine, defense, and security. The U.S. has substantially contributed to the original innovative concepts for 3D imaging and 3D display, and will benefit from further development of 3D technologies, and from research and development in U.S. universities. This project, a collaboration between two experts in 3D vision technologies at two U.S. universities, will address the human factors issues that persist in existing AR displays. Project outcomes will readily transition to commercialization of new 3D displays, and will train of the next generation of experts in the field of 3D displays, who will contribute to industry, high tech firms, commerce, government, education, and health related fields.\r\n\r\nThe key innovation of the project is that it will investigate and develop an innovative optical approach to OST-HMD design that uniquely integrates a 3D microscopic integral imaging (micro-InI) display and visualization method for full-parallax lightfield creation with an emerging optical design approach - freeform optical technology - for OST-HMD viewing optics. This approach enables the development of a compact 3D integral imaging optical see-through HMD with full-parallax lightfield rendering capability, which is anticipated to minimize the accommodation-convergence discrepancy problem plaguing existing AR displays, and thus substantially reduce the visual discomfort and fatigue for users. The project will design, develop, and implement a custom compact prototype system; develop system calibration and assessment methods; and perform preliminary user-based assessment experiments to evaluate the effects of our proposed technology on visual perception and visual fatigue.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bahram",
   "pi_last_name": "Javidi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bahram Javidi",
   "pi_email_addr": "bahram@engr.uconn.edu",
   "nsf_id": "000478015",
   "pi_start_date": "2014-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Connecticut",
  "inst_street_address": "438 WHITNEY RD EXTENSION UNIT 1133",
  "inst_street_address_2": "",
  "inst_city_name": "STORRS",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "8604863622",
  "inst_zip_code": "062699018",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CT02",
  "org_lgl_bus_name": "UNIVERSITY OF CONNECTICUT",
  "org_prnt_uei_num": "",
  "org_uei_num": "WNTPS995QBM7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Connecticut",
  "perf_str_addr": "Electrical & Computer Engineerin",
  "perf_city_name": "Storrs",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "062694157",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CT02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 86349.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 163651.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>An augmented reality (AR) 3D display, which enables the ability to overlay 2D or 3D digital information on a person&rsquo;s real-world view, has long been portrayed as a transformative technology to redefine the way we perceive and interact with digital information. Although several types of display devices have been explored for AR applications, a desired form of AR 3D displays is a lightweight compact optical see-through head-mounted display (OST-HMD) without visual fatigue, which enables optical superposition of digital information onto the direct view of the physical world and maintains see-through vision to the real world. With the rapidly increasing bandwidth of wireless networks, the miniaturization of electronics and increasing computational power, the prevailing cloud computing, and advances in image sensors and displays, a current trend is to realize an eyeglass-style, unobtrusive AR display that integrates the functions of OST-HWDs, mobile devices and miniature GPS technologies within the volume of a pair of eyeglasses. Such an AR display will make access to wireless networks, databases, video display, 3D contents, and location-specific information easier than ever, and has the potential to revolutionize many important fields and penetrate through the fabrics of life, including medical, defense and security, commerce, manufacturing, transportation, education, and entertainment.</p>\n<p>Despite these promises, AR technology has yet to be fully embraced and practically used in most application fields. The most critical barriers of realizing AR technology are defined by the displays. The lack of high-performance, compact, and low-cost AR displays limits the ability to explore the full range of benefits potentially offered by AR technology in most applications. Also, very limited efforts have been made to address the challenges of minimizing visual discomfort and fatigue experiences by the users. Visual discomfort is a critical concern in applications where users need to work with AR displays for an extended period of time. One of the key factors causing visual discomfort is the accommodation-convergence cue mismatch between digital information rendered by the HMD and the real-world scene, which is a fundamental problem inherent to many existing AR displays.</p>\n<p>This proposal was a collaboration between two leading US universities in the 3D field with the intention of using our existing synergy and resources to accomplish two main transformative objectives: 1) to investigate a compact, lightweight, glasses-style AR 3D display technology by uniquely integrating wearable AR display technology with the 3D integral imaging and visualization method to address the human factor issue persisting in most of the existing AR displays; and 2) to provide education in the 3D field not only to the students at our respective universities, but also to a wider scale of beneficiaries.</p>\n<p>The key innovation of the proposed research was that we investigated an innovative optical system that uniquely integrates 3D integral imaging display and visualization method for full-parallax lightfield creation with an emerging optical design approach with freeform optical technology for OST-HMD viewing optics. This approach enables the development of a compact 3D integral imaging optical see-through HMD with full-parallax lightfield rendering capability, which can minimize the accommodation-convergence discrepancy problem plaguing most of the existing AR displays and thus potentially minimize the visual discomfort and fatigue for users. This collaboration and NSF project led to publications in high quality archival journals, education of graduate students leading to PhD degrees, and foundation and organization of new conferences in this field.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2018<br>\n\t\t\t\t\tModified by: Bahram&nbsp;Javidi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAn augmented reality (AR) 3D display, which enables the ability to overlay 2D or 3D digital information on a person?s real-world view, has long been portrayed as a transformative technology to redefine the way we perceive and interact with digital information. Although several types of display devices have been explored for AR applications, a desired form of AR 3D displays is a lightweight compact optical see-through head-mounted display (OST-HMD) without visual fatigue, which enables optical superposition of digital information onto the direct view of the physical world and maintains see-through vision to the real world. With the rapidly increasing bandwidth of wireless networks, the miniaturization of electronics and increasing computational power, the prevailing cloud computing, and advances in image sensors and displays, a current trend is to realize an eyeglass-style, unobtrusive AR display that integrates the functions of OST-HWDs, mobile devices and miniature GPS technologies within the volume of a pair of eyeglasses. Such an AR display will make access to wireless networks, databases, video display, 3D contents, and location-specific information easier than ever, and has the potential to revolutionize many important fields and penetrate through the fabrics of life, including medical, defense and security, commerce, manufacturing, transportation, education, and entertainment.\n\nDespite these promises, AR technology has yet to be fully embraced and practically used in most application fields. The most critical barriers of realizing AR technology are defined by the displays. The lack of high-performance, compact, and low-cost AR displays limits the ability to explore the full range of benefits potentially offered by AR technology in most applications. Also, very limited efforts have been made to address the challenges of minimizing visual discomfort and fatigue experiences by the users. Visual discomfort is a critical concern in applications where users need to work with AR displays for an extended period of time. One of the key factors causing visual discomfort is the accommodation-convergence cue mismatch between digital information rendered by the HMD and the real-world scene, which is a fundamental problem inherent to many existing AR displays.\n\nThis proposal was a collaboration between two leading US universities in the 3D field with the intention of using our existing synergy and resources to accomplish two main transformative objectives: 1) to investigate a compact, lightweight, glasses-style AR 3D display technology by uniquely integrating wearable AR display technology with the 3D integral imaging and visualization method to address the human factor issue persisting in most of the existing AR displays; and 2) to provide education in the 3D field not only to the students at our respective universities, but also to a wider scale of beneficiaries.\n\nThe key innovation of the proposed research was that we investigated an innovative optical system that uniquely integrates 3D integral imaging display and visualization method for full-parallax lightfield creation with an emerging optical design approach with freeform optical technology for OST-HMD viewing optics. This approach enables the development of a compact 3D integral imaging optical see-through HMD with full-parallax lightfield rendering capability, which can minimize the accommodation-convergence discrepancy problem plaguing most of the existing AR displays and thus potentially minimize the visual discomfort and fatigue for users. This collaboration and NSF project led to publications in high quality archival journals, education of graduate students leading to PhD degrees, and foundation and organization of new conferences in this field.\n\n \n\n\t\t\t\t\tLast Modified: 11/30/2018\n\n\t\t\t\t\tSubmitted by: Bahram Javidi"
 }
}