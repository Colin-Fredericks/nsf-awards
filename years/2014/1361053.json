{
 "awd_id": "1361053",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research:XPS:CLCCA: Performance Portable Abstractions for Large-Scale Irregular Computations",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2013-09-10",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 299999.0,
 "awd_amount": 299999.0,
 "awd_min_amd_letter_date": "2013-11-06",
 "awd_max_amd_letter_date": "2013-11-06",
 "awd_abstract_narration": "Ongoing technology trends are accelerating scientific discovery by allowing researchers to generate enormous quantities of data, in domains ranging from computational biology to social networks.  There is an urgent need to make it easy and fast to extract useful content from this data using appropriate abstractions and parallel runtimes.  Work conducted under this project aims to make \"big data\" computing more readily available to applications with dynamic structure and irregular dependencies, thereby enabling advances in scientific computing in general and computational biology in particular.\r\n\r\nThis project extends the state of the art in scientific computing by developing programming abstractions to expose -- and run-time optimizations to exploit -- the parallelism available in large, irregular applications.  Parallelism is essential for the extraction of useful information from ever increasing volumes of scientific data, but the irregularity of data structure and access in many problem domains makes efficient parallelization difficult. At the level of the programming model, the project addresses the challenge of irregularity by identifying design patterns for important new classes of applications -- in particular, those that use trees and graphs for data representation and access but demonstrate some structure in the traversal.  At the level of the run-time system, it is developing computational engines that support and exploit the new patterns, leveraging the structure exposed to automatically and dynamically map computational tasks to hardware nodes.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Srinivas",
   "pi_last_name": "Aluru",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Srinivas Aluru",
   "pi_email_addr": "aluru@cc.gatech.edu",
   "nsf_id": "000388133",
   "pi_start_date": "2013-11-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 299999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aimed to extend the state-of-the-art in scientific computing by developing programming abstractions to expose -- and run-time optimizations to exploit -- the parallelism available in large, irregular applications. Parallelism is essential for the extraction of useful information from ever increasing volumes of scientific data, but the irregularity of data structure and access in many problem domains makes efficient parallelization difficult. At the level of the programming model, the project addressed the challenge of irregularity by identifying design patterns for important new classes of applications -- in particular, those that use trees and graphs for data representation and access but demonstrate some structure in the traversal. At the level of the run-time system, the project developed computational engines that support and exploit the new patterns, leveraging the structure exposed to automatically and dynamically map computational tasks to hardware nodes.<br /><br />Project activities were focused in three major areas: 1) fast point tree data structures and algorithms, 2) fast de Bruijn graph and algorithms for sequence analysis and assembly, and 3) efficient parallel run-time systems.<br /><br />The Georgia Institute of Technology team led the development of fast point tree data structures and algorithms to support tree-based applications including hierarchical methods in scientific computing, k-nearest neighbors and the Fast Multipole Method. A common framework is developed, including three sub libraries: the tree compute framework, the parallel tree library model/abstraction, and a library of distributed tree structure implementations (such as octrees and kd-trees). The first two sub libraries provide a common abstraction for constructing, accessing, and computing with different distributed tree structures, while the last sub-library contain tree-specific, state-of-the-art algorithms.&nbsp; These abstractions allow an application developer to perform computations in parallel with minimal knowledge in parallelism or underlying distributed computing resources.&nbsp;The code is demonstrated by implementing communication efficient kd-trees, showing a two- to three-fold improvement in performance over existing methods.&nbsp; <br /><br />The Georgia Institute of Technology team also led the development of efficient data structures and algorithms to support genome assembly as well as other sequence analysis tasks such as error corrrection, alignment, variant calling, etc. Best-in-class algorithms were developed for distributed memory k-mer indices (Kmerind and Kmerhash), and parallel directed and bi-directed de Bruijn graphs (Bruno) with fast construction, error detection and removal, linear chain compaction, and cycle detection.&nbsp; The k-mer counter out-performed previous state-of-the-art shared memory software by 1.7 times, and was able to count a 1TB sequence data set in under 12 seconds using 4096 cores on NERSC's Cori supercomputer.&nbsp; The de Bruijn graph software constructed and compacted a 695GB data set in 31 seconds using 7680 cores on NERSC's Edison supercomputer, 3.7 times faster than the previous state of the art, and 1.4 times faster than the previous state of the art in shared memory environments.&nbsp; These algorithms and implementations benefit not only computational biology and bioinformatics, but also the broader set of applications that depend on distributed and sequential hash tables.<br /><br />The University of Rochester team led the development of efficient parallel run-time systems.&nbsp;&nbsp;To make as effective use as possible of modern multiprocessors and clusters, techniques were developed to co-locate application tasks that share significant amounts of data, thereby minimizing communication costs. Related techniques were developed to automatically control the level of parallelism in each application. Both of these mechanisms leverage the performance monitoring features of modern processors to effect their adaptations without programmer or user intervention.For systems that share hardware resources across independent applications, the project also developed driver software thatguarantees fair access to extremely fast parallel I/O devices.</p>\n<p>In the area of speculative execution, techniques were developed to maximize the effectiveness of hardware transactional memory (HTM), which allows groups of instructions to be executed as a single indivisible operation. One such technique uses HTM as a prefetching mechanism that allows an application to maximize performance when an operation for which it is waiting finally completes; another technique minimizes data structure indirection, thereby reducing the odds of spurious HTM failures. Several new concurrent data structures were also developed, together with techniques that leverage emerging memory technologies to maintain the consistency of structured data across power outages and other system failures.<br /><br />The work performed under this project has broad impact both as a whole as well as indiviudal components.&nbsp; Tree abstractions as well as kd-trees and octrees are commonly used in scientific computing and computer science.&nbsp; De Bruijn graph and k-mer indices are useful for genomic assembly and sequence analysis, while the underlying distributed and sequential hash tables, vectorized hash functions, and primitives to support communication and computation overlaps have broad applicability.&nbsp; The improvements to core OS funcitonalities such as CPU scheduling, address translation, data persistance, and hardware transactional memory support impact OS as well as sequential and parallel application performance. Multiple software products from the research are made available as open source.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/27/2019<br>\n\t\t\t\t\tModified by: Srinivas&nbsp;Aluru</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project aimed to extend the state-of-the-art in scientific computing by developing programming abstractions to expose -- and run-time optimizations to exploit -- the parallelism available in large, irregular applications. Parallelism is essential for the extraction of useful information from ever increasing volumes of scientific data, but the irregularity of data structure and access in many problem domains makes efficient parallelization difficult. At the level of the programming model, the project addressed the challenge of irregularity by identifying design patterns for important new classes of applications -- in particular, those that use trees and graphs for data representation and access but demonstrate some structure in the traversal. At the level of the run-time system, the project developed computational engines that support and exploit the new patterns, leveraging the structure exposed to automatically and dynamically map computational tasks to hardware nodes.\n\nProject activities were focused in three major areas: 1) fast point tree data structures and algorithms, 2) fast de Bruijn graph and algorithms for sequence analysis and assembly, and 3) efficient parallel run-time systems.\n\nThe Georgia Institute of Technology team led the development of fast point tree data structures and algorithms to support tree-based applications including hierarchical methods in scientific computing, k-nearest neighbors and the Fast Multipole Method. A common framework is developed, including three sub libraries: the tree compute framework, the parallel tree library model/abstraction, and a library of distributed tree structure implementations (such as octrees and kd-trees). The first two sub libraries provide a common abstraction for constructing, accessing, and computing with different distributed tree structures, while the last sub-library contain tree-specific, state-of-the-art algorithms.  These abstractions allow an application developer to perform computations in parallel with minimal knowledge in parallelism or underlying distributed computing resources. The code is demonstrated by implementing communication efficient kd-trees, showing a two- to three-fold improvement in performance over existing methods.  \n\nThe Georgia Institute of Technology team also led the development of efficient data structures and algorithms to support genome assembly as well as other sequence analysis tasks such as error corrrection, alignment, variant calling, etc. Best-in-class algorithms were developed for distributed memory k-mer indices (Kmerind and Kmerhash), and parallel directed and bi-directed de Bruijn graphs (Bruno) with fast construction, error detection and removal, linear chain compaction, and cycle detection.  The k-mer counter out-performed previous state-of-the-art shared memory software by 1.7 times, and was able to count a 1TB sequence data set in under 12 seconds using 4096 cores on NERSC's Cori supercomputer.  The de Bruijn graph software constructed and compacted a 695GB data set in 31 seconds using 7680 cores on NERSC's Edison supercomputer, 3.7 times faster than the previous state of the art, and 1.4 times faster than the previous state of the art in shared memory environments.  These algorithms and implementations benefit not only computational biology and bioinformatics, but also the broader set of applications that depend on distributed and sequential hash tables.\n\nThe University of Rochester team led the development of efficient parallel run-time systems.  To make as effective use as possible of modern multiprocessors and clusters, techniques were developed to co-locate application tasks that share significant amounts of data, thereby minimizing communication costs. Related techniques were developed to automatically control the level of parallelism in each application. Both of these mechanisms leverage the performance monitoring features of modern processors to effect their adaptations without programmer or user intervention.For systems that share hardware resources across independent applications, the project also developed driver software thatguarantees fair access to extremely fast parallel I/O devices.\n\nIn the area of speculative execution, techniques were developed to maximize the effectiveness of hardware transactional memory (HTM), which allows groups of instructions to be executed as a single indivisible operation. One such technique uses HTM as a prefetching mechanism that allows an application to maximize performance when an operation for which it is waiting finally completes; another technique minimizes data structure indirection, thereby reducing the odds of spurious HTM failures. Several new concurrent data structures were also developed, together with techniques that leverage emerging memory technologies to maintain the consistency of structured data across power outages and other system failures.\n\nThe work performed under this project has broad impact both as a whole as well as indiviudal components.  Tree abstractions as well as kd-trees and octrees are commonly used in scientific computing and computer science.  De Bruijn graph and k-mer indices are useful for genomic assembly and sequence analysis, while the underlying distributed and sequential hash tables, vectorized hash functions, and primitives to support communication and computation overlaps have broad applicability.  The improvements to core OS funcitonalities such as CPU scheduling, address translation, data persistance, and hardware transactional memory support impact OS as well as sequential and parallel application performance. Multiple software products from the research are made available as open source.\n\n\t\t\t\t\tLast Modified: 02/27/2019\n\n\t\t\t\t\tSubmitted by: Srinivas Aluru"
 }
}