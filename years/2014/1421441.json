{
 "awd_id": "1421441",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Telescopic Analysis for Black-Box Troubleshooting of Distributed Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 498241.0,
 "awd_amount": 498241.0,
 "awd_min_amd_letter_date": "2014-08-13",
 "awd_max_amd_letter_date": "2014-08-13",
 "awd_abstract_narration": "This project is developing scalable mechanisms to debug, monitor, and\r\nassess the quality of the complex distributed systems that represent\r\nthe backbone of modern software infrastructure.  These methods are\r\nnecessarily highly-automated; they reason about the operation of\r\ndistributed systems while treating the components of such systems as\r\nblack boxes.  This means that the methods do not require source code,\r\nprogrammer annotation, or developer input to troubleshoot a\r\ndistributed system.  Instead, they rely on detailed information\r\ngleaned from pre-existing log messages that are nearly ubiquitous in\r\nevery large-scale distributed system and data extracted via binary\r\nanalysis of components as they run.\r\n\r\nThese new methods, termed telescopic analysis, combine the ability to\r\ncollect extremely detailed, low-level information about systems\r\nexecuting large numbers of requests with \"big data\" analysis that\r\nmines insights and create models of system operation from the corpus\r\nof detailed observations.  Telescopic analysis uses targeted,\r\nsample-based logging and/or binary analysis to generate substantial\r\nquantities of high-precision data about specific runs of the system\r\nunder observation.  It then combines these observations into models\r\nthat capture the aggregate behavior of the system. Comparing the\r\ngeneral model with the detailed observations of each run allows\r\nunderstanding of how that run conforms to or deviates from the common\r\noperation of the system.  The project is also developing tools and\r\nquery languages that allow understanding of the results of such\r\ncomparisons, both in aggregate and as pertains to specific runs, for\r\nperformance analysis, debugging data quality failures, understanding\r\noutlier behavior, and performing \"what-if\" analysis.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jason",
   "pi_last_name": "Flinn",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Jason N Flinn",
   "pi_email_addr": "jflinn@umich.edu",
   "nsf_id": "000096770",
   "pi_start_date": "2014-08-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Cafarella",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Cafarella",
   "pi_email_addr": "michjc@umich.edu",
   "nsf_id": "000544946",
   "pi_start_date": "2014-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "2260 Hayward",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092121",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 498241.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project developed new scalable mechanisms, termed telescopic analysis, to debug, monitor, and assess the quality of complex distributed systems.&nbsp; Telescopic analysis is designed to be highly-automated; it reasons about the operation of distributed systems while treating the individual components of the systems as black boxes.&nbsp; The techniques that we created combine the ability to collect extremely detailed, low-level information about systems executing large numbers of request with \"big data\" analysis that mines for insights and creates models of system operation from the corpus of detailed observations.</p>\n<p>The outcomes of the project have substantially improved the state-of-the-art for monitoring and debugging Internet-scale distributed systems that form the backbone of our nation's computing infrastrucutre.&nbsp; Our results have been disseminated through publication at top peer-reviewed forums, through open-source release of source code, and through technology transfer to industry.</p>\n<p><span>Our first major outcome derived from applying telescopic analysis to performance debugging of large-scale Internet pipelines. &nbsp;We observed that the scale of such systems means that even at low sampling rates, we can gather a tremendous amount of empirical performance observations through low-level request logging. &nbsp;We can then apply &ldquo;big data&rdquo; techniques to analyze those observations. &nbsp; We developed a system to automatically construct a model of request execution from pre-existing component logs by generating a large number of potential hypotheses about program behavior and rejecting hypotheses contradicted by the empirical observations. &nbsp;Our system is also able to validate potential performance improvements without costly implementation effort by leveraging the variation in component behavior that arises naturally over large numbers of requests to measure the impact of optimizing individual components or changing scheduling behavior.&nbsp; </span></p>\n<p><span>I<span>n collaboration with Facebook engineers, we integrated telescopic analysis into the company's existing logging infrastructure. &nbsp;As a result of this work, we were able to analyze performance traces of over 1.3 million requests to Facebook servers. &nbsp;We generated a detailed study of the factors that affect the end-to-end latency of such requests and used telescopic analysis to suggest and validate a scheduling optimization for improving Facebook request latency. &nbsp;We published the results of our study so that the broader computer science community could benefit from our insights.&nbsp; Through this technology transfer, telescopic analysis is now continuously used by thousands of Facebook software engineers as part of their Canopy and Kraken systems.</span></span></p>\n<p>Another major outcome of the project was the invesitgation of data-quality tradeoffs, which we define to be explicit decisions to return lower-fidelity data in order to improve response time or minimize resource usage. &nbsp;These tradeoffs arise because modern Internet services often involve hundreds of distinct software components cooperating to handle a single user request. &nbsp;Each component must balance the competing goals of minimizing service response time and maximizing the quality of the service provided.</p>\n<p>We built a system, called DQBarge, that enables better data-quality tradeoffs by propagating critical information along the causal path of request processing. &nbsp;This information includes data provenance, load metrics, and request critical path predictions. &nbsp;DBarge generates performance and quality models that help low-level components make better, more proactive, tradeoffs.&nbsp;&nbsp;</p>\n<p>Our next major outcome was showing how telescopic analysis can enable better understanding of the data and control flow of software components in distributed systems. &nbsp;Our JetStream system parallelizes information flow queries across a compute cluster. &nbsp;Parallelization of information flow tracking was a previously unsolved problem due to the difficulty of handling billions of fine-grained dependencies in program execution. &nbsp;JetStream uses two techniques to enable efficient parallelization. &nbsp;First, it uses time-slicing of recorded program executions to parallelize program instrumentation and data gathering. &nbsp;Second, it uses stream-style processing of the distributed graph of causal dependencies to parallelize the work of aggregation and output generation.</p>\n<p>JetStream is a fundamental building block for making telescopic analysis interactive. &nbsp;We have used JetStream to build debugging and troubleshooting tools that allow complex analyses of distributed systems to complete in a few seconds rather than minutes or hours.&nbsp; The insight in this work is that the execution of a program can be regarded as a queryable object.&nbsp; &nbsp;We can then define relations over the execution that can be evaluated at granularities as small as individual instructions.&nbsp; These relations produce a tremendous amount of data during program execution, so evaluating them requires \"big-data\" style scalable analysis techniques and a significant amount of optimization.&nbsp; One relation we developed for debugging is termed a&nbsp;<em>continuous function invariant</em>.&nbsp; The abstraction lets developers define a function over the state of their execution that is logically evaluated after every instruction.&nbsp;&nbsp;</p>\n<p>The scientific results of the project have also been incorporated into course modules used in the undergraduate operating systems and web systems courses.&nbsp; We have used the results of telescopic analysis to give students insight into the performance of Internet-scale systems, using actual results from measuring millions of requests at Facebook as an example of such systems.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/16/2018<br>\n\t\t\t\t\tModified by: Jason&nbsp;N&nbsp;Flinn</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project developed new scalable mechanisms, termed telescopic analysis, to debug, monitor, and assess the quality of complex distributed systems.  Telescopic analysis is designed to be highly-automated; it reasons about the operation of distributed systems while treating the individual components of the systems as black boxes.  The techniques that we created combine the ability to collect extremely detailed, low-level information about systems executing large numbers of request with \"big data\" analysis that mines for insights and creates models of system operation from the corpus of detailed observations.\n\nThe outcomes of the project have substantially improved the state-of-the-art for monitoring and debugging Internet-scale distributed systems that form the backbone of our nation's computing infrastrucutre.  Our results have been disseminated through publication at top peer-reviewed forums, through open-source release of source code, and through technology transfer to industry.\n\nOur first major outcome derived from applying telescopic analysis to performance debugging of large-scale Internet pipelines.  We observed that the scale of such systems means that even at low sampling rates, we can gather a tremendous amount of empirical performance observations through low-level request logging.  We can then apply \"big data\" techniques to analyze those observations.   We developed a system to automatically construct a model of request execution from pre-existing component logs by generating a large number of potential hypotheses about program behavior and rejecting hypotheses contradicted by the empirical observations.  Our system is also able to validate potential performance improvements without costly implementation effort by leveraging the variation in component behavior that arises naturally over large numbers of requests to measure the impact of optimizing individual components or changing scheduling behavior.  \n\nIn collaboration with Facebook engineers, we integrated telescopic analysis into the company's existing logging infrastructure.  As a result of this work, we were able to analyze performance traces of over 1.3 million requests to Facebook servers.  We generated a detailed study of the factors that affect the end-to-end latency of such requests and used telescopic analysis to suggest and validate a scheduling optimization for improving Facebook request latency.  We published the results of our study so that the broader computer science community could benefit from our insights.  Through this technology transfer, telescopic analysis is now continuously used by thousands of Facebook software engineers as part of their Canopy and Kraken systems.\n\nAnother major outcome of the project was the invesitgation of data-quality tradeoffs, which we define to be explicit decisions to return lower-fidelity data in order to improve response time or minimize resource usage.  These tradeoffs arise because modern Internet services often involve hundreds of distinct software components cooperating to handle a single user request.  Each component must balance the competing goals of minimizing service response time and maximizing the quality of the service provided.\n\nWe built a system, called DQBarge, that enables better data-quality tradeoffs by propagating critical information along the causal path of request processing.  This information includes data provenance, load metrics, and request critical path predictions.  DBarge generates performance and quality models that help low-level components make better, more proactive, tradeoffs.  \n\nOur next major outcome was showing how telescopic analysis can enable better understanding of the data and control flow of software components in distributed systems.  Our JetStream system parallelizes information flow queries across a compute cluster.  Parallelization of information flow tracking was a previously unsolved problem due to the difficulty of handling billions of fine-grained dependencies in program execution.  JetStream uses two techniques to enable efficient parallelization.  First, it uses time-slicing of recorded program executions to parallelize program instrumentation and data gathering.  Second, it uses stream-style processing of the distributed graph of causal dependencies to parallelize the work of aggregation and output generation.\n\nJetStream is a fundamental building block for making telescopic analysis interactive.  We have used JetStream to build debugging and troubleshooting tools that allow complex analyses of distributed systems to complete in a few seconds rather than minutes or hours.  The insight in this work is that the execution of a program can be regarded as a queryable object.   We can then define relations over the execution that can be evaluated at granularities as small as individual instructions.  These relations produce a tremendous amount of data during program execution, so evaluating them requires \"big-data\" style scalable analysis techniques and a significant amount of optimization.  One relation we developed for debugging is termed a continuous function invariant.  The abstraction lets developers define a function over the state of their execution that is logically evaluated after every instruction.  \n\nThe scientific results of the project have also been incorporated into course modules used in the undergraduate operating systems and web systems courses.  We have used the results of telescopic analysis to give students insight into the performance of Internet-scale systems, using actual results from measuring millions of requests at Facebook as an example of such systems.\n\n\t\t\t\t\tLast Modified: 09/16/2018\n\n\t\t\t\t\tSubmitted by: Jason N Flinn"
 }
}