{
 "awd_id": "1350160",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER: Human-Aware Autonomy for Team-Oriented Environments",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2014-08-01",
 "awd_exp_date": "2020-09-30",
 "tot_intn_awd_amt": 398575.0,
 "awd_amount": 398575.0,
 "awd_min_amd_letter_date": "2014-07-23",
 "awd_max_amd_letter_date": "2014-07-23",
 "awd_abstract_narration": "Robots are an increasingly common presence in human environments, working alongside people in factories, hospitals, and military field operations. However, today people must change how they work to accommodate robots in their workspace. This poses a significant barrier to adoption of robot technology by creating inefficiencies. This project provides an integrated research and educational approach to develop intelligent robotic technologies that more seamlessly integrate with human work environments. \r\n\r\nThe technical approach translates qualitative and quantitative insights from human studies into explicit computational models, and exploits these models to redesign robot algorithms for learning, decision-making, and control. The research effort specifically investigates three types modifications to robot behavior: (1) modifying robot motion planning using anticipatory signals of human motion, (2) customizing robot task plans using statistical models of human task execution, and (3) inferring and applying human domain expertise to expedite automated planning for mixed human-robot teams. Human subject experimentation is planned to assess ease-of-interaction, worker trust, and task performance, and the approach is validated using metrics to quantitatively assess the degree to which a robot's behavior preserves natural human workflow. By designing robot autonomy that minimizes disruption to human workflow, the approach supports graceful transitions from robotic work back to human work and vice versa.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Julie",
   "pi_last_name": "Shah",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Julie Shah",
   "pi_email_addr": "arnoldj@mit.edu",
   "nsf_id": "000611096",
   "pi_start_date": "2014-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 398575.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In settings from factories to hospitals it is common to see robots   working with people. However, given that robots lack the intelligence to   respond to their more dynamic human partners, the two work   independently on tasks best suited to their individual capabilities. In   nearly every industry, this ?either/or? tasking of people and robots   results in production inefficiency. This project envisioned robots that   are capable of working collaboratively and flexibly with people, as the   best human teammates do, to achieve what neither robots or humans can  do  alone. On an automotive assembly line, for example, a robot capable  of  anticipating a person?s needs and consequently providing the right   materials at the right time can enhance human capability and improve   productivity. It is challenging , however, for a machine to monitor a   human?s real-time progress through a plan. Prior activity recognition   approaches are designed and tuned for specific motions or tasks, and in   most scenarios no existing single technique provides accurate   predictions over short- and long-time horizons. The robot must predict   detailed space-time trajectories of human actions for short and long   timescales (&lt;1s to 10-20s) to react appropriately. This project aimed   to improve prediction of human behavior by explicitly modeling and   exploiting proven mechanisms of effective team coordination, including   anticipatory signals of human motion, motion and task-based statistical   models of human behavior, and communication strategies to develop and   maintain common understanding among team members. <br /><br />The first step   in the project aimed to develop data-driven approaches that  synthesized  anticipatory knowledge of both human motions and subsequent  action  steps in order to predict in real-time the intended target of a  human  performing a reaching motion.&nbsp; The techniques for predicting  human arm  reaching motions and human walking motion achieved over prior  techniques  in early prediction, achieving 70% or higher correct  classification on  average for the first third of the trajectory. <br /><br />A  variety of  human motion prediction approaches, including the  aforementioned  techniques are often designed for specific types of  tasks or motions,  and thus do not generalize well. Furthermore, it is  not always obvious  which of these methods is appropriate for a given  task, making human  motion prediction difficult to implement in  practice. We addressed this  problem by introducing a multiple-predictor  system (MPS) for human  motion prediction. In our approach, the system  learns directly from task  data in order to determine the most favorable  parameters for each  implemented prediction method and which  combination of these predictors  to use. Our implementation consists of  three complementary methods:  velocity-based position projection, time  series classification, and  sequence prediction. We describe the process  of forming the MPS and our  evaluation of its performance against the  individual methods in terms of  accuracy of predictions of human  position over a range of look-ahead  time values. We reported that our  method leads to a reduction in mean  error of 18.5%, 28.9%, and 37.3%  when compared with the three individual  methods, respectively.<br /><br />Finally,  we utilized the  multiple-prediction system within a human-aware  robotic system with  single-axis mobility that incorporated both  predictions of human motion  and planning in time to execute efficient  and safe motions during  automotive final assembly. We evaluated our  system in simulation against  three alternative methods, including a  baseline approach emulating the  behavior of standard safety systems in  factories today. We also assessed  the system within a factory test  environment. Through both live  demonstration and results from simulated  experiments, we demonstrated  that our approach produces statistically  significant improvements in  quantitative measures of safety and fluency  of interaction.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/25/2021<br>\n\t\t\t\t\tModified by: Julie&nbsp;Shah</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn settings from factories to hospitals it is common to see robots   working with people. However, given that robots lack the intelligence to   respond to their more dynamic human partners, the two work   independently on tasks best suited to their individual capabilities. In   nearly every industry, this ?either/or? tasking of people and robots   results in production inefficiency. This project envisioned robots that   are capable of working collaboratively and flexibly with people, as the   best human teammates do, to achieve what neither robots or humans can  do  alone. On an automotive assembly line, for example, a robot capable  of  anticipating a person?s needs and consequently providing the right   materials at the right time can enhance human capability and improve   productivity. It is challenging , however, for a machine to monitor a   human?s real-time progress through a plan. Prior activity recognition   approaches are designed and tuned for specific motions or tasks, and in   most scenarios no existing single technique provides accurate   predictions over short- and long-time horizons. The robot must predict   detailed space-time trajectories of human actions for short and long   timescales (&lt;1s to 10-20s) to react appropriately. This project aimed   to improve prediction of human behavior by explicitly modeling and   exploiting proven mechanisms of effective team coordination, including   anticipatory signals of human motion, motion and task-based statistical   models of human behavior, and communication strategies to develop and   maintain common understanding among team members. \n\nThe first step   in the project aimed to develop data-driven approaches that  synthesized  anticipatory knowledge of both human motions and subsequent  action  steps in order to predict in real-time the intended target of a  human  performing a reaching motion.  The techniques for predicting  human arm  reaching motions and human walking motion achieved over prior  techniques  in early prediction, achieving 70% or higher correct  classification on  average for the first third of the trajectory. \n\nA  variety of  human motion prediction approaches, including the  aforementioned  techniques are often designed for specific types of  tasks or motions,  and thus do not generalize well. Furthermore, it is  not always obvious  which of these methods is appropriate for a given  task, making human  motion prediction difficult to implement in  practice. We addressed this  problem by introducing a multiple-predictor  system (MPS) for human  motion prediction. In our approach, the system  learns directly from task  data in order to determine the most favorable  parameters for each  implemented prediction method and which  combination of these predictors  to use. Our implementation consists of  three complementary methods:  velocity-based position projection, time  series classification, and  sequence prediction. We describe the process  of forming the MPS and our  evaluation of its performance against the  individual methods in terms of  accuracy of predictions of human  position over a range of look-ahead  time values. We reported that our  method leads to a reduction in mean  error of 18.5%, 28.9%, and 37.3%  when compared with the three individual  methods, respectively.\n\nFinally,  we utilized the  multiple-prediction system within a human-aware  robotic system with  single-axis mobility that incorporated both  predictions of human motion  and planning in time to execute efficient  and safe motions during  automotive final assembly. We evaluated our  system in simulation against  three alternative methods, including a  baseline approach emulating the  behavior of standard safety systems in  factories today. We also assessed  the system within a factory test  environment. Through both live  demonstration and results from simulated  experiments, we demonstrated  that our approach produces statistically  significant improvements in  quantitative measures of safety and fluency  of interaction.\n\n\t\t\t\t\tLast Modified: 05/25/2021\n\n\t\t\t\t\tSubmitted by: Julie Shah"
 }
}