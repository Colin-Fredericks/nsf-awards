{
 "awd_id": "1447449",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: F: DKA: CSD: Human and Machine Co-Processing",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 1396830.0,
 "awd_amount": 1396830.0,
 "awd_min_amd_letter_date": "2014-08-25",
 "awd_max_amd_letter_date": "2018-11-09",
 "awd_abstract_narration": "Human experts are crucial to data analysis. Their roles include sifting through large datasets to facilitate search, retrieval, and machine learning. Humans often perform much better than machines at such tasks, but the speed and capacity of human experts is a limiting factor in the human-machine co-processing.  This project is addressing two aspects of human-machine co-processing:  winnowing Big Data to produce manageable subsets for human expert analysis, and machine learning algorithms that learn efficiently from human experts with a minimal amount of human interaction.  This has a wide range of applications; to ensure broad applicability of the results the project is evaluating the techniques in multiple domains: cognitive science, large-scale astronomical data analysis, and experimental design in materials science.\r\n\r\nThe approach used for data winnowing is based on developing predictive models and identifying data that does not fit the models.  A key research challenge is non-stationary environments:  the underlying model changes over time.  Preliminary work shows promise on selection from a finite set of models, and new work investigates more flexible parametric models. The active learning task uses the multi-armed bandit problem to model identify which features have the greatest impact on human decisions.  This task also investigates learning from comparisons/rankings rather than predictions; conjecturing that there may exist low-dimensional structure governing human reasoning and decision-making that enables learning with significantly fewer comparisons than might otherwise be required.  A common theme in both tasks is ensuring computational complexity is low enough to facilitate real-time interactions with human experts in spite of the volume of data. This is achieved using bounded approximations and convex relaxations of the optimization programs used to guide the interaction.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Nowak",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Robert D Nowak",
   "pi_email_addr": "rdnowak@wisc.edu",
   "nsf_id": "000338270",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Stephen",
   "pi_last_name": "Wright",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Stephen J Wright",
   "pi_email_addr": "swright@cs.wisc.edu",
   "nsf_id": "000485636",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rebecca",
   "pi_last_name": "Willett",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Rebecca M Willett",
   "pi_email_addr": "willett@g.uchicago.edu",
   "nsf_id": "000312123",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537061607",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 1396830.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The major outcomes of this project were the development of theory and methods for big data analysis which account explicitly for human-machine interactions. The project developed scalable online data processing algorithms that winnow large datasets to produce smaller subsets of the most important or informative data, for presentation to expert human analysts. New theory and algorithms that enable machines to learn efficiently from human experts, using a minimal amount of human interaction, were also developed in this project. These models inform the design of better algorithms for data processing. The work in this project solved challenging mathematical problems in optimization and machine learning;&nbsp;</span></p>\n<p><span><em>Data Thinning in Non-Stationary Environments. </em>New theory and methods were developed for extracting small amounts of critical data from data streams or large datasets and referring them to human experts for further analysis. Extraction of irrelevant data facilitates human analysts and accelerates the discovery process. Rather than compute simple summary statistics for an entire dataset, the methods developed in the project adapt the data-thinning strategy as the data environment evolves and as feedback is received from the human experts. The methods are robust to the presence of unknown dynamics in the distribution of the data and to missing, corrupted, or adversarial information. A key element data thinning is the detection and localization of times at which the environment or data-generating distribution changes. Major outcomes of this project include novel methods for change point localization in complex settings with strong performance guarantees. <br /></span></p>\n<p><span><em>Active Learning from Human Experts. </em>Theory and methods were developed for crowdsourcing training data <em>actively </em>to a pool of human experts. Rather than randomly selecting training examples for labeling, active crowdsourcing sequentially and adaptively selects the most informative examples, based on information gleaned from the analysis to date. By making optimal use of human expert judgment, these active learning method speeds up the training of a variety of machine learning algorithms.&nbsp;</span></p>\n<p><span><em>Algorithms for Computationally Constrained Settings. </em>Existing methods for data thinning and active learning can require significant computation time. In many important settings, computation time is limited. A significant outcome of the project is faster strategies that are suboptimal but that nevertheless retain key performance guarantees. The project assessed the tradeoffs among various approximations and relaxations, and their impact on the effectiveness of data-thinning and active-learning methods.&nbsp;</span></p>\n<p><em>Optimization Algorithms for Learning. </em>The project developed new algorithms for the optimization problems that arise in learning applications, and new theory about these algorithms. Progress was made in proving complexity bounds for algorithms for nonconvex optimization based on Newton's method and conjugate gradients; convergence rates for randomized coordinate descent methods; and a new variant of Frank-Wolfe that is highly efficient on a variety of learning applications.</p>\n<p><span>The broader impacts of the project range across almost the entire space of big data analysis. Human experts are a part of most data analysis pipelines; this project developed new methods that can leverage their expertise and effort to maximum effect, supercharging their contributions to data analysis. The PIs have collaborated with scientists from astronomy, materials science, cognitive science, and biology in order to transition the new methods into practice. Broader impacts of the project also include education and mentoring: Postdoctoral scholars and graduate students received training in optimization, statistical and online learning theory, and high-dimensional data analysis.&nbsp;</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/10/2019<br>\n\t\t\t\t\tModified by: Robert&nbsp;D&nbsp;Nowak</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe major outcomes of this project were the development of theory and methods for big data analysis which account explicitly for human-machine interactions. The project developed scalable online data processing algorithms that winnow large datasets to produce smaller subsets of the most important or informative data, for presentation to expert human analysts. New theory and algorithms that enable machines to learn efficiently from human experts, using a minimal amount of human interaction, were also developed in this project. These models inform the design of better algorithms for data processing. The work in this project solved challenging mathematical problems in optimization and machine learning; \n\nData Thinning in Non-Stationary Environments. New theory and methods were developed for extracting small amounts of critical data from data streams or large datasets and referring them to human experts for further analysis. Extraction of irrelevant data facilitates human analysts and accelerates the discovery process. Rather than compute simple summary statistics for an entire dataset, the methods developed in the project adapt the data-thinning strategy as the data environment evolves and as feedback is received from the human experts. The methods are robust to the presence of unknown dynamics in the distribution of the data and to missing, corrupted, or adversarial information. A key element data thinning is the detection and localization of times at which the environment or data-generating distribution changes. Major outcomes of this project include novel methods for change point localization in complex settings with strong performance guarantees. \n\n\nActive Learning from Human Experts. Theory and methods were developed for crowdsourcing training data actively to a pool of human experts. Rather than randomly selecting training examples for labeling, active crowdsourcing sequentially and adaptively selects the most informative examples, based on information gleaned from the analysis to date. By making optimal use of human expert judgment, these active learning method speeds up the training of a variety of machine learning algorithms. \n\nAlgorithms for Computationally Constrained Settings. Existing methods for data thinning and active learning can require significant computation time. In many important settings, computation time is limited. A significant outcome of the project is faster strategies that are suboptimal but that nevertheless retain key performance guarantees. The project assessed the tradeoffs among various approximations and relaxations, and their impact on the effectiveness of data-thinning and active-learning methods. \n\nOptimization Algorithms for Learning. The project developed new algorithms for the optimization problems that arise in learning applications, and new theory about these algorithms. Progress was made in proving complexity bounds for algorithms for nonconvex optimization based on Newton's method and conjugate gradients; convergence rates for randomized coordinate descent methods; and a new variant of Frank-Wolfe that is highly efficient on a variety of learning applications.\n\nThe broader impacts of the project range across almost the entire space of big data analysis. Human experts are a part of most data analysis pipelines; this project developed new methods that can leverage their expertise and effort to maximum effect, supercharging their contributions to data analysis. The PIs have collaborated with scientists from astronomy, materials science, cognitive science, and biology in order to transition the new methods into practice. Broader impacts of the project also include education and mentoring: Postdoctoral scholars and graduate students received training in optimization, statistical and online learning theory, and high-dimensional data analysis. \n\n \n\n\t\t\t\t\tLast Modified: 12/10/2019\n\n\t\t\t\t\tSubmitted by: Robert D Nowak"
 }
}