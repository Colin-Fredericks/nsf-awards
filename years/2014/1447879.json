{
 "awd_id": "1447879",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: F: DKA: CSD: DKM: Theory and Algorithms for Processing Data with Sparse and Multilinear Structure",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2014-10-01",
 "awd_exp_date": "2019-09-30",
 "tot_intn_awd_amt": 949011.0,
 "awd_amount": 949011.0,
 "awd_min_amd_letter_date": "2014-08-25",
 "awd_max_amd_letter_date": "2018-08-22",
 "awd_abstract_narration": "Tensors, or multidimensional array structures, naturally arise in big data applications such as psychometrics, multimedia, social media, genomics, neuroimaging, geospatial data, and turbulent flow simulations.  Tensors in these applications have massive amounts of data and are difficult to store, transmit, compute with, and analyze.  To perform these tasks successfully it is crucial to discover and utilize relevant and informative structure within the data, which, in the tensor context, often has the form of a decomposition or factorization into a relatively small number of simpler constituents.  Unfortunately, compared to the simpler matrix case, existing mathematical theory and computational tools for tensors are severely limited, and do not meet the needs of big data applications.  The broad goal of this project is to close this theoretical and practical gap in tools for tensors for big data.  Because of the fundamental and ubiquitous role of tensors in Big Data, the results of this research have the potential to impact every field in which big data is of interest.  In particular, the new tools and methodology have the potential to enable new fundamental discoveries in neuroscience, with important benefits to human health.\r\n\r\nMore specifically, this research aims for computationally efficient algorithms with theoretical performance guarantees.  The work emphasizes highly scalable online and distributed versions, approaching the fundamental limits. Approaches include relaxations to achieve low rank decomposition, identifying fundamental limits for compressed sensing, and consideration of practical issues such as noisy data.   These algorithms are validated on big data applications in multimodality functional neuroimaging and neuroscience.  As it draws on and includes mathematics, computer science, engineering, statistics, and neuroscience, this research is highly multidisciplinary.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yoram",
   "pi_last_name": "Bresler",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yoram Bresler",
   "pi_email_addr": "ybresler@uiuc.edu",
   "nsf_id": "000463491",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Marius",
   "pi_last_name": "Junge",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Marius Junge",
   "pi_email_addr": "mjunge@illinois.edu",
   "nsf_id": "000302225",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yihong",
   "pi_last_name": "Wu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yihong Wu",
   "pi_email_addr": "yihong.wu@yale.edu",
   "nsf_id": "000656290",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kiryung",
   "pi_last_name": "Lee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kiryung Lee",
   "pi_email_addr": "lee.8763@osu.edu",
   "nsf_id": "000673077",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "CSL 1308 W. Main St",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618012307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "125300",
   "pgm_ele_name": "OFFICE OF MULTIDISCIPLINARY AC"
  },
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  },
  {
   "pgm_ref_code": "8251",
   "pgm_ref_txt": "Math Sci Innovation Incubator"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 949011.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project addressed timely and fundamental problems of statistical estimation in large-scale (big) data and high-dimensional problems with underlying parsimonious structure. Such structure may be due to the mechanism of the data generation, including the physics of the observed phenomenon or the sensor in inverse problems; or the nature of social interaction expressed in social networks with community structures; or the interest in learning about a particular property of the data as in entropy estimation. These parsimonious structures enable reliable inferences with far fewer observations or less expensive sensors than otherwise possible. However, how to do this, or even tell how well it can be done in principle, requires extending existing theory, because it corresponds to combinatorial or highly non-linear and non-convex mathematical and computational problems. The project addressed several such open problems, elucidating the fundamental limits in these problems that cannot be overcome by any method, and computationally efficient algorithms that scale to big data with provably optimal performance, and theoretical guarantees.</p>\n<p>One class of results are theory and computational algorithms for multilinear inverse problems, in which observations depend on the tensor products of vectors consisting of unknown variables. Effective solutions must use both separability into rank-1 tensors and additional structural assumptions on unknown variables. Any reconstruction problem with uncertainty or errors in the system model, which is common in practice, belongs to this category. &nbsp;A unified framework with conditions for the unique identification of solutions was obtained and presented in the context of specific practical applications, along with a suite of scalable optimization algorithms backed by rigorous performance guarantees. Importantly, these achieved for the first time so-called \"order optimality\" up to a logarithmic factor compared to the fundamental limits, or improved (in order) on the best-known results.</p>\n<p>Data-driven procedures were developed for estimating low dimensional functionals of high dimensional distributions, such as entropy, based on a combination of information theoretic and approximation theoretic techniques. This also led to new computationally and statistically effective methods for the classical and fundamental problem of species prediction -- &nbsp;extrapolating the number of unseen new species from a limited number of data samples.</p>\n<p>&nbsp;A new method \"diagonal-less SVD\" was developed, which is useful and (provably) optimal for computing the singular value decomposition for a matrix with very asymmetric aspect ratio and heterogeneous noise. One application of this methodology is tensor PCA, a key procedure in big data analysis, where the flattened 3-tensor has dimension n x n^2, and is especially amenable to this approach.</p>\n<p>The research also produced provable algorithms for the generalized method of moments (GMM): one of the most widely used methods in econometrics and statistics for parameter estimation. The optimization in GMM is difficult, with previous (heuristic-based) methods performing poorly. For the important case of mixture models, the algorithm developed in this project solves GMM exactly and efficiently, with proven statistical optimality for the first time.</p>\n<p>Targeting statistical inference on large networks, and in particular estimating the community structure, information-theoretic techniques were developed to determine the fundamental limits, and efficient algorithms such as semidefinite relaxation and message passing were thoroughly analyzed.</p>\n<p>Fundamental mathematical results of independent interest were obtained, including generalization of the sparsity model in a collection of Banach spaces including infinite-dimensional cases, and accompanying dimensionality reduction theory. Another such result is an extension to the classical geometric-arithmetic mean inequality, which indicates, for example, that while avoiding repetition in recursive algorithms usually improves performance, there are some intermediate scenarios where a little repetition is useful in algorithms such as the gradient descent.</p>\n<p>The results of the project have been disseminated to the scientific community via refereed publications in top venues, numerous invited presentations world-wide, and posting of papers&nbsp;and PhD theses on public repositories. The project also supported cross-institution and international research collaborations.</p>\n<p>The project contributed to the mentoring and training of multiple PhD students in data science, and in particular on algorithms for solving challenging large scale nonlinear and nonconvex inverse problems, and the cutting-edge of high-dimensional statistics and information theory. Student achievements include multiple best paper awards and publications in the top-tier journals and conferences. The PIs also developed and offered a set of new courses on statistics, data science, and machine learning, contributing to interdisciplinary education and research.</p>\n<p>The project results are expected to impact many applications areas. Results for bilinear inverse problems have applications in science, engineering, and medicine, including astronomical imaging and radio-telescopy, remote sensing, wireless communications, seismic exploration, fluorescence microscopy, and medical imaging. The results on GMM estimation have applications in econometrics and statistics, those on tensor SVD have applications in big data analytics, such as in global climate and weather prediction. The results on species prediction, have numerous high impact applications such as natural language processing, computational genomics, and the monitoring of the earth?s biodiversity.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/08/2019<br>\n\t\t\t\t\tModified by: Yoram&nbsp;Bresler</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project addressed timely and fundamental problems of statistical estimation in large-scale (big) data and high-dimensional problems with underlying parsimonious structure. Such structure may be due to the mechanism of the data generation, including the physics of the observed phenomenon or the sensor in inverse problems; or the nature of social interaction expressed in social networks with community structures; or the interest in learning about a particular property of the data as in entropy estimation. These parsimonious structures enable reliable inferences with far fewer observations or less expensive sensors than otherwise possible. However, how to do this, or even tell how well it can be done in principle, requires extending existing theory, because it corresponds to combinatorial or highly non-linear and non-convex mathematical and computational problems. The project addressed several such open problems, elucidating the fundamental limits in these problems that cannot be overcome by any method, and computationally efficient algorithms that scale to big data with provably optimal performance, and theoretical guarantees.\n\nOne class of results are theory and computational algorithms for multilinear inverse problems, in which observations depend on the tensor products of vectors consisting of unknown variables. Effective solutions must use both separability into rank-1 tensors and additional structural assumptions on unknown variables. Any reconstruction problem with uncertainty or errors in the system model, which is common in practice, belongs to this category.  A unified framework with conditions for the unique identification of solutions was obtained and presented in the context of specific practical applications, along with a suite of scalable optimization algorithms backed by rigorous performance guarantees. Importantly, these achieved for the first time so-called \"order optimality\" up to a logarithmic factor compared to the fundamental limits, or improved (in order) on the best-known results.\n\nData-driven procedures were developed for estimating low dimensional functionals of high dimensional distributions, such as entropy, based on a combination of information theoretic and approximation theoretic techniques. This also led to new computationally and statistically effective methods for the classical and fundamental problem of species prediction --  extrapolating the number of unseen new species from a limited number of data samples.\n\n A new method \"diagonal-less SVD\" was developed, which is useful and (provably) optimal for computing the singular value decomposition for a matrix with very asymmetric aspect ratio and heterogeneous noise. One application of this methodology is tensor PCA, a key procedure in big data analysis, where the flattened 3-tensor has dimension n x n^2, and is especially amenable to this approach.\n\nThe research also produced provable algorithms for the generalized method of moments (GMM): one of the most widely used methods in econometrics and statistics for parameter estimation. The optimization in GMM is difficult, with previous (heuristic-based) methods performing poorly. For the important case of mixture models, the algorithm developed in this project solves GMM exactly and efficiently, with proven statistical optimality for the first time.\n\nTargeting statistical inference on large networks, and in particular estimating the community structure, information-theoretic techniques were developed to determine the fundamental limits, and efficient algorithms such as semidefinite relaxation and message passing were thoroughly analyzed.\n\nFundamental mathematical results of independent interest were obtained, including generalization of the sparsity model in a collection of Banach spaces including infinite-dimensional cases, and accompanying dimensionality reduction theory. Another such result is an extension to the classical geometric-arithmetic mean inequality, which indicates, for example, that while avoiding repetition in recursive algorithms usually improves performance, there are some intermediate scenarios where a little repetition is useful in algorithms such as the gradient descent.\n\nThe results of the project have been disseminated to the scientific community via refereed publications in top venues, numerous invited presentations world-wide, and posting of papers and PhD theses on public repositories. The project also supported cross-institution and international research collaborations.\n\nThe project contributed to the mentoring and training of multiple PhD students in data science, and in particular on algorithms for solving challenging large scale nonlinear and nonconvex inverse problems, and the cutting-edge of high-dimensional statistics and information theory. Student achievements include multiple best paper awards and publications in the top-tier journals and conferences. The PIs also developed and offered a set of new courses on statistics, data science, and machine learning, contributing to interdisciplinary education and research.\n\nThe project results are expected to impact many applications areas. Results for bilinear inverse problems have applications in science, engineering, and medicine, including astronomical imaging and radio-telescopy, remote sensing, wireless communications, seismic exploration, fluorescence microscopy, and medical imaging. The results on GMM estimation have applications in econometrics and statistics, those on tensor SVD have applications in big data analytics, such as in global climate and weather prediction. The results on species prediction, have numerous high impact applications such as natural language processing, computational genomics, and the monitoring of the earth?s biodiversity.\n\n \n\n\t\t\t\t\tLast Modified: 11/08/2019\n\n\t\t\t\t\tSubmitted by: Yoram Bresler"
 }
}