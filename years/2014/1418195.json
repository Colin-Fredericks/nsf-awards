{
 "awd_id": "1418195",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Harnessing Scalable Libraries for Statistical Computing on Modern Architectures and Bringing Statistics to Large Scale Computing",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Christopher Stark",
 "awd_eff_date": "2014-08-15",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 600000.0,
 "awd_amount": 600000.0,
 "awd_min_amd_letter_date": "2014-08-14",
 "awd_max_amd_letter_date": "2016-08-11",
 "awd_abstract_narration": "This project aims to increase participation in high performance computing (HPC) on medium- to large-scale platforms by the statistics community. Theoretical statisticians potentially have strong contributions to science where big data and HPC are involved, yet in implementation on large platforms they face low-level programming languages, libraries, and runtime environments that pose a high enough barrier to prevent most from entering. This project is centered on enabling exactly this community to experiment at a large scale by bridging most of the barriers while using state-of-the-art approaches from the HPC community. Broader impacts of this research include opening a new avenue for HPC scalable software reuse by the statistics and the data science communities, thus providing additional and more data-oriented feedback to HPC software research. Further, an HPC-engaged statistics community can bring statistical science to modern issues in supercomputing that are increasingly in need of statistical thinking for quantifying uncertainty.\r\n\r\nThe open source R programming language and environment for statistical computing is an ideal vehicle for the project as it currently dominates new work in statistics and it is widely used and rising in popularity in many other data-enabled science communities. This project will connect the R language to highly scalable HPC libraries at interfaces that make long-term sense and in a way that in most cases requires no change from current programming practice. In addition, ease-of-use components will be developed inside R for intuitive use of these libraries for big data input and data manipulation on large computing platforms and to bridge HPC runtime environments. Outreach consisting of documentation, examples, a schedule of tutorials at a number of key conferences, and workshops will be used to bring the results of this project to the statistics and other data-enabled science communities.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "George",
   "pi_last_name": "Ostrouchov",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "George Ostrouchov",
   "pi_email_addr": "ostrouchovg@utk.edu",
   "nsf_id": "000496527",
   "pi_start_date": "2014-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Tennessee Knoxville",
  "inst_street_address": "201 ANDY HOLT TOWER",
  "inst_street_address_2": "",
  "inst_city_name": "KNOXVILLE",
  "inst_state_code": "TN",
  "inst_state_name": "Tennessee",
  "inst_phone_num": "8659743466",
  "inst_zip_code": "379960001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "TN02",
  "org_lgl_bus_name": "UNIVERSITY OF TENNESSEE",
  "org_prnt_uei_num": "LXG4F9K8YZK5",
  "org_uei_num": "FN2YCS2YAUW3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Tennessee Knoxville",
  "perf_str_addr": "1 Circle Park",
  "perf_city_name": "Knoxville",
  "perf_st_code": "TN",
  "perf_st_name": "Tennessee",
  "perf_zip_code": "379960003",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "TN02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "125300",
   "pgm_ele_name": "OFFICE OF MULTIDISCIPLINARY AC"
  },
  {
   "pgm_ele_code": "689200",
   "pgm_ele_name": "CI REUSE"
  },
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8084",
   "pgm_ref_txt": "CDS&E"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 440000.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 85000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 75000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project made notable contributions to open source software for statistical computing research on medium to large supercomputing systems. Several software packages were developed and jointly released as pbdR-1.0. The latest package versions and documentation are available on the web site <a href=\"https://pbdr.org\" target=\"_blank\">https://pbdr.org</a>, which links to open source repositories on <a href=\"https://github.com/rbigdata\" target=\"_blank\">GitHub</a> and <a href=\"https://cran.r-project.org/mirrors.html\" target=\"_blank\">CRAN</a> as well as to build scripts for <a href=\"https://hub.docker.com/u/rbigdata/\" target=\"_blank\">Docker</a> and <a href=\"https://github.com/RBigData/singularity\" target=\"_blank\">Singularity</a>.</p>\n<p>An independent evaluation and comparison with other linear algebra (LA) based analytics software on medium systems [1] notes that pbdR \"... outperformed all the other systems in almost all cases on dense data.\"&nbsp; and that \"Overall, pbdR is best suited to users who want to rapidly prototype new LA based analysis algorithms at scale.\" Further testament to project success is early technology transfer of pbdR software to the <a href=\"https://www.cray.com/products/analytics\" target=\"_blank\">Cray Urika-CS AI and Analytics Suite</a>, the analytics software stack on Cray's supercomputing platforms.</p>\n<p>The software contributions include new R packages as well as updates to previously released packages, all available from <a href=\"https://pbdr.org\" target=\"_blank\">https://pbdr.org</a>. The new packages, developed specifially under this project, fall broadly into three categories:<em></em></p>\n<p><em>A Client-Server Interface</em>: Data analysis is a discovery process that is best prototyped in an interactive computing environment. HPC and all pbdR infrastructure so far have been for batch computing. To reconcile the two approaches, we built packages for an interactive client-server environment that is powered by pbdR scalable statistical computing infrastructure. It has three major components that (1) allow one R session to control another R session (remoter), (2) high-level asynchronous messaging for distributed applications (pbdZMQ), and (3) the client-server framework that starts a collection of cooperating R sessions and uses the first two components to control and communicate with the server sessions. The high-level messaging component (pbdZMQ) was also adopted by the immensely popular Jupyter notebook for its connection to R.<em></em></p>\n<p><em>Parallel Data Input</em>: The package pbdIO provides chunking options for reading large arrays or large collections of files from parallel file systems into the collective distributed memory of a cluster computer. The ability to read different files or portions of files by several processors simultaneously speeds up what is often the slowest step in the analysis of big data. Two more packages intended for specific binary data formats common in simulation science were developed: pbdNCDF4 is for reading NetCDF4 format binary files, which are common in climate and environmental sciences; pbdADIOS reads ADIOS bp format binary files, which are popular in several simulation science applications on supercomputing platforms.<em></em></p>\n<p><em>pbdR Installer and Containers</em>: While complex software installation is usually handled by systems administrators, statistical computing software is often not familiar to systems administrators. We developed a <a href=\"https://pbdr.org/releases/\" target=\"_blank\">pbdR installer</a> that automates this process on most platforms. We also developed <a href=\"https://hub.docker.com/u/rbigdata/\" target=\"_blank\">Docker containers</a> that enable installation of the full pbdR environment on Docker enabled platforms. These are usually cloud computing or personal computing platforms where the goals are primarily development and training in building scalable R analytics. We also provided <a href=\"https://github.com/RBigData/singularity\" target=\"_blank\">Singularity scripts</a>, where the goals are scaling and production on supercomputing platforms.</p>\n<p>One of the goals of the project was software reuse. The new packages pbdZMQ, pbdNCDF4, and pbdADIOS all incoporate scalable software developed by other communities, which we make available with R convenience and a simplified syntax that is made possible by R intelligence (ability to infer parameters from context and metadata). These packages are new additions and continue the project philosophy of not reinventing the wheel and introducing HPC standards when this makes sense. <br /><br />Outreach to the statistics and other data science communities over the five year span of the project took the form of 11 half-day to full-day tutorials and 12 regular presentations at national and international venues including the Joint Statistical Meetings, International Statistical Institute World Statistics Congress, and useR! - International R User Conference. Most presentations were invited and included keynotes at the National Institute of Standards and Technology and at the First Workshop for High Performance Technical Computing in Dynamic Languages. A presentation at the Intel Developer Conference, held in conjunction with Supercomputing 2016, won the People's Choice Award in the Technical Computing Track.<br /><br />The project also had a mentoring component, which provided support for several graduate students through a graduate research assitantship and several summer interships. The students had access to large computing systems where pbdR project specific as well as other parallel statistical computing components could be used. The students received instruction on the use of these systems and mentoring for their individual research directions. <br /><br /><br />[1] Anthony Thomas, Arun Kumar: A Comparative Evaluation of Systems for Scalable Linear Algebra-based Analytics. Proceedings of the VLDB Endowment, Volume 11, No. 13, September 2018, p. 2168-2182</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/25/2019<br>\n\t\t\t\t\tModified by: George&nbsp;Ostrouchov</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1418195/1418195_10332749_1574659555337_ScreenShot2019-11-25at12.06.01AM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1418195/1418195_10332749_1574659555337_ScreenShot2019-11-25at12.06.01AM--rgov-800width.jpg\" title=\"Example pbdR computation\"><img src=\"/por/images/Reports/POR/2019/1418195/1418195_10332749_1574659555337_ScreenShot2019-11-25at12.06.01AM--rgov-66x44.jpg\" alt=\"Example pbdR computation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A (possibly interactive) pbdR computation with 32 cooperating R sessions running on 8 nodes of a cluster computer with multicore processors and GPUs. Single Program Multiple Data (SPMD) means that the same program works asynchronously in parallel, possibly coupled, on different portions of the data.</div>\n<div class=\"imageCredit\">George Ostrouchov</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">George&nbsp;Ostrouchov</div>\n<div class=\"imageTitle\">Example pbdR computation</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project made notable contributions to open source software for statistical computing research on medium to large supercomputing systems. Several software packages were developed and jointly released as pbdR-1.0. The latest package versions and documentation are available on the web site https://pbdr.org, which links to open source repositories on GitHub and CRAN as well as to build scripts for Docker and Singularity.\n\nAn independent evaluation and comparison with other linear algebra (LA) based analytics software on medium systems [1] notes that pbdR \"... outperformed all the other systems in almost all cases on dense data.\"  and that \"Overall, pbdR is best suited to users who want to rapidly prototype new LA based analysis algorithms at scale.\" Further testament to project success is early technology transfer of pbdR software to the Cray Urika-CS AI and Analytics Suite, the analytics software stack on Cray's supercomputing platforms.\n\nThe software contributions include new R packages as well as updates to previously released packages, all available from https://pbdr.org. The new packages, developed specifially under this project, fall broadly into three categories:\n\nA Client-Server Interface: Data analysis is a discovery process that is best prototyped in an interactive computing environment. HPC and all pbdR infrastructure so far have been for batch computing. To reconcile the two approaches, we built packages for an interactive client-server environment that is powered by pbdR scalable statistical computing infrastructure. It has three major components that (1) allow one R session to control another R session (remoter), (2) high-level asynchronous messaging for distributed applications (pbdZMQ), and (3) the client-server framework that starts a collection of cooperating R sessions and uses the first two components to control and communicate with the server sessions. The high-level messaging component (pbdZMQ) was also adopted by the immensely popular Jupyter notebook for its connection to R.\n\nParallel Data Input: The package pbdIO provides chunking options for reading large arrays or large collections of files from parallel file systems into the collective distributed memory of a cluster computer. The ability to read different files or portions of files by several processors simultaneously speeds up what is often the slowest step in the analysis of big data. Two more packages intended for specific binary data formats common in simulation science were developed: pbdNCDF4 is for reading NetCDF4 format binary files, which are common in climate and environmental sciences; pbdADIOS reads ADIOS bp format binary files, which are popular in several simulation science applications on supercomputing platforms.\n\npbdR Installer and Containers: While complex software installation is usually handled by systems administrators, statistical computing software is often not familiar to systems administrators. We developed a pbdR installer that automates this process on most platforms. We also developed Docker containers that enable installation of the full pbdR environment on Docker enabled platforms. These are usually cloud computing or personal computing platforms where the goals are primarily development and training in building scalable R analytics. We also provided Singularity scripts, where the goals are scaling and production on supercomputing platforms.\n\nOne of the goals of the project was software reuse. The new packages pbdZMQ, pbdNCDF4, and pbdADIOS all incoporate scalable software developed by other communities, which we make available with R convenience and a simplified syntax that is made possible by R intelligence (ability to infer parameters from context and metadata). These packages are new additions and continue the project philosophy of not reinventing the wheel and introducing HPC standards when this makes sense. \n\nOutreach to the statistics and other data science communities over the five year span of the project took the form of 11 half-day to full-day tutorials and 12 regular presentations at national and international venues including the Joint Statistical Meetings, International Statistical Institute World Statistics Congress, and useR! - International R User Conference. Most presentations were invited and included keynotes at the National Institute of Standards and Technology and at the First Workshop for High Performance Technical Computing in Dynamic Languages. A presentation at the Intel Developer Conference, held in conjunction with Supercomputing 2016, won the People's Choice Award in the Technical Computing Track.\n\nThe project also had a mentoring component, which provided support for several graduate students through a graduate research assitantship and several summer interships. The students had access to large computing systems where pbdR project specific as well as other parallel statistical computing components could be used. The students received instruction on the use of these systems and mentoring for their individual research directions. \n\n\n[1] Anthony Thomas, Arun Kumar: A Comparative Evaluation of Systems for Scalable Linear Algebra-based Analytics. Proceedings of the VLDB Endowment, Volume 11, No. 13, September 2018, p. 2168-2182\n\n\t\t\t\t\tLast Modified: 11/25/2019\n\n\t\t\t\t\tSubmitted by: George Ostrouchov"
 }
}