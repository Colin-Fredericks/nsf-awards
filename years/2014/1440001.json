{
 "awd_id": "1440001",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Medium: Collaborative Research: Spatially Coupled Sparse Codes on Graphs - Theory, Practice, and Extensions",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Richard Brown",
 "awd_eff_date": "2014-02-01",
 "awd_exp_date": "2017-04-30",
 "tot_intn_awd_amt": 130691.0,
 "awd_amount": 130691.0,
 "awd_min_amd_letter_date": "2014-03-12",
 "awd_max_amd_letter_date": "2014-03-12",
 "awd_abstract_narration": "This research investigates a new approach to protecting the reliability of digital communication and digital storage systems.  This approach takes advantage of recent work (by the research team and others) that formulates the \"encoding\" and \"decoding\" of data in terms of a novel graphical representation; this formulation has several advantages over existing techniques for insuring data integrity, including better performance at very low power and the absence of an 'error floor', i.e., the ability to consistently (and significantly) lower the decoded error probability with incremental expenditures of power.  The ultimate goal of the research is more reliable delivery of digital data, text, computer files, speech and audio signals, video, etc. - using devices that require less power (and thus have longer battery life) and shorter processing delay.\r\n\r\nMore specifically, the research investigates the use of spatially coupled sparse codes - channel (error control) codes with a sparse parity check representation formed by coupling together a chain of small \"protographs\".  This approach, which was pioneered by the research team in the context of terminated low-density parity check convolutional codes, has recently been shown to possess a unique combination of properties - iterative decoding performance that approaches channel capacity and minimum distance that grows linearly with block length - as the code size gets large.  The research follows four tracks: (1) the design and analysis of low latency/memory decoding strategies; (2) decoded error probability performance guarantees; (3) the development and analysis of spatially coupled sparse codes with algebraic structure; and (4) the application of spatial coupling outside the immediate domain of channel coding, including cooperative diversity, compressed sensing, and multi-terminal source/channel coding.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Joerg",
   "pi_last_name": "Kliewer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Joerg Kliewer",
   "pi_email_addr": "jkliewer@njit.edu",
   "nsf_id": "000501242",
   "pi_start_date": "2014-03-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New Jersey Institute of Technology",
  "inst_street_address": "323 DR MARTIN LUTHER KING JR BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "NEWARK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "9735965275",
  "inst_zip_code": "071021824",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NJ10",
  "org_lgl_bus_name": "NEW JERSEY INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "SGBMHQ7VXNH5"
 },
 "perf_inst": {
  "perf_inst_name": "New Jersey Institute of Technology",
  "perf_str_addr": "323 Doctor Martin Luther",
  "perf_city_name": "Newark",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "071021982",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NJ10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 130691.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">Recently, a new class of protograph-based LDPC convolutional codes, also referred to as <em>spatially coupled (SC) LDPC codes</em>, has been shown to possess an unique combination of desirable asymptotic properties &ndash; <em>capacity achieving </em>iterative decoding performance <em>plus </em>minimum distance growing linearly with block length. As a consequence, codes of practical lengths chosen from this class are the first to promise to achieve near-optimal performance at <em>both </em>low and high signal-to-noise ratios.&nbsp;</p>\n<p>This study has addressed two important issues related to spatially coupled codes. First, it has provided techniques for improving the error floor performance for SC codes. This is relevant as the error floor regime is the typical operating region for a channel code, and any improvement on the residual error probability in this regime has a direct impact on schemes using these codes, as for example flash storage where error probabilities of 10^(-15) and less are desired.</p>\n<p>It is known that under message-passing decoding algorithms, as for example belief propagation (BP) decoding, certain non-codewords result in decoding failures for LDPC codes. Absorbing sets (ABSs) are substructures of the Tanner graph of the code which are responsible for the performance degradation of LDPC codes in the low error rate region. Note that this is typically the region of interest for the practical use of error control codes. Exemplarily, we have focused on so called array-based (AB) SC codes as they represent a particular class of implementation-friendly, quasi-cyclic codes that have excellent performance, in particular for moderate block lengths. We have introduced an analytical approach to find the exact number of ABSs in AB-SC codes. We have found the optimal cutting vector, an important design parameter for SC codes, for AB-SC codes with arbitrary circulant size. Here,&nbsp; optimality is defined in terms of dominant detrimental ABSs. Dominant ABSs are those that occur most frequently at the output of the decoder and &ldquo;dominate&rdquo; the error floor behavior of the code.? We have calculated the average number of ABSs in non-binary AB-SC codes constructed by uninformed (random) assignment of edge labels on top of a binary AB-SC code. Also, we have presented an analytical approach to provably reduce the number of problematic non-binary ABSs in our designed codes. Surprisingly, this can even further reduce the error floor beyond the binary case only with a small increase in fieldsize, for example, when moving from the binary case to GF(3) or GF(4).</p>\n<p class=\"p1\">As a second topic, we also have studied the application of SC-LDGM codes in source compression of binary sources and employed a practically interesting (J,K)-regular SC-LDGM construction based on protographs, which are amenable to efficient implementation. We have demonstrated distortion saturation numerically for these protograph-based code ensembles. To combat the need for very long code lengths, we have proposed a novel low-latency windowed encoding scheme based on guided decimation BP and have shown a distortion performance close to the rate-distortion (RD) bound with moderate latency for the binary symmetric source. To the best of our knowledge, regular SC-LDGM codes are the first regular LDGM constructions that perform close to the RD bound for low complexity encoding and moderate code lengths.</p>\n<p class=\"p4\">Further, this project helped to provide training and professional development to Ph.D. and MS students at both New Mexico State University and the New Jersey Institute of Technology. By integrating some of these research problems and their solutions into the curriculum of the PI&rsquo;s coding graduate class, the project also enabled exposing students to state-of-the-art research questions. The results of this project have been disseminated via publications in journals and presentations at international conferences within the information theory and coding community.</p>\n<p class=\"p4\">&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/06/2017<br>\n\t\t\t\t\tModified by: Joerg&nbsp;Kliewer</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Recently, a new class of protograph-based LDPC convolutional codes, also referred to as spatially coupled (SC) LDPC codes, has been shown to possess an unique combination of desirable asymptotic properties &ndash; capacity achieving iterative decoding performance plus minimum distance growing linearly with block length. As a consequence, codes of practical lengths chosen from this class are the first to promise to achieve near-optimal performance at both low and high signal-to-noise ratios. \n\nThis study has addressed two important issues related to spatially coupled codes. First, it has provided techniques for improving the error floor performance for SC codes. This is relevant as the error floor regime is the typical operating region for a channel code, and any improvement on the residual error probability in this regime has a direct impact on schemes using these codes, as for example flash storage where error probabilities of 10^(-15) and less are desired.\n\nIt is known that under message-passing decoding algorithms, as for example belief propagation (BP) decoding, certain non-codewords result in decoding failures for LDPC codes. Absorbing sets (ABSs) are substructures of the Tanner graph of the code which are responsible for the performance degradation of LDPC codes in the low error rate region. Note that this is typically the region of interest for the practical use of error control codes. Exemplarily, we have focused on so called array-based (AB) SC codes as they represent a particular class of implementation-friendly, quasi-cyclic codes that have excellent performance, in particular for moderate block lengths. We have introduced an analytical approach to find the exact number of ABSs in AB-SC codes. We have found the optimal cutting vector, an important design parameter for SC codes, for AB-SC codes with arbitrary circulant size. Here,  optimality is defined in terms of dominant detrimental ABSs. Dominant ABSs are those that occur most frequently at the output of the decoder and \"dominate\" the error floor behavior of the code.? We have calculated the average number of ABSs in non-binary AB-SC codes constructed by uninformed (random) assignment of edge labels on top of a binary AB-SC code. Also, we have presented an analytical approach to provably reduce the number of problematic non-binary ABSs in our designed codes. Surprisingly, this can even further reduce the error floor beyond the binary case only with a small increase in fieldsize, for example, when moving from the binary case to GF(3) or GF(4).\nAs a second topic, we also have studied the application of SC-LDGM codes in source compression of binary sources and employed a practically interesting (J,K)-regular SC-LDGM construction based on protographs, which are amenable to efficient implementation. We have demonstrated distortion saturation numerically for these protograph-based code ensembles. To combat the need for very long code lengths, we have proposed a novel low-latency windowed encoding scheme based on guided decimation BP and have shown a distortion performance close to the rate-distortion (RD) bound with moderate latency for the binary symmetric source. To the best of our knowledge, regular SC-LDGM codes are the first regular LDGM constructions that perform close to the RD bound for low complexity encoding and moderate code lengths.\nFurther, this project helped to provide training and professional development to Ph.D. and MS students at both New Mexico State University and the New Jersey Institute of Technology. By integrating some of these research problems and their solutions into the curriculum of the PI?s coding graduate class, the project also enabled exposing students to state-of-the-art research questions. The results of this project have been disseminated via publications in journals and presentations at international conferences within the information theory and coding community.\n \n\n\t\t\t\t\tLast Modified: 06/06/2017\n\n\t\t\t\t\tSubmitted by: Joerg Kliewer"
 }
}