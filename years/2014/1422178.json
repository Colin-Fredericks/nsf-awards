{
 "awd_id": "1422178",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: Hybrid Static-Dynamic Analyses for RegionSerializability",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 73727.0,
 "awd_amount": 73727.0,
 "awd_min_amd_letter_date": "2014-08-14",
 "awd_max_amd_letter_date": "2014-08-14",
 "awd_abstract_narration": "Title: SHF: Small: Collaborative Research: Hybrid Static-Dynamic Analyses for Region Serializability\r\n\r\nComputer systems' performance has grown exponentially for decades, enabling advances in science, health, engineering, and other areas. However, due to power, heat, and wire-length limitations, chip manufacturers are now producing microprocessors that have more, instead of faster, computing cores. To scale with this increasingly parallel hardware, software systems must become more parallel. However, writing correct, scalable shared-memory programs is notoriously difficult. A key challenge is that modern programming languages and software and hardware systems provide virtually no guarantees for programs that have a common, hard-to-eliminate behavior called data races -- because no one knows how to provide better guarantees while retaining high performance. As a result, software is difficult to reason about and fails unexpectedly, leading to high development and testing costs, and imperiling reliability and security of mission- and safety-critical systems. This project provides stronger guarantees for software, achieving reasonable performance on contemporary systems. The intellectual merits are novel program analyses and runtime support that provide strong behavioral guarantees for programs. The project's broader significance and importance are making software systems automatically more reliable; eliminating whole classes of errors; reducing development and testing costs by simplifying programming; and simplifying and reducing costs of program analyses and software system support. Furthermore, the PIs' educational, mentoring, and outreach activities enhance the project by helping educate a diverse workforce of computer scientists trained in the project's work.\r\n\r\nA key contribution is a novel hybrid static-dynamic analysis that enforces a memory model called statically bounded region serializability (SBRS) entirely in software. This memory model is strictly stronger than sequential consistency (SC) and has the potential to be more efficient than SC to enforce, since it allows compilers and hardware to reorder instructions within regions. The project involves designing, implementing, and evaluating (1) three compiler transformations for enforcing SBRS, (2) enhancements to the static-dynamic analysis for performance and flexibility, (3) a novel asynchronous protocol for overlapping concurrency control with program execution while enforcing SBRS, and (4) enhancements to a software transactional memory (STM) system to use the asynchronous protocol to improve scalability. The work provides, for the first time, support for always-on, end-to-end SBRS that is practical, and it makes further advancements in providing high-performance runtime support for atomicity.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Milind",
   "pi_last_name": "Kulkarni",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Milind Kulkarni",
   "pi_email_addr": "milind@purdue.edu",
   "nsf_id": "000549148",
   "pi_start_date": "2014-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "465 Northwestern Ave",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072035",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 73727.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-17b69b32-7fff-b4fe-918a-144b742f5638\">\n<p dir=\"ltr\"><span>As power and heat limitations prevent processor clock rates from increasing and processors necessarily add more cores to improve performance, software systems must become more parallel to achieve performance gains. However, writing parallel software that both performs well and is reliable is inherently challenging. The project developed new approaches for automatically improving the robustness of parallel software systems and for finding bugs automatically in parallel software.</span></p>\n<br />\n<p dir=\"ltr\"><span>The team designed, implemented, and evaluated compiler- and hardware-based techniques for automatically hardening (i.e., eliminating bugs that lead to errors such as crashes) of software systems by enforcing atomicity of executing regions of code and thereby eliminating many erroneous behaviors. The various techniques use a mix of software and hardware approaches that explore the tradeoffs between performance and flexibility. The most practical of the techniques leverages recently available processor support called hardware transactional memory to provide region atomicity efficiently, suggesting that it can be used in practice in production systems.</span></p>\n<br />\n<p dir=\"ltr\"><span>The team designed, implemented, and evaluated techniques that programmers can use when testing software to find hard-to-detect errors called data races that lead to crashes and other erroneous behaviors. These techniques extend predictive analysis to identify more data races than prior techniques have been able to find, while ensuring that reported data races are real and providing performance competitive with widely used commercial data race detectors that cannot \"predict\" data races and thus report fewer data races than the project's techniques.</span></p>\n<br />\n<p dir=\"ltr\"><span>These contributions </span><span>demonstrate how to make software and hardware systems more reliable and less costly, which has the potential for positive impact on all domains that rely on computing, including health, science, engineering, education, transportation, and business.</span></p>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/03/2018<br>\n\t\t\t\t\tModified by: Milind&nbsp;Kulkarni</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nAs power and heat limitations prevent processor clock rates from increasing and processors necessarily add more cores to improve performance, software systems must become more parallel to achieve performance gains. However, writing parallel software that both performs well and is reliable is inherently challenging. The project developed new approaches for automatically improving the robustness of parallel software systems and for finding bugs automatically in parallel software.\n\n\nThe team designed, implemented, and evaluated compiler- and hardware-based techniques for automatically hardening (i.e., eliminating bugs that lead to errors such as crashes) of software systems by enforcing atomicity of executing regions of code and thereby eliminating many erroneous behaviors. The various techniques use a mix of software and hardware approaches that explore the tradeoffs between performance and flexibility. The most practical of the techniques leverages recently available processor support called hardware transactional memory to provide region atomicity efficiently, suggesting that it can be used in practice in production systems.\n\n\nThe team designed, implemented, and evaluated techniques that programmers can use when testing software to find hard-to-detect errors called data races that lead to crashes and other erroneous behaviors. These techniques extend predictive analysis to identify more data races than prior techniques have been able to find, while ensuring that reported data races are real and providing performance competitive with widely used commercial data race detectors that cannot \"predict\" data races and thus report fewer data races than the project's techniques.\n\n\nThese contributions demonstrate how to make software and hardware systems more reliable and less costly, which has the potential for positive impact on all domains that rely on computing, including health, science, engineering, education, transportation, and business.\n\n\n \n\n\t\t\t\t\tLast Modified: 12/03/2018\n\n\t\t\t\t\tSubmitted by: Milind Kulkarni"
 }
}