{
 "awd_id": "1447795",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: F: DKM: Addressing the two V's of Veracity and Variety in Big Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 1000000.0,
 "awd_amount": 1000000.0,
 "awd_min_amd_letter_date": "2014-08-26",
 "awd_max_amd_letter_date": "2016-08-03",
 "awd_abstract_narration": "Data of questionable quality have led to significantly negative economic and social impacts on organizations, leading to overrun in costs, lost revenue, and decreased efficiencies. The issues on data reliability, credibility, and provenance have become even more daunting when dealing with the variety of data, especially data that are not directly collected by an organization, but from the third-party sources such as social media, data brokers, and crowdsourcing. To address such issues, this project aims to develop a Data Valuation Engine (DVE) that solves the critical problem of data reliability, credibility and provenance, and provides accountability and quality processes right from data acquisition. The DVE leverages and innovates techniques in estimation theory, data fusion and machine learning to fill a critical gap in data accountability and quality, thereby providing a transformative step in countering the ubiquitous data quality issues found in almost every application domain from business to environment to health to national security. The DVE will be integrated in the Hadoop ecosystem and will be agnostic to the data source, application or analytics, and provided as a hosted solution to the community.  The user will interact with DVE by providing the data sources and relevant data necessary to solve a problem. \r\n\r\n\r\nThe DVE in this project will be developed in a largely application-independent manner. The key challenges to develop this engine include: (i) How to generate the data quality indication labels to score data sources and the content of data based on various factors such as reliability, credibility, uncertainty and confidence? (ii) How to integrate data from various sources with different labeled scores? (iii) How to robustly evaluate the proposed engine in a broad spectrum of applications that serve as a proxy of a variety of real-world scenarios? The research plan has been designed to synergistically address the above challenges with a robust evaluation plan. Given the generality of the proposed methods, models and system, the project will potentially impact variety of applications of science, engineering, and social science and have broad environmental, economic, and health benefits. The PIs will release open source software and applicable data. The PIs will also provide a hosted DVE platform for a broad user and participant base. This project is also providing students with greater exposure to the areas of big data analytics, cloud computing, data fusion and data mining, both in courses and research experiences.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nitesh",
   "pi_last_name": "Chawla",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nitesh Chawla",
   "pi_email_addr": "nchawla@nd.edu",
   "nsf_id": "000484327",
   "pi_start_date": "2014-08-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Thanuka",
   "pi_last_name": "Wickramarathne",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Thanuka L Wickramarathne",
   "pi_email_addr": "thanuka@uml.edu",
   "nsf_id": "000637030",
   "pi_start_date": "2014-08-26",
   "pi_end_date": "2016-08-03"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Dong",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dong Wang",
   "pi_email_addr": "dwang24@illinois.edu",
   "nsf_id": "000672088",
   "pi_start_date": "2014-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Notre Dame",
  "inst_street_address": "940 GRACE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "NOTRE DAME",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "5746317432",
  "inst_zip_code": "465565708",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "IN02",
  "org_lgl_bus_name": "UNIVERSITY OF NOTRE DAME DU LAC",
  "org_prnt_uei_num": "FPU6XGFXMBE9",
  "org_uei_num": "FPU6XGFXMBE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Notre Dame",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "465565612",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "IN02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  },
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  },
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 1000000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project developed a <span style=\"left: 373.543px; top: 244.085px; font-size: 16.6043px; font-family: serif; transform: scaleX(1.27836);\">Data Valuation Engine (DVE) </span><span style=\"left: 634.832px; top: 244.085px; font-size: 16.6043px; font-family: serif; transform: scaleX(1.14349);\">that produces data scores about the </span><span style=\"left: 120px; top: 264.01px; font-size: 16.6043px; font-family: serif; transform: scaleX(1.11076);\">sources, as well as overall credibility score about the features or attributes extracted from those sources to</span><span style=\"left: 120px; top: 283.935px; font-size: 16.6043px; font-family: serif; transform: scaleX(1.08727);\">respond  to a solution/objective function. This project posited that it is  critical to build an accurate and relaiable \"small data\" from the \"Big  Data\", where the small data can then be leveraged for</span><span style=\"left: 120px; top: 303.86px; font-size: 16.6043px; font-family: serif; transform: scaleX(1.0945);\"> subsequent data and analytics operations.  Small data can be data abou t</span><span style=\"left: 120px; top: 323.786px; font-size: 16.6043px; font-family: serif; transform: scaleX(1.11019);\">one person (aka quantified self) or relevant data created to respond to a question or hypothesis.  Arguably,</span><span style=\"left: 120px; top: 343.711px; font-size: 16.6043px; font-family: serif; transform: scaleX(1.09453);\"> different questions asked of the Big Data can require a different small data and each of those subsets of data</span><span style=\"left: 120px; top: 363.636px; font-size: 16.6043px; font-family: serif; transform: scaleX(1.11351);\"> have a different overall quality score associated with it based on the sources used and features (attributes)</span><span style=\"left: 120px; top: 383.561px; font-size: 16.6043px; font-family: serif; transform: scaleX(1.08248);\"> derived from those sources.  The small data delivered by DVE is inclusive of the user provided relevant data</span><span style=\"left: 120px; top: 403.486px; font-size: 16.6043px; font-family: serif; transform: scaleX(1.08877);\"> and also contains meta-data such as the source reliability and data credibility along with confidence bounds,</span><span style=\"left: 120px; top: 423.412px; font-size: 16.6043px; font-family: serif; transform: scaleX(1.12352);\">and  overall credibility associated with the features (attributes) and the  record (instance). A number of published works, in the short duration,  have citations in hundreds. <br /></span></p>\n<p>Key outcomes of the project include:</p>\n<p>1)  We built a data scoring module (DSM) in DVE that could jointly estimate   the source reliability and data credibility without knowing either of   them a priori.</p>\n<p>2) We generalized the DSM to explicitly address topic relevance of data and complex dependency between data sources.</p>\n<p>3)  We developed a critical source selection scheme that identifies a set   of critical sources that are both independent and reliable to further   improve the accuracy of the data valuation engine and incorporated this   scoring function within the machine learning framework.</p>\n<p>4) We  built a  hierarchical hypothesis validation and fusion framework that  reliably  validates the truthfulness of high-level hypotheses by fusing   information from low-level claims.</p>\n<p>5)&nbsp; We explicitly explored  the  spatiotemporal and latent decision context to further optimize the   performance of our DVE using interdisciplinary techniques from machine   learning and NLP.</p>\n<p>6) We developed machine learning algorithms  for tackling the challenge of imbalanced data. In particular, we  addressed the challenge that becomes even more pronounced with big data,  namely lack of data and small disjuncts.</p>\n<p><br />7) We advanced the  field of learning from imbalanced data by providing a comprehensive  review, in the context of modern day challenges associated with big  data, that was published in JAIR.&nbsp;</p>\n<p>8) We developed graph learning  algorithms that explicitly addressed the challenge associated with the  \"variety component\" of big data. That is, the learning algorithms  tackled the issue of heterogeneous or multi-modal data, especially when  represented as graphs.</p>\n<p>9) We developed novel algorithms for  temporal learning for data captured from different wearable sensors.  This work addressed the challenge of accurately capturing the small data  associated with an indivdual and learning personalized algorithms to  that individual.</p>\n<p>10) We implemented a novel framework, namely  NPVModel, that suggests the best possible business practice for   analytics tasks or strategy. In this framework, one can unify costs of   model development, external data acquisition, and those of the time   value of predictions; this facilitates the development of strategies   that derive synergy from the appropriate confluence of model development   and external data acquisition.</p>\n<p>11) We implemented a framework to  tackle the problem of unstructured data, as found in online reviews, to  be able to detect fake reviews.</p>\n<p>12) We implemented various  use-cases to tackle the  veracity and variety components of big data in  crowdsensing, social network, healthcare, e-commerece, environmental  science, and education applications.</p>\n<div class=\"yj6qo ajU\">\n<div id=\":20s\" class=\"ajR\"><img class=\"ajT\" src=\"https://ssl.gstatic.com/ui/v1/icons/mail/images/cleardot.gif\" alt=\"\" /></div>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2020<br>\n\t\t\t\t\tModified by: Nitesh&nbsp;Chawla</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project developed a Data Valuation Engine (DVE) that produces data scores about the sources, as well as overall credibility score about the features or attributes extracted from those sources torespond  to a solution/objective function. This project posited that it is  critical to build an accurate and relaiable \"small data\" from the \"Big  Data\", where the small data can then be leveraged for subsequent data and analytics operations.  Small data can be data abou tone person (aka quantified self) or relevant data created to respond to a question or hypothesis.  Arguably, different questions asked of the Big Data can require a different small data and each of those subsets of data have a different overall quality score associated with it based on the sources used and features (attributes) derived from those sources.  The small data delivered by DVE is inclusive of the user provided relevant data and also contains meta-data such as the source reliability and data credibility along with confidence bounds,and  overall credibility associated with the features (attributes) and the  record (instance). A number of published works, in the short duration,  have citations in hundreds. \n\n\nKey outcomes of the project include:\n\n1)  We built a data scoring module (DSM) in DVE that could jointly estimate   the source reliability and data credibility without knowing either of   them a priori.\n\n2) We generalized the DSM to explicitly address topic relevance of data and complex dependency between data sources.\n\n3)  We developed a critical source selection scheme that identifies a set   of critical sources that are both independent and reliable to further   improve the accuracy of the data valuation engine and incorporated this   scoring function within the machine learning framework.\n\n4) We  built a  hierarchical hypothesis validation and fusion framework that  reliably  validates the truthfulness of high-level hypotheses by fusing   information from low-level claims.\n\n5)  We explicitly explored  the  spatiotemporal and latent decision context to further optimize the   performance of our DVE using interdisciplinary techniques from machine   learning and NLP.\n\n6) We developed machine learning algorithms  for tackling the challenge of imbalanced data. In particular, we  addressed the challenge that becomes even more pronounced with big data,  namely lack of data and small disjuncts.\n\n\n7) We advanced the  field of learning from imbalanced data by providing a comprehensive  review, in the context of modern day challenges associated with big  data, that was published in JAIR. \n\n8) We developed graph learning  algorithms that explicitly addressed the challenge associated with the  \"variety component\" of big data. That is, the learning algorithms  tackled the issue of heterogeneous or multi-modal data, especially when  represented as graphs.\n\n9) We developed novel algorithms for  temporal learning for data captured from different wearable sensors.  This work addressed the challenge of accurately capturing the small data  associated with an indivdual and learning personalized algorithms to  that individual.\n\n10) We implemented a novel framework, namely  NPVModel, that suggests the best possible business practice for   analytics tasks or strategy. In this framework, one can unify costs of   model development, external data acquisition, and those of the time   value of predictions; this facilitates the development of strategies   that derive synergy from the appropriate confluence of model development   and external data acquisition.\n\n11) We implemented a framework to  tackle the problem of unstructured data, as found in online reviews, to  be able to detect fake reviews.\n\n12) We implemented various  use-cases to tackle the  veracity and variety components of big data in  crowdsensing, social network, healthcare, e-commerece, environmental  science, and education applications.\n\n\n\n\n\t\t\t\t\tLast Modified: 11/29/2020\n\n\t\t\t\t\tSubmitted by: Nitesh Chawla"
 }
}