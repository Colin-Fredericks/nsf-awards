{
 "awd_id": "1449236",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: By the People, For the People: Community Ratings for App Privacy",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2017-10-31",
 "tot_intn_awd_amt": 148025.0,
 "awd_amount": 148025.0,
 "awd_min_amd_letter_date": "2014-08-20",
 "awd_max_amd_letter_date": "2014-08-20",
 "awd_abstract_narration": "Application stores use sophisticated user interfaces to help users understand the permissions sought by applications. Unfortunately, these interfaces are complex and may fail to address their goal of helping users give informed consent. As a result, users may inadvertently surrender private information or open themselves up to security attacks.\r\n\r\nThis project tackles the problem of improving the nature of information provided by these interfaces. It focuses both on new interface designs that will better represent this information, and on techniques to bootstrap the provision of that information. On the user interface side, it designs new interfaces that help untrained users recognize the security and privacy consequences of the sought permissions. To populate this information, it posits the use of crowdsourcing to obtain information at scale about the suitability of permissions. The goal is to eventually populate an application store with this information to encourage adoption and additional feedback from users. The project will study how effectively and accurately crowdsourcing can be used to gather this information.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shriram",
   "pi_last_name": "Krishnamurthi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shriram Krishnamurthi",
   "pi_email_addr": "sk+17@cs.brown.edu",
   "nsf_id": "000280993",
   "pi_start_date": "2014-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029121910",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 148025.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Every day, literally millions of users worldwide are asked to make decisions about apps and about individual apps' permissions, decisions that have significant impacts on their privacy and more broadly well-being. However, the motivating premise of asking users is false. Users are presented with information and asked to consent, but that is not the same as true informed consent. Not being experts in the meaning of these permissions or their consequences, and being worn down by decision fatigue, users are unable to make sound decisions.</p>\n<p>This project set out to accomplish two tasks. First, it intended to create a mechanism for end-users to provide informed consent to app permission settings on their devices (such as smartphones and tablets). Second, it intended to examine the potential for crowdsourcing to provide this information.</p>\n<p>The project has accomplished both ends. It has explored the use of crowdsourcing and found that the crowd is capable of providing reasonable quality information. This is a useful finding because only automation or the use of large numbers of people can scale the provision of this knowledge, and automation is poor at context and nuance.</p>\n<p>The project has also leveraged this information to build two tools for helping users make decisions about apps. One tool is a privacy-enabled app search engine that ranks apps higher if they are more privacy-protecting. The other is an aid for apps already installed, by indicating which permissions should be turned off. The combination covers both use-cases that a user might encounter.</p>\n<p>The project has also had useful findings that are sub-points to or augmentations of the above. For instance, it has substantially explored the design of user interfaces for presenting rating information about permissions. It finds numerous subtleties, including quite surprising ones, in the design of such an interface, and arrives at designs that pass user interface evaluations. It has also investigated factors that might impact how people perceive and rate apps, such as the role of brands in user perceptions.</p>\n<p>This work is entirely driven by its potential for broader impact. It observes a problem with real-world systems, and identifies two tasks that can help address those problems. It has successfully executed both tasks, resulting in working systems as the manifestation.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/02/2017<br>\n\t\t\t\t\tModified by: Shriram&nbsp;Krishnamurthi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nEvery day, literally millions of users worldwide are asked to make decisions about apps and about individual apps' permissions, decisions that have significant impacts on their privacy and more broadly well-being. However, the motivating premise of asking users is false. Users are presented with information and asked to consent, but that is not the same as true informed consent. Not being experts in the meaning of these permissions or their consequences, and being worn down by decision fatigue, users are unable to make sound decisions.\n\nThis project set out to accomplish two tasks. First, it intended to create a mechanism for end-users to provide informed consent to app permission settings on their devices (such as smartphones and tablets). Second, it intended to examine the potential for crowdsourcing to provide this information.\n\nThe project has accomplished both ends. It has explored the use of crowdsourcing and found that the crowd is capable of providing reasonable quality information. This is a useful finding because only automation or the use of large numbers of people can scale the provision of this knowledge, and automation is poor at context and nuance.\n\nThe project has also leveraged this information to build two tools for helping users make decisions about apps. One tool is a privacy-enabled app search engine that ranks apps higher if they are more privacy-protecting. The other is an aid for apps already installed, by indicating which permissions should be turned off. The combination covers both use-cases that a user might encounter.\n\nThe project has also had useful findings that are sub-points to or augmentations of the above. For instance, it has substantially explored the design of user interfaces for presenting rating information about permissions. It finds numerous subtleties, including quite surprising ones, in the design of such an interface, and arrives at designs that pass user interface evaluations. It has also investigated factors that might impact how people perceive and rate apps, such as the role of brands in user perceptions.\n\nThis work is entirely driven by its potential for broader impact. It observes a problem with real-world systems, and identifies two tasks that can help address those problems. It has successfully executed both tasks, resulting in working systems as the manifestation.\n\n \n\n\t\t\t\t\tLast Modified: 12/02/2017\n\n\t\t\t\t\tSubmitted by: Shriram Krishnamurthi"
 }
}