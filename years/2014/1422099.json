{
 "awd_id": "1422099",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Citizen Science Embedded Assessment",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Robert Russell",
 "awd_eff_date": "2015-01-01",
 "awd_exp_date": "2018-12-31",
 "tot_intn_awd_amt": 299957.0,
 "awd_amount": 299957.0,
 "awd_min_amd_letter_date": "2014-08-15",
 "awd_max_amd_letter_date": "2014-08-15",
 "awd_abstract_narration": "The Citizen Science Embedded Assessment project will explore the use of embedded assessment to measure participant science inquiry skill development within the context of citizen science projects. Citizen science (CS) projects partner volunteers with scientists to participate directly in research endeavors. Embedded assessments (EAs) assess participant skills and performance that are directly integrated and are indistinguishable from day-to-day activities. As such, EAs allow learners to demonstrate their science competencies through tasks that are integrated seamlessly into the learning experience itself. The CS field has a growing inventory of self-assessment tools, however, the evaluation of citizen science (and other informal science projects) using such subjective assessments can be remarkably improved when these are used in combination with objective measures of knowledge, skills or other resources participants gain through their participation. Science skills, such as data collection and analysis, are particularly important for CS projects because of their focus on the scientific process and their need for rigorous data collection. Despite the focus on skill gains, CS projects rarely measure such improvements. Embedded assessments (EAs) offer a critical method for understanding the impacts of these participatory learning environments. The project will develop and field test EAs on citizen science topics with an environmental science focus. It will also design training to support their use by individual projects.\r\n\r\nThe project has three primary research foci: (1) identifying common and unique science inquiry skills targeted by CS projects, and how skills are currently being measured to document project impact; (2) identifying the opportunities and challenges present in developing and administering EA tools customized for CS projects to assess science inquiry skills; and (3) assessing whether EA tools created for a CS project can provide project leaders with a better understanding of their project's impact on participant science inquiry skills. The project will address these questions with a needs assessment of research and evaluation studies within the CS community and case studies to develop and test EAs customized for three identified and interested CS projects.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cathlyn",
   "pi_last_name": "Davis",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Cathlyn M Davis",
   "pi_email_addr": "Cathlyn.Davis@umces.edu",
   "nsf_id": "000476041",
   "pi_start_date": "2014-08-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Karen",
   "pi_last_name": "Peterman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Karen Peterman",
   "pi_email_addr": "karenpetermanphd@gmail.com",
   "nsf_id": "000556467",
   "pi_start_date": "2014-08-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rachel",
   "pi_last_name": "Becker-Klein",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rachel Becker-Klein",
   "pi_email_addr": "rachel@peerassociates.net",
   "nsf_id": "000614063",
   "pi_start_date": "2014-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland Center for Environmental Sciences",
  "inst_street_address": "2020 HORNS POINT RD",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4102212014",
  "inst_zip_code": "216133368",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MD01",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND CENTER FOR ENVIRONMENTAL SCIENCE",
  "org_prnt_uei_num": "",
  "org_uei_num": "JHTYTGKYWLL9"
 },
 "perf_inst": {
  "perf_inst_name": "UMCES Appalachian Laboratory",
  "perf_str_addr": "301 Braddock Road",
  "perf_city_name": "Frostburg",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "215322307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MD06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725900",
   "pgm_ele_name": "AISL"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0414",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001415DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 299957.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-9f39a528-7fff-ee1f-f700-fb891531462c\"> </span></p>\n<p dir=\"ltr\"><strong>Summary</strong></p>\n<p dir=\"ltr\"><span>Citizen science offers an important informal learning approach as it immerses the public directly in scientific research. Such efforts vary in purpose and approach but all require volunteers to be proficient in their targeted science inquiry skills such as asking questions, making observations, and communicating results. Despite this common goal, initial evidence suggests citizen science projects rarely measure volunteers&rsquo; science inquiry skills. Even when they do, they often rely on volunteers&rsquo; self-reports of their proficiency, which may not align with their actual performance.</span></p>\n<p dir=\"ltr\"><span>Embedded assessments offer a critical method for measuring volunteer skills in informal learning venues. They allow learners to demonstrate their science proficiency through tasks that are integrated seamlessly into the learning experience itself. These methods can be performance assessments, in which learners do something to demonstrate their knowledge and skills, and authentic assessments, where the learning tasks mirror real-life problem-solving situations. Despite their benefits, the use of embedded assessment is limited, partially because practitioners lack the experience and expertise to develop and implement these complex tools.</span></p>\n<p dir=\"ltr\"><span>This project sought to deepen understanding of embedded assessment through two concurrent studies: (a) a review across the citizen science field to determine targeted science inquiry skills and assessment of these skills and (b) a pilot-test of embedded assessments that were developed for three existing citizen science projects. The project goals were to develop a deeper understanding of relevant science inquiry skills and issues around assessment of these skills; produce sample embedded assessment tools for a set of science inquiry skills; and describe the process to develop these skill-based embedded assessment tools.</span></p>\n<p dir=\"ltr\"><span><br /></span></p>\n<p dir=\"ltr\"><strong>Intellectual Merit</strong></p>\n<p dir=\"ltr\"><span>The project&rsquo;s review of the field demonstrated that most citizen science projects target a narrow range of skills centered on data collection. Volunteer skills were only infrequently measured using formal robust assessments. This restricted use occurred in part because projects did not have time and staff to conduct assessment and because projects often relied on informal or indirect methods that produced anecdotal data (e.g., observations and conversations lacking protocols). These findings provided clear evidence of the limited breadth and assessment of skills targeted within citizen science. </span><span>The case study research articulated an iterative three-stage process for developing reliable and valid embedded assessments with sufficient flexibility to meet the needs of the three study projects. Using this process, an effective embedded assessment focused on a different science inquiry skill was created and used within the context of each study project. All three demonstrated that this tool can be integrated into existing citizen science activities. Additionally, they all produced evidence of skill learning, and provided critical guidance for refining support of citizen science volunteers. However, this work also indicated that developing embedded assessment requires extensive time and resources, which may not be feasible for many citizen science project staff.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><strong>Broader Impacts</strong></p>\n<p dir=\"ltr\"><span>This project both highlighted and addressed an important gap in measuring and understanding science inquiry skills in authentic and performance-based ways. It demonstrated both the tremendous potential of embedded assessments to advance citizen science practice and informal science learning research, and the need for resources to promote and expand their use. Project findings of process, benefits and challenges of embedded assessments were documented and disseminated through six national and international conferences and meetings, two blog posts, a book chapter (Peterman et al., 2017), a journal manuscript (Stylinski et al., under review), and the informalscience.org website. Additionally, an essay introducing researchers, evaluators and practitioners to embedded assessments was published in the first issue of a new citizen science journal (Becker-Klein et al., 2016), while an invited presentation on embedded assessments was given to a National Academy of Science panel on citizen science. The three participating citizen science projects gained a customized embedded assessment to strengthen their programming and deepen their understanding of volunteer learning. </span><span>This exploratory project also led to a full-scale four-year NSF project to study effective and efficient ways to develop embedded assessment of volunteers&rsquo; skills. Building from this exploratory project, the new study is exploring two collaborative strategies to design and study embedded assessment of participants&rsquo; science skills. One will build on existing procedures to validate volunteers&rsquo; submitted data, while the other will create a small set of embedded assessment activities that can be used by many different citizen science efforts. </span></p>\n<p>&nbsp;</p>\n<p><strong>References Cited</strong></p>\n<p dir=\"ltr\"><span>Becker-Klein, R., Peterman, K., &amp; Stylinski, C. (2016). Embedded assessment as an essential method for understanding public engagement in citizen science. </span><span>Citizen Science: Theory and Practice</span><span>, </span><span>1</span><span>(1).</span></p>\n<p dir=\"ltr\"><span>Peterman, K., Becker-Klein, R., Stylinski, C., &amp; Nelson, A. G. (2017). Exploring embedded assessment to document scientific inquiry skills within citizen science. In </span><span>Citizen Inquiry</span><span> (pp. 81-100). Routledge.</span></p>\n<p><span>Stylinski C., Peterman K., Phillips T., Linhart J. &amp; Becker-Klein R. (</span><span>in review</span><span>) A review of volunteers&rsquo; science Inquiry skills and assessment in citizen science. Citizen Science: Theory and Practice.</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/24/2019<br>\n\t\t\t\t\tModified by: Cathlyn&nbsp;D&nbsp;Stylinski</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nSummary\nCitizen science offers an important informal learning approach as it immerses the public directly in scientific research. Such efforts vary in purpose and approach but all require volunteers to be proficient in their targeted science inquiry skills such as asking questions, making observations, and communicating results. Despite this common goal, initial evidence suggests citizen science projects rarely measure volunteers? science inquiry skills. Even when they do, they often rely on volunteers? self-reports of their proficiency, which may not align with their actual performance.\nEmbedded assessments offer a critical method for measuring volunteer skills in informal learning venues. They allow learners to demonstrate their science proficiency through tasks that are integrated seamlessly into the learning experience itself. These methods can be performance assessments, in which learners do something to demonstrate their knowledge and skills, and authentic assessments, where the learning tasks mirror real-life problem-solving situations. Despite their benefits, the use of embedded assessment is limited, partially because practitioners lack the experience and expertise to develop and implement these complex tools.\nThis project sought to deepen understanding of embedded assessment through two concurrent studies: (a) a review across the citizen science field to determine targeted science inquiry skills and assessment of these skills and (b) a pilot-test of embedded assessments that were developed for three existing citizen science projects. The project goals were to develop a deeper understanding of relevant science inquiry skills and issues around assessment of these skills; produce sample embedded assessment tools for a set of science inquiry skills; and describe the process to develop these skill-based embedded assessment tools.\n\n\nIntellectual Merit\nThe project?s review of the field demonstrated that most citizen science projects target a narrow range of skills centered on data collection. Volunteer skills were only infrequently measured using formal robust assessments. This restricted use occurred in part because projects did not have time and staff to conduct assessment and because projects often relied on informal or indirect methods that produced anecdotal data (e.g., observations and conversations lacking protocols). These findings provided clear evidence of the limited breadth and assessment of skills targeted within citizen science. The case study research articulated an iterative three-stage process for developing reliable and valid embedded assessments with sufficient flexibility to meet the needs of the three study projects. Using this process, an effective embedded assessment focused on a different science inquiry skill was created and used within the context of each study project. All three demonstrated that this tool can be integrated into existing citizen science activities. Additionally, they all produced evidence of skill learning, and provided critical guidance for refining support of citizen science volunteers. However, this work also indicated that developing embedded assessment requires extensive time and resources, which may not be feasible for many citizen science project staff.\n\n \nBroader Impacts\nThis project both highlighted and addressed an important gap in measuring and understanding science inquiry skills in authentic and performance-based ways. It demonstrated both the tremendous potential of embedded assessments to advance citizen science practice and informal science learning research, and the need for resources to promote and expand their use. Project findings of process, benefits and challenges of embedded assessments were documented and disseminated through six national and international conferences and meetings, two blog posts, a book chapter (Peterman et al., 2017), a journal manuscript (Stylinski et al., under review), and the informalscience.org website. Additionally, an essay introducing researchers, evaluators and practitioners to embedded assessments was published in the first issue of a new citizen science journal (Becker-Klein et al., 2016), while an invited presentation on embedded assessments was given to a National Academy of Science panel on citizen science. The three participating citizen science projects gained a customized embedded assessment to strengthen their programming and deepen their understanding of volunteer learning. This exploratory project also led to a full-scale four-year NSF project to study effective and efficient ways to develop embedded assessment of volunteers? skills. Building from this exploratory project, the new study is exploring two collaborative strategies to design and study embedded assessment of participants? science skills. One will build on existing procedures to validate volunteers? submitted data, while the other will create a small set of embedded assessment activities that can be used by many different citizen science efforts. \n\n \n\nReferences Cited\nBecker-Klein, R., Peterman, K., &amp; Stylinski, C. (2016). Embedded assessment as an essential method for understanding public engagement in citizen science. Citizen Science: Theory and Practice, 1(1).\nPeterman, K., Becker-Klein, R., Stylinski, C., &amp; Nelson, A. G. (2017). Exploring embedded assessment to document scientific inquiry skills within citizen science. In Citizen Inquiry (pp. 81-100). Routledge.\n\nStylinski C., Peterman K., Phillips T., Linhart J. &amp; Becker-Klein R. (in review) A review of volunteers? science Inquiry skills and assessment in citizen science. Citizen Science: Theory and Practice.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 01/24/2019\n\n\t\t\t\t\tSubmitted by: Cathlyn D Stylinski"
 }
}