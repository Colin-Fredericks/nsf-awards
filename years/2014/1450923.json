{
 "awd_id": "1450923",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BRAIN EAGER: Flashes of insight: Revealing dynamic mental models during rodent virtual reality foraging",
 "cfda_num": "47.074",
 "org_code": "08090200",
 "po_phone": "7032928167",
 "po_email": "ethiels@nsf.gov",
 "po_sign_block_name": "Edda Thiels",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2014-08-18",
 "awd_max_amd_letter_date": "2014-08-18",
 "awd_abstract_narration": "A primary goal of neuroscience is to understand how the brain works-- not in artificial lab tasks, but when using its full capabilities to thrive in the rigors of the natural environment. Neuroscience has made enormous progress by examining how the brain performs simplified tasks, but these tasks do not expose the richly adaptive dynamics that the brain must use in a changing world. Therefore, the current neuroscientific understanding of the brain is missing fundamental ingredients. The current project begins to fill this gap, providing a new paradigm for the conduct of behavioral neuroscience and offering an unprecedented opportunity to observe the neural computations that solve a complex natural task. Team members will record activity of many neurons in multiple areas of a mouse brain while the mouse is foraging in a virtual reality environment, and develop mathematical models to make sense of the complex data. This research will thereby provide a unique training opportunity for undergraduate and graduate students in both computational and experimental neuroscience. The project results will be widely disseminated by sharing data, computational models, and analysis techniques with the neuroscience community through public data repositories, so conclusions can be replicated and extended. This research will thereby advance society?s goals of understanding the biology of healthy and disordered brains, with the ultimate hope of repairing neurological problems.\r\n\r\n\tExperimenters will train mice to forage in a virtual reality environment, while recording activity from many neurons in four brain areas involved in vision and navigation: visual cortex, entorhinal cortex, posterior parietal cortex and hippocampus. State-of-the-art analysis techniques will be used to describe the mouse's behavior, and to discover neural representations of the internal models that express the animal's beliefs about things that cannot be observed directly in sense data. Finally, the project will uncover how neural representations of critical task variables are communicated and transformed across brain areas, guided by the hidden variable dynamics of the behavioral model. Together, these experiments, theory, and analysis will provide an unprecedented, system-wide understanding of neural computation, ranging from the scale of individual neurons up to a multi-region system. A key quality of the approach is the pervasive influence of theory, both in structuring experiments and dictating analyses. Since the great strength of the human brain is its ability to comprehend the hidden structure in the world, this approach takes an essential step toward unraveling the mysteries of cognition.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "BIO",
 "org_dir_long_name": "Directorate for Biological Sciences",
 "div_abbr": "IOS",
 "org_div_long_name": "Division Of Integrative Organismal Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dora",
   "pi_last_name": "Angelaki",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dora Angelaki",
   "pi_email_addr": "da93@nyu.edu",
   "nsf_id": "000623431",
   "pi_start_date": "2014-08-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Xaq",
   "pi_last_name": "Pitkow",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xaq Pitkow",
   "pi_email_addr": "xaq@cmu.edu",
   "nsf_id": "000674276",
   "pi_start_date": "2014-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Baylor College of Medicine",
  "inst_street_address": "1 BAYLOR PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "HOUSTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7137981297",
  "inst_zip_code": "770303411",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "TX09",
  "org_lgl_bus_name": "BAYLOR COLLEGE OF MEDICINE",
  "org_prnt_uei_num": "FXKMA43NTV21",
  "org_uei_num": "FXKMA43NTV21"
 },
 "perf_inst": {
  "perf_inst_name": "Baylor College of Medicine",
  "perf_str_addr": "One Baylor Plaza, MS:BCM295",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "770303411",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "TX09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "771400",
   "pgm_ele_name": "Modulation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our project has created new experimental and theoretical methods for understanding brain computations while animals perform naturalistic tasks. Our new experimental system allows us to record from the brain of a rodent while we maintain unprecedented control over its sensory environment. We designed and precisely engineered a virtual reality (VR) system for rodents that will enable us to test how the animal navigates. We built a projection system with an immersive spherical screen, and designed a 3D-printed calibration device that functions like a planetarium to provide spots at known visual locations, along with sophisticated calibration software that ensures the projected image matches these target spots. Together, these advances ensure that the animal sees the exact visual features we want for our experiments with state-of-the-art precision. These outcomes will shortly be distributed to the scientific community as open-source calibration software and a 3D-printable calibration device.</p>\n<p>In addition, unlike conventional VR systems currently in neuroscience, we have also created a system that physically moves the animal during its virtual navigation. Previous experiments observed that neural responses of head-fixed animals in VR were inconsistent with neural responses during real physical movements, possibly because they did not experience real movements. We are now excellently situated to test this idea, and other ideas about how the brain combines complex patterns of information from multiple sensory sources.</p>\n<p>Our theoretical outcomes include new methods to model behavior and a new framework for relating neural activity to stimuli and behavior. Our behavioral modelling approach allows us to use an animal&rsquo;s actions to predict the inner beliefs they have about objects or events that are not directly observable but rather must be inferred indirectly. These descriptions provide us a novel set of predictions for neural activity patterns and their dynamics in the brains of behaving animals. To apply these models in practice, we have developed a mathematical framework for relating the modelled beliefs to neural activity. Over the lifetime of the project, we have refined the concepts needed to apply this framework, and built simple example systems where the ground truth is known, validating our method.</p>\n<p>These experimental and theoretical outcomes are general purpose. We have also applied them to our own specific experimental task, catching fireflies in near darkness. We have designed, programmed, and tested the complex 3D visual stimuli that produce the illusion of motion. We have also analyzed the expected dynamics of beliefs during the task, and found that these behavioral models predict previously reported biases in motion perception.</p>\n<p>Overall, we expect that, taken together, our experimental tools, behavioral modelling approach, and data analysis framework will be extremely useful for the next generation of neuroscience experiments that study the computations of large groups of neurons in the brains of animals performing complex, naturalistic tasks. Since there are severe limitations on how we understand brain function in conventional simple tasks, neuroscience dearly needs an approach like ours to understand the complex, adaptive and dynamic brain. By providing tools and paradigms for revealing and interpreting neural activity in the face of natural complexity, our research will thereby advance society&rsquo;s goals of understanding the biology of healthy and disordered human brains, moving toward the ultimate hope of repairing neurological problems.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/15/2016<br>\n\t\t\t\t\tModified by: Dora&nbsp;Angelaki</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOur project has created new experimental and theoretical methods for understanding brain computations while animals perform naturalistic tasks. Our new experimental system allows us to record from the brain of a rodent while we maintain unprecedented control over its sensory environment. We designed and precisely engineered a virtual reality (VR) system for rodents that will enable us to test how the animal navigates. We built a projection system with an immersive spherical screen, and designed a 3D-printed calibration device that functions like a planetarium to provide spots at known visual locations, along with sophisticated calibration software that ensures the projected image matches these target spots. Together, these advances ensure that the animal sees the exact visual features we want for our experiments with state-of-the-art precision. These outcomes will shortly be distributed to the scientific community as open-source calibration software and a 3D-printable calibration device.\n\nIn addition, unlike conventional VR systems currently in neuroscience, we have also created a system that physically moves the animal during its virtual navigation. Previous experiments observed that neural responses of head-fixed animals in VR were inconsistent with neural responses during real physical movements, possibly because they did not experience real movements. We are now excellently situated to test this idea, and other ideas about how the brain combines complex patterns of information from multiple sensory sources.\n\nOur theoretical outcomes include new methods to model behavior and a new framework for relating neural activity to stimuli and behavior. Our behavioral modelling approach allows us to use an animal?s actions to predict the inner beliefs they have about objects or events that are not directly observable but rather must be inferred indirectly. These descriptions provide us a novel set of predictions for neural activity patterns and their dynamics in the brains of behaving animals. To apply these models in practice, we have developed a mathematical framework for relating the modelled beliefs to neural activity. Over the lifetime of the project, we have refined the concepts needed to apply this framework, and built simple example systems where the ground truth is known, validating our method.\n\nThese experimental and theoretical outcomes are general purpose. We have also applied them to our own specific experimental task, catching fireflies in near darkness. We have designed, programmed, and tested the complex 3D visual stimuli that produce the illusion of motion. We have also analyzed the expected dynamics of beliefs during the task, and found that these behavioral models predict previously reported biases in motion perception.\n\nOverall, we expect that, taken together, our experimental tools, behavioral modelling approach, and data analysis framework will be extremely useful for the next generation of neuroscience experiments that study the computations of large groups of neurons in the brains of animals performing complex, naturalistic tasks. Since there are severe limitations on how we understand brain function in conventional simple tasks, neuroscience dearly needs an approach like ours to understand the complex, adaptive and dynamic brain. By providing tools and paradigms for revealing and interpreting neural activity in the face of natural complexity, our research will thereby advance society?s goals of understanding the biology of healthy and disordered human brains, moving toward the ultimate hope of repairing neurological problems.\n\n\t\t\t\t\tLast Modified: 11/15/2016\n\n\t\t\t\t\tSubmitted by: Dora Angelaki"
 }
}