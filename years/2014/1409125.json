{
 "awd_id": "1409125",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC: Medium: Collaborative: Re[DP]: Realistic Data Mining Under Differential Privacy",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2014-08-01",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 273424.0,
 "awd_amount": 328084.0,
 "awd_min_amd_letter_date": "2014-07-25",
 "awd_max_amd_letter_date": "2019-04-23",
 "awd_abstract_narration": "The collection and analysis of personal data about individuals has revolutionized information systems and fueled US and global economies. But privacy concerns regarding the use of such data loom large. Differential privacy has emerged as a gold standard for mathematically characterizing the privacy risks of algorithms using personal data.  Yet, adoption of differentially private algorithms in industry or government agencies has been startlingly rare.  This failure of adoption stems largely from a mismatch between the idealized problem settings considered to date by privacy researchers and the complex real-world workflows needed for mining personal data.  This project will expand the practical usefulness of privacy algorithms, encouraging their use through technology transfer to the US Census and medical researchers at Duke University, and ultimately ensuring privacy protection with increased data sharing and transmission of knowledge.\r\n\r\nThis project aims to systematically study the complete workflow involved in mining personal data, and solve key problems that have diminished usability and prevented widespread deployment of differential privacy. Research activities include developing (i) private algorithms for data preprocessing (cleaning, imputation, and other transformations), (ii) algorithms to support parallel and iterative model selection, (iii) semantically meaningful guidelines for setting privacy policies and utility benchmarks.  Results will guide the design and implementation of a novel web-based framework (DPcomp) for testing and evaluating the deployment of privacy algorithms.  Broader impacts of this project include technology transfer to the US Census and medical researchers at Duke University, and incorporating privacy themes into new undergraduate courses. DPcomp will stimulate interaction between data owners and privacy researchers, and help unearth new research questions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Hay",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Hay",
   "pi_email_addr": "michael@tmlt.io",
   "nsf_id": "000653724",
   "pi_start_date": "2014-07-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Colgate University",
  "inst_street_address": "13 OAK DR",
  "inst_street_address_2": "",
  "inst_city_name": "HAMILTON",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "3152287457",
  "inst_zip_code": "133461386",
  "inst_country_name": "United States",
  "cong_dist_code": "22",
  "st_cong_dist_code": "NY22",
  "org_lgl_bus_name": "COLGATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "D4P7H8NWZER7"
 },
 "perf_inst": {
  "perf_inst_name": "Colgate University",
  "perf_str_addr": "13 Oak Drive",
  "perf_city_name": "Hamilton",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "133461338",
  "perf_ctry_code": "US",
  "perf_cong_dist": "22",
  "perf_st_cong_dist": "NY22",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 273424.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 54660.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-2a0c4183-7fff-0f53-708b-cd4883ee4e63\"> </span></p>\n<p dir=\"ltr\"><span>In this project, we developed tools and software artifacts that bring differential privacy (DP) into the real world by solving the key problems that have so far diminished usability and prevented wide deployment of this powerful privacy paradigm. Our contributions are three-fold. First, we developed </span><span>novel differential privacy algorithms</span><span> that extract the most utility from the data at a given level of privacy loss. These include HDMM, a highly scalable and state-of-the-art DP algorithm for answering sets of counting queries with the least error, PrivateSQL, a first-of-its-kind end-to-end relational database system for DP query answering, PeGaSus, a DP stream processing system targeted to settings like the Internet of Things, and PGM, a highly scalable method for ?inference? to derive a single consistent and constraint-satisfying representation of the input data from a set of noisy measurements. Second, we released </span><span>innovative differential privacy platforms and benchmarks</span><span> to ease the burden of developing DP programs. These include, Ektelo, an open source system whose goal is to simplify and accelerate the development of private, efficient and accurate differentially private algorithms, and DPBench, the first benchmark of DP algorithms and datasets for the task of answering range queries on low dimensional datasets. Third, we created </span><span>usable DP tools for practitioners </span><span>including, DPComp (</span><a href=\"https://www.dpcomp.org/\"><span>https://www.dpcomp.org/</span></a><span>),&nbsp; a web based framework that makes performance of differentially private algorithms accessible to practitioners and researchers, and PSynDB, a web-based tool designed to bring together a number of technologies developed in this project, and to provide an easy-to-use interface allowing novices to load tabular data and generate private synthetic data.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Our research, and the artifacts arising out of it, have had a transformational impact on the field of differential privacy. In addition to several publications in top-tier conferences and journals, our research has helped bring differential privacy (DP) into the real world. Our research on query answering, and HDMM in particular, has helped assist the design of DP algorithms for the release of statistics from the 2020 Decennial Census by the US Census Bureau. HDMM, Ektelo and PrivateSQL are licensed to Tumult Labs, a startup founded by the PIs that helps organizations safely share data using differential privacy. Ektelo has helped inform the design of the next generation open source differential privacy platform being built by OpenDP. PGM was a key technical ingredient in the winning entry to the NIST Differential Privacy Synthetic Data Challenge. PeGaSus was deployed aboard naval vessels in the context of the US Navy?s Trident Warrior 2019 exercise to showcase privacy-preserving technologies in creating sensor-based awareness using the Internet of Things (IoT). DPBench and DPComp have been used by researchers and programmers in organizations like the US Census Bureau, Google, and NIST to understand privacy-utility tradeoffs in DP algorithms.&nbsp;</span></p>\n<p dir=\"ltr\"><span>The project helped train 13 PhD students (including 3 women and 1 person from underrepresented minority groups) at Duke University and University of Massachusetts, Amherst, and 15 undergraduate students (including 5 women and 2 persons from underrepresented minority groups) at Duke, University of Massachusetts, and Colgate. One of the students has gone on to become an Assistant Professor in CS at the University of Waterloo. This project also led to the development of publicly available teaching materials on differential privacy, which include tutorials presented at top-tier database conferences, and day-long bootcamps delivered to employees of federal statistical agencies in the US. </span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/21/2020<br>\n\t\t\t\t\tModified by: Michael&nbsp;Hay</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nIn this project, we developed tools and software artifacts that bring differential privacy (DP) into the real world by solving the key problems that have so far diminished usability and prevented wide deployment of this powerful privacy paradigm. Our contributions are three-fold. First, we developed novel differential privacy algorithms that extract the most utility from the data at a given level of privacy loss. These include HDMM, a highly scalable and state-of-the-art DP algorithm for answering sets of counting queries with the least error, PrivateSQL, a first-of-its-kind end-to-end relational database system for DP query answering, PeGaSus, a DP stream processing system targeted to settings like the Internet of Things, and PGM, a highly scalable method for ?inference? to derive a single consistent and constraint-satisfying representation of the input data from a set of noisy measurements. Second, we released innovative differential privacy platforms and benchmarks to ease the burden of developing DP programs. These include, Ektelo, an open source system whose goal is to simplify and accelerate the development of private, efficient and accurate differentially private algorithms, and DPBench, the first benchmark of DP algorithms and datasets for the task of answering range queries on low dimensional datasets. Third, we created usable DP tools for practitioners including, DPComp (https://www.dpcomp.org/),  a web based framework that makes performance of differentially private algorithms accessible to practitioners and researchers, and PSynDB, a web-based tool designed to bring together a number of technologies developed in this project, and to provide an easy-to-use interface allowing novices to load tabular data and generate private synthetic data. \nOur research, and the artifacts arising out of it, have had a transformational impact on the field of differential privacy. In addition to several publications in top-tier conferences and journals, our research has helped bring differential privacy (DP) into the real world. Our research on query answering, and HDMM in particular, has helped assist the design of DP algorithms for the release of statistics from the 2020 Decennial Census by the US Census Bureau. HDMM, Ektelo and PrivateSQL are licensed to Tumult Labs, a startup founded by the PIs that helps organizations safely share data using differential privacy. Ektelo has helped inform the design of the next generation open source differential privacy platform being built by OpenDP. PGM was a key technical ingredient in the winning entry to the NIST Differential Privacy Synthetic Data Challenge. PeGaSus was deployed aboard naval vessels in the context of the US Navy?s Trident Warrior 2019 exercise to showcase privacy-preserving technologies in creating sensor-based awareness using the Internet of Things (IoT). DPBench and DPComp have been used by researchers and programmers in organizations like the US Census Bureau, Google, and NIST to understand privacy-utility tradeoffs in DP algorithms. \nThe project helped train 13 PhD students (including 3 women and 1 person from underrepresented minority groups) at Duke University and University of Massachusetts, Amherst, and 15 undergraduate students (including 5 women and 2 persons from underrepresented minority groups) at Duke, University of Massachusetts, and Colgate. One of the students has gone on to become an Assistant Professor in CS at the University of Waterloo. This project also led to the development of publicly available teaching materials on differential privacy, which include tutorials presented at top-tier database conferences, and day-long bootcamps delivered to employees of federal statistical agencies in the US. \n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 11/21/2020\n\n\t\t\t\t\tSubmitted by: Michael Hay"
 }
}