{
 "awd_id": "1443046",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF21 DIBBs: STORM: Spatio-Temporal Online Reasoning and Management of Large Data",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924538",
 "po_email": "awalton@nsf.gov",
 "po_sign_block_name": "Amy Walton",
 "awd_eff_date": "2014-11-01",
 "awd_exp_date": "2019-10-31",
 "tot_intn_awd_amt": 1157975.0,
 "awd_amount": 1173975.0,
 "awd_min_amd_letter_date": "2014-08-14",
 "awd_max_amd_letter_date": "2016-08-10",
 "awd_abstract_narration": "A fundamental challenge for many research projects is the ability to handle large quantities of heterogeneous data. Data collected from different sources and time periods can be inconsistent, or stored in different formats and data management systems. Thus, a critical step in many projects is to develop a customized query and analytical engine to translate inputs.  But for each new dataset, or for each new query type or analytic task for an existing dataset, a new query interface or program must be developed, requiring significant investments of time and effort.  This project will develop an automatic engine for searching large, heterogeneous data collections for weather and meteorology, particularly from instruments in the western US, in a regional network called MesoWest. \r\n\r\nThis project develops an automatic query and analytical engine for large, heterogeneous spatial and temporal data. This capability allows users to automatically deploy a query and analytical engine instance over their large, heterogeneous data with spatial and temporal dimensions.  The system supports a simple search-box and map-like query interface that allows numerous powerful analytical queries.  Techniques to make these queries robust, relevant, and highly scalable will be developed.  The project also enables users to execute queries over multiple data sources simultaneously and seamlessly. The goal of the work is to dramatically simplify the management and analysis of large spatio-temporal data at different institutions, groups, and corporations.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Feifei",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Feifei Li",
   "pi_email_addr": "lifeifei@cs.utah.edu",
   "nsf_id": "000598994",
   "pi_start_date": "2014-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Horel",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "John D Horel",
   "pi_email_addr": "john.horel@utah.edu",
   "nsf_id": "000451841",
   "pi_start_date": "2014-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Paul",
   "pi_last_name": "Rosen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Paul Rosen",
   "pi_email_addr": "paul.rosen@utah.edu",
   "nsf_id": "000584395",
   "pi_start_date": "2014-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jeff",
   "pi_last_name": "Phillips",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jeff M Phillips",
   "pi_email_addr": "jeffp@cs.utah.edu",
   "nsf_id": "000610188",
   "pi_start_date": "2014-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "50 S. Central Campus Drive",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841120101",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "152500",
   "pgm_ele_name": "Physical & Dynamic Meteorology"
  },
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  },
  {
   "pgm_ele_code": "807400",
   "pgm_ele_name": "EarthCube"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "4444",
   "pgm_ref_txt": "INTERDISCIPLINARY PROPOSALS"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8048",
   "pgm_ref_txt": "Data Infrstr Bldg Blocks-DIBBs"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 1157975.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project develops an automatic query and analytical engine for large, heterogeneous spatial and temporal data. This capability allows users to automatically deploy a query and analytical engine instance over their large, heterogeneous data with spatial and temporal dimensions. The system supports a simple search-box and map-like query interface that allows numerous powerful analytical queries. Techniques to make these queries robust, relevant, and highly scalable will be developed. The project also enables users to execute queries over multiple data sources simultaneously and seamlessly. The goal of the work is to dramatically simplify the management and analysis of large spatio-temporal data at different institutions, groups, and corporations.</p>\n<p>We have designed and implemented an initial prototype of STORM at www.estorm.org. The system currently supports multiple social media data sources, as well as data from the MesoWest project (weather data). To process large data, we devised novel techniques for online spatial sampling and aggregation, that is able to produce online estimators that continuously produce approximations (for the final exact results) whose approximation quality improves gradually over time. Using this technique, we are able to general kernel density estimate (KDE) in real time over large social media data (such as a large collection of tweets).</p>\n<p>We have also designed and implemented the STORM storage engine based on MongoDB. Due to the large amount of data we have dealt with. We designed and implemented novel indexing structures that sit on top of MongoDB that's able to answer spatio-temporal range queries efficiently.</p>\n<p>We also introduced a visualization layer that supports a number of visualization modules, for example, user trajectory, heat map, word cloud, and topic modeling.&nbsp;</p>\n<p>With our collaborators from the Department of Atmospheric Sciences, Crosman et al. describe ongoing efforts to collect and analyze air quality data obtained from a traffic helicopter at 10s intervals; see http://meso2.chpc.utah.edu/aq/ for examples of the ongoing data collection. Jacques et al. developed and analyzed pressure data collected at 1 Hz from hundreds of seismic sites in the contiguous United States. The data from that project is stored in the Research Data Archive of the National Center for Atmospheric Research; see http://meso1.chpc.utah.edu/usarray/cgi-bin/usarray_home.cgi for more information.&nbsp; Collaborators have created a unique archive of output obtained from the High Resolution Rapid Refresh model run operationally by the NOAA Environmental Modeling Center. This archive is hosted by a private cloud storage solution at the University of Utah's Center for High Performance Computing. Over 70 Tbytes of model grids are now being stored and made accessible to the research and educational communities. This data set is being used by the University of Utah's Marriott Library as one of the prototype data sets for long-term storage on campus. The Library has provided a DOI for the archive hosted by the Center for High Performance Computing (https://doi.org/10.7278/S5JQ0Z5B).&nbsp;</p>\n<p>Our results and findings in this project have been reported in related conferences and journals, and the core codebase of the STORM system has also been open sourced on github.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/07/2020<br>\n\t\t\t\t\tModified by: Feifei&nbsp;Li</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project develops an automatic query and analytical engine for large, heterogeneous spatial and temporal data. This capability allows users to automatically deploy a query and analytical engine instance over their large, heterogeneous data with spatial and temporal dimensions. The system supports a simple search-box and map-like query interface that allows numerous powerful analytical queries. Techniques to make these queries robust, relevant, and highly scalable will be developed. The project also enables users to execute queries over multiple data sources simultaneously and seamlessly. The goal of the work is to dramatically simplify the management and analysis of large spatio-temporal data at different institutions, groups, and corporations.\n\nWe have designed and implemented an initial prototype of STORM at www.estorm.org. The system currently supports multiple social media data sources, as well as data from the MesoWest project (weather data). To process large data, we devised novel techniques for online spatial sampling and aggregation, that is able to produce online estimators that continuously produce approximations (for the final exact results) whose approximation quality improves gradually over time. Using this technique, we are able to general kernel density estimate (KDE) in real time over large social media data (such as a large collection of tweets).\n\nWe have also designed and implemented the STORM storage engine based on MongoDB. Due to the large amount of data we have dealt with. We designed and implemented novel indexing structures that sit on top of MongoDB that's able to answer spatio-temporal range queries efficiently.\n\nWe also introduced a visualization layer that supports a number of visualization modules, for example, user trajectory, heat map, word cloud, and topic modeling. \n\nWith our collaborators from the Department of Atmospheric Sciences, Crosman et al. describe ongoing efforts to collect and analyze air quality data obtained from a traffic helicopter at 10s intervals; see http://meso2.chpc.utah.edu/aq/ for examples of the ongoing data collection. Jacques et al. developed and analyzed pressure data collected at 1 Hz from hundreds of seismic sites in the contiguous United States. The data from that project is stored in the Research Data Archive of the National Center for Atmospheric Research; see http://meso1.chpc.utah.edu/usarray/cgi-bin/usarray_home.cgi for more information.  Collaborators have created a unique archive of output obtained from the High Resolution Rapid Refresh model run operationally by the NOAA Environmental Modeling Center. This archive is hosted by a private cloud storage solution at the University of Utah's Center for High Performance Computing. Over 70 Tbytes of model grids are now being stored and made accessible to the research and educational communities. This data set is being used by the University of Utah's Marriott Library as one of the prototype data sets for long-term storage on campus. The Library has provided a DOI for the archive hosted by the Center for High Performance Computing (https://doi.org/10.7278/S5JQ0Z5B). \n\nOur results and findings in this project have been reported in related conferences and journals, and the core codebase of the STORM system has also been open sourced on github.\n\n \n\n\t\t\t\t\tLast Modified: 04/07/2020\n\n\t\t\t\t\tSubmitted by: Feifei Li"
 }
}