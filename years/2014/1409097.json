{
 "awd_id": "1409097",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Medium: Deep Annotation: Measuring Human Vision to Improve Machine Vision",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 674099.0,
 "awd_amount": 674099.0,
 "awd_min_amd_letter_date": "2014-08-07",
 "awd_max_amd_letter_date": "2014-08-07",
 "awd_abstract_narration": "Machine learning is the science of designing computational systems that can learn from data, much as humans do.  However, while many machine learning approaches rely on humans to provide labels for training examples that are used for learning, human-provided labels represent just a tiny fraction of the information that can be gleaned from humans.  This project brings together a multidisciplinary team with expertise spanning computer science, neuroscience and psychology to pioneer a new paradigm in machine learning that seeks to better mimic human performance by incorporating new kinds of information about human behavior.  \r\n\r\nSpecifically, this project brings the disciplines of psychophysics and psychometrics, which seek to quantitatively describe human performance -- patterns of errors, reaction times, and variations across populations of humans -- together with machine learning to develop systems that learn both from human successes and failures, to generate artificial systems that perform better and generalize better to data outside of their training sets.  The project team has already shown initial proof of concept in applying these ideas to the problem of face detection in difficult, cluttered real-world images.  During the project period, the team will greatly expand these ideas, developing new applications (including face and object recognition tasks), a broader range of machine learning settings (including regression and feature selection), and methods for incorporating new kinds of data (such as fMRI brain scans) for guiding machine learning algorithms.  This research represents a new direction in machine learning research, which increasingly has important and broad impact in our modern, data-driven world.  In addition, it is anticipated that the theoretical gains in machine learning derived from this work will feed back into psychology, enabling rapid screening of candidate hypotheses about how the brain works by artificial systems which can then be tested on humans using an advanced crowdsourcing platform for quantifying human behavior.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Cox",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Cox",
   "pi_email_addr": "davidcox@fas.harvard.edu",
   "nsf_id": "000516916",
   "pi_start_date": "2014-08-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ken",
   "pi_last_name": "Nakayama",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ken Nakayama",
   "pi_email_addr": "k2ibo@berkeley.edu",
   "nsf_id": "000152801",
   "pi_start_date": "2014-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University",
  "perf_str_addr": "52 Oxford St.",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021381903",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 674099.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The objective of this project was to explore the intersection between machine learning and neuroscience and psychology. Over the course of the project, we advanced three key areas of research at the intersection of neuroscience and machine learning:<br /><br />First, we extended previous work showing that measurements of humans perceptual judgments could be used to improve the performance of machine learning algorithms (an approach called \"perceptual annotation\").&nbsp; A key intuition for the technique of perceptual annotation is the idea that observations of a biological intelligence (e.g. psychophysical measurements of item-wise task perforamnce) can serve as a powerful regularizer for machine learning models.&nbsp; In previous work, purely behavioral results were used, but in the context of this award, we showed that one can also use direct measurements of brain activity.&nbsp; In particular, we showed that fMRI measurements of brain activity could be incorporated into the training of a computer vision classifier in such a way that it enhanced its performance.<br /><br />Second, as a further foray into exploring the intersection of neuroscience and machine learning, we developed a new neuroscience-inspired deep learning network model, called a \"PredNet\" (\"Predictive Coding Network\"), which draws inspiration from the classic notion of \"predictive coding\" from the neuroscience literature, which posits that one of the key computational principles of the brain is that it predicts its own activity, in order fill in missing information, predict future states of the world, and as a mechanism to learn about the structure of the world.&nbsp; The PredNet is a recurrent feedforward/feedback network that is trained end to end to predict future frames in a video sequence, generating a predicted frame and then comparing it to the next true frame that arrives in the sequence, and minimizing the difference (error) between the two.&nbsp; This brain-inspired network has served as the foundation for many other scientific investigations (the publication describing it has over 300 citations) and the network has been used in a wide variety of practical contexts, ranging from robotics to accident detection in factories.<br /><br />Finally, we analyzed the PredNet and found that it was capable of explaining a wide range of perceptual phenomena from the neuroscience literature, building on a growing body of work that uses deep learning as a model for understanding the brain.&nbsp; We found that the PredNet recapitulates many phenomena observed in the responses of cortical neurons, despite having been trained for future-frame video prediction (rather than being trained to mimic neural data, per se). The PredNet demonstrates classically observed neuroscience phenomena including: end-stopping and surround suppression in V1, temporal profiles of visual cortical neurons, and even high level illusions such as the flash-lag illusion.&nbsp; This work suggests that there may be deep connections between biological neural networks and artificial recurrent neural networks.<br /><br />In terms of broader impacts, this project was directly responsible for the development of technologies that led to the founding of two startup companies (one focused on perception modules for autonomous vehicles, and the other focused on medical image analysis), both of which have gone on to raise venture capital funding.&nbsp; The project also contributed to the training of a number of individuals who have continued in STEM fields.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/01/2019<br>\n\t\t\t\t\tModified by: David&nbsp;Cox</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe objective of this project was to explore the intersection between machine learning and neuroscience and psychology. Over the course of the project, we advanced three key areas of research at the intersection of neuroscience and machine learning:\n\nFirst, we extended previous work showing that measurements of humans perceptual judgments could be used to improve the performance of machine learning algorithms (an approach called \"perceptual annotation\").  A key intuition for the technique of perceptual annotation is the idea that observations of a biological intelligence (e.g. psychophysical measurements of item-wise task perforamnce) can serve as a powerful regularizer for machine learning models.  In previous work, purely behavioral results were used, but in the context of this award, we showed that one can also use direct measurements of brain activity.  In particular, we showed that fMRI measurements of brain activity could be incorporated into the training of a computer vision classifier in such a way that it enhanced its performance.\n\nSecond, as a further foray into exploring the intersection of neuroscience and machine learning, we developed a new neuroscience-inspired deep learning network model, called a \"PredNet\" (\"Predictive Coding Network\"), which draws inspiration from the classic notion of \"predictive coding\" from the neuroscience literature, which posits that one of the key computational principles of the brain is that it predicts its own activity, in order fill in missing information, predict future states of the world, and as a mechanism to learn about the structure of the world.  The PredNet is a recurrent feedforward/feedback network that is trained end to end to predict future frames in a video sequence, generating a predicted frame and then comparing it to the next true frame that arrives in the sequence, and minimizing the difference (error) between the two.  This brain-inspired network has served as the foundation for many other scientific investigations (the publication describing it has over 300 citations) and the network has been used in a wide variety of practical contexts, ranging from robotics to accident detection in factories.\n\nFinally, we analyzed the PredNet and found that it was capable of explaining a wide range of perceptual phenomena from the neuroscience literature, building on a growing body of work that uses deep learning as a model for understanding the brain.  We found that the PredNet recapitulates many phenomena observed in the responses of cortical neurons, despite having been trained for future-frame video prediction (rather than being trained to mimic neural data, per se). The PredNet demonstrates classically observed neuroscience phenomena including: end-stopping and surround suppression in V1, temporal profiles of visual cortical neurons, and even high level illusions such as the flash-lag illusion.  This work suggests that there may be deep connections between biological neural networks and artificial recurrent neural networks.\n\nIn terms of broader impacts, this project was directly responsible for the development of technologies that led to the founding of two startup companies (one focused on perception modules for autonomous vehicles, and the other focused on medical image analysis), both of which have gone on to raise venture capital funding.  The project also contributed to the training of a number of individuals who have continued in STEM fields.\n\n\t\t\t\t\tLast Modified: 12/01/2019\n\n\t\t\t\t\tSubmitted by: David Cox"
 }
}