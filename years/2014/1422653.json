{
 "awd_id": "1422653",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Small: Collaborative Research: Development of a Wearable 3D Integral Imaging Augmented Reality Display Technology",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2014-08-20",
 "awd_max_amd_letter_date": "2015-07-28",
 "awd_abstract_narration": "An augmented reality (AR) display which enables the ability to overlay 2D or 3D digital information on a person's real-world view has long been portrayed as a technology that will transform the way that people perceive and interact with digital information. Although several types of display devices have been explored for AR applications, the ideal display would be a lightweight and compact optical-see-through head-mounted-display (OST-HMD) which enables digital information to be optically superposed onto the direct view of the physical world, and which at the same time maintains a see-through view of the world. With recent advances in mobile computing, image sensors, and cloud computing, the single remaining barrier to realizing ubiquitous AR technology is the display technology. The lack of high-performance, compact, and low-cost AR displays limits the ability to explore its potential benefits. One of the specific display problems that has not yet been adequately addressed, and is thus a specific barrier to widespread use of AR technology, is the visual discomfort and fatigue experiences by users of OST-HMDs. Visual discomfort is a critical concern in applications where users need to work with AR displays for an extended period of time. One of the key factors causing visual discomfort is the accommodation-convergence cue mismatch between digital information rendered by the display and the real-world scene. This is a fundamental problem inherent to existing AR displays. This project will address the human factor issues that persist in existing AR displays by developing a compact, lightweight, glasses-style 3D AR display technology that integrates wearable AR display technology with a microscopic integral imaging method. 3D products will soon pervade daily activities in education, transportation, computers, medicine, defense, and security. The U.S. has substantially contributed to the original innovative concepts for 3D imaging and 3D display, and will benefit from further development of 3D technologies, and from research and development in U.S. universities. This project, a collaboration between two experts in 3D vision technologies at two U.S. universities, will address the human factors issues that persist in existing AR displays. Project outcomes will readily transition to commercialization of new 3D displays, and will train of the next generation of experts in the field of 3D displays, who will contribute to industry, high tech firms, commerce, government, education, and health related fields.\r\n\r\nThe key innovation of the project is that it will investigate and develop an innovative optical approach to OST-HMD design that uniquely integrates a 3D microscopic integral imaging (micro-InI) display and visualization method for full-parallax lightfield creation with an emerging optical design approach - freeform optical technology - for OST-HMD viewing optics. This approach enables the development of a compact 3D integral imaging optical see-through HMD with full-parallax lightfield rendering capability, which is anticipated to minimize the accommodation-convergence discrepancy problem plaguing existing AR displays, and thus substantially reduce the visual discomfort and fatigue for users. The project will design, develop, and implement a custom compact prototype system; develop system calibration and assessment methods; and perform preliminary user-based assessment experiments to evaluate the effects of our proposed technology on visual perception and visual fatigue.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hong",
   "pi_last_name": "Hua",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hong Hua",
   "pi_email_addr": "hhua@optics.arizona.edu",
   "nsf_id": "000482958",
   "pi_start_date": "2014-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Arizona",
  "inst_street_address": "845 N PARK AVE RM 538",
  "inst_street_address_2": "",
  "inst_city_name": "TUCSON",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "5206266000",
  "inst_zip_code": "85721",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "AZ07",
  "org_lgl_bus_name": "UNIVERSITY OF ARIZONA",
  "org_prnt_uei_num": "",
  "org_uei_num": "ED44Y3W6P7B9"
 },
 "perf_inst": {
  "perf_inst_name": "College of Optical Sciences, University of Arizona",
  "perf_str_addr": "1630 E University Blvd",
  "perf_city_name": "Tucson",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "857210094",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "AZ07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 73223.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 176777.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>An augmented reality (AR) display, which allows overlaying 2D or 3D digital information on a person&rsquo;s real-world view, is considered to be a transformative technology to redefine the way we perceive and interact with digital information. Despite significant advancements and commercial development, one of the most critical barriers of AR technology lies in the challenge of minimizing visual discomfort of AR displays. None of the existing technological solutions offers a truly portable, lightweight, and robust system that addresses both quality and visual comfort.</p>\n<p>&nbsp;</p>\n<p>In this funded research, <em>we investigated and developed a fundamentally novel approach to AR display design where the system offers the ability to render the true light field of 3D scene by reproducing the directional samples of the light rays apparently emitted by each point of the 3D scene rather than stimulating the perception of 3D space and shapes via a pair of two-dimensional images in conventional stereoscopic displays.&nbsp; By offering the ability to render the true light field of 3D scene, the display offers the ability of rendering correct focusing cues and thus providing the natural ability of stimulating the eyes to yield correct accommodative response when the eyes view contents of different depths, which effectively address </em>the accommodation-convergence discrepancy problem plaguing most of the existing AR displays and thus substantially reduce the visual discomfort and fatigue for users.</p>\n<p>&nbsp;</p>\n<p>In terms of research outcome of this project, we investigated and developed enabling optical methods for the proposed 3D AR display technology, and developed the first portable, lightweight, and high performance true 3D light field display prototype that is anticipated to is much less vulnerable to visual fatigue than the state-of-art wearable display technology. We further developed system calibration and assessment methods, and performed assessment experiments to evaluate the effects of our proposed technology on visual perception. Finally, <em>through this research program, we systematically developed display quality metrics and assessment methods relevant to lightfield 3D technology, which will help to shape the standards and guidelines for this type of 3D display technology.</em> The results of this research work have been published through nearly 40 scientific papers, presentations, and patent applications. 6 of the patent applications have all been licensed by a commercial entity who is seeking for opportunities to commercialize the resulted technology so that a larger user community can benefit from the developed technology.</p>\n<p>In terms of education, the proposed research served as a vehicle to aid in the training of the next generation of scientists and engineers. The mixture of optical engineering, human factors, and hands-on experience with integrating a complex system provides an excellent training ground for graduate and undergraduate students as well as a source of new knowledge for all participants involved in. The graduate students who worked in the project have learned skills from planning a research project, to grasping interdisciplinary knowledge and skills in human factors and computer graphics besides optical engineering, while they didn&rsquo;t come with such interdisciplinary background in nature.&nbsp; Graduate students received extensive training on research and engineering skills through this project, as well as extensive training in scientific writing skills. Though the entire funding period of this project, four Ph.D. students, 1 post-doc, and 1 MS students in the College of Optical Sciences have involved in this project for their dissertation or partially contributed to this project. The PI also offered tutorials, workshops, and seminars at several major international conferences and industrial forums and these tutorials and seminars have accumulated attendees of nearly 1500 over the 3 years of project period.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/14/2018<br>\n\t\t\t\t\tModified by: Hong&nbsp;Hua</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1422653/1422653_10335344_1534292231746_Figure1_prototype--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1422653/1422653_10335344_1534292231746_Figure1_prototype--rgov-800width.jpg\" title=\"Light Field Augmented Reality Display\"><img src=\"/por/images/Reports/POR/2018/1422653/1422653_10335344_1534292231746_Figure1_prototype--rgov-66x44.jpg\" alt=\"Light Field Augmented Reality Display\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Light Field Augmented Reality Display Prototype</div>\n<div class=\"imageCredit\">Hong Hua</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Hong&nbsp;Hua</div>\n<div class=\"imageTitle\">Light Field Augmented Reality Display</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1422653/1422653_10335344_1534292318370_Figure1_Results--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1422653/1422653_10335344_1534292318370_Figure1_Results--rgov-800width.jpg\" title=\"Rendered Light Field Display\"><img src=\"/por/images/Reports/POR/2018/1422653/1422653_10335344_1534292318370_Figure1_Results--rgov-66x44.jpg\" alt=\"Rendered Light Field Display\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Photo of Augmented View Captured via Light Field Display Prototype Developed at University of Arizona</div>\n<div class=\"imageCredit\">Hong Hua</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Hong&nbsp;Hua</div>\n<div class=\"imageTitle\">Rendered Light Field Display</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nAn augmented reality (AR) display, which allows overlaying 2D or 3D digital information on a person?s real-world view, is considered to be a transformative technology to redefine the way we perceive and interact with digital information. Despite significant advancements and commercial development, one of the most critical barriers of AR technology lies in the challenge of minimizing visual discomfort of AR displays. None of the existing technological solutions offers a truly portable, lightweight, and robust system that addresses both quality and visual comfort.\n\n \n\nIn this funded research, we investigated and developed a fundamentally novel approach to AR display design where the system offers the ability to render the true light field of 3D scene by reproducing the directional samples of the light rays apparently emitted by each point of the 3D scene rather than stimulating the perception of 3D space and shapes via a pair of two-dimensional images in conventional stereoscopic displays.  By offering the ability to render the true light field of 3D scene, the display offers the ability of rendering correct focusing cues and thus providing the natural ability of stimulating the eyes to yield correct accommodative response when the eyes view contents of different depths, which effectively address the accommodation-convergence discrepancy problem plaguing most of the existing AR displays and thus substantially reduce the visual discomfort and fatigue for users.\n\n \n\nIn terms of research outcome of this project, we investigated and developed enabling optical methods for the proposed 3D AR display technology, and developed the first portable, lightweight, and high performance true 3D light field display prototype that is anticipated to is much less vulnerable to visual fatigue than the state-of-art wearable display technology. We further developed system calibration and assessment methods, and performed assessment experiments to evaluate the effects of our proposed technology on visual perception. Finally, through this research program, we systematically developed display quality metrics and assessment methods relevant to lightfield 3D technology, which will help to shape the standards and guidelines for this type of 3D display technology. The results of this research work have been published through nearly 40 scientific papers, presentations, and patent applications. 6 of the patent applications have all been licensed by a commercial entity who is seeking for opportunities to commercialize the resulted technology so that a larger user community can benefit from the developed technology.\n\nIn terms of education, the proposed research served as a vehicle to aid in the training of the next generation of scientists and engineers. The mixture of optical engineering, human factors, and hands-on experience with integrating a complex system provides an excellent training ground for graduate and undergraduate students as well as a source of new knowledge for all participants involved in. The graduate students who worked in the project have learned skills from planning a research project, to grasping interdisciplinary knowledge and skills in human factors and computer graphics besides optical engineering, while they didn?t come with such interdisciplinary background in nature.  Graduate students received extensive training on research and engineering skills through this project, as well as extensive training in scientific writing skills. Though the entire funding period of this project, four Ph.D. students, 1 post-doc, and 1 MS students in the College of Optical Sciences have involved in this project for their dissertation or partially contributed to this project. The PI also offered tutorials, workshops, and seminars at several major international conferences and industrial forums and these tutorials and seminars have accumulated attendees of nearly 1500 over the 3 years of project period.\n\n \n\n\t\t\t\t\tLast Modified: 08/14/2018\n\n\t\t\t\t\tSubmitted by: Hong Hua"
 }
}