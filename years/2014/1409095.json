{
 "awd_id": "1409095",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: Medium: Collaborative Research: Enabling GPUs as First-Class Computing Engines",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2014-08-01",
 "awd_exp_date": "2018-07-31",
 "tot_intn_awd_amt": 484068.0,
 "awd_amount": 484068.0,
 "awd_min_amd_letter_date": "2014-07-31",
 "awd_max_amd_letter_date": "2016-07-08",
 "awd_abstract_narration": "Graphics Processing Units (GPUs) are rapidly bringing the computing\r\npower traditionally associated with massively parallel supercomputers\r\ninto the mainstream devices we use today. They have the power to\r\nrevolutionize computing by enabling orders of magnitude faster and\r\nmore efficient execution of many applications. Unfortunately, many\r\nmodern applications and users cannot take advantage of the computing\r\ncapability present in today's GPUs because today's GPUs are used as\r\nsecondary devices to the much less powerful CPUs. As a result, the massive\r\ncomputing power of GPUs gets wasted and underutilized for a large\r\nnumber of important applications.\r\n\r\nThis project aims to take a fresh and comprehensive look at GPU design\r\nwith the goal of enabling GPUs as first-class computing engines that\r\ncan benefit an overwhelming majority of real-world applications and\r\nusers. To this end, this project systematically investigates the\r\nhardware/software design space of three new execution models, which\r\nprogressively turn a GPU into an independent, first-class compute\r\nengine in a hybrid computing system: 1) an enhanced master-slave model\r\nwhere the GPU is able to perform multiple-application execution, 2) a\r\nnew peer-to-peer model where the GPU is autonomous of the CPU, 3) a\r\nhybrid model where GPUs and CPUs are integrated on the same die and\r\nare equals from the applications' and system's viewpoint. The project\r\ncomprehensively develops software, hardware and software/hardware\r\ncooperative scheduling, resource management, and system design\r\ntechniques for all three models.\r\n\r\nIf successful, this project can pave the way to making GPUs\r\nfirst-class computing engines used in all aspects of our everyday\r\nlives for a majority of applications. Doing so is not only expected to\r\nlead to much higher degrees of energy efficiency and user productivity\r\nbut can also potentially enable new applications and devices that can\r\ntake advantage GPUs.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mahmut",
   "pi_last_name": "Kandemir",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Mahmut T Kandemir",
   "pi_email_addr": "mtk2@psu.edu",
   "nsf_id": "000163936",
   "pi_start_date": "2014-07-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Chitaranjan",
   "pi_last_name": "Das",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chitaranjan Das",
   "pi_email_addr": "cxd12@psu.edu",
   "nsf_id": "000358842",
   "pi_start_date": "2014-07-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "354C IST Bldg.",
  "perf_city_name": "University Park",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168027000",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "PA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 128331.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 160384.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 195353.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Abstract at the Time of Award</strong></p>\n<p>Graphics Processing Units (GPUs) are rapidly bringing the computing power traditionally associated with massively parallel supercomputers into the mainstream devices we use today. They have the power to revolutionize computing by enabling orders of magnitude faster and more efficient execution of many applications. Unfortunately, many modern applications and users cannot take advantage of the computing capability present in today's GPUs because today's GPUs are used as secondary devices to the much less powerful CPUs. As a result, the massive computing power of GPUs gets wasted and underutilized for a large number of important applications.<br /> <br /> This project aims to take a fresh and comprehensive look at GPU design with the goal of enabling GPUs as first-class computing engines that can benefit an overwhelming majority of real-world applications and users. To this end, this project systematically investigates the hardware/software design space of three new execution models, which progressively turn a GPU into an independent, first-class compute engine in a hybrid computing system: (1) an enhanced master-slave model where the GPU is able to perform multiple-application execution, (2) a new peer-to-peer model where the GPU is autonomous of the CPU, (3) a hybrid model where GPUs and CPUs are integrated on the same die and are equals from the applications' and system's viewpoint.&nbsp;<br /> <br /> If successful, this project can pave the way to making GPUs first-class computing engines used in all aspects of our everyday lives for a majority of applications.&nbsp;</p>\n<p><strong>Publications Produced as a Result of this Research</strong></p>\n<ul>\n<li>Haibo Zhang, Prasanna Venkatesh Rengasamy, Nachiappan Chidambaram Nachiappan, Shulin Zhao, Anand Sivasubramaniam, Mahmut T. Kandemir, Chita R. Das&nbsp;(2018).&nbsp;FLOSS: FLOw sensitive scheduling on mobile platforms.&nbsp;&nbsp;<em>Design Automation Conference</em><em> (DAC)</em>.&nbsp; </li>\n<li>Jihyun Ryoo, Orhan Kislal, Xulong Tang, Mahmut T. Kandemir&nbsp;(2018).&nbsp;Quantifying and Optimizing Data Access Parallelism on Manycores.&nbsp;<em>MASCOTS</em>.&nbsp; &nbsp;</li>\n<li>Kaisheng Ma, Xueqing Li, Mahmut Taylan Kandemir, Jack Sampson, Vijaykrishnan Narayanan, Jinyang Li, Tongda Wu, Zhibo Wang, Yongpan Liu, Yuan Xie&nbsp;(2018).&nbsp;NEOFog: Nonvolatility-Exploiting Optimizations for Fog Computing.&nbsp;&nbsp;<em>ASPLOS</em>.&nbsp; </li>\n<li>Orhan Kislal, Jagadish B. Kotra, Xulong Tang, Mahmut T. Kandemir, Myoungsoo Jung&nbsp;(2018).&nbsp;Enhancing Computation-to-Core Assignment with Physical Location Information.&nbsp;&nbsp;<em>ACM SIGPLAN C</em><em>onference on Programming Language Design and Implementation</em><em> (PLDI)</em>.&nbsp; </li>\n<li>Orhan Kislal, Mahmut T. Kandemir&nbsp;(2018).&nbsp;Data access skipping for recursive partitioning methods.&nbsp;&nbsp;<em>Computer Languages, Systems &amp; Structures</em>.&nbsp; &nbsp;</li>\n<li>Prashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut T. Kandemir, Chita R. Das&nbsp;(2018).&nbsp;The Curious Case of Container Orchestration and Scheduling in GPU-based Datacenters.&nbsp;&nbsp;<em>SoCC</em>.&nbsp; &nbsp;</li>\n<li>Xulong Tang, Ashutosh Pattnaik, Onur Kayiran, Adwait Jog, Mahmut Taylan Kandemir, Chita Das&nbsp;(2019).&nbsp;Quantifying Data Locality in Dynamic Parallelism in GPUs.&nbsp;&nbsp;<em>ACM SIGMETRICS</em>.&nbsp; &nbsp;</li>\n<li>J. Ryoo, M. Arunachalam, R. Khanna, M. Kandemir&nbsp;(2018).&nbsp;<em>Efficient K Nearest Neighbor Algorithm Implementations for Throughput-Oriented Architectures</em>. ISQED.&nbsp;</li>\n<li>Rachata Ausavarungnirun, Saugata Ghose, Onur Kayiran, Gabriel H. Loh, Chita R. Das, Mahmut T. Kandemir, Onur Mutlu&nbsp;(2018).&nbsp;<em>Holistic Management of the GPGPU Memory Hierarchy to Manage Warp-level Latency Tolerance</em>. Technical Report. </li>\n<li>A. Pattnaik, X. Tang, O. Kayiran, A. Jog, A. Mishra, M. Kandemir, A. Sivasubramaniam, C. Das&nbsp;(2019).&nbsp;<em>Opportunistic Computing in GPU architectures</em>. ISCA.&nbsp;</li>\n<li>Xulong Tang, Mahmut T Kandemir&nbsp;(2019).&nbsp;<em>Quantifying the impact of GPU optimizations on address translation overheads</em>. SIGMETRICS (in preparation).&nbsp;</li>\n</ul>\n<p class=\"indentedcitation\">&nbsp;</p>\n<p class=\"indentedcitation\"><strong>Project Outcomes</strong></p>\n<p class=\"indentedcitation\"><strong>&nbsp;</strong>The performance and effectiveness of many scientific applications of national interest, e.g., those from nuclear simulations, astrophysics, climate analysis, computational chemistry and bioinformatics depend strongly on high performance computing machines installed throughout the States. An overwhelming majority of these machines employ a high performance accelerator named GPU (graphical processing unit). The question of architecting next generation GPUs and integrating them with the current and emerging high computing platforms has been the overreaching goal of this NSF project.</p>\n<p><strong>Major Research Outcomes:</strong> Our research activities (1) enabled researchers investigate&nbsp;the limits of the current CPUs and GPUs and investigate novel techniques for significantly enhancing both performance and energy efficiency. The techniques explored included efficient scheduling techniques, facilitating dynamic parallelism in GPU cores, compiler support for identifying multiple parallel kernels, and resource partitioning/scheduling for maximizing resource utilization; (2) &nbsp;explored a new peer-to-peer model of computation, where the GPU acts as a peer with the CPU by providing feedback to accelerate/initiate computation on both CPUs/GPUs. Using feedback and autonomous actions from the GPU, we devised effective warp/thread/kernel/application scheduling techniques to enable better cooperation between CPUs/GPUs; and (3) studied an integrated/hybrid CPU-GPU paradigm to its limits via new software/hardware mechanisms.&nbsp;</p>\n<p class=\"indentedcitation\"><strong>Broader Impact: </strong>&nbsp;This funding has enabled graduate student education and&nbsp;training&nbsp;on topics that go beyond conventional computing, covering cross-layer management of novel GPU architectures and behavior of scientific applications that run on top of them. The training from this project enabled students to better prepare as the next generation workforce in science and enginerring. The project also generated research publications in several top computer science and engineering conferences, including ISCA, PLDI, ASPLOS, SIGMETRICS, and DAC.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/10/2018<br>\n\t\t\t\t\tModified by: Mahmut&nbsp;T&nbsp;Kandemir</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAbstract at the Time of Award\n\nGraphics Processing Units (GPUs) are rapidly bringing the computing power traditionally associated with massively parallel supercomputers into the mainstream devices we use today. They have the power to revolutionize computing by enabling orders of magnitude faster and more efficient execution of many applications. Unfortunately, many modern applications and users cannot take advantage of the computing capability present in today's GPUs because today's GPUs are used as secondary devices to the much less powerful CPUs. As a result, the massive computing power of GPUs gets wasted and underutilized for a large number of important applications.\n \n This project aims to take a fresh and comprehensive look at GPU design with the goal of enabling GPUs as first-class computing engines that can benefit an overwhelming majority of real-world applications and users. To this end, this project systematically investigates the hardware/software design space of three new execution models, which progressively turn a GPU into an independent, first-class compute engine in a hybrid computing system: (1) an enhanced master-slave model where the GPU is able to perform multiple-application execution, (2) a new peer-to-peer model where the GPU is autonomous of the CPU, (3) a hybrid model where GPUs and CPUs are integrated on the same die and are equals from the applications' and system's viewpoint. \n \n If successful, this project can pave the way to making GPUs first-class computing engines used in all aspects of our everyday lives for a majority of applications. \n\nPublications Produced as a Result of this Research\n\nHaibo Zhang, Prasanna Venkatesh Rengasamy, Nachiappan Chidambaram Nachiappan, Shulin Zhao, Anand Sivasubramaniam, Mahmut T. Kandemir, Chita R. Das (2018). FLOSS: FLOw sensitive scheduling on mobile platforms.  Design Automation Conference (DAC).  \nJihyun Ryoo, Orhan Kislal, Xulong Tang, Mahmut T. Kandemir (2018). Quantifying and Optimizing Data Access Parallelism on Manycores. MASCOTS.   \nKaisheng Ma, Xueqing Li, Mahmut Taylan Kandemir, Jack Sampson, Vijaykrishnan Narayanan, Jinyang Li, Tongda Wu, Zhibo Wang, Yongpan Liu, Yuan Xie (2018). NEOFog: Nonvolatility-Exploiting Optimizations for Fog Computing.  ASPLOS.  \nOrhan Kislal, Jagadish B. Kotra, Xulong Tang, Mahmut T. Kandemir, Myoungsoo Jung (2018). Enhancing Computation-to-Core Assignment with Physical Location Information.  ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI).  \nOrhan Kislal, Mahmut T. Kandemir (2018). Data access skipping for recursive partitioning methods.  Computer Languages, Systems &amp; Structures.   \nPrashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut T. Kandemir, Chita R. Das (2018). The Curious Case of Container Orchestration and Scheduling in GPU-based Datacenters.  SoCC.   \nXulong Tang, Ashutosh Pattnaik, Onur Kayiran, Adwait Jog, Mahmut Taylan Kandemir, Chita Das (2019). Quantifying Data Locality in Dynamic Parallelism in GPUs.  ACM SIGMETRICS.   \nJ. Ryoo, M. Arunachalam, R. Khanna, M. Kandemir (2018). Efficient K Nearest Neighbor Algorithm Implementations for Throughput-Oriented Architectures. ISQED. \nRachata Ausavarungnirun, Saugata Ghose, Onur Kayiran, Gabriel H. Loh, Chita R. Das, Mahmut T. Kandemir, Onur Mutlu (2018). Holistic Management of the GPGPU Memory Hierarchy to Manage Warp-level Latency Tolerance. Technical Report. \nA. Pattnaik, X. Tang, O. Kayiran, A. Jog, A. Mishra, M. Kandemir, A. Sivasubramaniam, C. Das (2019). Opportunistic Computing in GPU architectures. ISCA. \nXulong Tang, Mahmut T Kandemir (2019). Quantifying the impact of GPU optimizations on address translation overheads. SIGMETRICS (in preparation). \n\n \nProject Outcomes\n The performance and effectiveness of many scientific applications of national interest, e.g., those from nuclear simulations, astrophysics, climate analysis, computational chemistry and bioinformatics depend strongly on high performance computing machines installed throughout the States. An overwhelming majority of these machines employ a high performance accelerator named GPU (graphical processing unit). The question of architecting next generation GPUs and integrating them with the current and emerging high computing platforms has been the overreaching goal of this NSF project.\n\nMajor Research Outcomes: Our research activities (1) enabled researchers investigate the limits of the current CPUs and GPUs and investigate novel techniques for significantly enhancing both performance and energy efficiency. The techniques explored included efficient scheduling techniques, facilitating dynamic parallelism in GPU cores, compiler support for identifying multiple parallel kernels, and resource partitioning/scheduling for maximizing resource utilization; (2)  explored a new peer-to-peer model of computation, where the GPU acts as a peer with the CPU by providing feedback to accelerate/initiate computation on both CPUs/GPUs. Using feedback and autonomous actions from the GPU, we devised effective warp/thread/kernel/application scheduling techniques to enable better cooperation between CPUs/GPUs; and (3) studied an integrated/hybrid CPU-GPU paradigm to its limits via new software/hardware mechanisms. \nBroader Impact:  This funding has enabled graduate student education and training on topics that go beyond conventional computing, covering cross-layer management of novel GPU architectures and behavior of scientific applications that run on top of them. The training from this project enabled students to better prepare as the next generation workforce in science and enginerring. The project also generated research publications in several top computer science and engineering conferences, including ISCA, PLDI, ASPLOS, SIGMETRICS, and DAC.\n\n \n\n\t\t\t\t\tLast Modified: 12/10/2018\n\n\t\t\t\t\tSubmitted by: Mahmut T Kandemir"
 }
}