{
 "awd_id": "1356486",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: ABI Development: A New Platform for highly-optimized, low-latency pipelines for genomic data analysis",
 "cfda_num": "47.074",
 "org_code": "08080000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Peter McCartney",
 "awd_eff_date": "2014-09-15",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 519999.0,
 "awd_amount": 519999.0,
 "awd_min_amd_letter_date": "2014-09-15",
 "awd_max_amd_letter_date": "2014-09-15",
 "awd_abstract_narration": "Next-generation sequencing has transformed genomics into a new paradigm of data-intensive computing, raising several salient challenges. First, the deluge of genomic data needs to undergo deep analysis to mine biological information, which requires a full pipeline that integrates many data processing and analysis tools. Second, deep analysis pipelines often take long to run, which entails a long cycle for algorithm and method development. This project aims to bring the latest big data technology and database technology to the genomics domain to revolutionize its data crunching power. This project is anticipated to produce significant scientific and educational benefits. By providing a highly-optimized parallel processing platform for genomic data analysis and making it accessible in private and public clouds, it will enable many new models and algorithms to be developed for genomics and help advance this field at unprecedented speed as big data technology did for Internet companies. This project also integrates research and education with curriculum development, tutorials for K-12 teachers and community college faculty, and engaging women in research through college outreach and NSF-funded outreach programs.\r\n\r\nThe proposed research includes the development of (1) a deep pipeline for genomic data analysis by assembling state-of-the-art methods, (2) automatic parallelization of the workflow using the big data technology, (3) a principled approach to optimizing the genomic pipeline, and (4) integration of streaming technology to reduce latency of important results. The prototype system will be deployed in both private and public cloud environments, and fully evaluated using existing long-running pipelines at the New York Genome Center and in a variety of real use cases. By way of doing so, this project will provide new knowledge regarding how to adapt and advance big data technology, including new optimization, partitioning, and scheduling techniques, for the genomics domain. The results of the project are disseminated at the web site: http://gesall.cs.umass.edu.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "BIO",
 "org_dir_long_name": "Directorate for Biological Sciences",
 "div_abbr": "DBI",
 "org_div_long_name": "Division of Biological Infrastructure",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yanlei",
   "pi_last_name": "Diao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yanlei Diao",
   "pi_email_addr": "yanlei@cs.umass.edu",
   "nsf_id": "000487811",
   "pi_start_date": "2014-09-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "140 Governors Drive",
  "perf_city_name": "Amherst",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010039264",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "116500",
   "pgm_ele_name": "ADVANCES IN BIO INFORMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 519999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Next-generation sequencing has transformed genomics into a new paradigm of data-intensive computing, raising several salient challenges. First, the deluge of genomic data needs to undergo deep analysis to mine biological information. Second, deep analysis pipelines often take long to run, which entails a long cycle for algorithm and method development. This project aims to bring the latest big data technology and database technology to the genomics domain, and innovate in this new domain to revolutionize its data crunching power.&nbsp;&nbsp;</p>\n<p>In our research, we developed a deep pipeline for genomic data analysis by assembling state-of-the-art methods, conducted intensive benchmarking to understand the strengths and limitations of Big Data technology for the new domain of genomic data analysis, and developed a new platform and algorithms to parallelize the genome analysis programs in deep pipelines, without having to rewrite these programs while ensuring high-quality variant detection results.</p>\n<p>Results of this project significantly advanced the state of the art with the following contributions: (1) Our benchmarking study of a deep variant calling pipeline enables understanding of the strengths and limitations of Big Data technology, including when Big Data technology offers linear or superlinear speedup, when it offers sublinear performance, and&nbsp; why data parallelism produces different results from serial execution. (2) Our parallel platform is among the first that enables parallelism of many genomic analysis programs (designed for serial execution) without having to rewrite them while ensuring high-quality results. In particular, our Genome Data Parallel Toolkit (GDPT) provides a suit of data partitioning methods and algorithms that suit different data access patterns of genomic analysis programs.&nbsp; (3) In particular, our GDPT provides novel parallel algorithms for window-based variant detection that lacked a parallel solution prior to this work. Our algorithm for HaplotypeCaller&nbsp; outperforms &nbsp;the Spark implementation, a state of the art parallel algorithm for HaplotypeCaller, by 2.7x in running time while providing 4 orders of magnitude improvement in consistency of parallel output (8 different results from the serial output of 4,931,429 variants, while Spark HC&nbsp; produces 84,869 differences).</p>\n<p>We provided open-source release to the broader scientific community, with the goal to provide high-performance parallel genomic data analysis pipelines, as well as methods and tools for developing such pipelines for new analysis needs. We anticipate that such a parallel platform and new methods/tools, once accessed for free to genomics researchers, will be a key enabler of many new models and algorithms developed for genomics and help advance this field at an unprecedented speed as Big Data technology has advanced&nbsp; Internet applications. This project also involved a number of educational efforts, including an integrated undergraduate and graduate curriculum on scalable data analytics, and outreach and mentoring activities to engage women in research.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/21/2019<br>\n\t\t\t\t\tModified by: Yanlei&nbsp;Diao</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nNext-generation sequencing has transformed genomics into a new paradigm of data-intensive computing, raising several salient challenges. First, the deluge of genomic data needs to undergo deep analysis to mine biological information. Second, deep analysis pipelines often take long to run, which entails a long cycle for algorithm and method development. This project aims to bring the latest big data technology and database technology to the genomics domain, and innovate in this new domain to revolutionize its data crunching power.  \n\nIn our research, we developed a deep pipeline for genomic data analysis by assembling state-of-the-art methods, conducted intensive benchmarking to understand the strengths and limitations of Big Data technology for the new domain of genomic data analysis, and developed a new platform and algorithms to parallelize the genome analysis programs in deep pipelines, without having to rewrite these programs while ensuring high-quality variant detection results.\n\nResults of this project significantly advanced the state of the art with the following contributions: (1) Our benchmarking study of a deep variant calling pipeline enables understanding of the strengths and limitations of Big Data technology, including when Big Data technology offers linear or superlinear speedup, when it offers sublinear performance, and  why data parallelism produces different results from serial execution. (2) Our parallel platform is among the first that enables parallelism of many genomic analysis programs (designed for serial execution) without having to rewrite them while ensuring high-quality results. In particular, our Genome Data Parallel Toolkit (GDPT) provides a suit of data partitioning methods and algorithms that suit different data access patterns of genomic analysis programs.  (3) In particular, our GDPT provides novel parallel algorithms for window-based variant detection that lacked a parallel solution prior to this work. Our algorithm for HaplotypeCaller  outperforms  the Spark implementation, a state of the art parallel algorithm for HaplotypeCaller, by 2.7x in running time while providing 4 orders of magnitude improvement in consistency of parallel output (8 different results from the serial output of 4,931,429 variants, while Spark HC  produces 84,869 differences).\n\nWe provided open-source release to the broader scientific community, with the goal to provide high-performance parallel genomic data analysis pipelines, as well as methods and tools for developing such pipelines for new analysis needs. We anticipate that such a parallel platform and new methods/tools, once accessed for free to genomics researchers, will be a key enabler of many new models and algorithms developed for genomics and help advance this field at an unprecedented speed as Big Data technology has advanced  Internet applications. This project also involved a number of educational efforts, including an integrated undergraduate and graduate curriculum on scalable data analytics, and outreach and mentoring activities to engage women in research.\n\n\t\t\t\t\tLast Modified: 11/21/2019\n\n\t\t\t\t\tSubmitted by: Yanlei Diao"
 }
}