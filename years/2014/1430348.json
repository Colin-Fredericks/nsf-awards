{
 "awd_id": "1430348",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CRCNS: Collaborative Research: Naturalistic computation and signaling by neural populations in the primate retina",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2022-02-28",
 "tot_intn_awd_amt": 431441.0,
 "awd_amount": 517451.0,
 "awd_min_amd_letter_date": "2014-08-18",
 "awd_max_amd_letter_date": "2021-01-28",
 "awd_abstract_narration": "Vision begins in the retina, where light is converted into electrical signals, processed to extract and compress visual information, and transmitted through the optic nerve to the brain.  Despite decades of research, a full understanding of these transformations remains incomplete.  In particular, most studies have documented specific properties of the responses of single retinal cells in isolation, using specialized artificial visual stimuli.  The research performed under this grant aims to develop a full, unified computational model of retinal processing, including spatial and temporal filtering, nonlinear transformations, and adaptation to local luminance and contrast, in complete populations of neurons.  The model will be tested by comparing its predictions to data from large-scale multi-electrode recordings of primate retinal ganglion cells (RGCs), verifying that it can mimic known retinal responses, and critically, testing its ability to explain responses to natural visual images, including the effects of fixational and saccadic eye movements.  The resulting model will provide a compact encapsulation of the \"neural code\" of the retina, which will serve as a substrate for understanding all subsequent visual processing in the brain.  In addition, the model will provide an essential component in the development of high-acuity retinal prostheses for people blinded by diseases of photoreceptor degeneration.  Finally, the model will offer a useful tool for the development and testing of new display technologies.\r\n\r\nThe research has two main aims:  (1) Develop and test a model of nonlinear subunits in RGC populations-- No current model captures the effects of nonlinear computations in a complete sensory neural circuit.  The researchers will develop a model incorporating nonlinear subunits that captures the stimulus encoding properties of complete populations of RGCs at the resolution of photoreceptors, and will quantify the implications of these nonlinearities for encoding naturally-occurring visual stimuli. The researchers will develop methods to reliably fit the model to RGC responses to targeted stimuli that stringently constrain model structure, and verify model predictions in closed-loop experiments.  (2) Incorporate adaptation; test model with targeted and naturalistic stimuli-- RGC responses adapt to luminance and stimulus contrast.  No current model of the RGC population response incorporates adaptation with subunit nonlinearities, natural scenes, and eye movements. The researchers will incorporate adaptation in the model, fit the adaptive model using stochastic stimuli with varying mean and contrast, and test the model using stimuli that produce adaptation within and across subunits.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eduardo",
   "pi_last_name": "Chichilnisky",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Eduardo J Chichilnisky",
   "pi_email_addr": "ej@stanford.edu",
   "nsf_id": "000469126",
   "pi_start_date": "2014-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "452 Lomita Mall",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943052004",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "732700",
   "pgm_ele_name": "CRCNS-Computation Neuroscience"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7327",
   "pgm_ref_txt": "CRCNS"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 400752.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 30689.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 86010.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This grant was used to understand fundamental properties about how the retina of the eye communicates visual information to&nbsp;the brain. Using cutting-edge physiological experiments and novel computational methods, we examined light responses of complete collections of retinal ganglion cells, the neurons that send visual information from the eye to the brain. We then explored how visual information&nbsp;is encoded in the population activity of these cells, specifically by presenting natural images to the retina, recording the population activity of the cells in response to these images, and examining how the images can be decoded in the&nbsp;brain to infer the structure of the image. We developed algorithms for performing this decoding, for the first time, and determined how faithfully the brain could extract visual information from the retinal input. This revealed that while simple linear decoding could extract much of the image information, more sophisticated nonlinear computations that take into account the statistical structure of natural images performed better. We also developed models of how this retinal representation is created by the nonlinear computations performed by&nbsp;individual neurons, and specifically found techniques for investigating the more complex nonlinear computations that are not captured by typical models. These findings advance our understanding of the first stages of processing in the visual system, and also&nbsp;provide computational tools for neuroengineering to produce devices for vision restoration for the blind.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/29/2022<br>\n\t\t\t\t\tModified by: Eduardo&nbsp;J&nbsp;Chichilnisky</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis grant was used to understand fundamental properties about how the retina of the eye communicates visual information to the brain. Using cutting-edge physiological experiments and novel computational methods, we examined light responses of complete collections of retinal ganglion cells, the neurons that send visual information from the eye to the brain. We then explored how visual information is encoded in the population activity of these cells, specifically by presenting natural images to the retina, recording the population activity of the cells in response to these images, and examining how the images can be decoded in the brain to infer the structure of the image. We developed algorithms for performing this decoding, for the first time, and determined how faithfully the brain could extract visual information from the retinal input. This revealed that while simple linear decoding could extract much of the image information, more sophisticated nonlinear computations that take into account the statistical structure of natural images performed better. We also developed models of how this retinal representation is created by the nonlinear computations performed by individual neurons, and specifically found techniques for investigating the more complex nonlinear computations that are not captured by typical models. These findings advance our understanding of the first stages of processing in the visual system, and also provide computational tools for neuroengineering to produce devices for vision restoration for the blind.\n\n\t\t\t\t\tLast Modified: 06/29/2022\n\n\t\t\t\t\tSubmitted by: Eduardo J Chichilnisky"
 }
}