{
 "awd_id": "1418122",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Revealing the Invisible: Data-Intensive Research Using Cognitive, Psychological, and Physiological Measures to Optimize STEM Learning",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032928333",
 "po_email": "gesolomo@nsf.gov",
 "po_sign_block_name": "Gregg Solomon",
 "awd_eff_date": "2014-08-15",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 365480.0,
 "awd_amount": 365480.0,
 "awd_min_amd_letter_date": "2014-08-05",
 "awd_max_amd_letter_date": "2019-01-29",
 "awd_abstract_narration": "Virtual learning environments are an increasingly important component of individualized learning in STEM domains. New technologies (including biometry and neuro-imaging) provide new opportunities to unobtrusively measure student engagement and learning. This project-developed in connection with an Ideas Lab on Data-Intensive Research to Improve Teaching and Learning that NSF convened in October 2014 -will utilize these technologies to provide foundational knowledge of the ways in which measures of implicit learning might be linked to explicit learning to develop educationally relevant games that are adaptive to diverse learners.  \r\n\r\nInvestigators from TERC, Landmark College, and the Massachusetts Institute of Technology will collaborate to examine the relationships among: (1) patterns of play in a digital game (\"Impulse\"); (2) student attention (measured from eye- and head-tracking devices); and (3) student learning about Newton's first and second law. The researchers will collect measures of student engagement and learning outcomes embedded in the game. Subjects will comprise a neurodiverse group of students including regular undergraduates and those with Attention Deficit Hyperactivity Disorder and/or Autism Spectrum Disorder. The researchers will develop a model of visual attention and patterns of play, examining the extent to which eye movements are allocated strategically to objects of relevance to the current game state as a student learns in the game. They will then link the initial model with measures of student engagement and conceptual understanding of relevant physical science constructs to refine the model.  The refined model will be used to develop a modified game based on the players' attention, and a prototype of the modified game will be tested. The final phase of the research will be a within-subject design with the adaptive version versus the normal version of the game across learners with different profiles of disability.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Micah",
   "pi_last_name": "Altman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Micah Altman",
   "pi_email_addr": "micah_altman@alumni.brown.edu",
   "nsf_id": "000263614",
   "pi_start_date": "2014-08-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "762500",
   "pgm_ele_name": "REAL"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8244",
   "pgm_ref_txt": "EHR CL Opportunities (NSF 14-302)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0414",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001415DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 365480.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-7cae1c62-7fff-f9fb-6a24-0f46dcaf6c3a\"> </span></p>\n<p dir=\"ltr\"><span>The</span><span> Revealing the Invisible </span><span>project </span><span>was inspired by an audacious question developed at a multi-disciplinary NSF hosted Ideas Lab: &nbsp; How can we observe learning (almost) directly, in real-time,  unobtrusively, and within formal and informal learning environments?</span></p>\n<p dir=\"ltr\"><span>Traditional learning assessments are limited; they may exclude the measurement of individual learning of many learners; they are often external to the flow of teaching and thus take valuable time away from classroom activity. Further, they provide coarse and delayed measures of learning --&nbsp; and lack the richness and timeliness needed to guide adaptation of teaching to the learner.</span><span>&nbsp; Meanwhile, a plethora of companies are introducing devices -- including many that collect biometrics -- and activities that they claim will help people learn. But these claims lack rigorous research to back them up.&nbsp;</span></p>\n<p dir=\"ltr\"><span>The RTI project brought together research in data science, learning sciences, and cognitive psychology to develop to improve the measurement of learning by incorporating eye-tracking biometrics and data mining of learners interactions with a virtual learning environment. </span><span>&nbsp;</span><span>Specifically, investigators from TERC, Landmark College, and the Massachusetts Institute of Technology will collaborated to examine the relationships among: (1) patterns of play in a digital game (\"Impulse\"); (2) student attention (measured from eye- and head-tracking devices); and (3) student learning about Newton's first and second law.&nbsp; The researchers collected measures of student engagement and learning outcomes embedded in the game. Subjects comprised a neurodiverse group of students including regular undergraduates and those with Attention Deficit Hyperactivity Disorder and Autism Spectrum Disorder.</span></p>\n<p dir=\"ltr\"><span>Using the Impulse physics game as an exemplar, the researchers developed real-time multimodal data analytics system that can integrate multiple streams of data -- including gameplay and biometric measures -- for analysis; and that can synchronize this data at a millisecond level of precision. The researchers then developed a playback tool that creates a visualization of the data streams -- this enables researchers to review user game play overlaid with measures of attention and measure of play. This system was extended to enable labeling of key features in eye-tracking that potentially correspond with game play. The outputs of this project included peer reviewed publications, educational presentations, and operational software tools.&nbsp;&nbsp;</span></p>\n<p dir=\"ltr\"><span>The impact of the project&nbsp; has been to advance the field?s ability to measure implicit learning. And by developing such non-intrusive approaches to assessment of learning, the project lays the groundwork for educational approaches that are better at assessing and adapting to a spectrum of learners.&nbsp;&nbsp;</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/10/2020<br>\n\t\t\t\t\tModified by: Micah&nbsp;Altman</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1418122/1418122_10328434_1581339069418_RTI--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1418122/1418122_10328434_1581339069418_RTI--rgov-800width.jpg\" title=\"RTI Multimodal Data Analytics\"><img src=\"/por/images/Reports/POR/2020/1418122/1418122_10328434_1581339069418_RTI--rgov-66x44.jpg\" alt=\"RTI Multimodal Data Analytics\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Integrating Actual Gameplay, Eye-Tracking, and Expert Labelling</div>\n<div class=\"imageCredit\">Micah Altman</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Micah&nbsp;Altman</div>\n<div class=\"imageTitle\">RTI Multimodal Data Analytics</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nThe Revealing the Invisible project was inspired by an audacious question developed at a multi-disciplinary NSF hosted Ideas Lab:   How can we observe learning (almost) directly, in real-time,  unobtrusively, and within formal and informal learning environments?\nTraditional learning assessments are limited; they may exclude the measurement of individual learning of many learners; they are often external to the flow of teaching and thus take valuable time away from classroom activity. Further, they provide coarse and delayed measures of learning --  and lack the richness and timeliness needed to guide adaptation of teaching to the learner.  Meanwhile, a plethora of companies are introducing devices -- including many that collect biometrics -- and activities that they claim will help people learn. But these claims lack rigorous research to back them up. \nThe RTI project brought together research in data science, learning sciences, and cognitive psychology to develop to improve the measurement of learning by incorporating eye-tracking biometrics and data mining of learners interactions with a virtual learning environment.  Specifically, investigators from TERC, Landmark College, and the Massachusetts Institute of Technology will collaborated to examine the relationships among: (1) patterns of play in a digital game (\"Impulse\"); (2) student attention (measured from eye- and head-tracking devices); and (3) student learning about Newton's first and second law.  The researchers collected measures of student engagement and learning outcomes embedded in the game. Subjects comprised a neurodiverse group of students including regular undergraduates and those with Attention Deficit Hyperactivity Disorder and Autism Spectrum Disorder.\nUsing the Impulse physics game as an exemplar, the researchers developed real-time multimodal data analytics system that can integrate multiple streams of data -- including gameplay and biometric measures -- for analysis; and that can synchronize this data at a millisecond level of precision. The researchers then developed a playback tool that creates a visualization of the data streams -- this enables researchers to review user game play overlaid with measures of attention and measure of play. This system was extended to enable labeling of key features in eye-tracking that potentially correspond with game play. The outputs of this project included peer reviewed publications, educational presentations, and operational software tools.  \nThe impact of the project  has been to advance the field?s ability to measure implicit learning. And by developing such non-intrusive approaches to assessment of learning, the project lays the groundwork for educational approaches that are better at assessing and adapting to a spectrum of learners.  \n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 02/10/2020\n\n\t\t\t\t\tSubmitted by: Micah Altman"
 }
}