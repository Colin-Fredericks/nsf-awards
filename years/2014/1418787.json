{
 "awd_id": "1418787",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Dynamical Systems on Tensor Approximations",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leland Jameson",
 "awd_eff_date": "2014-08-01",
 "awd_exp_date": "2017-07-31",
 "tot_intn_awd_amt": 210000.0,
 "awd_amount": 210000.0,
 "awd_min_amd_letter_date": "2014-07-27",
 "awd_max_amd_letter_date": "2014-07-27",
 "awd_abstract_narration": "Functions of many variables arise in numerous mathematical, statistical, and scientific problems; a particularly notable example is the multiparticle Schrodinger equation in quantum mechanics. The effort required to compute in a straightforward way with such functions grows extremely rapidly as the number of variables increases, and soon becomes prohibitive. Mathematical methods have been developed that in some cases allow one to compute without this rapid growth, but crucial parts of the method are poorly understood and unreliable. This project seeks to understand and then fix these crucial parts. Students will be actively involved in the project and so learn mathematics and how to conduct mathematical research; they will also develop skills in writing, presenting seminars and posters, and software development and usage.  \r\n\r\nA mathematical study will be conducted on the approximation of tensors using sums of separable tensors and the approximation of multivariate functions using sums of separable functions.  The objectives are to understand (1) how such approximations behave and (2) how such approximations can be effectively computed. The method is to consider iterative tensor approximation algorithms as dynamical systems to probe the set of sum-of-separable tensors and to understand the behavior of the algorithm within this set.  The approximation of tensors by sums of separable tensors enables a promising computational paradigm for bypassing the curse of dimensionality when working with functions of many variables. This project addresses a bottleneck, in understanding and in computation, that prevents the computational paradigm from achieving its full potential.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Martin",
   "pi_last_name": "Mohlenkamp",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Martin J Mohlenkamp",
   "pi_email_addr": "mohlenka@ohio.edu",
   "nsf_id": "000279936",
   "pi_start_date": "2014-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Todd",
   "pi_last_name": "Young",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Todd R Young",
   "pi_email_addr": "youngt@ohio.edu",
   "nsf_id": "000344465",
   "pi_start_date": "2014-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio University",
  "inst_street_address": "1 OHIO UNIVERSITY",
  "inst_street_address_2": "",
  "inst_city_name": "ATHENS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "7405932857",
  "inst_zip_code": "457012979",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "OH12",
  "org_lgl_bus_name": "OHIO UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "LXHMMWRKN5N8"
 },
 "perf_inst": {
  "perf_inst_name": "Ohio University",
  "perf_str_addr": "1 Ohio University",
  "perf_city_name": "Athens",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "457012979",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "OH12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 210000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project helped develop the next generation of Mathematicians by<br />providing research opportunities for 3 doctoral students and 10<br />Master's students in Mathematics. Participation helped develop student<br />skills in Mathematics itself, the process of conducting research,<br />mathematical writing and presentation, and software development.<br /><br />Progress in understanding tensor approximations has been hampered by<br />lack of appropriate tools. In particular, the standard tools in<br />optimization do not help in understanding the transient dynamics<br />observed in tensor approximation algorithms. We have developed an<br />analysis framework to provide appropriate tools and measures.<br />The key to understanding the transient dynamics is to look at both how<br />fast the error decreases (measured by the norm of the gradient) and<br />the shape of the error perpendicular to the downhill direction<br />(measured by the eigenvalues of the Hessian projected transverse to<br />the gradient). When the error decreases slowly (the gradient has small<br />norm) and the shape is a valley with steep sides (the eigenvalues are<br />positive with some large) then algorithms will slowly zig-zag down the<br />valley.<br /><br />We have completed an in-depth analysis of the two simplest non-trivial<br />cases of tensor approximation: a rank-2 tensor approximated by a<br />rank-1 tensor and by a rank-2 tensor. Among the many results of this<br />analysis, two especially deserve highlighting:<br /><br />(1) For a range of parameter values, the problem exhibits minima<br />embedded within long, gradually-descending, steep-sided valleys. As<br />noted above, such valleys slow algorithms by causing zig-zag<br />behavior. Thus one should choose algorithms specifically designed to<br />work well in valleys.<br /><br />(2) For a range of parameter values, the problem exhibits a novel<br />feature that creates valleys that are more gradual in descent and more<br />steeply-sided than is normally possible in optimization problems.&nbsp; The<br />feature is saddle-like in that from some starting points the downhill<br />direction leads very close to the feature and then turns and leads<br />away from it. At the feature, the error function is discontinuous<br />(with an essential singularity), which causes the sides of the valley<br />to become infinitely steep.&nbsp; This feature explains the great mystery in<br />tensor approximation algorithms: the presence and prevalence of<br />``transient swamps'', when an algorithm reduces the error by minuscule<br />amounts for many iterations and then converges rapidly.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/06/2017<br>\n\t\t\t\t\tModified by: Martin&nbsp;J&nbsp;Mohlenkamp</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1418787/1418787_10324076_1507233494378_transientoutcomes--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1418787/1418787_10324076_1507233494378_transientoutcomes--rgov-800width.jpg\" title=\"View of a feature that can cause a transient swamp.\"><img src=\"/por/images/Reports/POR/2017/1418787/1418787_10324076_1507233494378_transientoutcomes--rgov-66x44.jpg\" alt=\"View of a feature that can cause a transient swamp.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">View of a feature that can cause a transient swamp. From starting points in the red, and from many directions out of the plotting plane, the downhill direction leads into the blue valleys, which become infinitely steep in the center of the plot.</div>\n<div class=\"imageCredit\">Martin J. Mohlenkamp</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Martin&nbsp;J&nbsp;Mohlenkamp</div>\n<div class=\"imageTitle\">View of a feature that can cause a transient swamp.</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project helped develop the next generation of Mathematicians by\nproviding research opportunities for 3 doctoral students and 10\nMaster's students in Mathematics. Participation helped develop student\nskills in Mathematics itself, the process of conducting research,\nmathematical writing and presentation, and software development.\n\nProgress in understanding tensor approximations has been hampered by\nlack of appropriate tools. In particular, the standard tools in\noptimization do not help in understanding the transient dynamics\nobserved in tensor approximation algorithms. We have developed an\nanalysis framework to provide appropriate tools and measures.\nThe key to understanding the transient dynamics is to look at both how\nfast the error decreases (measured by the norm of the gradient) and\nthe shape of the error perpendicular to the downhill direction\n(measured by the eigenvalues of the Hessian projected transverse to\nthe gradient). When the error decreases slowly (the gradient has small\nnorm) and the shape is a valley with steep sides (the eigenvalues are\npositive with some large) then algorithms will slowly zig-zag down the\nvalley.\n\nWe have completed an in-depth analysis of the two simplest non-trivial\ncases of tensor approximation: a rank-2 tensor approximated by a\nrank-1 tensor and by a rank-2 tensor. Among the many results of this\nanalysis, two especially deserve highlighting:\n\n(1) For a range of parameter values, the problem exhibits minima\nembedded within long, gradually-descending, steep-sided valleys. As\nnoted above, such valleys slow algorithms by causing zig-zag\nbehavior. Thus one should choose algorithms specifically designed to\nwork well in valleys.\n\n(2) For a range of parameter values, the problem exhibits a novel\nfeature that creates valleys that are more gradual in descent and more\nsteeply-sided than is normally possible in optimization problems.  The\nfeature is saddle-like in that from some starting points the downhill\ndirection leads very close to the feature and then turns and leads\naway from it. At the feature, the error function is discontinuous\n(with an essential singularity), which causes the sides of the valley\nto become infinitely steep.  This feature explains the great mystery in\ntensor approximation algorithms: the presence and prevalence of\n``transient swamps'', when an algorithm reduces the error by minuscule\namounts for many iterations and then converges rapidly.\n\n\t\t\t\t\tLast Modified: 10/06/2017\n\n\t\t\t\t\tSubmitted by: Martin J Mohlenkamp"
 }
}