{
 "awd_id": "1422358",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: A Framework for Low Latency Universal Compression with Privacy Guarantees",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 498213.0,
 "awd_amount": 498213.0,
 "awd_min_amd_letter_date": "2014-07-18",
 "awd_max_amd_letter_date": "2014-07-18",
 "awd_abstract_narration": "In contrast to the traditional data communications models in which large blocks of data are compressed, the evolving information generation, access, and storage contexts require compressing relatively smaller blocks of data asynchronously and concurrently from a large number of sources, and often, with additional security and privacy constraints. This research addresses this growing need by developing a rigorous framework for universal lossy and lossless compression algorithms in the finite blocklength regime with strong theoretical guarantees. It also addresses the related need for privacy guarantees in low latency applications via new privacy metrics and mechanisms applicable to datasets of&#8232; all sizes. Finally, the research will develop open-source computational tools for finite blocklength analysis, with applications to numerous communication and compression problems.\r\n\r\nThis research can be applied to the wide variety of systems that continuously collect, store, and process data, including online retailers, search engines, social network sites, and storage systems for electronic medical records. A key impact of the research will be much-needed compression techniques that are more suited to these low-latency applications than traditional methods. In addition, this research will develop privacy mechanisms for these applications, to provide solid privacy assurances in this modern environment in which users are increasingly concerned about their own sensitive data in various electronic forms. The research will also integrate undergraduate and graduate student involvement through curriculum development, theoretical research, and open-source software efforts.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Oliver",
   "pi_last_name": "Kosut",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Oliver Kosut",
   "pi_email_addr": "okosut@asu.edu",
   "nsf_id": "000648964",
   "pi_start_date": "2014-07-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Lalitha",
   "pi_last_name": "Sankar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lalitha Sankar",
   "pi_email_addr": "lalithasankar@asu.edu",
   "nsf_id": "000547715",
   "pi_start_date": "2014-07-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "P Box 876011",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852876011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 498213.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project studied data compression and data publishing in the low latency setting. Low latency refers to the constraint that the time from transmission to reception is very short. Applications with such constraints are pervasive; for example, an online retailer in which users continuously and asynchronously generate short requests to be processed, or a power grid needing to collect measurement data on the state of the system and rapidly choose appropriate control actions based on this data. However, low latency requirements in data compression have traditionally been difficult to approach rigorously due to the mathematical intricacies that underlie the basic theory behind data compression. For this reason, the fundamental limits of data compression (how much a file of a given type can be compressed) have been more well understood for very large files than very short files. This project sought to make use of new ideas from finite blocklength information theory to target this more challenging regime, both for data compression as well as the emerging field of publishing arbitrarily sized datasets in a privacy-assuring manner. This project also sought to understand how to ensure guarantees on restricting leakage of sensitive data in any data sharing context with low latency requirements.</p>\n<p>For the data compression problem, this project led to new characterizations for the fundamental limits of compression of short files, given certain assumptions about the process that created the file. Specifically, a new class of compression algorithm, known as the Type Size code, was shown to outperform all previously considered algorithms, in the sense that it can compress a file with fewer bits if it has been produced from a given family of distributions. Moreover, it was proved that no other algorithm could do any better, up to a small remainder term. The key insight behind the Type Size code is that the amount of information contained in a given data file can be quantified by the number of other conceivable files with similar empirical properties (these properties define what is called a ?type?). Thus, a file with less information?i.e., fewer other files of the same ?type??can be more compressed than a file with more information. This notion of ?type size? as a measure of information was extended to several families of distributions.</p>\n<p>On the privacy front, this project focused on developing tools and techniques to quantify information leakage and design privacy mappings that can restrict undesired inferential learning when data changes hands. Recently, there have been two distinct approaches to quantifying privacy and information leakage. One is the worst-case context-free (i.e., independent of data statistics) notion of differential privacy, which seeks to ensure that a published dataset does not allow distinguishing between two ?neighboring? entries in the original dataset, thereby preserving identity or membership in the data. The other is an information-theoretic approach of providing rigorous average-case guarantees against a large class of adversaries thereby ensuring statistical utility from the published data. This project focused on developing a deeper understanding of the appropriateness of each approach and their mutual relationships.</p>\n<p>Specifically, this project led to multiple novel results on privacy. First, it was shown that exploiting data statistics can allow providing refined statistical utility alongside differential privacy guarantees. Second, focusing on the information-theoretic leakage measure of mutual information, it was shown that when arbitrary queries on a dataset are modeled via general non-separable distortion functions, optimal guarantees require applying the randomizing privacy mechanism to the dataset as a whole, rather than to each entry independently. Finally, this work introduced a new tunable information-theoretic leakage measure called maximal alpha-leakage, which measures privacy leakage against a potential inferring adversary. Tunability of the adversarial capabilities allow straddling between average and worst-case definitions of privacy. Building upon classical information theoretic tools allowed us to characterize the optimal privacy-preserving mechanisms in these settings.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/18/2018<br>\n\t\t\t\t\tModified by: Oliver&nbsp;Kosut</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1422358/1422358_10320310_1545185747545_online_retailer--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1422358/1422358_10320310_1545185747545_online_retailer--rgov-800width.jpg\" title=\"Online Retailer\"><img src=\"/por/images/Reports/POR/2018/1422358/1422358_10320310_1545185747545_online_retailer--rgov-66x44.jpg\" alt=\"Online Retailer\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A motivation application: an online retailer that continuously generates, processes, and stores numerous short user-generated requests</div>\n<div class=\"imageCredit\">Kosut and Sankar</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Oliver&nbsp;Kosut</div>\n<div class=\"imageTitle\">Online Retailer</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1422358/1422358_10320310_1545185846889_TypeSize--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1422358/1422358_10320310_1545185846889_TypeSize--rgov-800width.jpg\" title=\"Type Size Code\"><img src=\"/por/images/Reports/POR/2018/1422358/1422358_10320310_1545185846889_TypeSize--rgov-66x44.jpg\" alt=\"Type Size Code\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A code that sorts sequences (or files) in order by size of their \"type\". Smaller types are compressed more than larger types.</div>\n<div class=\"imageCredit\">Kosut and Sankar</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Oliver&nbsp;Kosut</div>\n<div class=\"imageTitle\">Type Size Code</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1422358/1422358_10320310_1545185992922_privacy_mech--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1422358/1422358_10320310_1545185992922_privacy_mech--rgov-800width.jpg\" title=\"Privacy Setting\"><img src=\"/por/images/Reports/POR/2018/1422358/1422358_10320310_1545185992922_privacy_mech--rgov-66x44.jpg\" alt=\"Privacy Setting\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An example privacy problem: if left unmodified, browsing history would reveal sensitive political preferences. The privacy mechanism distorts the data so that a third party cannot infer the sensitive data.</div>\n<div class=\"imageCredit\">Kosut and Sankar</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Oliver&nbsp;Kosut</div>\n<div class=\"imageTitle\">Privacy Setting</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project studied data compression and data publishing in the low latency setting. Low latency refers to the constraint that the time from transmission to reception is very short. Applications with such constraints are pervasive; for example, an online retailer in which users continuously and asynchronously generate short requests to be processed, or a power grid needing to collect measurement data on the state of the system and rapidly choose appropriate control actions based on this data. However, low latency requirements in data compression have traditionally been difficult to approach rigorously due to the mathematical intricacies that underlie the basic theory behind data compression. For this reason, the fundamental limits of data compression (how much a file of a given type can be compressed) have been more well understood for very large files than very short files. This project sought to make use of new ideas from finite blocklength information theory to target this more challenging regime, both for data compression as well as the emerging field of publishing arbitrarily sized datasets in a privacy-assuring manner. This project also sought to understand how to ensure guarantees on restricting leakage of sensitive data in any data sharing context with low latency requirements.\n\nFor the data compression problem, this project led to new characterizations for the fundamental limits of compression of short files, given certain assumptions about the process that created the file. Specifically, a new class of compression algorithm, known as the Type Size code, was shown to outperform all previously considered algorithms, in the sense that it can compress a file with fewer bits if it has been produced from a given family of distributions. Moreover, it was proved that no other algorithm could do any better, up to a small remainder term. The key insight behind the Type Size code is that the amount of information contained in a given data file can be quantified by the number of other conceivable files with similar empirical properties (these properties define what is called a ?type?). Thus, a file with less information?i.e., fewer other files of the same ?type??can be more compressed than a file with more information. This notion of ?type size? as a measure of information was extended to several families of distributions.\n\nOn the privacy front, this project focused on developing tools and techniques to quantify information leakage and design privacy mappings that can restrict undesired inferential learning when data changes hands. Recently, there have been two distinct approaches to quantifying privacy and information leakage. One is the worst-case context-free (i.e., independent of data statistics) notion of differential privacy, which seeks to ensure that a published dataset does not allow distinguishing between two ?neighboring? entries in the original dataset, thereby preserving identity or membership in the data. The other is an information-theoretic approach of providing rigorous average-case guarantees against a large class of adversaries thereby ensuring statistical utility from the published data. This project focused on developing a deeper understanding of the appropriateness of each approach and their mutual relationships.\n\nSpecifically, this project led to multiple novel results on privacy. First, it was shown that exploiting data statistics can allow providing refined statistical utility alongside differential privacy guarantees. Second, focusing on the information-theoretic leakage measure of mutual information, it was shown that when arbitrary queries on a dataset are modeled via general non-separable distortion functions, optimal guarantees require applying the randomizing privacy mechanism to the dataset as a whole, rather than to each entry independently. Finally, this work introduced a new tunable information-theoretic leakage measure called maximal alpha-leakage, which measures privacy leakage against a potential inferring adversary. Tunability of the adversarial capabilities allow straddling between average and worst-case definitions of privacy. Building upon classical information theoretic tools allowed us to characterize the optimal privacy-preserving mechanisms in these settings.\n\n\t\t\t\t\tLast Modified: 12/18/2018\n\n\t\t\t\t\tSubmitted by: Oliver Kosut"
 }
}