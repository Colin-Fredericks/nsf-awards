{
 "awd_id": "1412566",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Simultaneous Blind De-Convolution of Repeated Astronomical Exposures",
 "cfda_num": "47.049",
 "org_code": "03020000",
 "po_phone": "7032924905",
 "po_email": "nsharp@nsf.gov",
 "po_sign_block_name": "Nigel Sharp",
 "awd_eff_date": "2014-09-15",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 241309.0,
 "awd_amount": 241309.0,
 "awd_min_amd_letter_date": "2014-09-06",
 "awd_max_amd_letter_date": "2014-09-06",
 "awd_abstract_narration": "Images are ubiquitous throughout the scientific endeavor.  Although many pictures are perfectly adequate in their original form, there are many scientific fields where single frames are not sufficient.  Traditional methods of improving such results to enable research with them include combining multiple frames, which often reduces the final quality to around that of the lowest common denominator, and taking long sequences from which only the best are selected and combined, thus throwing away a lot of information.  This is a project to find new ways through statistics and image processing to combine repeated exposures to produce images of superior quality, with less blur and higher resolution, and to carry this out with automatic pipeline processing.  The value of high quality images that retain the maximum amount of information from all the painstakingly assembled data is inestimable, and will impact pretty well every field of science, including amateur activities and citizen science projects, and will be generally useful in any situation where blurred or faint pictures are a limiting factor.\r\n\r\nImaging detectors of increasing size and complexity are nowadays the primary source of data in many scientific experiments.  The images they produce, however, are often blurred by distortions that can change rapidly, such as the atmosphere between astronomical objects and telescopes.  Eliminating such effects with hardware is either extremely complex (e.g,. adaptive optics) or extremely expensive (e.g., space-based observatories).  To detect fainter signals requires multiple exposures, which are traditionally combined by convolving to the lowest acceptable quality, but doing that throws away a lot of the information in the images.  There has to be a better way.  This project will develop new methodologies in computational statistics and image processing for the optimal combination of repeated exposures to produce images of superior quality, having minimal blur and higher resolution than the originals.  This requires developing novel Bayesian algorithms and industrial-strength scalable software.\r\n\r\nThe study combines statistics, computer science and data-intensive science into a focused, powerful research program that should lead to a significant leap in image quality.  The new idea is potentially game changing, is particularly well suited to low signal-to-noise images, and should help in the design of new experiments and observing strategies.  The algorithms and tools developed will be directly applicable to other research fields as diverse as meteorology and genomics, and will be open-source and publicly available.  These next-generation data challenges will be especially valuable training for the graduate student who will be doing much of the work.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "AST",
 "org_div_long_name": "Division Of Astronomical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tamas",
   "pi_last_name": "Budavari",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tamas Budavari",
   "pi_email_addr": "budavari@jhu.edu",
   "nsf_id": "000234436",
   "pi_start_date": "2014-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182685",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "121700",
   "pgm_ele_name": "EXTRAGALACTIC ASTRON & COSMOLO"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1206",
   "pgm_ref_txt": "THEORETICAL & COMPUTATIONAL ASTROPHYSICS"
  },
  {
   "pgm_ref_code": "1207",
   "pgm_ref_txt": "OBSERVATIONAL ASTRONOMY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 241309.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Today dedicated telescopes systematically survey the sky every night producing a steady stream of data. The widest and deepest observations are obtained by multicolor imaging cameras. The development of these high-throughput devices changed the way astronomers think and conduct their studies today. Normal point-and-shoot cameras take pictures at tens of megapixel resolutions, while ongoing scientific experiments already use gigapixel sensors &ndash; the largest planned astronomical camera is a 3.2 Gigapixel array of CCD devices, which will take 600,000 CDs worth of data every night. The vision of these cameras is often blurred by ever-changing, unknown distortions, such as those induced by the atmosphere and the other mediums that act as a screen between the sky and the observer. Developing instruments to correct for these artifacts is often completely impossible or extremely expensive in practice. For example, we pay a high price for launching telescopes into space to eliminate the fluctuating air between the camera lenses and the celestial objects or developing deformable mirrors to correct for the distortions in the wavefront due to the atmosphere.</span></p>\n<p><span>This project&rsquo;s contributions revolve around overcoming these challenges by the optimal combination of repeated observations across multiple epochs. <span>Previous imaging solutions selected a smaller number of&nbsp;</span>lucky images with minimal blur, i.e., sharp point-spread functions or PSFs, and combined those exposures for better signal-to-noise results. The images, however, can only be consistently co-added if their PSFs are the same shape. This is achieved by convolution, which essentially degrades the measurements to the worst acceptable quality. The funded effort used an explicit mathematical model of PSFs and the sky behind the atmosphere to infer them using robust statistics. A scalable implementation on Graphics Processing Units was deployed f</span>or optimal data fusion that can achieve higher spatial resolution and signal to noise ratio than standard techniques. The extracted catalogs provide unbiased estimates of source properties, such as magnitudes. Multiepoch data fusion was also studied on the extracted catalogs, and was shown to map on probabilistic cross-identification. The observational constraints (likelihood functions) are practically identical to those derived from coadded images. A globally optimal strategy was developed based on combinatorial optimization.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/29/2018<br>\n\t\t\t\t\tModified by: Tamas&nbsp;Budavari</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nToday dedicated telescopes systematically survey the sky every night producing a steady stream of data. The widest and deepest observations are obtained by multicolor imaging cameras. The development of these high-throughput devices changed the way astronomers think and conduct their studies today. Normal point-and-shoot cameras take pictures at tens of megapixel resolutions, while ongoing scientific experiments already use gigapixel sensors &ndash; the largest planned astronomical camera is a 3.2 Gigapixel array of CCD devices, which will take 600,000 CDs worth of data every night. The vision of these cameras is often blurred by ever-changing, unknown distortions, such as those induced by the atmosphere and the other mediums that act as a screen between the sky and the observer. Developing instruments to correct for these artifacts is often completely impossible or extremely expensive in practice. For example, we pay a high price for launching telescopes into space to eliminate the fluctuating air between the camera lenses and the celestial objects or developing deformable mirrors to correct for the distortions in the wavefront due to the atmosphere.\n\nThis project?s contributions revolve around overcoming these challenges by the optimal combination of repeated observations across multiple epochs. Previous imaging solutions selected a smaller number of lucky images with minimal blur, i.e., sharp point-spread functions or PSFs, and combined those exposures for better signal-to-noise results. The images, however, can only be consistently co-added if their PSFs are the same shape. This is achieved by convolution, which essentially degrades the measurements to the worst acceptable quality. The funded effort used an explicit mathematical model of PSFs and the sky behind the atmosphere to infer them using robust statistics. A scalable implementation on Graphics Processing Units was deployed for optimal data fusion that can achieve higher spatial resolution and signal to noise ratio than standard techniques. The extracted catalogs provide unbiased estimates of source properties, such as magnitudes. Multiepoch data fusion was also studied on the extracted catalogs, and was shown to map on probabilistic cross-identification. The observational constraints (likelihood functions) are practically identical to those derived from coadded images. A globally optimal strategy was developed based on combinatorial optimization.\n\n \n\n\t\t\t\t\tLast Modified: 01/29/2018\n\n\t\t\t\t\tSubmitted by: Tamas Budavari"
 }
}