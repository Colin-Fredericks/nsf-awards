{
 "awd_id": "1416259",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Mid-Scale: DA: Collaborative Research: Genomes Galore - Core Techniques, Libraries, and Domain Specific Languages for High-Throughput DNA Sequencing",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2013-08-31",
 "awd_exp_date": "2018-12-31",
 "tot_intn_awd_amt": 1233193.0,
 "awd_amount": 1285507.0,
 "awd_min_amd_letter_date": "2014-01-22",
 "awd_max_amd_letter_date": "2017-11-07",
 "awd_abstract_narration": "The recent emergence of a variety of high-throughput DNA sequencing instrumentation, and the concomitant rapid decline in the cost per base, is causing severe data deluge in all areas of life sciences. The heterogeneity of sequencing instrumentation and the vast diversity of applications enabled by them are creating numerous analytics problems for the bioinformatics community to address. In addition, the conventional serial algorithms that have been the mainstay of bioinformatics research are severely challenged by the ever increasing data sets. The goal of the proposed project is to develop core techniques and software libraries to enable scalable, efficient, high performance computing solutions for high-throughput DNA sequencing, also known as next-generation sequencing (NGS). To empower the larger community, the project seeks to 1) identify a set of core functionalities that frequently occur in many types of high-throughput sequencing applications, 2) develop efficient parallel algorithms and high performance implementations for them, 3) pursue mapping to HPC architectures including clusters, multicores, and GPUs, 4) develop software libraries encapsulating these functionalities with the goal of enabling the bioinformatics community to exploit HPC architectures, and 5) design a domain specific language to enable bioinformatics researchers unfamiliar with parallel processing to benefit from this work through automatic generation of parallel codes. The research will be conducted in the context of challenging problems in human genetics and metagenomics, in collaboration with domain specialists.\r\n\r\nThis project is focused on a key capacity building activity to facilitate pervasive use of parallelism by NGS bioinformatics researchers and practitioners. The goal is to empower the broader community to benefit from clever parallel algorithms, highly tuned implementations, and specialized HPC hardware, without requiring expertise in any of these. The software libraries will be released as open source for use, further development, enhancements, and incorporation by the community. The project will provide opportunities for training postdoctoral and graduate students in bigdata analytics and computer science driven interdisciplinary research. Diverse existing mechanisms at the partner institutions will be leveraged to advance goals of minority and women recruitment, undergraduate participation in research, and K-12 outreach.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Srinivas",
   "pi_last_name": "Aluru",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Srinivas Aluru",
   "pi_email_addr": "aluru@cc.gatech.edu",
   "nsf_id": "000388133",
   "pi_start_date": "2014-01-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5921",
   "pgm_ref_txt": "JAPAN"
  },
  {
   "pgm_ref_code": "7299",
   "pgm_ref_txt": "INTERNATIONAL PLAN & WORKSHOPS"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 1233193.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 52314.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>High throughput genome sequencing has become ubiquitous due to increasing accessibility and decreasing cost.&nbsp; The resulting large data volume and high rate of production present significant big data challenges for large-scale bioinformatic data analyses.&nbsp; The growths in data size, computation time, and problem complexity have outpaced growth in CPU capabilities and memory capacity, often described by Moore&rsquo;s Law.<br /><br />This project seeks to support large-scale data analytics in the presence of such growth disparity, through the development of novel, efficient algorithms, their parallel and sequential implementations, and core HPC techniques and data structures.&nbsp; To facilitate adoption and increase the impact for multiple biological and non-biological applications, we have formulated our implementations as flexible and reusable libraries for both standalone and clusters of computers.<br /><br />We have targeted common tasks that are fundamental to current and anticipated biological applications and data analytics across a diversity of organisms and sequencing technologies, yet previously were computationally costly and/or resource intensive.&nbsp; We have significantly advanced the state-of-the-art in theoretical and empirical computational performance as well as scalability in data and problem size&nbsp; in multiple applications.&nbsp; We highlight our contributions in a select few areas: sequence indexing, sequence comparison and mapping, and genome assembly.<br /><br />Exact pattern search is a fundamental task for many sequence analysis applications ranging from error correction to genome assembly.&nbsp; Finding the locations of the matching patterns and the related task of counting their occurrences are greatly facilitated by <strong>sequence indexing</strong>.&nbsp; We developed several state-of-the-art algorithms for indexing and querying sequences.&nbsp; For counting fixed-length patterns, our algorithm indexed and queried a 1TB human sequence data set in 11.8 and 5.8 seconds respectively, using 4096 CPU cores.&nbsp; For indexing variable length patterns, our algorithm, for the first time, allows index construction and query from an input sequence that is partitioned and distributed across all computers in a cluster, thus enabling data size to scale beyond the resources of a single machine.&nbsp; This algorithm indexed a reference human genome in less than 8 seconds on 1024 CPU cores, 110x faster than the previous best sequential algorithm.<br /><br />Using the distribution of fixed-length patterns within a sequence as signature, we developed fast approximate algorithms&nbsp; for sequence mapping and comparison of long reads and genomic segments.&nbsp; Our mapping algorithm is shown to be 290x faster than BWA-mem, while our comparison algorithm is up to 3 orders of magnitude faster than alignment based methods.&nbsp; Application of these approximate algorithms have already led to new scientific knowledge.&nbsp; Our mapping algorithm was able to identify more segmental duplications in the human genome than previously known.&nbsp; Our approximate sequence comparison algorithm, when applied, for the first time, to all ~90,000 prokaryotic genomes in the NCBI database, definitively answered the age-old question in microbiology of whether there exist clear species boundaries based on genomic variations (Nature Communications &lsquo;18).<br /><br />De novo<strong> genome assembly</strong> is the process by which a genome is reconstructed from sequencer output, typically by traversing an internal graph data structure.&nbsp; This is a time consuming task that is data- and communication-intensive.&nbsp; We developed fast algorithms for constructing, traversing, and filtering this domain-specific graph structure.&nbsp; We showed that for a 695GB human sequence data set, our algorithm reconstructed the initial sequences in 31.1 seconds using 7680 CPU cores, a 3.7x speed up relative to the previous state-of-the-art assembler.&nbsp; We further developed an algorithm for identifying disjoint components in the graph, thus enabling independent and parallel assembly from the components.&nbsp;&nbsp; This is critical for accelerating and scaling metagenomic assembly, where multiple bacterial genomes are sequenced concurrently and sequencer output contains a mixture of genome fragments.&nbsp; We demonstrated component labeling on a metagenomic graph with 50 billion edges in 215 seconds using 32 thousand CPU cores.<br /><br />The software implementations have been released in a public repository under open source licenses (https://github.com/ParBLiSS).&nbsp; The algorithms and implementations have broad impact for biological sequence analysis and beyond.&nbsp; Our sequence indexing and comparison algorithms are applicable to general text and strings, while our graph component labeling algorithm has been tested on a wide range of graph types, achieving up to 24x speed up over the previous state-of-the-art.&nbsp; Low level high performance data structures and algorithms, where possible, have also been designed to be domain agnostic, and can benefit a broad range of applications.</p>\n<p>The project is a collaborative effort between 3 PIs, one each in computer science, plant biology, and human genetics. The project supported the research of 3 research scientists, 1 postdoctoral fellow, and 7 Ph.D. students who gained valuable interdisciplinary research experience.&nbsp; The project supported the Ph.D. dissertation work of these students, including three whose Ph.D. disseration is solely based on the work carried out under the project. The lead PI organized workshops and gave several invited and keynote presentations to inform the research community about results from this project.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/12/2019<br>\n\t\t\t\t\tModified by: Srinivas&nbsp;Aluru</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696468571_Motivation--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696468571_Motivation--rgov-800width.jpg\" title=\"Intersections of High Performance Computing, High Throughput Sequencing, and Life Science\"><img src=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696468571_Motivation--rgov-66x44.jpg\" alt=\"Intersections of High Performance Computing, High Throughput Sequencing, and Life Science\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Biological sequences analysis has become a big data endeavour due to advances in high throughput sequencing technologies, motivating increasingly sophisticated bioinformatic analyses, and necessitating novel high performance computing hardware, techniques, and algorithms.</div>\n<div class=\"imageCredit\">Srinivas Aluru</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Srinivas&nbsp;Aluru</div>\n<div class=\"imageTitle\">Intersections of High Performance Computing, High Throughput Sequencing, and Life Science</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696549502_Pipeline--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696549502_Pipeline--rgov-800width.jpg\" title=\"High Throughput Sequencing and Analysis Pipeline\"><img src=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696549502_Pipeline--rgov-66x44.jpg\" alt=\"High Throughput Sequencing and Analysis Pipeline\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Illustration of high throughput sequencing and analysis pipeline.  Genomes from diverse organisms are sequenced via high throughput technologies.  Analytics, including error correction, sequence mapping, assembly, and indexing are then applied to the sequencing output in order to extract knowledge.</div>\n<div class=\"imageCredit\">Tony Pan, Patrick Flick, Srinvas Aluru</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Srinivas&nbsp;Aluru</div>\n<div class=\"imageTitle\">High Throughput Sequencing and Analysis Pipeline</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696643117_ParallelApproximateSequenceMatching--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696643117_ParallelApproximateSequenceMatching--rgov-800width.jpg\" title=\"Parallel Approximate Sequence Matching\"><img src=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696643117_ParallelApproximateSequenceMatching--rgov-66x44.jpg\" alt=\"Parallel Approximate Sequence Matching\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Given input sequences of size n, our algorithm computes sufficiently long pairwise alignments with bounded number of mismatches.  this is a key step in many sequence analysis tasks.  We show near linear scaling with number of CPU cores for 1- and 2-mismatches alignments.</div>\n<div class=\"imageCredit\">Sriram Chocklingam, Srinivas Aluru</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Srinivas&nbsp;Aluru</div>\n<div class=\"imageTitle\">Parallel Approximate Sequence Matching</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696739389_GraphComponents--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696739389_GraphComponents--rgov-800width.jpg\" title=\"Parallel Graph Partitioning and Genome Sssembly\"><img src=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696739389_GraphComponents--rgov-66x44.jpg\" alt=\"Parallel Graph Partitioning and Genome Sssembly\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Metagenomic sequences from soil, water, gut, and other environmental sources contain mixture of bacterial species and form disjoint graph components.  Partitioning the assembly graph allows the components to be assembled in parallel.</div>\n<div class=\"imageCredit\">Tony Pan, Chirag Jain, Srinivas Aluru</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Srinivas&nbsp;Aluru</div>\n<div class=\"imageTitle\">Parallel Graph Partitioning and Genome Sssembly</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696876582_NCBIAnalysis--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696876582_NCBIAnalysis--rgov-800width.jpg\" title=\"Genomic Variation between Prokaryotic Species\"><img src=\"/por/images/Reports/POR/2019/1416259/1416259_10217512_1555696876582_NCBIAnalysis--rgov-66x44.jpg\" alt=\"Genomic Variation between Prokaryotic Species\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">ANI values from pairwise comparisons, using FastANI, of ~90000 prokaryotic genomes in the NCBI database (left) indicates a wide inter-species genetic discontinuum.  Species identity can be established above 95% ANI similarity (right).</div>\n<div class=\"imageCredit\">Chirag Jain, Srinivas Aluru, Nature Communications 2018</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Srinivas&nbsp;Aluru</div>\n<div class=\"imageTitle\">Genomic Variation between Prokaryotic Species</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nHigh throughput genome sequencing has become ubiquitous due to increasing accessibility and decreasing cost.  The resulting large data volume and high rate of production present significant big data challenges for large-scale bioinformatic data analyses.  The growths in data size, computation time, and problem complexity have outpaced growth in CPU capabilities and memory capacity, often described by Moore?s Law.\n\nThis project seeks to support large-scale data analytics in the presence of such growth disparity, through the development of novel, efficient algorithms, their parallel and sequential implementations, and core HPC techniques and data structures.  To facilitate adoption and increase the impact for multiple biological and non-biological applications, we have formulated our implementations as flexible and reusable libraries for both standalone and clusters of computers.\n\nWe have targeted common tasks that are fundamental to current and anticipated biological applications and data analytics across a diversity of organisms and sequencing technologies, yet previously were computationally costly and/or resource intensive.  We have significantly advanced the state-of-the-art in theoretical and empirical computational performance as well as scalability in data and problem size  in multiple applications.  We highlight our contributions in a select few areas: sequence indexing, sequence comparison and mapping, and genome assembly.\n\nExact pattern search is a fundamental task for many sequence analysis applications ranging from error correction to genome assembly.  Finding the locations of the matching patterns and the related task of counting their occurrences are greatly facilitated by sequence indexing.  We developed several state-of-the-art algorithms for indexing and querying sequences.  For counting fixed-length patterns, our algorithm indexed and queried a 1TB human sequence data set in 11.8 and 5.8 seconds respectively, using 4096 CPU cores.  For indexing variable length patterns, our algorithm, for the first time, allows index construction and query from an input sequence that is partitioned and distributed across all computers in a cluster, thus enabling data size to scale beyond the resources of a single machine.  This algorithm indexed a reference human genome in less than 8 seconds on 1024 CPU cores, 110x faster than the previous best sequential algorithm.\n\nUsing the distribution of fixed-length patterns within a sequence as signature, we developed fast approximate algorithms  for sequence mapping and comparison of long reads and genomic segments.  Our mapping algorithm is shown to be 290x faster than BWA-mem, while our comparison algorithm is up to 3 orders of magnitude faster than alignment based methods.  Application of these approximate algorithms have already led to new scientific knowledge.  Our mapping algorithm was able to identify more segmental duplications in the human genome than previously known.  Our approximate sequence comparison algorithm, when applied, for the first time, to all ~90,000 prokaryotic genomes in the NCBI database, definitively answered the age-old question in microbiology of whether there exist clear species boundaries based on genomic variations (Nature Communications ?18).\n\nDe novo genome assembly is the process by which a genome is reconstructed from sequencer output, typically by traversing an internal graph data structure.  This is a time consuming task that is data- and communication-intensive.  We developed fast algorithms for constructing, traversing, and filtering this domain-specific graph structure.  We showed that for a 695GB human sequence data set, our algorithm reconstructed the initial sequences in 31.1 seconds using 7680 CPU cores, a 3.7x speed up relative to the previous state-of-the-art assembler.  We further developed an algorithm for identifying disjoint components in the graph, thus enabling independent and parallel assembly from the components.   This is critical for accelerating and scaling metagenomic assembly, where multiple bacterial genomes are sequenced concurrently and sequencer output contains a mixture of genome fragments.  We demonstrated component labeling on a metagenomic graph with 50 billion edges in 215 seconds using 32 thousand CPU cores.\n\nThe software implementations have been released in a public repository under open source licenses (https://github.com/ParBLiSS).  The algorithms and implementations have broad impact for biological sequence analysis and beyond.  Our sequence indexing and comparison algorithms are applicable to general text and strings, while our graph component labeling algorithm has been tested on a wide range of graph types, achieving up to 24x speed up over the previous state-of-the-art.  Low level high performance data structures and algorithms, where possible, have also been designed to be domain agnostic, and can benefit a broad range of applications.\n\nThe project is a collaborative effort between 3 PIs, one each in computer science, plant biology, and human genetics. The project supported the research of 3 research scientists, 1 postdoctoral fellow, and 7 Ph.D. students who gained valuable interdisciplinary research experience.  The project supported the Ph.D. dissertation work of these students, including three whose Ph.D. disseration is solely based on the work carried out under the project. The lead PI organized workshops and gave several invited and keynote presentations to inform the research community about results from this project.\n\n\t\t\t\t\tLast Modified: 05/12/2019\n\n\t\t\t\t\tSubmitted by: Srinivas Aluru"
 }
}