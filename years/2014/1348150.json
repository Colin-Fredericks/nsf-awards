{
 "awd_id": "1348150",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "The time course of speech perception and production in individual language users",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Badecker",
 "awd_eff_date": "2014-07-01",
 "awd_exp_date": "2018-12-31",
 "tot_intn_awd_amt": 389320.0,
 "awd_amount": 389320.0,
 "awd_min_amd_letter_date": "2014-06-07",
 "awd_max_amd_letter_date": "2014-06-07",
 "awd_abstract_narration": "Clarifying the highly complex dynamic processes that underlie the production and perception of speech is critical both to our understanding of human language processing and to improvements in technologies for computer-mediated communication. Speakers must fluently coordinate the actions of multiple vocal organs (such as the lips, tongue, and jaw) to produce the overlapping movements necessary for smooth and rapid speech. In deriving meaning from the resulting acoustic signal, listeners must attend to the changing acoustic properties as they evolve over time.\r\n\r\nWith the support of the National Science Foundation, Dr. Beddor and Dr. Coetzee are studying the relation between the dynamics of spoken language production and perception. Previous research has found that speakers differ from each other in their precise patterns of articulatory coordination, and that listeners differ in their sensitivity to those variable coarticulated patterns in deciding what a speaker has said. This project investigates whether there is a link between a listener's use of coarticulatory information in perception and that language user's own coarticulated productions. \r\n\r\nGuided by the hypothesis that the relation between a language user's perception and production is mediated by social, cognitive, and other factors, a series of experiments tests both socially neutral and socially indexed patterns of articulatory coordination. These experiments also test language users' perceptual awareness of, and articulatory accommodation to, new patterns of coordination. Listeners' real-time processing of the acoustic signal is monitored using eye-tracking methods; the time course of production is assessed via airflow, ultrasound imaging, and acoustic analysis.  The project will gather data on the production and perception of America English and Afrikaans. The Afrikaans work will broaden empirical coverage of a phonetically understudied language and will extend collaboration with South African researchers. An overarching goal of studying the production-perception relation in individual language users is to understand how linguistic structures are represented in the human mind. Elucidating this relation in its social context should also contribute to an understanding of how individual differences in these structures might serve as a source of new sound patterns that spread through a speech community.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Patrice",
   "pi_last_name": "Beddor",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Patrice S Beddor",
   "pi_email_addr": "beddor@umich.edu",
   "nsf_id": "000379878",
   "pi_start_date": "2014-06-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andries",
   "pi_last_name": "Coetzee",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Andries W Coetzee",
   "pi_email_addr": "coetzee@umich.edu",
   "nsf_id": "000096229",
   "pi_start_date": "2014-06-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "440 Lorch Hall, 611 Tappan St.",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091220",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 389320.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>When we speak, we coordinate the movements of our lips, tongue, jaw, and other vocal organs in order to produce fluent, continuous speech. Because these coordinated movements temporally overlap with each other&mdash;that is, they are coarticulated&mdash;they have the potential to provide listeners with useful information about an upcoming speech sound before that sound actually occurs. Research has shown that, when we listen, we use this anticipatory information in our decisions about what speakers are saying as the speech signal unfolds in real time.</p>\n<p>This project investigated differences between speakers in their coarticulation patterns and differences between listeners in their attention to the anticipatory information resulting from coarticulation. Two main discoveries came out of this work. First, our results show that the perceptual usefulness of coarticulated speech for a particular language user is closely related to that individual's own productions: the more an individual uses anticipatory information in their moment-by-moment decisions of what a speaker is saying, the more the same individual produces that coarticulation pattern in their own speech. Establishing this link between an individual's perception and production is important to understanding the dynamic properties of perceiving and producing speech and, relatedly, to understanding how speakers and listeners successfully communicate with each other in everyday conversational interactions. Establishing a perception-production link for individuals is also important to understanding how listeners might contribute to a novel coarticulation pattern becoming the new norm within their speech community. For listeners to contribute to the spread of a new speech variant through the community, their percepts&mdash;for example, percepts that a variant is especially useful or otherwise important&mdash;must be made public. Our results for perception and production of coarticulated speech indicate that listeners do make their percepts known through their productions.</p>\n<p>The second main discovery emerged from this project's study of the influence of social factors on perception and production of coarticulated speech. Because spread of a new speech variant can be restricted to a particular speech community, members of different communities often differ in their speech patterns, including in their patterns of overlapping movements of the speech articulators. Our findings for two socio-ethnic varieties of Afrikaans (spoken in South Africa) show that, as speakers, members of each community differ systematically in how they coordinate overlapping gestures for vowels and following consonants. As listeners, community members perceptually attend to the information afforded by each group's coarticulation patterns in ways that are conditioned by the social structuring of that information. The scientific contribution of these results is that, by delineating the linguistic and social dynamics of speaking and listening, they inform the ways that social expectations influence spoken communication between interlocutors from different speech communities.</p>\n<p>In addition to these two primary outcomes, the project led to the development of novel experimental and analytic techniques, including a new method for analyzing ultrasound images of the tongue during continuous speech. Ultrasound imaging of the tongue provides detailed articulatory information used to address both research and practical issues, including issues related to articulatory delays in children and specific language impairments. However, using ultrasound data&mdash;for example, to analyze patterns of coarticulation or the tongue contours of misarticulating children&mdash;typically requires the time-consuming process of manually labeling tongue contours. Researchers in our lab developed a time-saving, accurate method for the automatic identification and extraction of tongue contours using a machine-learning algorithm.</p>\n<p>This interdisciplinary project has involved the collaboration of linguists and psychologists across multiple universities in the United States and abroad. We have integrated research and education by providing postdoctoral scholars, graduate students, and undergraduate students with training in a wide range of methodological techniques (ultrasound, airflow, eye-tracking, acoustic analysis) and statistical methods. Most of the undergraduate research assistants on the project have continued on to graduate study in linguistics or the speech and hearing sciences. The findings have been disseminated to the scientific community through peer-reviewed publications and presentations.</p>\n<p>An impact of this project beyond science and technology is that it has fostered close collaboration with colleagues at the North-West University in Potchefstroom, South Africa. This collaboration, which involves faculty and students at that institution, has led to strengthened ties between the University of Michigan and African scholars. The project has, as well, contributed to our knowledge of a phonetically understudied language and the speech patterns of minority speakers of that language.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/28/2019<br>\n\t\t\t\t\tModified by: Patrice&nbsp;S&nbsp;Beddor</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhen we speak, we coordinate the movements of our lips, tongue, jaw, and other vocal organs in order to produce fluent, continuous speech. Because these coordinated movements temporally overlap with each other&mdash;that is, they are coarticulated&mdash;they have the potential to provide listeners with useful information about an upcoming speech sound before that sound actually occurs. Research has shown that, when we listen, we use this anticipatory information in our decisions about what speakers are saying as the speech signal unfolds in real time.\n\nThis project investigated differences between speakers in their coarticulation patterns and differences between listeners in their attention to the anticipatory information resulting from coarticulation. Two main discoveries came out of this work. First, our results show that the perceptual usefulness of coarticulated speech for a particular language user is closely related to that individual's own productions: the more an individual uses anticipatory information in their moment-by-moment decisions of what a speaker is saying, the more the same individual produces that coarticulation pattern in their own speech. Establishing this link between an individual's perception and production is important to understanding the dynamic properties of perceiving and producing speech and, relatedly, to understanding how speakers and listeners successfully communicate with each other in everyday conversational interactions. Establishing a perception-production link for individuals is also important to understanding how listeners might contribute to a novel coarticulation pattern becoming the new norm within their speech community. For listeners to contribute to the spread of a new speech variant through the community, their percepts&mdash;for example, percepts that a variant is especially useful or otherwise important&mdash;must be made public. Our results for perception and production of coarticulated speech indicate that listeners do make their percepts known through their productions.\n\nThe second main discovery emerged from this project's study of the influence of social factors on perception and production of coarticulated speech. Because spread of a new speech variant can be restricted to a particular speech community, members of different communities often differ in their speech patterns, including in their patterns of overlapping movements of the speech articulators. Our findings for two socio-ethnic varieties of Afrikaans (spoken in South Africa) show that, as speakers, members of each community differ systematically in how they coordinate overlapping gestures for vowels and following consonants. As listeners, community members perceptually attend to the information afforded by each group's coarticulation patterns in ways that are conditioned by the social structuring of that information. The scientific contribution of these results is that, by delineating the linguistic and social dynamics of speaking and listening, they inform the ways that social expectations influence spoken communication between interlocutors from different speech communities.\n\nIn addition to these two primary outcomes, the project led to the development of novel experimental and analytic techniques, including a new method for analyzing ultrasound images of the tongue during continuous speech. Ultrasound imaging of the tongue provides detailed articulatory information used to address both research and practical issues, including issues related to articulatory delays in children and specific language impairments. However, using ultrasound data&mdash;for example, to analyze patterns of coarticulation or the tongue contours of misarticulating children&mdash;typically requires the time-consuming process of manually labeling tongue contours. Researchers in our lab developed a time-saving, accurate method for the automatic identification and extraction of tongue contours using a machine-learning algorithm.\n\nThis interdisciplinary project has involved the collaboration of linguists and psychologists across multiple universities in the United States and abroad. We have integrated research and education by providing postdoctoral scholars, graduate students, and undergraduate students with training in a wide range of methodological techniques (ultrasound, airflow, eye-tracking, acoustic analysis) and statistical methods. Most of the undergraduate research assistants on the project have continued on to graduate study in linguistics or the speech and hearing sciences. The findings have been disseminated to the scientific community through peer-reviewed publications and presentations.\n\nAn impact of this project beyond science and technology is that it has fostered close collaboration with colleagues at the North-West University in Potchefstroom, South Africa. This collaboration, which involves faculty and students at that institution, has led to strengthened ties between the University of Michigan and African scholars. The project has, as well, contributed to our knowledge of a phonetically understudied language and the speech patterns of minority speakers of that language.\n\n \n\n\t\t\t\t\tLast Modified: 03/28/2019\n\n\t\t\t\t\tSubmitted by: Patrice S Beddor"
 }
}