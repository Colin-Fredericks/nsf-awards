{
 "awd_id": "1421678",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF:Small:Collaborative Research: Compositional Verification of Heterogeneous Software Protocol Stacks",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2014-07-01",
 "awd_exp_date": "2017-12-31",
 "tot_intn_awd_amt": 252996.0,
 "awd_amount": 268996.0,
 "awd_min_amd_letter_date": "2014-06-18",
 "awd_max_amd_letter_date": "2015-02-18",
 "awd_abstract_narration": "Developing a software protocol stack is a complex task with many parties and products \r\ninvolved over multiple years. There are many issues that have to be resolved in the \r\nprocess, and it is incredibly hard to get all of them correct for all platforms and \r\nall possible states of a system. Hence, there are numerous examples of serious errors\r\nthat ended up in production, where the cost of fixing them is high. Software protocol \r\nstacks are widely used in many domains, and rigorous methods to improve their \r\nreliability would have a very broad impact. \r\n\r\nThe project develops a more rigorous approach to developing and maintaining such complex software\r\n protocol stacks.In particular, formal methods are used to find errors early through rigorous \r\nverification and testing, as well as to assist the analysis in locating reported errors. The approach\r\n is based on automatically learning abstract and succinct protocol models at different layers of the\r\n target software stack. Compositional reasoning is then applied to find errors effectively and \r\nprecisely. The generated models are leveraged to help with error localization and diagnosis. The \r\nusability of the approach is assessed through a real-life case study on the Android Bluetooth\r\n software stack.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zvonimir",
   "pi_last_name": "Rakamaric",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zvonimir Rakamaric",
   "pi_email_addr": "zvonimir@cs.utah.edu",
   "nsf_id": "000623290",
   "pi_start_date": "2014-06-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841129205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8206",
   "pgm_ref_txt": "Formal Methods and Verification"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 252996.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main research goal of this project was to devise novel software verification and testing techniques for improving the reliability and safety of complex protocol stacks, spanning multiple abstraction levels and/or programming languages. Our specific proposed target was the Android ecosystem, which includes the application, Java libraries, and C/C++ operating system (OS) levels. Next, we describe our accomplishments at each of these levels.</p>\n<p>At the application level, we developed a simple, and yet highly effective technique for detecting malicious Android applications. It is well-known that application market places often contain malicious applications, which can be dangerous when installed to users' phones. Our technique performs automatic classification of applications based on tracking system calls while they are executed in a sandbox environment. We implemented the technique in a tool called maline, and performed extensive empirical evaluation on a suite of around 12,000 applications. The evaluation yields a promising overall detection accuracy as compared to related approaches. This indicates that our technique is viable to be used in practice to detect Android malware. Finally, we show that even simplistic feature choices are highly effective, suggesting that more heavyweight approaches should be thoroughly (re)evaluated. As a part of this line of work we publicly released a large dataset that has been used by other researchers in the area of Android malware detection and machine learning.</p>\n<p>At the Java libraries level, we devised a novel approach to improve code coverage of automatic testing of Java libraries. The testing of Java libraries is challenging since it requires from the testing tool to generate complex sequences of library method invocations as input in addition to covering hard-to-reach program paths within each method. The approach we proposed is based on a&nbsp;novel combination of random testing and dynamic symbolic execution, where random testing is used to generate interesting sequences of library invocations, while dynamic symbolic execution is used to explore program paths based on each sequence. We implemented this combination as the JDoop automatic Java testing tool, which combines the JDart dynamic symbolic execution engine with the Randoop random software tester. We performed an extensive empirical evaluation of our combination, analyzed that gathered data, and draw conclusions about its pros and cons. In particular, we do show that in some instances our combination outperforms both of the individual approaches, thereby improving state-of-the-art in the area of automatic testing of Java libraries.</p>\n<p>At the operating system level, we observed that Rust, in combination with C/C++, is gaining traction when it comes to implementing safer operating system modules and protocol stacks. Rust is a new programming language that includes features that make it safer than the traditional OS languages such as C/C++. Hence, we extended our flagship software verifier SMACK with support for cross-language verification of Rust/C/C++ programs. Our architecture based on an intermediate verification language, into which all input languages are translated, allows us to perform uniform verification across language boundaries. We applied SMACK to verify simple Rust implementation of a safe information flow control protocol, thereby showing its promise. We also showed that SMACK can now be used to verify programs that combine Rust with C/C++.</p>\n<p>We disseminated our research results by publishing conference research papers and reports. We also implemented tools and extensions stemming from this research, and we disseminated those to the academic community as well as practitioners. We made all of the developed tools publicly available as open-source projects. As a part of this project, we also trained a generation of students, including both graduates and undergraduates, in the areas of software verification and testing.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/20/2018<br>\n\t\t\t\t\tModified by: Zvonimir&nbsp;Rakamaric</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe main research goal of this project was to devise novel software verification and testing techniques for improving the reliability and safety of complex protocol stacks, spanning multiple abstraction levels and/or programming languages. Our specific proposed target was the Android ecosystem, which includes the application, Java libraries, and C/C++ operating system (OS) levels. Next, we describe our accomplishments at each of these levels.\n\nAt the application level, we developed a simple, and yet highly effective technique for detecting malicious Android applications. It is well-known that application market places often contain malicious applications, which can be dangerous when installed to users' phones. Our technique performs automatic classification of applications based on tracking system calls while they are executed in a sandbox environment. We implemented the technique in a tool called maline, and performed extensive empirical evaluation on a suite of around 12,000 applications. The evaluation yields a promising overall detection accuracy as compared to related approaches. This indicates that our technique is viable to be used in practice to detect Android malware. Finally, we show that even simplistic feature choices are highly effective, suggesting that more heavyweight approaches should be thoroughly (re)evaluated. As a part of this line of work we publicly released a large dataset that has been used by other researchers in the area of Android malware detection and machine learning.\n\nAt the Java libraries level, we devised a novel approach to improve code coverage of automatic testing of Java libraries. The testing of Java libraries is challenging since it requires from the testing tool to generate complex sequences of library method invocations as input in addition to covering hard-to-reach program paths within each method. The approach we proposed is based on a novel combination of random testing and dynamic symbolic execution, where random testing is used to generate interesting sequences of library invocations, while dynamic symbolic execution is used to explore program paths based on each sequence. We implemented this combination as the JDoop automatic Java testing tool, which combines the JDart dynamic symbolic execution engine with the Randoop random software tester. We performed an extensive empirical evaluation of our combination, analyzed that gathered data, and draw conclusions about its pros and cons. In particular, we do show that in some instances our combination outperforms both of the individual approaches, thereby improving state-of-the-art in the area of automatic testing of Java libraries.\n\nAt the operating system level, we observed that Rust, in combination with C/C++, is gaining traction when it comes to implementing safer operating system modules and protocol stacks. Rust is a new programming language that includes features that make it safer than the traditional OS languages such as C/C++. Hence, we extended our flagship software verifier SMACK with support for cross-language verification of Rust/C/C++ programs. Our architecture based on an intermediate verification language, into which all input languages are translated, allows us to perform uniform verification across language boundaries. We applied SMACK to verify simple Rust implementation of a safe information flow control protocol, thereby showing its promise. We also showed that SMACK can now be used to verify programs that combine Rust with C/C++.\n\nWe disseminated our research results by publishing conference research papers and reports. We also implemented tools and extensions stemming from this research, and we disseminated those to the academic community as well as practitioners. We made all of the developed tools publicly available as open-source projects. As a part of this project, we also trained a generation of students, including both graduates and undergraduates, in the areas of software verification and testing.\n\n\t\t\t\t\tLast Modified: 02/20/2018\n\n\t\t\t\t\tSubmitted by: Zvonimir Rakamaric"
 }
}