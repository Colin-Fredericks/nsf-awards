{
 "awd_id": "1362458",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Project Smart-Recon: Smart Device-Enabled Reconnaissance after Earthquakes",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "coskay",
 "awd_eff_date": "2014-06-01",
 "awd_exp_date": "2019-05-31",
 "tot_intn_awd_amt": 227958.0,
 "awd_amount": 227958.0,
 "awd_min_amd_letter_date": "2014-04-04",
 "awd_max_amd_letter_date": "2014-04-04",
 "awd_abstract_narration": "Whenever a catastrophic event occurs, reconnaissance teams are deployed within the affected areas to conduct visual inspections of buildings. The teams tag the buildings red, yellow or green to indicate their probable condition and permitted use. This function often takes weeks. The central premise of this work is that widespread citizen ownership of smartphones and devices can be leveraged to automate and significantly accelerate this first reconnaissance effort. Under this project, research will be conducted on how to integrate measurements performed by sensors that are typically part of most modern smart devices (e.g. accelerometers, gyroscopes, etc.) to infer information about their motion during a seismic event. By increasing the speed and accuracy with which building damage may be assessed in the aftermath of natural disasters, the proposed reconnaissance technology will reduce potential hazards and hardships to citizens and will provide enormous cost savings. Knowing this information will also enable first responders to optimize their response and physical inspection teams to prioritize their efforts, thereby minimizing confusion in the aftermath of a disaster. On the educational front, this project will have a substantial impact on the development of human resources. By bridging civil and electrical engineering, the students who will work on this project will attain a multi-disciplinary education at the intersection of both disciplines.\r\n\r\nTo attain the project's objectives, new algorithms will be developed to permit smart devices to sense (or learn) the type of surface they are on and use that knowledge to infer information about their motion during a seismic event. Since the motion of each device may be contaminated by secondary motion, e.g. sliding on a surface, signal processing techniques will be employed to investigate how ensemble observations across multiple sensors that experience correlated motion can be used to yield highly accurate estimates of floor motion. Studies will also be conducted to explore the necessary level of accuracy required for device location within a building and device-measured parameters to ensure a meaningful assessment of seismic structural demands. The automated first reconnaissance effort will be enabled through computation of interstory drift ratios and comparing those ratios to known damage limits. As such, it is possible to electronically tag buildings for their level of damage within minutes of a seismic event.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ahmed",
   "pi_last_name": "Eltawil",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ahmed Eltawil",
   "pi_email_addr": "aeltawil@uci.edu",
   "nsf_id": "000160962",
   "pi_start_date": "2014-04-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Irvine",
  "inst_street_address": "160 ALDRICH HALL",
  "inst_street_address_2": "",
  "inst_city_name": "IRVINE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9498247295",
  "inst_zip_code": "926970001",
  "inst_country_name": "United States",
  "cong_dist_code": "47",
  "st_cong_dist_code": "CA47",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA IRVINE",
  "org_prnt_uei_num": "MJC5FCYQTPE6",
  "org_uei_num": "MJC5FCYQTPE6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Irvine",
  "perf_str_addr": "4412 Engineering Hall",
  "perf_city_name": "Irvine",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "926970001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "47",
  "perf_st_cong_dist": "CA47",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "163700",
   "pgm_ele_name": "Structural and Architectural E"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "039E",
   "pgm_ref_txt": "STRUCTURAL SYSTEMS"
  },
  {
   "pgm_ref_code": "040E",
   "pgm_ref_txt": "Haz mitigation of structural sys"
  },
  {
   "pgm_ref_code": "043E",
   "pgm_ref_txt": "EARTHQUAKE ENGINEERING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 227958.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Whenever a catastrophic event occurs, reconnaissance teams are deployed within the affected areas to conduct visual inspections of buildings. The teams tag the buildings red, yellow or green to indicate their probable condition and permitted use. This function is often slow, cumbersome and takes weeks to conclude. &nbsp;</p>\n<p>The intellectual merit of this work lies in utilizing the widespread citizen ownership of smartphones and devices to automate and significantly accelerate this first reconnaissance effort. The objective is to take advantage of the vast data readily available by these sensors, especially acceleration data, to enable an automated and accurate reconnaissance effort in the aftermath of a disaster. By increasing the speed and accuracy with which building damage can be assessed in the aftermath of natural disasters, the developed reconnaissance technology will reduce potential hazards and hardships to citizens and will provide enormous cost savings. Knowing this information will also enable first responders to optimize their response and physical inspection teams to prioritize their efforts, thereby minimizing confusion in the aftermath of a disaster.</p>\n<p>From a broader impact perspective, the proposed ideas effectively enable instrumentation of all buildings in a city, something that would otherwise need vast resources. Data from such an instrumentation effort is very valuable and will allow city officials to keep records of how each building responded during past events and possibly predict their vulnerability during future events. On the educational front, this project had a substantial impact on the development of human resources where students who worked on this project gained a broad multi-disciplinary education at the intersection of both civil and electrical engineering.</p>\n<p>Under the project, new algorithms were developed to permit smart devices to sense (or learn) the type of surface they are on and use that knowledge to infer information about their motion during a seismic event. Since the motion of each device may be contaminated by secondary motion, e.g. sliding on a surface, signal processing techniques were employed to investigate how ensemble observations across multiple sensors that experience correlated motion can be used to yield highly accurate estimates of floor motion. Studies were conducted to explore the necessary level of accuracy required for device location within a building and device-measured parameters to ensure a meaningful assessment of seismic structural demands. The automated first reconnaissance effort was enabled through computation of interstory drift ratios and comparing those ratios to known damage limits. As such, it is possible to electronically tag buildings for their level of damage within minutes of a seismic event.</p>\n<p>Technically, the project proceeded along two main thrusts.</p>\n<p>Thrust I &ndash; Device Related Parameters: In this activity we studied and quantified device-related parameters in terms of feasibility and achievable/improvable accuracy. Specifically, the goals of this thrust were: 1) to study means by which a device can glean information about the surface on which it resides, and 2) study means by which accurate displacement records can be obtained from inaccurate or noisy estimates of localization of sensors and sensor information.&nbsp;</p>\n<p>Thrust II &ndash; Experimental Validation: In this thrust direct experimentation was used to study what motion signal characteristics mean regarding the surface on which a device is placed. Another central focus was to evaluate how combining multiple correlated readings from collocated devices can minimize the effect of observation noise and improve the accuracy of the estimated response of each floor.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/23/2019<br>\n\t\t\t\t\tModified by: Ahmed&nbsp;Eltawil</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhenever a catastrophic event occurs, reconnaissance teams are deployed within the affected areas to conduct visual inspections of buildings. The teams tag the buildings red, yellow or green to indicate their probable condition and permitted use. This function is often slow, cumbersome and takes weeks to conclude.  \n\nThe intellectual merit of this work lies in utilizing the widespread citizen ownership of smartphones and devices to automate and significantly accelerate this first reconnaissance effort. The objective is to take advantage of the vast data readily available by these sensors, especially acceleration data, to enable an automated and accurate reconnaissance effort in the aftermath of a disaster. By increasing the speed and accuracy with which building damage can be assessed in the aftermath of natural disasters, the developed reconnaissance technology will reduce potential hazards and hardships to citizens and will provide enormous cost savings. Knowing this information will also enable first responders to optimize their response and physical inspection teams to prioritize their efforts, thereby minimizing confusion in the aftermath of a disaster.\n\nFrom a broader impact perspective, the proposed ideas effectively enable instrumentation of all buildings in a city, something that would otherwise need vast resources. Data from such an instrumentation effort is very valuable and will allow city officials to keep records of how each building responded during past events and possibly predict their vulnerability during future events. On the educational front, this project had a substantial impact on the development of human resources where students who worked on this project gained a broad multi-disciplinary education at the intersection of both civil and electrical engineering.\n\nUnder the project, new algorithms were developed to permit smart devices to sense (or learn) the type of surface they are on and use that knowledge to infer information about their motion during a seismic event. Since the motion of each device may be contaminated by secondary motion, e.g. sliding on a surface, signal processing techniques were employed to investigate how ensemble observations across multiple sensors that experience correlated motion can be used to yield highly accurate estimates of floor motion. Studies were conducted to explore the necessary level of accuracy required for device location within a building and device-measured parameters to ensure a meaningful assessment of seismic structural demands. The automated first reconnaissance effort was enabled through computation of interstory drift ratios and comparing those ratios to known damage limits. As such, it is possible to electronically tag buildings for their level of damage within minutes of a seismic event.\n\nTechnically, the project proceeded along two main thrusts.\n\nThrust I &ndash; Device Related Parameters: In this activity we studied and quantified device-related parameters in terms of feasibility and achievable/improvable accuracy. Specifically, the goals of this thrust were: 1) to study means by which a device can glean information about the surface on which it resides, and 2) study means by which accurate displacement records can be obtained from inaccurate or noisy estimates of localization of sensors and sensor information. \n\nThrust II &ndash; Experimental Validation: In this thrust direct experimentation was used to study what motion signal characteristics mean regarding the surface on which a device is placed. Another central focus was to evaluate how combining multiple correlated readings from collocated devices can minimize the effect of observation noise and improve the accuracy of the estimated response of each floor. \n\n \n\n\t\t\t\t\tLast Modified: 09/23/2019\n\n\t\t\t\t\tSubmitted by: Ahmed Eltawil"
 }
}