{
 "awd_id": "1349125",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Doctoral Dissertation Research: Speech perception in bilingual and monolingual speakers under normal and adverse listening conditions",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Badecker",
 "awd_eff_date": "2014-03-15",
 "awd_exp_date": "2016-10-31",
 "tot_intn_awd_amt": 15106.0,
 "awd_amount": 15106.0,
 "awd_min_amd_letter_date": "2014-03-07",
 "awd_max_amd_letter_date": "2015-10-13",
 "awd_abstract_narration": "The ability of listeners to identify words and speech sounds in sub-optimal listening conditions is a remarkable adaptation to the everyday use of language, and in order to understand this capacity fully it is necessary to clarify the role of prior linguistic experience in shaping this ability.  Recent research suggests that whether a listener is a monolingual or bilingual speaker of the target languages plays an important role in shaping this ability. \r\n\r\nUnder the direction of Dr. Aline Godfroid, Mr. Jens Schmidtke will investigate speech perception in noise (SPIN) in bilingual speakers for his dissertation research. While noisy environments generally make understanding speech more difficult, noise seems to put an extra burden on bilingual speakers. Results from many studies suggest that monolinguals and early bilinguals tested in their dominant language perform the same under quiet conditions; however, bilinguals suffer more from adverse listening conditions than monolinguals. Though this finding is quite robust, relatively little is known about the cognitive demands of bilingual SPIN and how noise affects bilingual speech perception in real time.\r\n\r\nIn the first part of this study the researchers will investigate individual differences in bottom-up (phoneme perception) and top-down (executive functions) processes that contribute to SPIN in monolingual and early bilingual listeners. To this end, participants will complete a test of SPIN and  results from various tests (vocabulary knowledge, working memory, auditory attention, and phoneme discrimination ability) will be used to predict SPIN performance. The prediction is that bilingual speakers will rely more on top-down processes to compensate for weaker processing of bottom-up information. In the second part of the study, the researchers will investigate SPIN in real time by recording listeners' eye movements. In the visual-world eye-tracking paradigm, participants see pictures of objects on a screen while they hear instructions to click on one of the pictures. Given that eye movements to pictures are closely linked to ongoing language processing, results will show how noise affects speech perception in the moment.  The researchers predict that, in bilinguals, noise will result in greater distraction by pictures with similar sounding referents and thus slower word recognition compared to monolinguals.\r\n\r\nResults from these experiments may help us better understand the bilingual disadvantage for SPIN. Results may also deepen our understanding of how factors other than hearing acuity contribute to bilinguals' ability to hear in noise and thus be of value to a wide range of researchers and practitioners.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aline",
   "pi_last_name": "Godfroid",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aline Godfroid",
   "pi_email_addr": "godfroid@msu.edu",
   "nsf_id": "000643753",
   "pi_start_date": "2014-03-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jens",
   "pi_last_name": "Schmidtke",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jens Schmidtke",
   "pi_email_addr": "schmi474@msu.edu",
   "nsf_id": "000643760",
   "pi_start_date": "2014-03-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Michigan State University",
  "inst_street_address": "426 AUDITORIUM RD RM 2",
  "inst_street_address_2": "",
  "inst_city_name": "EAST LANSING",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "5173555040",
  "inst_zip_code": "488242600",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MI07",
  "org_lgl_bus_name": "MICHIGAN STATE UNIVERSITY",
  "org_prnt_uei_num": "VJKZC4D1JN36",
  "org_uei_num": "R28EKN92ZTZ9"
 },
 "perf_inst": {
  "perf_inst_name": "Michigan State University",
  "perf_str_addr": "619 Red Cedar Rd.",
  "perf_city_name": "East Lansing",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "488243416",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "MI",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 15106.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We can all attest to the fact that following a conversation gets more difficult when there is background noise such as it occurs in busy restaurants or bars. Previous research suggests that this is even more difficult for second language speakers. More surpisingly, even those who learned a second language early in life still have greater difficulty hearing speech in noise in their second language compared to monolingual speakers of that language. The purpose of the present project was to find factors that could explain these differences between first and second language speakers. The results were expected to help advance our theoretical understanding of how words are stored in the mind but may also be useful for those serving bilingual speakers such as audiologists.</p>\n<p>The main hypothesis of this study was that bilinguals are disadvantaged when it comes to listening in noise because they have, on average, less experience with each of their languages. This is because they speak each of their languages less frequently compared to a monolingual person. To test this hypothesis, we measured approximately 100 people's vocabulary knowledge using a commonly used and standardized vocabulary test. The assumption was that people who have more experience in a language likely also know more words compared to someone with less language experience; therefore, we used vocabulary knowledge as a proxy for language experience.</p>\n<p>The population tested in this project were Spanish-English bilingual speakers who had learned English around the age of four. This linguistic group is the largest in the US among those who speak a language other than English at home (around 40 Mil. out of 300 Mil. or 13% of the US population according to 2014 Census data). We also tested a control group of monolingual English speakers, who had a similar age and education level as the bilingual speakers.</p>\n<p>Main findings: The results confirmed previous studies by showing that Spanish-English bilinguals recognized, on average, fewer words on an English sentences-in-noise test than the English monolinguals. However, bilinguals also scored below monolinguals on the English vocabulary test and this test predicted hearing in noise ability. When we accounted for a speaker's vocabulary knowledge, it became less important whether they were a monolingual or a bilingual. Vocabulary knowledge (i.e., language experience), rather than whether someone is a monolingual or a bilingual speaker, was the most important predictor of how well they could understand speech in noise. When the noisy input contained words that are infrequent in the English language (difficult words), those with reduced language experience were especially disadvantaged.</p>\n<p>These results suggest that differences in language experience, rather than bilingualism, are primarily responsible for any disadvantages for understanding speech in noise. When testing bilinguals, audiologists should therefore keep their patients' language proficiency in mind. Especially those with low proficiency in the tested language may experience hearing problems that are not related to reduced hearing acuity.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/23/2017<br>\n\t\t\t\t\tModified by: Aline&nbsp;Godfroid</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWe can all attest to the fact that following a conversation gets more difficult when there is background noise such as it occurs in busy restaurants or bars. Previous research suggests that this is even more difficult for second language speakers. More surpisingly, even those who learned a second language early in life still have greater difficulty hearing speech in noise in their second language compared to monolingual speakers of that language. The purpose of the present project was to find factors that could explain these differences between first and second language speakers. The results were expected to help advance our theoretical understanding of how words are stored in the mind but may also be useful for those serving bilingual speakers such as audiologists.\n\nThe main hypothesis of this study was that bilinguals are disadvantaged when it comes to listening in noise because they have, on average, less experience with each of their languages. This is because they speak each of their languages less frequently compared to a monolingual person. To test this hypothesis, we measured approximately 100 people's vocabulary knowledge using a commonly used and standardized vocabulary test. The assumption was that people who have more experience in a language likely also know more words compared to someone with less language experience; therefore, we used vocabulary knowledge as a proxy for language experience.\n\nThe population tested in this project were Spanish-English bilingual speakers who had learned English around the age of four. This linguistic group is the largest in the US among those who speak a language other than English at home (around 40 Mil. out of 300 Mil. or 13% of the US population according to 2014 Census data). We also tested a control group of monolingual English speakers, who had a similar age and education level as the bilingual speakers.\n\nMain findings: The results confirmed previous studies by showing that Spanish-English bilinguals recognized, on average, fewer words on an English sentences-in-noise test than the English monolinguals. However, bilinguals also scored below monolinguals on the English vocabulary test and this test predicted hearing in noise ability. When we accounted for a speaker's vocabulary knowledge, it became less important whether they were a monolingual or a bilingual. Vocabulary knowledge (i.e., language experience), rather than whether someone is a monolingual or a bilingual speaker, was the most important predictor of how well they could understand speech in noise. When the noisy input contained words that are infrequent in the English language (difficult words), those with reduced language experience were especially disadvantaged.\n\nThese results suggest that differences in language experience, rather than bilingualism, are primarily responsible for any disadvantages for understanding speech in noise. When testing bilinguals, audiologists should therefore keep their patients' language proficiency in mind. Especially those with low proficiency in the tested language may experience hearing problems that are not related to reduced hearing acuity.\n\n\t\t\t\t\tLast Modified: 01/23/2017\n\n\t\t\t\t\tSubmitted by: Aline Godfroid"
 }
}