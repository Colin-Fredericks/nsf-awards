{
 "awd_id": "1350787",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Cognitive Diagnostic Adaptive Testing for AP Statistics",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Finbarr Sloane",
 "awd_eff_date": "2014-05-15",
 "awd_exp_date": "2020-10-31",
 "tot_intn_awd_amt": 592986.0,
 "awd_amount": 688747.0,
 "awd_min_amd_letter_date": "2014-05-07",
 "awd_max_amd_letter_date": "2018-07-05",
 "awd_abstract_narration": "This project, carried out by the University of Notre Dame, seeks to contribute to statistics education by developing improved methods for computerized adaptive testing.  These methods use modern versions of item response theory, going beyond older versions that are commonly used in adaptive tests.  Hence, the project has the potential to lead to tests that more successfully measure student knowledge and provide diagnostic feedback, as computerized testing increasing comes into wide use.\r\n\r\nThe project is a CAREER award, supporting not only research but educational outreach and professional development by a Notre Dame faculty member, Dr. Ying Cheng.  The educational outreach includes providing summer research fellowships to high school and college students, and offering a workshop to high school statistics teachers.  The test items and computerized testing/feedback programs developed in this project will be made available to students and teachers.\r\n\r\nThe project involves the participation of several hundred students, taking Advanced Placement (AP) statistics classes in high school or introductory statistics in college, as well as about 30 AP statistics high school teachers.\r\n\r\nThis work helps the Education and Human Resources directorate, and the Division of Research on Learning, pursue the mission of supporting science, technology, engineering, and mathematics (STEM) education research.  In particular, this project focuses on improving STEM learning, including assessment of learning and use of technology in STEM learning environments such as schools.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ying",
   "pi_last_name": "Cheng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ying Cheng",
   "pi_email_addr": "ycheng4@nd.edu",
   "nsf_id": "000540912",
   "pi_start_date": "2014-05-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Notre Dame",
  "inst_street_address": "940 GRACE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "NOTRE DAME",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "5746317432",
  "inst_zip_code": "465565708",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "IN02",
  "org_lgl_bus_name": "UNIVERSITY OF NOTRE DAME DU LAC",
  "org_prnt_uei_num": "FPU6XGFXMBE9",
  "org_uei_num": "FPU6XGFXMBE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Notre Dame",
  "perf_str_addr": "940 Grace Hall",
  "perf_city_name": "Notre Dame",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "465565612",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "IN02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "762500",
   "pgm_ele_name": "REAL"
  },
  {
   "pgm_ele_code": "798000",
   "pgm_ele_name": "ECR-EDU Core Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "CL10",
   "pgm_ref_txt": "CLB-Career Life Balance"
  }
 ],
 "app_fund": [
  {
   "app_code": "0414",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001415DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0415",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001516DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0416",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001617DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0417",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001718DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 193528.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 139622.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 98520.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 86970.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 170107.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-fe0259a7-7fff-5360-8a91-7f212268d55a\"><span>The AP-CAT (Advanced Placement - Computerized Adaptive Testing) platform, which has been funded by the National Science Foundation since 2014, was designed for the development of adaptive formative assessments for high-school AP Statistics classes. It has been used to examine the effectiveness of score reports that provide diagnostic feedback for promoting student engagement and learning (Brodersen et al., 2020). In the assessment platform, teachers are able to create assignments by selecting items to cover intended content, or can create an adaptive assignment. Adaptive assignments present items to students in a manner that &ldquo;matches&rdquo; the item difficulty parameters with students' estimated ability based on their performance on past items. In creating the assignments, researchers and teachers also have the flexibility to choose deadlines, the number of items on the assignment, and which sections to receive the assignment, regardless of whether it is adaptive or not. For non-adaptive assignments, there is the option to randomize the order in which items are presented to students.&nbsp;</span></span></p>\n<p><span><span><span id=\"docs-internal-guid-5e1dc81f-7fff-df2b-e738-945876184365\"><span>Aside from serving as a platform for researchers and teachers to create formative assessments of student learning the AP-CAT system provides students an opportunity to reflect and learn from their past work. For example, digital logs are recorded when students check the solution to a particularly challenging question or review their progress via a personalized score report. Each question will come with a set of step-wise solutions to support students who wish to understand the process involved for arriving at the correct answer. The score report provides teachers and students estimates of students&rsquo; overall performance on each assignment, how fast they work through the assignment, their progress in mastering certain topics in the curriculum, whether or not they answered a certain question correctly or not and what the correct answer should be, as well as step-by-step solutions to each question. While students can examine only their individual progress, teachers can also examine student progress in aggregate for an entire class in addition to individual students.</span></span></span></span></p>\n<p><span id=\"docs-internal-guid-e227727b-7fff-02bb-ad26-0d6141eed51d\"> </span></p>\n<p dir=\"ltr\"><span>Overall, from this project the research team has:</span></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Created an item bank with 842 items that are mapped to 157 learning attributes in statistics and probability;&nbsp;</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Developed and tested a web-based interactive assessment platform for teachers to design, assemble and administer automatically graded assignments and monitor student progress, and for students to take and review their assignments and receive diagnostic feedback;</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Built in adaptive item selection and automated scoring algorithms in the backend of the interface (Cheng et al., 2017) as well as scale-up functionalities through cloud for large-scale implementations (Brodersen et al., 2020);&nbsp;</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Collected data from five cohorts of students in 7 schools in Indiana taking AP statistics classes and using the AP-CAT system (Spring 2016 - Spring 2020) and based on their feedback iteratively developed and refined the system;&nbsp;&nbsp;</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Developed and validated a self-report measure to assess students&rsquo; engagement in statistics, the Scale of Student Engagement in Statistics (SSE-S; Whitney et al., 2019), which consists of 24 Likert-type items, with eight items each reflecting the affective, behavioral, and cognitive dimensions of engagement. In addition, we validated BFI-2, a 60-item personality measure measuring five domains of personality in the high-school student population (Ober et al., 2020). Personality traits are treated as covariates in preditive models of student engagement, particularly the conscientiousness dimension.&nbsp;</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Derived metrics from digital log data that describe the user&rsquo;s access, responses to statistics questions, and process in answering, receiving feedback, or otherwise navigating the system. Current work is underway to examine whether such metrics are linked with students self-reported engagement and performance on AP-CAT assessments (Ober et al., under review).</span></p>\n</li>\n</ul>\n<p>In addition to the intellectual contributions, the project achieved broader impact through the training of students, staff, and teachers who have partcipated in this project. Since the beginning of this project, more than a dozen undergraduate research assistants and more than 5 graduate research assistants have received mentorship from the project PIs, in addition to project management staff and postdoctoral scholars. The project team has also given more than 10 workshops to teachers in Indiana. More than 50 teachers have participated in these workshops.&nbsp;</p>\n<p>As high schools transitioned instruction from a face-to-face to an online and remote learning format due to COVID-19, we developed a public version of AP-CAT called AP-CAT Open in March and April 2020, a platform that requires no teacher involvement but allows students nationwide to register and use on their own. The AP-CAT Open system (https://apcat.crc.nd.edu/) provides free, off-the-shelf online practice assessments and diagnostic score reports at the level of AP Statistics course. It was launched in May 2020.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/01/2020<br>\n\t\t\t\t\tModified by: Ying&nbsp;Cheng</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe AP-CAT (Advanced Placement - Computerized Adaptive Testing) platform, which has been funded by the National Science Foundation since 2014, was designed for the development of adaptive formative assessments for high-school AP Statistics classes. It has been used to examine the effectiveness of score reports that provide diagnostic feedback for promoting student engagement and learning (Brodersen et al., 2020). In the assessment platform, teachers are able to create assignments by selecting items to cover intended content, or can create an adaptive assignment. Adaptive assignments present items to students in a manner that \"matches\" the item difficulty parameters with students' estimated ability based on their performance on past items. In creating the assignments, researchers and teachers also have the flexibility to choose deadlines, the number of items on the assignment, and which sections to receive the assignment, regardless of whether it is adaptive or not. For non-adaptive assignments, there is the option to randomize the order in which items are presented to students. \n\nAside from serving as a platform for researchers and teachers to create formative assessments of student learning the AP-CAT system provides students an opportunity to reflect and learn from their past work. For example, digital logs are recorded when students check the solution to a particularly challenging question or review their progress via a personalized score report. Each question will come with a set of step-wise solutions to support students who wish to understand the process involved for arriving at the correct answer. The score report provides teachers and students estimates of students\u2019 overall performance on each assignment, how fast they work through the assignment, their progress in mastering certain topics in the curriculum, whether or not they answered a certain question correctly or not and what the correct answer should be, as well as step-by-step solutions to each question. While students can examine only their individual progress, teachers can also examine student progress in aggregate for an entire class in addition to individual students.\n\n \nOverall, from this project the research team has:\n\n\nCreated an item bank with 842 items that are mapped to 157 learning attributes in statistics and probability; \n\n\nDeveloped and tested a web-based interactive assessment platform for teachers to design, assemble and administer automatically graded assignments and monitor student progress, and for students to take and review their assignments and receive diagnostic feedback;\n\n\nBuilt in adaptive item selection and automated scoring algorithms in the backend of the interface (Cheng et al., 2017) as well as scale-up functionalities through cloud for large-scale implementations (Brodersen et al., 2020); \n\n\nCollected data from five cohorts of students in 7 schools in Indiana taking AP statistics classes and using the AP-CAT system (Spring 2016 - Spring 2020) and based on their feedback iteratively developed and refined the system;  \n\n\nDeveloped and validated a self-report measure to assess students\u2019 engagement in statistics, the Scale of Student Engagement in Statistics (SSE-S; Whitney et al., 2019), which consists of 24 Likert-type items, with eight items each reflecting the affective, behavioral, and cognitive dimensions of engagement. In addition, we validated BFI-2, a 60-item personality measure measuring five domains of personality in the high-school student population (Ober et al., 2020). Personality traits are treated as covariates in preditive models of student engagement, particularly the conscientiousness dimension. \n\n\nDerived metrics from digital log data that describe the user\u2019s access, responses to statistics questions, and process in answering, receiving feedback, or otherwise navigating the system. Current work is underway to examine whether such metrics are linked with students self-reported engagement and performance on AP-CAT assessments (Ober et al., under review).\n\n\n\nIn addition to the intellectual contributions, the project achieved broader impact through the training of students, staff, and teachers who have partcipated in this project. Since the beginning of this project, more than a dozen undergraduate research assistants and more than 5 graduate research assistants have received mentorship from the project PIs, in addition to project management staff and postdoctoral scholars. The project team has also given more than 10 workshops to teachers in Indiana. More than 50 teachers have participated in these workshops. \n\nAs high schools transitioned instruction from a face-to-face to an online and remote learning format due to COVID-19, we developed a public version of AP-CAT called AP-CAT Open in March and April 2020, a platform that requires no teacher involvement but allows students nationwide to register and use on their own. The AP-CAT Open system (https://apcat.crc.nd.edu/) provides free, off-the-shelf online practice assessments and diagnostic score reports at the level of AP Statistics course. It was launched in May 2020. \n\n\t\t\t\t\tLast Modified: 12/01/2020\n\n\t\t\t\t\tSubmitted by: Ying Cheng"
 }
}