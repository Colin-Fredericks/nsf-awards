{
 "awd_id": "1421407",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Behavior Based User Authentication for Mobile Devices",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2014-08-15",
 "awd_exp_date": "2018-07-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2014-08-06",
 "awd_max_amd_letter_date": "2014-08-06",
 "awd_abstract_narration": "Mobile devices equipped with touch screens have increasingly rich functionality, enhanced computing power, and greater storage capacity. These devices often contain private information such as personal photos, emails, and even corporate data. Therefore, it is crucial to have secure yet convenient user authentication mechanisms for touch screen devices. However, the widely used password/PIN/pattern based solutions are susceptible to shoulder surfing (as mobile devices are often used in public settings where shoulder surfing often happens either purposely or inadvertently) and smudge attacks (as oily residues left by fingers on touch screens can be recognized by impostors) and are sometimes inconvenient for users to input when they are walking or driving.\r\n\r\nThe goal of this project is to develop a behavior based user authentication approach for touch screen devices. Rather than authenticating users solely based on what they input (such as a password/PIN/pattern), Behavioral Authentication is based upon how users provide input input. Specifically, a user is first asked to perform certain actions, such as gestures/signatures, on touch screens and then the behavior feature information (such as velocity magnitude and device acceleration) is extracted from the actions to authenticate the user based on machine learning techniques. The intuition behind the proposed approach is that people have consistent and distinguishing behavior of performing gestures and signatures on touch screens. Compared with current user authentication schemes for touch screen devices, the proposed approach is significantly more difficult to compromise because it is nearly impossible for impostors to reproduce the behavior of others doing gestures/signatures through shoulder surfing or smudge attacks - they can see it, but they cannot do it.\r\n\r\nThis project will advance the knowledge and understanding of behavior based user authentication on touch screen devices. This is potentially transformative research with high-impact. If successful, this project will not only yield a theoretical foundation for behavior based user authentication on touch screen devices but also invite future research along this direction.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alex",
   "pi_last_name": "Liu",
   "pi_mid_init": "X",
   "pi_sufx_name": "",
   "pi_full_name": "Alex X Liu",
   "pi_email_addr": "alexliu@cse.msu.edu",
   "nsf_id": "000482202",
   "pi_start_date": "2014-08-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Michigan State University",
  "inst_street_address": "426 AUDITORIUM RD RM 2",
  "inst_street_address_2": "",
  "inst_city_name": "EAST LANSING",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "5173555040",
  "inst_zip_code": "488242600",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MI07",
  "org_lgl_bus_name": "MICHIGAN STATE UNIVERSITY",
  "org_prnt_uei_num": "VJKZC4D1JN36",
  "org_uei_num": "R28EKN92ZTZ9"
 },
 "perf_inst": {
  "perf_inst_name": "Michigan State University",
  "perf_str_addr": "428 S. Shaw Lane, Room 2132",
  "perf_city_name": "East Lansing",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "488241226",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MI07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Mobile devices equipped with touch screens have become prevalent in our lives with increasingly rich functionalities, enhanced computing power, and more storage capacity. These devices often contain private information such as personal photos, emails, and even corporate data. Therefore, it is crucial to have secure yet convenient user authentication mechanisms for touch screen devices. However, the widely used password/PIN/pattern based solutions are susceptible to shoulder surfing (as mobile devices are often used in public settings where shoulder surfing often happens either purposely or inadvertently) and smudge attacks (as oily residues left by fingers on touch screens can be recognized by imposters) and are sometimes inconvenient for users to input when they are walking or driving. In this project, the PI developed BEAT, a behavior based user authentication approach for touch screen devices. Rather than authenticating users solely based on what they input (such as a password/PIN/pattern), which is inherently subject to shoulder surfing and smudge attacks, BEAT authenticates users based on how they input. Specifically, BEAT first asks a user to perform certain actions, such as gestures/signatures, on touch screens and then uses the behavior feature information (such as velocity magnitude and device acceleration) extracted from the actions to authenticate the user based on machine learning techniques. The intuition behind the proposed approach is that people have consistent and distinguishing behavior of performing gestures and signatures on touch screens. Compared with current user authentication schemes for touch screen devices, the proposed approach is significantly more difficult to compromise because it is nearly impossible for imposters to reproduce the behavior of others doing gestures/signatures through shoulder surfing or smudge attacks - they can see it, but they cannot do it. This project represents the first effort towards developing behavior based user authentication approaches based on machine learning techniques for touch screen devices. The PI reveals many new observations (such as people often exhibit different behaviors when they perform the same action under different types of postures such as standing and sitting) and proposes many new concepts. <br /><br />This project has advanced the knowledge and understanding of behavior based user authentication on touch screen devices. The fundamental concepts developed in this project have led to a much deeper understanding of behavior based user authentication approach for touch screen devices. In this project, the PI's team has successfully achieved the objectives of developing gesture based user authentication schemes for touch screen devices and developing signature based user authentication schemes for touch screen devices. They have proposed, implemented, and evaluated a gesture and signature behavior based authentication scheme for the authentication on touch screen devices. They have identified a set of effective features that capture the behavioral information of performing gestures and signatures on touch screens. They have developed algorithms that can automatically segments each stroke into sub-strokes of different time duration where for each sub-stroke the user has consistent and distinguishing behavior. They have also developed methods to automatically identify combined strokes in signatures and split them at appropriate locations. They have also developed algorithms to extract multiple behaviors from the training samples of a given action.<br /><br />The research results have been successfully published in top tier computer science conferences (such as MOBICOM, MobiSys, and UbiComp), and computer science journals (such as IEEE Transactions on Mobile Computing, IEEE/ACM Transactions on Networking, and IEEE Journal on Selected Areas in Communications). This project has supported a number of Ph.D. students and post-docs. <br /><br />The results that we developed in this project has been incorporated into the graduate courses CSE 825 \"Computer and Network Security\". The PI has designed course projects based on this project for students to work on. The course materials help to educate the next generation of computer engineers for the nation. In addition, this project has provided new opportunities for Ph.D. students to develop their research skills as they pursue their doctoral degrees and eventual careers in academia and/or industry.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/10/2018<br>\n\t\t\t\t\tModified by: Alex&nbsp;X&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMobile devices equipped with touch screens have become prevalent in our lives with increasingly rich functionalities, enhanced computing power, and more storage capacity. These devices often contain private information such as personal photos, emails, and even corporate data. Therefore, it is crucial to have secure yet convenient user authentication mechanisms for touch screen devices. However, the widely used password/PIN/pattern based solutions are susceptible to shoulder surfing (as mobile devices are often used in public settings where shoulder surfing often happens either purposely or inadvertently) and smudge attacks (as oily residues left by fingers on touch screens can be recognized by imposters) and are sometimes inconvenient for users to input when they are walking or driving. In this project, the PI developed BEAT, a behavior based user authentication approach for touch screen devices. Rather than authenticating users solely based on what they input (such as a password/PIN/pattern), which is inherently subject to shoulder surfing and smudge attacks, BEAT authenticates users based on how they input. Specifically, BEAT first asks a user to perform certain actions, such as gestures/signatures, on touch screens and then uses the behavior feature information (such as velocity magnitude and device acceleration) extracted from the actions to authenticate the user based on machine learning techniques. The intuition behind the proposed approach is that people have consistent and distinguishing behavior of performing gestures and signatures on touch screens. Compared with current user authentication schemes for touch screen devices, the proposed approach is significantly more difficult to compromise because it is nearly impossible for imposters to reproduce the behavior of others doing gestures/signatures through shoulder surfing or smudge attacks - they can see it, but they cannot do it. This project represents the first effort towards developing behavior based user authentication approaches based on machine learning techniques for touch screen devices. The PI reveals many new observations (such as people often exhibit different behaviors when they perform the same action under different types of postures such as standing and sitting) and proposes many new concepts. \n\nThis project has advanced the knowledge and understanding of behavior based user authentication on touch screen devices. The fundamental concepts developed in this project have led to a much deeper understanding of behavior based user authentication approach for touch screen devices. In this project, the PI's team has successfully achieved the objectives of developing gesture based user authentication schemes for touch screen devices and developing signature based user authentication schemes for touch screen devices. They have proposed, implemented, and evaluated a gesture and signature behavior based authentication scheme for the authentication on touch screen devices. They have identified a set of effective features that capture the behavioral information of performing gestures and signatures on touch screens. They have developed algorithms that can automatically segments each stroke into sub-strokes of different time duration where for each sub-stroke the user has consistent and distinguishing behavior. They have also developed methods to automatically identify combined strokes in signatures and split them at appropriate locations. They have also developed algorithms to extract multiple behaviors from the training samples of a given action.\n\nThe research results have been successfully published in top tier computer science conferences (such as MOBICOM, MobiSys, and UbiComp), and computer science journals (such as IEEE Transactions on Mobile Computing, IEEE/ACM Transactions on Networking, and IEEE Journal on Selected Areas in Communications). This project has supported a number of Ph.D. students and post-docs. \n\nThe results that we developed in this project has been incorporated into the graduate courses CSE 825 \"Computer and Network Security\". The PI has designed course projects based on this project for students to work on. The course materials help to educate the next generation of computer engineers for the nation. In addition, this project has provided new opportunities for Ph.D. students to develop their research skills as they pursue their doctoral degrees and eventual careers in academia and/or industry.\n\n\t\t\t\t\tLast Modified: 08/10/2018\n\n\t\t\t\t\tSubmitted by: Alex X Liu"
 }
}