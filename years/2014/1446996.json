{
 "awd_id": "1446996",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Collaborative Research: Scaling Up Discriminative Learning for Natural Language Understanding and Translation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2014-08-15",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 129053.0,
 "awd_amount": 129053.0,
 "awd_min_amd_letter_date": "2014-08-13",
 "awd_max_amd_letter_date": "2014-08-13",
 "awd_abstract_narration": "This EArly Grant for Exploratory Research aims to improve automatic understanding of natural language by machines, and automatic translation between languages such as Chinese and English. In the realm of understanding, the project develops methods for syntactically and semantically analyzing, or parsing, sentences. Improved parsing can help in accessing the enormous amount of information available in unstructured text on the web and in databases of newspapers and scanned books. Improved translation between languages increases opportunities for trade as well as for dissemination of information generally between nations and cultures. Machine translation is widely used today despite its generally poor quality, and any improvement in quality will improve access to information for millions of people.  This project aims to exploit the power of machine learning algorithms that are designed to discriminate between correct and incorrect outputs by numerically optimizing mathematical functions that are defined in terms of the data available for training.  Discriminative structured prediction algorithms have witnessed great success in the field of natural language processing (NLP) over the past decade, generally surpassing their generative counterparts. However, there remain two major problems which prevent discriminative methods from scaling to very large datasets: first, they typically assume exact search (over a prohibitively large search space), which is rarely possible in practice for problems such as parsing and translation. Secondly, they normally assume the data is completely annotated, whereas many naturally occurring datasets are only partially annotated: for example a parallel text in machine translation includes the source and target sentence pairs but not the derivation between them. As a result of these two problems, the current methods are not taking full advantage of the enormous and ever increasing amount of text data available to us.\r\n\r\nThis EArly Grant ofr Exploratory Research (EAGER) aims to: \r\n- Develop a linear-time structured learning framework specifically tailored for inexact search, which hopefully retains theoretical properties of structured learning (e.g. convergence) under exact search.  \r\n- Extend this framework to handle latent variables, such as derivations in machine translation, syntactic structures in semantic parsing, and semantic representations in question answering.  \r\nIf the exploratory extension to latent variable frameworks is sucessful, it will enable longer-term research to: \r\n- Apply these efficient learning algorithms to discriminative training of machine translation systems over the entire training dataset rather than only on a small development set.  \r\n- Apply these efficient learning algorithms to discriminative training for syntactic and semantic parsing, with the goal of scaling up semantic parsing to enable web-scale knowledge extraction.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Gildea",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel Gildea",
   "pi_email_addr": "gildea@cs.rochester.edu",
   "nsf_id": "000449779",
   "pi_start_date": "2014-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146270140",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 129053.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aimed to learn directly the correspondence between words in English<br />and objects and action in video.&nbsp; We worked with videos of experiments<br />in a biology laboratory, along with experimental protocols that describe the <br />steps of the experiment in English.&nbsp; This work could ultimately be used<br />automatically analyze videos of experiments, with the long-term goal<br />of recognizing possible errors or small discrepancies in experimental<br />protocols, and ultimately increasing the reproducibility of<br />scientific experiments.&nbsp; Our model assumes no knowledge of English <br />vocabulary, and aims to learn the interpretation of the English<br />words in the protocol by finding correspondences between the <br />sentences in the text and the temporal sequence of the video.<br />This unsupervised approach reduces the need for annotation of data<br />and hand-built domain-specific resources.&nbsp; It is also interesting <br />from the general viewpoint of language learning because it is<br />similar to the scenario in which a baby begins to learn its <br />native language by observing the world around it.<br /><br />Using techniques from statistical machine translation, we model <br />the alignment of sentences of the text to frames of the video<br />by using a Hidden Markov Model.&nbsp; Within each sentence-to-frame<br />correspondence, we model the alignment of objects in the image<br />to words in the sentence with the standard bag-of-words IBM Model 1. <br />This approach was able to learn the correspondence between<br />words and objects, and to align video to text.&nbsp; <br />More recently, we have extended<br />the model to allow discriminative training with arbitrary features.<br />It is common in machine learning for discriminative <br />models to perform better by virtue of being trained to directly optimize<br />the error criterion on which they are evaluated.&nbsp; <br />This experiment was interesting from a machine learning perspective<br />in that it showed the benefits of discriminative training<br />even in an unsupervised setting: we obtained improved<br />alignments despite the fact that the system never observes<br />the true correspondence between text and video.<br /><br />We have also experimented with our model in other <br />text-to-video domains; we have obtained promising <br />results in learning the correspondence between faces and names<br />in movie scripts.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/09/2017<br>\n\t\t\t\t\tModified by: Daniel&nbsp;Gildea</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project aimed to learn directly the correspondence between words in English\nand objects and action in video.  We worked with videos of experiments\nin a biology laboratory, along with experimental protocols that describe the \nsteps of the experiment in English.  This work could ultimately be used\nautomatically analyze videos of experiments, with the long-term goal\nof recognizing possible errors or small discrepancies in experimental\nprotocols, and ultimately increasing the reproducibility of\nscientific experiments.  Our model assumes no knowledge of English \nvocabulary, and aims to learn the interpretation of the English\nwords in the protocol by finding correspondences between the \nsentences in the text and the temporal sequence of the video.\nThis unsupervised approach reduces the need for annotation of data\nand hand-built domain-specific resources.  It is also interesting \nfrom the general viewpoint of language learning because it is\nsimilar to the scenario in which a baby begins to learn its \nnative language by observing the world around it.\n\nUsing techniques from statistical machine translation, we model \nthe alignment of sentences of the text to frames of the video\nby using a Hidden Markov Model.  Within each sentence-to-frame\ncorrespondence, we model the alignment of objects in the image\nto words in the sentence with the standard bag-of-words IBM Model 1. \nThis approach was able to learn the correspondence between\nwords and objects, and to align video to text.  \nMore recently, we have extended\nthe model to allow discriminative training with arbitrary features.\nIt is common in machine learning for discriminative \nmodels to perform better by virtue of being trained to directly optimize\nthe error criterion on which they are evaluated.  \nThis experiment was interesting from a machine learning perspective\nin that it showed the benefits of discriminative training\neven in an unsupervised setting: we obtained improved\nalignments despite the fact that the system never observes\nthe true correspondence between text and video.\n\nWe have also experimented with our model in other \ntext-to-video domains; we have obtained promising \nresults in learning the correspondence between faces and names\nin movie scripts.\n\n\t\t\t\t\tLast Modified: 02/09/2017\n\n\t\t\t\t\tSubmitted by: Daniel Gildea"
 }
}