{
 "awd_id": "1444861",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Collaborative: Understanding How Manipulated Images Influence People",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2014-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 90000.0,
 "awd_amount": 90000.0,
 "awd_min_amd_letter_date": "2014-07-15",
 "awd_max_amd_letter_date": "2014-07-15",
 "awd_abstract_narration": "As an abundance of hardware and software tools is dramatically decreasing the cost and effort required to manipulate digital images, the risks and dangers associated with malicious attackers easily routing doctored images through computer and social networks to purposefully influence viewers' opinions, attitudes, and actions have never been more severe. While there is a growing awareness that images no longer represent an authentic proof of reality, there is a gap in research about the public's vulnerabilities to visual misinformation and how individuals make credible evaluations about image authenticity. Filling the gap in research, this work conducts a series of empirical studies to find out the social and cognitive heuristics online viewers use in image credibility evaluation and how such evaluations influence their attitudes and behaviors. The data from these studies will help predict the ways by which viewers are most likely to accept evidence that online images have been manipulated and how they subsequently revise their emotions and beliefs surrounding them. This work also looks at potential ways cyber attackers could use social media to subvert social order by spreading visual misinformation, and what strategies would be effective in combating such behavior. Results from this work will inform the design of software for forensic image analysis and will lay the grounds for new technologies that help Internet users in continuously assessing the veracity of the mediated visual hoaxes and scams they receive online.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cuihua",
   "pi_last_name": "Shen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cuihua Shen",
   "pi_email_addr": "cuishen@ucdavis.edu",
   "nsf_id": "000607841",
   "pi_start_date": "2014-07-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Davis",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956168695",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "114Z",
   "pgm_ref_txt": "SaTC-CISE-SBE New Collabs"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8225",
   "pgm_ref_txt": "SaTC Special Projects"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 90000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-be5a6b33-f1f0-2050-e840-807b999f8004\">\n<p dir=\"ltr\"><span>This project has three goals: 1) constructing a corpus of documented cases of image manipulation and their impact on viewers, 2) surveying scholarly work in related fields, including online credibility, information manipulation, and image manipulation, and investigating how existing literature could shed light on credibility evaluation of images, and 3) conducting a series of empirical studies to find out the social and cognitive heuristics used in image credibility evaluation and how such evaluations influence people. The overarching research questions are: How do people make judgments about image authenticity? And what effects do fake images have on people&rsquo;s attitudes and behaviors?</span></p>\n<br />\n<p dir=\"ltr\"><span>We conducted a series of focus group studies and online experiments. In the exploratory focus group studies, </span><span>we found that people are generally bad at making credibility assessments of images in an online context. Further, non-image factors, such as the source of the image and the accompanying story of the image, appear to play a much more significant role in participants&rsquo; credibility judgment than image-specific factors such as inconsistencies in lighting and shadows. </span></p>\n<br />\n<p dir=\"ltr\"><span>Based on the exploratory findings, we designed a large-scale online experiment using Amazon Mechanical Turk that probes how people evaluate image credibility in various online platforms. We ran a series of six between-subjects experiments, each of which randomly assigned participants to one of 28 news-source mockups featuring a forged image, and asked participants to evaluate its credibility based on various features. We found that participants&rsquo; internet skills, photo-editing experience, and social media use were significant predictors of image credibility evaluation, while most social and heuristic cues of online credibility (e.g. source trustworthiness, bandwagon, intermediary trustworthiness) had no significant impact. Viewers&rsquo; favorable attitude towards the issue depicted also positively influenced their credibility rating. </span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/13/2018<br>\n\t\t\t\t\tModified by: Cuihua&nbsp;Shen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThis project has three goals: 1) constructing a corpus of documented cases of image manipulation and their impact on viewers, 2) surveying scholarly work in related fields, including online credibility, information manipulation, and image manipulation, and investigating how existing literature could shed light on credibility evaluation of images, and 3) conducting a series of empirical studies to find out the social and cognitive heuristics used in image credibility evaluation and how such evaluations influence people. The overarching research questions are: How do people make judgments about image authenticity? And what effects do fake images have on people?s attitudes and behaviors?\n\n\nWe conducted a series of focus group studies and online experiments. In the exploratory focus group studies, we found that people are generally bad at making credibility assessments of images in an online context. Further, non-image factors, such as the source of the image and the accompanying story of the image, appear to play a much more significant role in participants? credibility judgment than image-specific factors such as inconsistencies in lighting and shadows. \n\n\nBased on the exploratory findings, we designed a large-scale online experiment using Amazon Mechanical Turk that probes how people evaluate image credibility in various online platforms. We ran a series of six between-subjects experiments, each of which randomly assigned participants to one of 28 news-source mockups featuring a forged image, and asked participants to evaluate its credibility based on various features. We found that participants? internet skills, photo-editing experience, and social media use were significant predictors of image credibility evaluation, while most social and heuristic cues of online credibility (e.g. source trustworthiness, bandwagon, intermediary trustworthiness) had no significant impact. Viewers? favorable attitude towards the issue depicted also positively influenced their credibility rating. \n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 01/13/2018\n\n\t\t\t\t\tSubmitted by: Cuihua Shen"
 }
}