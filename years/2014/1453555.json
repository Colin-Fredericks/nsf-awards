{
 "awd_id": "1453555",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: EAGER: Prototype of an Image-Based Ecological Information System (IBEIS)",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 128292.0,
 "awd_amount": 191186.0,
 "awd_min_amd_letter_date": "2014-08-27",
 "awd_max_amd_letter_date": "2016-09-02",
 "awd_abstract_narration": "Images are rapidly becoming the most abundant, widely available, and cheapest source of information about the natural world. Images taken by field scientists, tourists, and incidental photographers, and gathered from camera traps and autonomous vehicles provide rich data with the promise of addressing big ecological questions at high resolution and at fine-grained scale. Realizing this potential requires building a large autonomous computational system that starts from image collections and progresses all the way to answering ecological queries, such as population sizes, species distributions and interactions, and movement patterns. The system must have methods of extracting the relevant ecological information from the images and of integrating with other ecological data sources, with minimal human interaction, using state-of-the art information management, computer vision, and data analytics technologies. Such a system will advance computer systems and simultaneously enable ecology to develop as a science of connections across spatial, temporal, and biological scales, as well as provide data- and scientifically-grounded support for ecological decisions. \r\n\r\nThis work aims to build a prototype of an Image-Based Ecological Information Software System (IBEIS) that relies on a proliferation of images collected daily on a single facility from many different sources, both human and automatic, to determine both the species as well as recognition of distinct individuals. The system will allow for tracking location and movement while providing a data management system that will allow scientists to better understand, and at finer granularity, behaviors and motivations. The system will include: (1) an infrastructure and a mechanism for collecting images from tourists and other sources; (2) a (cloud) infrastructure and a data management system for storing, accessing, and manipulating the images and the derived data; (3) computer vision techniques for extracting information from the images about the identity of individual units, as well as techniques for combining that information with other relevant data to derive information about meaningful ecological units; and (4) statistical techniques and query structures to support ecological queries of the data, such as population sizes and dynamics, movement history and home ranges, and species interactions. \r\n\r\nThis work will advance computer systems including information management, computer vision, and data analytics technologies, all the while increasing public engagement in science and ecology.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tanya",
   "pi_last_name": "Berger-Wolf",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tanya Berger-Wolf",
   "pi_email_addr": "berger-wolf.1@osu.edu",
   "nsf_id": "000296514",
   "pi_start_date": "2014-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Chicago",
  "inst_street_address": "809 S MARSHFIELD AVE M/C 551",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3129962862",
  "inst_zip_code": "606124305",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "IL07",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "W8XEAJDKMXH3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Chicago",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606124305",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "IL07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 128292.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 62894.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>How many bobcats are there in North America? Where do the whales go after they are seen off the coast of Portland? How many juvenile turtles survive to adulthood after hatching on a beach in Hawaii? To answer these types of questions, we must obtain and analyze large-scale and high-resolution data (in time and space) about animal populations and the individual animals within them. Neither traditional visual observations or various tracking devices are the answer. Fortunately, much of this needed raw data for synthesis is available ? in the form of images and videos taken by scientists, technicians, volunteers, tourists and citizen scientists ? and is often posted on social media. Unfortunately, the conservation technology ecosystem lacks the software tools and platforms needed to turn this raw data into scientific insight and guidance for data-driven management decisions.</p>\n<p>&nbsp;</p>\n<p>This project built Wildbook (the product name of IBEIS). Wildbook (<a href=\"https://www.wildbook.org/\">wildbook.org</a>) is an open-source, web-based software application that blends collaboration, citizen science, and machine learning to take advantage of the large volume of visual data available and to scalably feed it into structured research and data-driven conservation efforts. Wildbook combines heterogeneous wildlife data (especially mark-and-recapture ?tagging?, social, genetic, etc.) with machine learning techniques to enable large-scale (regional and global) collaborative wildlife studies in the fields of population biology, animal biometrics, social ecology, molecular ecology, toxicology, and more. Wildbook is an autonomous cloud-based, data-driven, Artificial Intelligence-enabled system that turns crowdsourced photographs into information about animals.&nbsp;</p>\n<p>&nbsp;</p>\n<p>We have built Wildbooks for more than 20 species, with the support from this project. We supported hundreds of scientists, engaged thousands of citizen scientists, and tracked tens of thousands of animals across the globe. Data from Wildbooks is becoming the authoritative source on the populations of several species for the International Unit for Conservation of Nature (IUCN) Red List and has prompted the change in the conservation status designation of whale sharks from ?vulnerable? to ?endangered?.</p>\n<p>&nbsp;</p>\n<p>This project is enabling science and conservation at planetary scale and high resolution over space, time and individual animals. It is at the forefront of AI for conservation.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/01/2019<br>\n\t\t\t\t\tModified by: Tanya&nbsp;Berger-Wolf</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1453555/1453555_10338594_1564643015128_Wildbooks--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1453555/1453555_10338594_1564643015128_Wildbooks--rgov-800width.jpg\" title=\"Wildbook examples\"><img src=\"/por/images/Reports/POR/2019/1453555/1453555_10338594_1564643015128_Wildbooks--rgov-66x44.jpg\" alt=\"Wildbook examples\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Examples of Wildbook (product name for IBEIS) front pages for turtles, seals, and giraffes</div>\n<div class=\"imageCredit\">Tanya Berger-Wolf and Wild Me</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tanya&nbsp;Berger-Wolf</div>\n<div class=\"imageTitle\">Wildbook examples</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1453555/1453555_10338594_1564643114255_WildbookBias--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1453555/1453555_10338594_1564643114255_WildbookBias--rgov-800width.jpg\" title=\"Bias of photographic data\"><img src=\"/por/images/Reports/POR/2019/1453555/1453555_10338594_1564643114255_WildbookBias--rgov-66x44.jpg\" alt=\"Bias of photographic data\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Various sources of bias that accumulate between the original population size seen in the wild and the estimates made from images posted on social media.</div>\n<div class=\"imageCredit\">Sreejith Menon and Tanya Berger-Wolf</div>\n<div class=\"imageSubmitted\">Tanya&nbsp;Berger-Wolf</div>\n<div class=\"imageTitle\">Bias of photographic data</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1453555/1453555_10338594_1564644136051_WildbookPipeline--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1453555/1453555_10338594_1564644136051_WildbookPipeline--rgov-800width.jpg\" title=\"IBEIS pipeline\"><img src=\"/por/images/Reports/POR/2019/1453555/1453555_10338594_1564644136051_WildbookPipeline--rgov-66x44.jpg\" alt=\"IBEIS pipeline\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">From images to an entry in a Wildbook (product name for IBEIS) page.</div>\n<div class=\"imageCredit\">Tanya Berger-Wolf</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tanya&nbsp;Berger-Wolf</div>\n<div class=\"imageTitle\">IBEIS pipeline</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nHow many bobcats are there in North America? Where do the whales go after they are seen off the coast of Portland? How many juvenile turtles survive to adulthood after hatching on a beach in Hawaii? To answer these types of questions, we must obtain and analyze large-scale and high-resolution data (in time and space) about animal populations and the individual animals within them. Neither traditional visual observations or various tracking devices are the answer. Fortunately, much of this needed raw data for synthesis is available ? in the form of images and videos taken by scientists, technicians, volunteers, tourists and citizen scientists ? and is often posted on social media. Unfortunately, the conservation technology ecosystem lacks the software tools and platforms needed to turn this raw data into scientific insight and guidance for data-driven management decisions.\n\n \n\nThis project built Wildbook (the product name of IBEIS). Wildbook (wildbook.org) is an open-source, web-based software application that blends collaboration, citizen science, and machine learning to take advantage of the large volume of visual data available and to scalably feed it into structured research and data-driven conservation efforts. Wildbook combines heterogeneous wildlife data (especially mark-and-recapture ?tagging?, social, genetic, etc.) with machine learning techniques to enable large-scale (regional and global) collaborative wildlife studies in the fields of population biology, animal biometrics, social ecology, molecular ecology, toxicology, and more. Wildbook is an autonomous cloud-based, data-driven, Artificial Intelligence-enabled system that turns crowdsourced photographs into information about animals. \n\n \n\nWe have built Wildbooks for more than 20 species, with the support from this project. We supported hundreds of scientists, engaged thousands of citizen scientists, and tracked tens of thousands of animals across the globe. Data from Wildbooks is becoming the authoritative source on the populations of several species for the International Unit for Conservation of Nature (IUCN) Red List and has prompted the change in the conservation status designation of whale sharks from ?vulnerable? to ?endangered?.\n\n \n\nThis project is enabling science and conservation at planetary scale and high resolution over space, time and individual animals. It is at the forefront of AI for conservation.\n\n \n\n\t\t\t\t\tLast Modified: 08/01/2019\n\n\t\t\t\t\tSubmitted by: Tanya Berger-Wolf"
 }
}