{
 "awd_id": "1408730",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC SBE: Medium: Collaborative: A Socio-Technical Approach to Privacy in a Camera-Rich World",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "James Joshi",
 "awd_eff_date": "2014-10-01",
 "awd_exp_date": "2019-09-30",
 "tot_intn_awd_amt": 800000.0,
 "awd_amount": 800000.0,
 "awd_min_amd_letter_date": "2014-08-26",
 "awd_max_amd_letter_date": "2014-08-26",
 "awd_abstract_narration": "Cameras are now pervasive on consumer devices, including smartphones, laptops, tablets, and new wearable devices like Google Glass and the Narrative Clip lifelogging camera. The ubiquity of these cameras will soon create a new era of visual sensing applications, for example, devices that collect photos and videos of our daily lives, augmented reality applications that help us understand and navigate the world around us, and community-oriented applications, e.g., where cameras close to a crisis tasked with obtaining a real-time \"million-eye view\" of the scene to guide first responders in an emergency. These technologies raise significant implications for individuals and society, including both potential benefits for individuals and communities, but also significant hazards including privacy invasion for individuals, and, if unchecked, for society, as surveillance causes a chilling effect in the public square.  This research couples a sociological understanding of privacy with an investigation of technical mechanisms to address these needs.  Issues such as context (e.g., capturing images for public use may be okay at a public event, but not in the home) and content (are individuals recognizable?) will be explored both on technical and sociological fronts: What can we determine about images, what does this mean in terms of privacy risk, and how can systems protect against risk to privacy?\r\n\r\nSpecific research challenges to be addressed include formulating technical means through image and context analysis to improve the privacy of people captured in images; exploring the unique privacy needs of camera owners and how image and contextual analysis can improve privacy; and developing image transformations to afford privacy as well as enable novel applications using the cloud and crowdsourcing.  Companion sociological studies will examine how context affects privacy perceptions, the impact on perception of new technologies, and image-sharing behavior.  These studies will guide each other, ensuring that mechanisms for image transformation/privatization, non-visual transformations (e.g., altering or obscuring image metadata) and other techniques can improve both privacy protection against automated analysis and how they affect individual perceptions of the invasiveness of the technology.  Through a deeper understanding of the privacy implications of such technologies from both a social and technical perspective, the proposed research has the potential for profound and positive societal impact by laying a foundation for privacy-sensitive visual sensing techniques for a society where cameras are ubiquitous.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Apu",
   "pi_last_name": "Kapadia",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Apu Kapadia",
   "pi_email_addr": "kapadia@indiana.edu",
   "nsf_id": "000552793",
   "pi_start_date": "2014-08-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Crandall",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Crandall",
   "pi_email_addr": "djcran@indiana.edu",
   "nsf_id": "000571471",
   "pi_start_date": "2014-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Indiana University",
  "inst_street_address": "107 S INDIANA AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BLOOMINGTON",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "3172783473",
  "inst_zip_code": "474057000",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IN09",
  "org_lgl_bus_name": "TRUSTEES OF INDIANA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "YH86RTW2YVJ4"
 },
 "perf_inst": {
  "perf_inst_name": "Indiana University",
  "perf_str_addr": "150 S. Woodlawn",
  "perf_city_name": "Bloomington",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "474057104",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IN09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 800000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><br /><br />This project investigated and addressed privacy issues related to the pervasive use of cameras in today&rsquo;s society. Cameras are in our phones, laptops, smart home devices, TVs, and even wearable devices. For example, people can use wearable cameras to &lsquo;lifelog,&rsquo; or automatically capture photos to build a photo journal of their day. Our analysis of photos collected from a lifelogging study showed that people have heightened privacy concerns related to &lsquo;impression management&rsquo;: photos that capture behaviors and habits that could affect one&rsquo;s standing in their social and professional circles. This study also inspired the development of algorithms to detect sensitive content in photos. People were highly concerned about wearable cameras capturing objects such as computer screens, so we developed a deep learning-based algorithm to detect monitors and screens with high accuracy. We also investigated recognition algorithms that produce a textual description of a lifelogging image. Keywords in these textual descriptions can then be used to locate and remove potentially private content; the descriptions can also be used to automatically generate textual summaries or &ldquo;diaries&rdquo; of the visual data.</p>\n<p><br />In an online follow-up study, we sought to experimentally manipulate and identify which aspects of a photo are more sensitive than others. For example, we found that photos containing one person were between two and three times more likely to be rated as private than photos with no or two people. We also found that one&rsquo;s relationship to the photo affected ratings of privacy: people are much more likely to say a photo is private, regardless of content, if they are in it.&nbsp;</p>\n<p><br />Once sensitive content is detected is photos, the next question is what actions should be taken. For example, the photo might simply be deleted or not uploaded to the cloud. Alternatively, redactions could be applied to the photo so that they can be shared after addressing the privacy violation. Unfortunately, owners of the photo may choose not to apply such redactions because they might degrade the viewers&rsquo; experience. We conducted multiple studies to catalog and understand the impact of various redactions on both privacy and the viewers&rsquo; experience. We found examples of redactions that were both privacy-enhancing as well as visually appealing. We also found that some redactions that may seem to obscure private content are ineffective against today&rsquo;s modern computer vision algorithms. As proof of this, we presented a deep learning-based algorithm that can accurately recognize activities occurring in video even after the video has been reduced to an extremely low resolution.</p>\n<p><br />We also explored the extent to which people may be influenced to take action on a photo that might affect the privacy of the person in the photo. We conducted an online experiment to investigate if telling someone to be mindful of the privacy of the person in the photo would affect their likelihood to share the photo. We found a paradoxical result where people indicate they are more likely to share a photo when asked to consider the privacy of the person in the photo. This work shows that online privacy in the context of photo sharing is a complex problem that needs further exploration.&nbsp;</p>\n<p><br />Our project also examined the privacy concerns of people with visual impairments and explored how wearable cameras could be used as assistive devices for improved privacy. Our work uncovered several security, privacy, and safety concerns of people with visual impairments, and the need for a camera-based solution that could assess one&rsquo;s surroundings and provide feedback about people in the vicinity. Our work also examined the privacy concerns of people in the vicinity and found that such bystanders were more willing to share information for assistive purposes as compared to sharing information with sighted people. In cases where people with visual impairments share photos with crowd workers or volunteers for further interpretation, their privacy is put at increased risk. We conducted a study to understand such privacy concerns and found that people with visual impairments were more concerned about the privacy of others than their own and were more comfortable sharing potentially embarrassing information with their family than their friends. Thus, future systems need to consider design from a humanizing perspective so as to protect and not harm people with visual impairments.<br /><br /><br /><br /><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/22/2020<br>\n\t\t\t\t\tModified by: Apu&nbsp;Kapadia</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\nThis project investigated and addressed privacy issues related to the pervasive use of cameras in today\u2019s society. Cameras are in our phones, laptops, smart home devices, TVs, and even wearable devices. For example, people can use wearable cameras to \u2018lifelog,\u2019 or automatically capture photos to build a photo journal of their day. Our analysis of photos collected from a lifelogging study showed that people have heightened privacy concerns related to \u2018impression management\u2019: photos that capture behaviors and habits that could affect one\u2019s standing in their social and professional circles. This study also inspired the development of algorithms to detect sensitive content in photos. People were highly concerned about wearable cameras capturing objects such as computer screens, so we developed a deep learning-based algorithm to detect monitors and screens with high accuracy. We also investigated recognition algorithms that produce a textual description of a lifelogging image. Keywords in these textual descriptions can then be used to locate and remove potentially private content; the descriptions can also be used to automatically generate textual summaries or \"diaries\" of the visual data.\n\n\nIn an online follow-up study, we sought to experimentally manipulate and identify which aspects of a photo are more sensitive than others. For example, we found that photos containing one person were between two and three times more likely to be rated as private than photos with no or two people. We also found that one\u2019s relationship to the photo affected ratings of privacy: people are much more likely to say a photo is private, regardless of content, if they are in it. \n\n\nOnce sensitive content is detected is photos, the next question is what actions should be taken. For example, the photo might simply be deleted or not uploaded to the cloud. Alternatively, redactions could be applied to the photo so that they can be shared after addressing the privacy violation. Unfortunately, owners of the photo may choose not to apply such redactions because they might degrade the viewers\u2019 experience. We conducted multiple studies to catalog and understand the impact of various redactions on both privacy and the viewers\u2019 experience. We found examples of redactions that were both privacy-enhancing as well as visually appealing. We also found that some redactions that may seem to obscure private content are ineffective against today\u2019s modern computer vision algorithms. As proof of this, we presented a deep learning-based algorithm that can accurately recognize activities occurring in video even after the video has been reduced to an extremely low resolution.\n\n\nWe also explored the extent to which people may be influenced to take action on a photo that might affect the privacy of the person in the photo. We conducted an online experiment to investigate if telling someone to be mindful of the privacy of the person in the photo would affect their likelihood to share the photo. We found a paradoxical result where people indicate they are more likely to share a photo when asked to consider the privacy of the person in the photo. This work shows that online privacy in the context of photo sharing is a complex problem that needs further exploration. \n\n\nOur project also examined the privacy concerns of people with visual impairments and explored how wearable cameras could be used as assistive devices for improved privacy. Our work uncovered several security, privacy, and safety concerns of people with visual impairments, and the need for a camera-based solution that could assess one\u2019s surroundings and provide feedback about people in the vicinity. Our work also examined the privacy concerns of people in the vicinity and found that such bystanders were more willing to share information for assistive purposes as compared to sharing information with sighted people. In cases where people with visual impairments share photos with crowd workers or volunteers for further interpretation, their privacy is put at increased risk. We conducted a study to understand such privacy concerns and found that people with visual impairments were more concerned about the privacy of others than their own and were more comfortable sharing potentially embarrassing information with their family than their friends. Thus, future systems need to consider design from a humanizing perspective so as to protect and not harm people with visual impairments.\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 01/22/2020\n\n\t\t\t\t\tSubmitted by: Apu Kapadia"
 }
}