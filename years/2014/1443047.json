{
 "awd_id": "1443047",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CIF21 DIBBs: Domain-Aware Management of Heterogeneous Workflows: Active Data Management for Gravitational-Wave Science Workflows",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924538",
 "po_email": "awalton@nsf.gov",
 "po_sign_block_name": "Amy Walton",
 "awd_eff_date": "2014-10-01",
 "awd_exp_date": "2019-09-30",
 "tot_intn_awd_amt": 900000.0,
 "awd_amount": 1078712.0,
 "awd_min_amd_letter_date": "2014-08-13",
 "awd_max_amd_letter_date": "2018-08-16",
 "awd_abstract_narration": "Analysis and management of large data sets are vital for progress in the data-intensive realm of scientific research and education.  Scientists are producing, analyzing, storing and retrieving massive amounts of data.  The anticipated growth in the analysis of scientific data raises complex issues of stewardship, curation and long-term access. Scientific data is tracked and described by metadata.  This award will fund the design, development, and deployment of metadata-aware workflows to enable the management of large data sets produced by scientific analysis.  Scientific workflows for data analysis are used by a broad community of scientists including astronomy, biology, ecology, and physics. Making workflows metadata-aware is an important step towards making scientific results easier to share, to reuse, and to support reproducibility.  This project will pilot new workflow tools using data from the Laser Interferometer Gravitational-wave Observatory (LIGO), a data-intensive project at the frontiers of astrophysics. The goal of LIGO is to use gravitational waves---ripples in the fabric of spacetime---to explore the physics of black holes and understand the nature of gravity.  \r\n\r\nEfficient methods for accessing and mining the large data sets generated by LIGO's diverse gravitational-wave searches are critical to the overall success of gravitational-wave physics and astronomy.  Providing these capabilities will maximize existing NSF investments in LIGO, support new modes of collaboration within the LIGO Scientific Collaboration, and better enable scientists to explain their results to a wider community, including the critical issue of data and analysis provenance for LIGO's first detections.  The interdisciplinary collaboration involved in this project brings together computational and informatics theories and methods to solve data and workflow management problems in gravitational-wave physics.  The research generated from this project will make a significant contribution to the theory and methods in identification of science requirements, metadata modeling, eScience workflow management, data provenance, reproducibility, data discovery and analysis.  The LIGO scientists participating in this project will ensure that the needs of the community are met. The cyberinfrastructure and data-management scientists will ensure that the software products are well-designed and that the work funded by this award is useful to a broader community.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Duncan",
   "pi_last_name": "Brown",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Duncan A Brown",
   "pi_email_addr": "dabrown@syr.edu",
   "nsf_id": "000336360",
   "pi_start_date": "2014-08-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ewa",
   "pi_last_name": "Deelman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ewa Deelman",
   "pi_email_addr": "deelman@isi.edu",
   "nsf_id": "000119337",
   "pi_start_date": "2014-08-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jian",
   "pi_last_name": "Qin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jian Qin",
   "pi_email_addr": "jqin@syr.edu",
   "nsf_id": "000300057",
   "pi_start_date": "2014-08-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Couvares",
   "pi_mid_init": "F",
   "pi_sufx_name": "",
   "pi_full_name": "Peter F Couvares",
   "pi_email_addr": "peter.couvares@ligo.org",
   "nsf_id": "000328523",
   "pi_start_date": "2014-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Syracuse University",
  "inst_street_address": "900 S CROUSE AVE",
  "inst_street_address_2": "",
  "inst_city_name": "SYRACUSE",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "3154432807",
  "inst_zip_code": "13244",
  "inst_country_name": "United States",
  "cong_dist_code": "22",
  "st_cong_dist_code": "NY22",
  "org_lgl_bus_name": "SYRACUSE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "C4BXLBC11LC6"
 },
 "perf_inst": {
  "perf_inst_name": "Syracuse University",
  "perf_str_addr": "",
  "perf_city_name": "Syracuse",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "132441200",
  "perf_ctry_code": "US",
  "perf_cong_dist": "22",
  "perf_st_cong_dist": "NY22",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "755300",
   "pgm_ele_name": "PHYSICS AT THE INFO FRONTIER"
  },
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7569",
   "pgm_ref_txt": "CYBERINFRASTRUCTURE/SCIENCE"
  },
  {
   "pgm_ref_code": "8048",
   "pgm_ref_txt": "Data Infrstr Bldg Blocks-DIBBs"
  },
  {
   "pgm_ref_code": "8084",
   "pgm_ref_txt": "CDS&E"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 600000.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 150000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 150000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 178712.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-b53ce5ad-7fff-3d3f-23f0-e42581df2ace\">\n<p dir=\"ltr\"><span>Large-scale scientific workflows are essential to LIGO&rsquo;s discoveries. To detect gravitational waves, LIGO data must be filtered through hundreds of thousands of signal models. This is repeated many times using simulated signals to measure the search&rsquo;s efficiency and to diagnose and fix problems with the detectors. Searches are also run multiple times to tune the scientific parameters for maximum sensitivity. Analyses are run by teams of scientists in distributed locations and are executed using heterogeneous computing environments. LIGO was an early adopter of the Pegasus Workflow Management System (WMS)&nbsp; and HTCondor for its binary black hole searches. This project built on the widely-used Pegasus WMS to address the problems encountered in large-scale, distributed scientific  analysis.  Advanced made possible by this project allowed Pegasus to manage LIGO workflow runs that were instrumental in the first direct detection of gravitational waves from colliding black holes, and the subsequent detection of colliding neutron stars observed both in gravitational wave and visible light spectrums.</span></p>\n<p dir=\"ltr\"><span>The project team collaborated to develop new data management techniques in Pegasus and improved data access for LIGO workflows. This allowed LIGO to seamlessly execute large LIGO workflows across the&nbsp; LIGO Data Grid and other NSF funded nation-wide computing infrastructures including the Open Science Grid (OSG) and XSEDE. We improved the Pegasus workflow monitoring dashboard for multi-user access, and improved visualization of workflow status and progress. These new capabilities proved important tools for both system administrators and the scientists running the workflows. The tools we developed provided valuable insight into the monitoring and error analysis of the workflows executed&nbsp; to detect gravitational waves. A new web dashboard built on top of distributed data stores enables scientists and system administrators to get a holistic, global overview of the compact analysis workflows being run, monitor computational resource use, and identify trends and errors as they occur.  With DIBBS-related improvements LIGO improved the turnaround of its offline binary search analysis from many weeks to only a few days. This speed increase proved essential for LIGO Scientific Collaboration to confirm the discoveries of GW150914 and GW170817, as well as other low-latency alerts that are generated and distributed to the astronomy community.</span></p>\n<div>This award provided training for doctoral students who have subsequently moved to positions at national laboratories and in industry, furthering the development of the nation's STEM workforce.</div>\n</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/30/2020<br>\n\t\t\t\t\tModified by: Duncan&nbsp;A&nbsp;Brown</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nLarge-scale scientific workflows are essential to LIGO\u2019s discoveries. To detect gravitational waves, LIGO data must be filtered through hundreds of thousands of signal models. This is repeated many times using simulated signals to measure the search\u2019s efficiency and to diagnose and fix problems with the detectors. Searches are also run multiple times to tune the scientific parameters for maximum sensitivity. Analyses are run by teams of scientists in distributed locations and are executed using heterogeneous computing environments. LIGO was an early adopter of the Pegasus Workflow Management System (WMS)  and HTCondor for its binary black hole searches. This project built on the widely-used Pegasus WMS to address the problems encountered in large-scale, distributed scientific  analysis.  Advanced made possible by this project allowed Pegasus to manage LIGO workflow runs that were instrumental in the first direct detection of gravitational waves from colliding black holes, and the subsequent detection of colliding neutron stars observed both in gravitational wave and visible light spectrums.\nThe project team collaborated to develop new data management techniques in Pegasus and improved data access for LIGO workflows. This allowed LIGO to seamlessly execute large LIGO workflows across the  LIGO Data Grid and other NSF funded nation-wide computing infrastructures including the Open Science Grid (OSG) and XSEDE. We improved the Pegasus workflow monitoring dashboard for multi-user access, and improved visualization of workflow status and progress. These new capabilities proved important tools for both system administrators and the scientists running the workflows. The tools we developed provided valuable insight into the monitoring and error analysis of the workflows executed  to detect gravitational waves. A new web dashboard built on top of distributed data stores enables scientists and system administrators to get a holistic, global overview of the compact analysis workflows being run, monitor computational resource use, and identify trends and errors as they occur.  With DIBBS-related improvements LIGO improved the turnaround of its offline binary search analysis from many weeks to only a few days. This speed increase proved essential for LIGO Scientific Collaboration to confirm the discoveries of GW150914 and GW170817, as well as other low-latency alerts that are generated and distributed to the astronomy community.\nThis award provided training for doctoral students who have subsequently moved to positions at national laboratories and in industry, furthering the development of the nation's STEM workforce.\n\n\n\t\t\t\t\tLast Modified: 01/30/2020\n\n\t\t\t\t\tSubmitted by: Duncan A Brown"
 }
}