{
 "awd_id": "1409422",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CIF: Medium: Collaborative Research: Tracking low-dimensional information in data streams and dynamical systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 370009.0,
 "awd_amount": 370009.0,
 "awd_min_amd_letter_date": "2014-06-11",
 "awd_max_amd_letter_date": "2015-09-04",
 "awd_abstract_narration": "Many applications of significant societal impact are modeled by\r\ncomplex dynamical system behavior, including the (life, physical\r\nand social) sciences, medicine, economics, law, urban development,\r\ninternational politics and global conflict. Fortunately, recent\r\nadvances in sensor technology have allowed observation of these\r\nphenomena at an unprecedented scale. Unfortunately, the volume and\r\ncomplexity of available data present many challenges to extracting\r\nmeaningful information about these systems. Low-dimensional models\r\nserve as a useful structure for understanding the information in\r\nhigh-dimensional signals and systems. However, this information\r\noften changes over time, and so these models can further be\r\nimproved by exploiting temporal dynamics. This project is concerned\r\nwith developing new methods for tracking changing low-dimensional\r\nstructure in data streams and dynamical systems, particularly in\r\nsettings where the observations may be missing, incomplete,\r\ncorrupted, or compressed.\r\n\r\nThe first research aim in this project is to develop new and\r\nsubstantially improve existing techniques for tracking\r\nlow-dimensional structure and, in particular, to extend tracking\r\ncapabilities far beyond conventional signals to much more general\r\ndata sets with intrinsic low-dimensional structure. A second\r\nresearch aim is to develop new tools for tracking low-dimensional\r\nstructure in systems jointly with estimating the content of\r\ntime-varying signals and data sets. A third research aim is\r\nconcerned with higher-dimensional and more complex dynamical\r\nsystems, and the goal is to develop improved methods that exploit\r\nlow-dimensional structure to perform quantitative and qualitative\r\nanalysis in systems that are too complex and high-dimensional for\r\nsystem identification. In a fourth, educational aim, accessible\r\nK-12 outreach materials are being developed for dissemination\r\nthrough an online digital library.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Rozell",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher J Rozell",
   "pi_email_addr": "crozell@gatech.edu",
   "nsf_id": "000079965",
   "pi_start_date": "2014-06-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Ave NW",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 177395.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 192614.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Many applications of significant societal impact are modeled by complex dynamical system behavior. Fortunately, recent engineering advances in sensor technology have allowed observation of these phenomena at an unprecedented scale. Unfortunately, the volume and complexity of available data present many challenges to extracting meaningful information about these systems. When we have to make inferences about these systems from from corrupted and incomplete data, we often use an assumption that this high-dimensional data has a simpler structure that we can exploit due to regularities in the physical world. Mathematically, when you dig into the technical details of our best algorithms, we often use geometry to describe this structure (which we call low-dimensional because it doesn't have as many degrees of freedom as the size of the data might suggest). But, many of those methods assume that the world is fixed and static. However, the essential structure in a signal or system can change over time, and so the inference can further be improved if we build this knowledge into our algorithms.<br /><br />Intellectual merit: This project worked on developing new fundamental mathematical methods for tracking changing low-dimensional structure for inference problems in data streams and dynamical systems, particularly in settings where the observations may be missing, incomplete, corrupted, or compressed. In particular, we have built a family of new algorithms (called dynamical filtering algorithms) that track a particular kind of geometric structure over time called sparsity (meaning that there are just a few underlying degrees of freedom affecting things at a given time). These algorithms are based on mathematical problems called optimization problems, where we use algorithms to search for the \"best\" explanations for the data we're seeing from within a family of structured models. In our approaches, we have modified the structure of these optimization problems in several ways that we postulated would perform better in practical situations, and indeed we have seen that we improve performance significantly over state of the art in many applications.<br /><br />Broader impacts: The methods described above are very general, producing broad impact because of the wide variety of the applications that can be impacted. For example, we have published results adapting these methods to an entirely novel applications in automated sleep analysis, high-throughput electrophysiology and methods for state estimation in neurophysiology data.<br /><br />Regarding sleep analysis, we have developed a new time-series analysis method that can distinguish wakefulness from sleep by solely using observed change events in the photoplethysmogram (PPG) and accelerometer signals from non-invasive (wrist worn) wearable sensors. The technique uses temporal information in the changes and the coupling between multiple sources to optimize classification. Our performance relative to gold-standard polysomnography scoring indicates that our method could provide reliable and unbiased estimates of sleep and wakefulness for long-term studies. Such techniques will likely help treatment of disorders such as PTSD.<br /><br />Regarding high-throughput electrophysiology, intracellular patch-clamp electrophysiology involves delicately attaching a pipette to the membrane of an individual cell to collect information from it. It is one of the most ubiquitous high-fidelity techniques in biophysics, but remains laborious and low-throughput. We recently demonstrated a robotic \"PatcherBot\" system that can perform many patch-clamp recordings sequentially, fully unattended. This project supported the development of tracking algorithms that added machine vision to the robot, allowing the PatcherBot to obtain data at a rate exceeding human capability (up to 16 cells per hour) and work with no human intervention for up to 3 hours. The system is potentially transformative for applications that depend on many high-quality measurements of single cells, such as drug screening, protein functional characterization, and multimodal cell type investigations. Such systems could be important of understanding neurologic diseases and medicines to treat them.<br /><br />Regarding the analysis of neurophysiology data, oscillatory brain activity reflects different internal brain states including neurons? excitatory state and synchrony among neurons. We have recently published a new method to separate single oscillatory cycles into distinct states based on frequency and phase coupling, identifying new states in the area of the brain responsible for memory consolidation (hippocampus). This method provides a new approach to investigate oscillatory brain dynamics broadly. Such approaches could be important for understanding diseases such as Alzheimers Disease.<br /><br />Beyond broad application impacts, this project has also increased public science education. The project team hosted a well attended neuroengineering event at the Atlanta Science Festival. We have also begun to develop educational modules based on the probability techniques of this proposal and are currently preparing them for public release.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/18/2019<br>\n\t\t\t\t\tModified by: Christopher&nbsp;J&nbsp;Rozell</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMany applications of significant societal impact are modeled by complex dynamical system behavior. Fortunately, recent engineering advances in sensor technology have allowed observation of these phenomena at an unprecedented scale. Unfortunately, the volume and complexity of available data present many challenges to extracting meaningful information about these systems. When we have to make inferences about these systems from from corrupted and incomplete data, we often use an assumption that this high-dimensional data has a simpler structure that we can exploit due to regularities in the physical world. Mathematically, when you dig into the technical details of our best algorithms, we often use geometry to describe this structure (which we call low-dimensional because it doesn't have as many degrees of freedom as the size of the data might suggest). But, many of those methods assume that the world is fixed and static. However, the essential structure in a signal or system can change over time, and so the inference can further be improved if we build this knowledge into our algorithms.\n\nIntellectual merit: This project worked on developing new fundamental mathematical methods for tracking changing low-dimensional structure for inference problems in data streams and dynamical systems, particularly in settings where the observations may be missing, incomplete, corrupted, or compressed. In particular, we have built a family of new algorithms (called dynamical filtering algorithms) that track a particular kind of geometric structure over time called sparsity (meaning that there are just a few underlying degrees of freedom affecting things at a given time). These algorithms are based on mathematical problems called optimization problems, where we use algorithms to search for the \"best\" explanations for the data we're seeing from within a family of structured models. In our approaches, we have modified the structure of these optimization problems in several ways that we postulated would perform better in practical situations, and indeed we have seen that we improve performance significantly over state of the art in many applications.\n\nBroader impacts: The methods described above are very general, producing broad impact because of the wide variety of the applications that can be impacted. For example, we have published results adapting these methods to an entirely novel applications in automated sleep analysis, high-throughput electrophysiology and methods for state estimation in neurophysiology data.\n\nRegarding sleep analysis, we have developed a new time-series analysis method that can distinguish wakefulness from sleep by solely using observed change events in the photoplethysmogram (PPG) and accelerometer signals from non-invasive (wrist worn) wearable sensors. The technique uses temporal information in the changes and the coupling between multiple sources to optimize classification. Our performance relative to gold-standard polysomnography scoring indicates that our method could provide reliable and unbiased estimates of sleep and wakefulness for long-term studies. Such techniques will likely help treatment of disorders such as PTSD.\n\nRegarding high-throughput electrophysiology, intracellular patch-clamp electrophysiology involves delicately attaching a pipette to the membrane of an individual cell to collect information from it. It is one of the most ubiquitous high-fidelity techniques in biophysics, but remains laborious and low-throughput. We recently demonstrated a robotic \"PatcherBot\" system that can perform many patch-clamp recordings sequentially, fully unattended. This project supported the development of tracking algorithms that added machine vision to the robot, allowing the PatcherBot to obtain data at a rate exceeding human capability (up to 16 cells per hour) and work with no human intervention for up to 3 hours. The system is potentially transformative for applications that depend on many high-quality measurements of single cells, such as drug screening, protein functional characterization, and multimodal cell type investigations. Such systems could be important of understanding neurologic diseases and medicines to treat them.\n\nRegarding the analysis of neurophysiology data, oscillatory brain activity reflects different internal brain states including neurons? excitatory state and synchrony among neurons. We have recently published a new method to separate single oscillatory cycles into distinct states based on frequency and phase coupling, identifying new states in the area of the brain responsible for memory consolidation (hippocampus). This method provides a new approach to investigate oscillatory brain dynamics broadly. Such approaches could be important for understanding diseases such as Alzheimers Disease.\n\nBeyond broad application impacts, this project has also increased public science education. The project team hosted a well attended neuroengineering event at the Atlanta Science Festival. We have also begun to develop educational modules based on the probability techniques of this proposal and are currently preparing them for public release.\n\n\t\t\t\t\tLast Modified: 10/18/2019\n\n\t\t\t\t\tSubmitted by: Christopher J Rozell"
 }
}