{
 "awd_id": "1414153",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "PFI:AIR - TT:  Automated Out-of-Core Execution of Parallel Message-Passing Applications",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Barbara H. Kenny",
 "awd_eff_date": "2014-08-15",
 "awd_exp_date": "2017-01-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 206034.0,
 "awd_min_amd_letter_date": "2014-08-19",
 "awd_max_amd_letter_date": "2016-06-17",
 "awd_abstract_narration": "This PFI: AIR Technology Translation project focuses on translating a software technology to fill the need for executing parallel applications on architectures with limited physical memory. This software technology, called BDMPI (Big Data Message Passing Interface), is important because it will allow approaches that rely on computational modeling and simulation to efficiently and economically solve very large problems on existing and upcoming computer systems, many of which are optimized for low power. This capability will positively impact many science & engineering disciplines, government, defense, commercial companies, and non-profit organizations. The project will result in a software prototype of BDMPI. The advantages of BDMPI over competing approaches are that (i) it allows existing parallel programs written in MPI (Message Passing Interface) to automatically switch to an efficient disk-based execution with no software re-engineering efforts, and (ii) it provides a flexible framework for developing disk-based distributed programs that can achieve levels of performance that are higher than leading competing approaches (e.g., Hadoop).\r\n\r\nThis project addresses the following technology gap(s) as it translates from research discovery toward commercial application. It will expand BDMPI to support a large subset of MPI's standard API (Application Programming Interface), it will optimize its runtime system so that to reduce the overheads associated with disk-based execution, it will implement fault tolerance features, and it will optimize its runtime system for solid-state disks. In addition, the personnel involved in this project (graduate and undergraduate students), will receive innovation, entrepreneurship, and technology commercialization experiences through the Step-It-Up program that places students in part-time roles of supporting and performing commercialization efforts, their participation in an \"Innovation Training\" workshop, and by interacting with attorneys during patent application drafting.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "George",
   "pi_last_name": "Karypis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "George Karypis",
   "pi_email_addr": "karypis@cs.umn.edu",
   "nsf_id": "000386588",
   "pi_start_date": "2014-08-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andrew",
   "pi_last_name": "Morrow",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Andrew D Morrow",
   "pi_email_addr": "amorrow@umn.edu",
   "nsf_id": "000657626",
   "pi_start_date": "2014-08-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "Department of Computer Science & Engineering",
  "perf_str_addr": "200 Union St SE",
  "perf_city_name": "Minneapolis",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "554552070",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MN05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801900",
   "pgm_ele_name": "Accelerating Innovation Rsrch"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8019",
   "pgm_ref_txt": "Accelerating Innovation Rsrch"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 200000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 6034.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The objective of our project was to translate&nbsp;a software technology to fill the need for executing parallel applications on architectures with limited physical memory. This software technology, called BDMPI, allows approaches that rely on Computational Modeling and Simulation (CM&amp;S) to efficiently and economically solve very large problems on existing and upcoming computer systems, many of which are optimized for low power. The advantages of BDMPI over competing approaches are that it allows existing parallel programs written in the message passing paradigm (MPI) to automatically switch to an efficient disk-based execution with no software re-engineering efforts, and it provides a flexible framework for developing disk-based distributed programs that can achieve levels of performance that are higher than leading competing approaches.</p>\n<p>&nbsp;</p>\n<p>During the course of the project, our work focused on addressing the following technology gaps that were important on the road of translating our research discovery toward a commercially-viable product. We expanded the features from the MPI specification that are efficiently supported by BDMPI. We developed new mechanisms by which data transparently migrates between disk and memory that is compatible with BDMPI&rsquo;s way of scheduling the computations and leads to substantial performance improvements. We developed new task scheduling mechanisms that lead to a more uniform distribution of the computations across the processors, resulting in faster execution time. Finally, we extended BDMPI to support multi-threaded processing within each of its processes, so that to support shared-memory/distributed-memory applications.</p>\n<p>In addition, the project contributed to the training of the graduated students that were directly supported by it in the areas of high-performance computing, distributed systems, and scientific computing, as well as in the areas of innovation, entrepreneurship, technology commercialization, and IP protection. The students attended NSF sponsored meetings and workshops on these topics and also seminars on the issues, challenges, and approaches for starting up a company.</p>\n<p>Finally, the results of the project were disseminated via papers and via the release and ongoing development of the BDMPI software.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/28/2017<br>\n\t\t\t\t\tModified by: George&nbsp;Karypis</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe objective of our project was to translate a software technology to fill the need for executing parallel applications on architectures with limited physical memory. This software technology, called BDMPI, allows approaches that rely on Computational Modeling and Simulation (CM&amp;S) to efficiently and economically solve very large problems on existing and upcoming computer systems, many of which are optimized for low power. The advantages of BDMPI over competing approaches are that it allows existing parallel programs written in the message passing paradigm (MPI) to automatically switch to an efficient disk-based execution with no software re-engineering efforts, and it provides a flexible framework for developing disk-based distributed programs that can achieve levels of performance that are higher than leading competing approaches.\n\n \n\nDuring the course of the project, our work focused on addressing the following technology gaps that were important on the road of translating our research discovery toward a commercially-viable product. We expanded the features from the MPI specification that are efficiently supported by BDMPI. We developed new mechanisms by which data transparently migrates between disk and memory that is compatible with BDMPI?s way of scheduling the computations and leads to substantial performance improvements. We developed new task scheduling mechanisms that lead to a more uniform distribution of the computations across the processors, resulting in faster execution time. Finally, we extended BDMPI to support multi-threaded processing within each of its processes, so that to support shared-memory/distributed-memory applications.\n\nIn addition, the project contributed to the training of the graduated students that were directly supported by it in the areas of high-performance computing, distributed systems, and scientific computing, as well as in the areas of innovation, entrepreneurship, technology commercialization, and IP protection. The students attended NSF sponsored meetings and workshops on these topics and also seminars on the issues, challenges, and approaches for starting up a company.\n\nFinally, the results of the project were disseminated via papers and via the release and ongoing development of the BDMPI software.\n\n \n\n\t\t\t\t\tLast Modified: 04/28/2017\n\n\t\t\t\t\tSubmitted by: George Karypis"
 }
}