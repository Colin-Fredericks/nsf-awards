{
 "awd_id": "1405641",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "II-New: Secure and Efficient Cloud Infrastructure and Accessibility Services",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 199912.0,
 "awd_amount": 221812.0,
 "awd_min_amd_letter_date": "2014-07-21",
 "awd_max_amd_letter_date": "2016-08-10",
 "awd_abstract_narration": "This project will create an experimental infrastructure for studying cloud computing at Stony Brook University.  Cloud computing is the predominant approach for organizing and managing servers for online services such as Amazon, Google, Facebook, and Twitter.  Although cloud computing providers are rapidly expanding, very little is clearly understood in the research literature about how best to build and use a cloud.  This disparity arises primarily from the extreme secrecy in which cloud computing operators conduct their business, limiting the dissemination of such knowledge to retain competitive advantage.  This project will advance the principled study of cloud computing hardware, software, and applications, by giving researchers the ability to directly experiment with a complete cloud infrastructure.\r\n \r\nThe funding for this project enables the purchase of a small computing cloud to be hosted in the Computer Science building at Stony Brook University, configured to mimic a state-of-the-art datacenter.  Users of commercial clouds cannot study many aspects of cloud system design.  This project provides researchers with complete physical access to the cloud infrastructure, enabling measurement of the physical characteristics such as power consumption, temperature, and air flow; access to the entire software stack will enable experimentation on cloud resource management and hypervisor implementation; unrestricted access to the cloud resources will enable rapid flexible benchmark and application development and integration.  Moreover, direct access to the complete cloud environment, including the locally-developed applications and management infrastructure, will provide researchers with full introspection that enables end-to-end studies of cloud behavior.\r\n\r\nThis proposal brings together a group of PIs who will conduct cloud-related research with a new level of empirical rigor.  Because researchers and educators at Stony Brook have a long list of anticipated projects, the infrastructure should immediately garner heavy use.  Among the first projects will be a characterization study of virtualization on the scaling efficiency of cloud applications, which will identify the pressing research opportunities in cloud architecture.  Another will begin at-scale measurement and testing of lightweight virtualization techniques.  This infrastructure will be leveraged to develop and deploy a cloud-based Accessibility as a Service model for delivering accessible digital content to people with disabilities.  This project brings together researchers working at all layers of the cloud computing stack---creating the potential for crosscutting insights from study in a realistic deployment with an active user community.  \r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Ferdman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Ferdman",
   "pi_email_addr": "mferdman@cs.stonybrook.edu",
   "nsf_id": "000634656",
   "pi_start_date": "2014-07-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "IV",
   "pi_last_name": "Ramakrishnan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "IV Ramakrishnan",
   "pi_email_addr": "ram@cs.stonybrook.edu",
   "nsf_id": "000365929",
   "pi_start_date": "2014-07-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "C.",
   "pi_last_name": "Ramakrishnan",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "C. R Ramakrishnan",
   "pi_email_addr": "cram@cs.stonybrook.edu",
   "nsf_id": "000326890",
   "pi_start_date": "2014-07-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Donald",
   "pi_last_name": "Porter",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Donald E Porter",
   "pi_email_addr": "porter@cs.unc.edu",
   "nsf_id": "000569931",
   "pi_start_date": "2014-07-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117944400",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  },
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 199912.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 21900.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this CRI (Computing Research Infrastructure) project was to create a private cloud system at the Department of Computer Science at Stony Brook University, offering full introspection and access to the underlying machines while mimicking a slice of a typical cloud data center, thus allowing in-depth study of cloud computing systems and their behavior.&nbsp; The private cloud system comprises server machines, network switches, storage appliances, and the software to manage and provision these services.&nbsp; The system was built for dual purposes: first, to serve as an experimental testbed for cloud computing; second, to offer cloud computing services to the various research labs in the department.&nbsp;&nbsp;</p>\n<p><br />While the original proposal was relatively limited, the rapid success of the project actually resulted in a massive expansion of scope.&nbsp; Because of the system&rsquo;s convenience in providing computing resources to a diverse set of research labs in the department, and the system&rsquo;s inherent scalability through the simple addition of more hardware, external sources of funding and hardware donations were provided to expand the cloud system.&nbsp; What was originally planned as a small single-rack 20-server cloud has now grown to 8 racks comprising 312 servers (over 4200 cores, 11TB of RAM, and 1PB of storage).</p>\n<p><br />The process of bringing up and managing the infrastructure has exposed students to a unique environment and tools that practically no one in academia and almost no one in industry has access to. The skills gained have made the students valuable assets, exposing them to system administration at scale and giving them an appreciation of what happens at large-scale deployments in production cloud environments.&nbsp; Over 10 MS students, 5 PhD students, a 3 undergraduate students gained skills in working with cloud infrastructure.&nbsp; Multiple students have gone on to positions where they are now managing infrastructure for public cloud providers, including Amazon EC2.</p>\n<p><br />Beyond its original uses for cloud, filesystem, and accessibility research, this private cloud infrastructure has been used (and continues to be used) by a large number of research labs and several courses.&nbsp; The infrastructure has enabled numerous projects to conduct research and advance their respective fields, including computer architecture, operating systems/virtualization, accessibility, computer security, computational biology, cloud resource management, human computer interaction, networks, economics, web/information retrieval, machine learning, natural language processing, and several others.&nbsp; So far, 53 publications across a wide range of fields have actively benefited from and acknowledged this project.&nbsp; Many publications are currently under submission and many active research projects are now running on the cloud hardware.&nbsp; In fact, the availability of the system has spawned several research projects in computational biology, machine learning, and internet security that do not just benefit from the available resources, but would be fundamentally impossible without such resources.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/18/2018<br>\n\t\t\t\t\tModified by: Michael&nbsp;Ferdman</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1405641/1405641_10321348_1539852227548_20181016_155701(1)--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1405641/1405641_10321348_1539852227548_20181016_155701(1)--rgov-800width.jpg\" title=\"cloud racks\"><img src=\"/por/images/Reports/POR/2018/1405641/1405641_10321348_1539852227548_20181016_155701(1)--rgov-66x44.jpg\" alt=\"cloud racks\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">view of 6 of the server racks in cold-aisle containment with in-row chiller</div>\n<div class=\"imageCredit\">PI</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Michael&nbsp;Ferdman</div>\n<div class=\"imageTitle\">cloud racks</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1405641/1405641_10321348_1539852701196_20181016_155813(3)--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1405641/1405641_10321348_1539852701196_20181016_155813(3)--rgov-800width.jpg\" title=\"blade and storage racks\"><img src=\"/por/images/Reports/POR/2018/1405641/1405641_10321348_1539852701196_20181016_155813(3)--rgov-66x44.jpg\" alt=\"blade and storage racks\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">additional server racks (64x HP blades, 7x Dell servers, 3x 36-disk chassis)</div>\n<div class=\"imageCredit\">PI</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Michael&nbsp;Ferdman</div>\n<div class=\"imageTitle\">blade and storage racks</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1405641/1405641_10321348_1539852920810_20181016_155850(2)--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1405641/1405641_10321348_1539852920810_20181016_155850(2)--rgov-800width.jpg\" title=\"back of rack\"><img src=\"/por/images/Reports/POR/2018/1405641/1405641_10321348_1539852920810_20181016_155850(2)--rgov-66x44.jpg\" alt=\"back of rack\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">back of one rack, showing three networks (management, internal, and public) and power distribution.</div>\n<div class=\"imageCredit\">PI</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Michael&nbsp;Ferdman</div>\n<div class=\"imageTitle\">back of rack</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe goal of this CRI (Computing Research Infrastructure) project was to create a private cloud system at the Department of Computer Science at Stony Brook University, offering full introspection and access to the underlying machines while mimicking a slice of a typical cloud data center, thus allowing in-depth study of cloud computing systems and their behavior.  The private cloud system comprises server machines, network switches, storage appliances, and the software to manage and provision these services.  The system was built for dual purposes: first, to serve as an experimental testbed for cloud computing; second, to offer cloud computing services to the various research labs in the department.  \n\n\nWhile the original proposal was relatively limited, the rapid success of the project actually resulted in a massive expansion of scope.  Because of the system?s convenience in providing computing resources to a diverse set of research labs in the department, and the system?s inherent scalability through the simple addition of more hardware, external sources of funding and hardware donations were provided to expand the cloud system.  What was originally planned as a small single-rack 20-server cloud has now grown to 8 racks comprising 312 servers (over 4200 cores, 11TB of RAM, and 1PB of storage).\n\n\nThe process of bringing up and managing the infrastructure has exposed students to a unique environment and tools that practically no one in academia and almost no one in industry has access to. The skills gained have made the students valuable assets, exposing them to system administration at scale and giving them an appreciation of what happens at large-scale deployments in production cloud environments.  Over 10 MS students, 5 PhD students, a 3 undergraduate students gained skills in working with cloud infrastructure.  Multiple students have gone on to positions where they are now managing infrastructure for public cloud providers, including Amazon EC2.\n\n\nBeyond its original uses for cloud, filesystem, and accessibility research, this private cloud infrastructure has been used (and continues to be used) by a large number of research labs and several courses.  The infrastructure has enabled numerous projects to conduct research and advance their respective fields, including computer architecture, operating systems/virtualization, accessibility, computer security, computational biology, cloud resource management, human computer interaction, networks, economics, web/information retrieval, machine learning, natural language processing, and several others.  So far, 53 publications across a wide range of fields have actively benefited from and acknowledged this project.  Many publications are currently under submission and many active research projects are now running on the cloud hardware.  In fact, the availability of the system has spawned several research projects in computational biology, machine learning, and internet security that do not just benefit from the available resources, but would be fundamentally impossible without such resources.\n\n\t\t\t\t\tLast Modified: 10/18/2018\n\n\t\t\t\t\tSubmitted by: Michael Ferdman"
 }
}