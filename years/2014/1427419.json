{
 "awd_id": "1427419",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "NRI: Electrosense imaging for underwater telepresence and manipulation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "David Miller",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 1800000.0,
 "awd_amount": 1816000.0,
 "awd_min_amd_letter_date": "2014-08-25",
 "awd_max_amd_letter_date": "2016-08-01",
 "awd_abstract_narration": "Human telepresence underwater is essential for tasks such as security sweeps in harbors and oil field servicing. Co-robotic solutions are needed, because the risks are great for human divers, while autonomous robots do not deal well with contingencies. A major problem is that vision works poorly in murky environments, such as when mud is kicked up from the bottom. In this National Robotics Initiative (NRI) project the researchers are investigating and developing a replacement for vision -- electrosense -- used by Amazonian fish that navigate and hunt in murky water. These \"weakly electric fish\" generate an AC electric field that is perturbed by objects nearby. Electroreceptors covering the body of the fish detect the perturbations, which the fish decodes into information about its surroundings. The researchers are developing methods of preprocessing electric images for human understanding, and new computed methods for machine interpretation. \r\n\r\nThe research creates electrosense hardware and practical testbeds, for navigation and for manipulation underwater.  It investigates methods and software to facilitate human interpretation of electric images, as well as machine interpretation. In hardware, the researchers are creating a kilopixel-scale electrosense array as an input sensor for human interpretation of electric images, and development of preprocessing algorithms to make human interpretation workable.  The researchers are also using sparser and non-coplanar groups of electroreceptors on a manipulator, for control of pre-grasp and manipulation tasks.  For human interpretation, electric image preprocessing includes contour painting and spatial high-pass filtering, as well as temporal filtering. For machine interpretation, methods include specific recognition strategies for simple geometric primitives, and sparse beamforming techniques for more complex environments.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Peshkin",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Michael A Peshkin",
   "pi_email_addr": "peshkin@northwestern.edu",
   "nsf_id": "000317165",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Malcolm",
   "pi_last_name": "MacIver",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Malcolm A MacIver",
   "pi_email_addr": "maciver@northwestern.edu",
   "nsf_id": "000286882",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Konrad",
   "pi_last_name": "Kording",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Konrad Kording",
   "pi_email_addr": "koerding@gmail.com",
   "nsf_id": "000096260",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Joshua",
   "pi_last_name": "Smith",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Joshua R Smith",
   "pi_email_addr": "jrs@cs.washington.edu",
   "nsf_id": "000500347",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Alexander",
   "pi_last_name": "Makhlin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alexander Makhlin",
   "pi_email_addr": "amakhlin@kineadesign.com",
   "nsf_id": "000606503",
   "pi_start_date": "2016-05-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Solberg",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "James R Solberg",
   "pi_email_addr": "jsolberg@kineadesign.com",
   "nsf_id": "000606507",
   "pi_start_date": "2014-08-25",
   "pi_end_date": "2016-05-16"
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "2145 Sheridan Road",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602080837",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "IL",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 1339152.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 90716.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 386132.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Human telepresence and telemanipulation in unstructured underwater environments is essential for tasks such as security sweeps in harbors and oil field servicing. Co-robotic solutions are needed, as the risks are great for human divers and autonomous robots lack the capability to deal with unpredictable contingencies. A key challenge for underwater human telepresence is providing the human with situation awareness, both for navigation and manipulation. Vision fails in murky environments such as when mud is kicked up from the bottom. Sonar is difficult at short range. This project focused on development of technology and algorithms to exploit a naturally evolved sensory modality used by a special group of nocturnal fish living in the murky waters of Amazonian rivers: active electrosense. Electrosense is used by these weakly electric fish to navigate and hunt water where vision is useless. Weakly electric fish generate an AC electric field that is perturbed by objects nearby. Electroreceptors covering the body of the fish report the amplitude and phase of the local field. The animal decodes electric field perturbations into geometric information about its surroundings. Electrosense is fundamentally different from optical vision (and other imaging) that create projective images of 3D space. To develop electrosense for aiding telepresence and telemanipulation in unstructured underwater environments, the team developed several innovative hardware devices: a new robotic arm and hand that is able to sense objects in water prior to grasp using electrosense (see image); an improved robotic arm and hand that has similar capability, but for objects in air; and algorithms to support pre-touch using electrosense. One of the team?s core scientific contributions has been the development of a modality-independent approach to tuning the movement of robots for sensing under high levels of uncertainty, as typify unstructured underwater environments, called ergodic information harvesting (see image). Comparison to measured movements of animals tuning motion for sensing shows excellent agreement across visual-, olfactory-, and electrosense-guided tracking tasks with degraded signal conditions. We are able to demonstrate that the method is able to rapidly reject distractors compared to another leading algorithm for controlling sensor motion, entropy minimization, and naturally varies the level of exploration and exploitation appropriate to the information landscape. The project has cross-trained several doctoral candidates in biology and engineering in the domain of improving sensory intelligence in robots, including two women and one under-represented minority undergraduate.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/29/2019<br>\n\t\t\t\t\tModified by: Michael&nbsp;A&nbsp;Peshkin</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1427419/1427419_10337461_1577671818944_fig1-new--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1427419/1427419_10337461_1577671818944_fig1-new--rgov-800width.jpg\" title=\"ergodic information harvesting\"><img src=\"/por/images/Reports/POR/2019/1427419/1427419_10337461_1577671818944_fig1-new--rgov-66x44.jpg\" alt=\"ergodic information harvesting\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">development of a modality-independent approach to tuning the movement of robots for sensing under high levels of uncertainty, as typify unstructured underwater environments, called ergodic information harvesting</div>\n<div class=\"imageCredit\">own image</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Michael&nbsp;A&nbsp;Peshkin</div>\n<div class=\"imageTitle\">ergodic information harvesting</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1427419/1427419_10337461_1577671895410_correctthumbplacement2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1427419/1427419_10337461_1577671895410_correctthumbplacement2--rgov-800width.jpg\" title=\"robotic arm and hand\"><img src=\"/por/images/Reports/POR/2019/1427419/1427419_10337461_1577671895410_correctthumbplacement2--rgov-66x44.jpg\" alt=\"robotic arm and hand\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">a new robotic arm and hand that is able to sense objects in water prior to grasp using electrosense</div>\n<div class=\"imageCredit\">own image</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Michael&nbsp;A&nbsp;Peshkin</div>\n<div class=\"imageTitle\">robotic arm and hand</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nHuman telepresence and telemanipulation in unstructured underwater environments is essential for tasks such as security sweeps in harbors and oil field servicing. Co-robotic solutions are needed, as the risks are great for human divers and autonomous robots lack the capability to deal with unpredictable contingencies. A key challenge for underwater human telepresence is providing the human with situation awareness, both for navigation and manipulation. Vision fails in murky environments such as when mud is kicked up from the bottom. Sonar is difficult at short range. This project focused on development of technology and algorithms to exploit a naturally evolved sensory modality used by a special group of nocturnal fish living in the murky waters of Amazonian rivers: active electrosense. Electrosense is used by these weakly electric fish to navigate and hunt water where vision is useless. Weakly electric fish generate an AC electric field that is perturbed by objects nearby. Electroreceptors covering the body of the fish report the amplitude and phase of the local field. The animal decodes electric field perturbations into geometric information about its surroundings. Electrosense is fundamentally different from optical vision (and other imaging) that create projective images of 3D space. To develop electrosense for aiding telepresence and telemanipulation in unstructured underwater environments, the team developed several innovative hardware devices: a new robotic arm and hand that is able to sense objects in water prior to grasp using electrosense (see image); an improved robotic arm and hand that has similar capability, but for objects in air; and algorithms to support pre-touch using electrosense. One of the team?s core scientific contributions has been the development of a modality-independent approach to tuning the movement of robots for sensing under high levels of uncertainty, as typify unstructured underwater environments, called ergodic information harvesting (see image). Comparison to measured movements of animals tuning motion for sensing shows excellent agreement across visual-, olfactory-, and electrosense-guided tracking tasks with degraded signal conditions. We are able to demonstrate that the method is able to rapidly reject distractors compared to another leading algorithm for controlling sensor motion, entropy minimization, and naturally varies the level of exploration and exploitation appropriate to the information landscape. The project has cross-trained several doctoral candidates in biology and engineering in the domain of improving sensory intelligence in robots, including two women and one under-represented minority undergraduate.\n\n\t\t\t\t\tLast Modified: 12/29/2019\n\n\t\t\t\t\tSubmitted by: Michael A Peshkin"
 }
}