{
 "awd_id": "1423487",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: CGV: Small: A Scalable Visual Analytics Framework for Exascale Scientific Simulations",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2015-01-01",
 "awd_exp_date": "2019-12-31",
 "tot_intn_awd_amt": 397378.0,
 "awd_amount": 405378.0,
 "awd_min_amd_letter_date": "2014-07-28",
 "awd_max_amd_letter_date": "2016-04-21",
 "awd_abstract_narration": "By leveraging advanced parallel computing systems, scientists can answer important questions that are critical to US energy and economic security. Exascale computing will further enable scientists to perform detailed simulations at higher resolution and greater complexity. Advanced visualization is necessary for scientists to explore massive and complex simulation data at high interactivity and fidelity to study various physical, chemical, and biological phenomena. Although visualization technology has significantly progressed in recent years, conventional visualization techniques are not yet ready for exascale systems and applications. Future exascale systems are expected to be characterized with many-core processors, deep memory hierarchies, and high levels of concurrency. The design of new visualization techniques must adapt to the need for timely discovery from complex and extremely large data sets as well as these emerging hardware and software trends. The goal of this project is to address the current technology gap by investigating a complete course of visualization pipeline with scientific simulations in a holistic fashion, and thus ensure parallelism and efficiency in exascale data visual analytics. This project will integrate research with teaching and outreach programs, where visualization of scientific applications will be used as an effective means to promote students' interest and proficiency in science and engineering studies, and to attract and retain both undergraduate and graduate students, particularly female students, into research.\r\n\r\nThis project plans to account directly for the complex interdependencies with and among the critical components of visual analytics for exascale computing. This project focuses on three key research tasks: (1) developing a novel in-situ data reduction and indexing algorithm to capture essentials from large-scale simulations; (2) studying parallel visualization algorithms to promise scalable performance for high-throughput and high-resolution exploration of large-scale simulation data based on in-situ compact data representations; and (3) designing user interface to parse and deploy application knowledge for visual analytics to acquire critical scientific discovery from in-situ simulation output with enhanced user experience and performance. This project is driven by real-world large-scale scientific applications that involve the modeling and analysis of evolving phenomena with heterogeneous data types, and demand scalable capabilities of visual analytics. Scientific collaborators will be involved into the development, evaluation, and deployment of the solutions to close the gap between advanced visualization techniques and scientific applications, and help solve some of the most challenging scientific problems. The techniques developed within this project will be readily adapted for use by many applications beyond the primary demonstration targets with similar needs, and thus will have a significant impact on scientists' capability for data analysis and visualization. The success of this research will potentially change the conventional scientific discovery pipeline and accelerate the study of large-scale simulation data. The project results will be disseminated through different venues and forms that are publicized at the project website (http://cse.unl.edu/~yu/research/nsf15_exascale/).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hongfeng",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hongfeng Yu",
   "pi_email_addr": "yu@cse.unl.edu",
   "nsf_id": "000621545",
   "pi_start_date": "2014-07-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Nebraska-Lincoln",
  "inst_street_address": "2200 VINE ST # 830861",
  "inst_street_address_2": "",
  "inst_city_name": "LINCOLN",
  "inst_state_code": "NE",
  "inst_state_name": "Nebraska",
  "inst_phone_num": "4024723171",
  "inst_zip_code": "685032427",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NE01",
  "org_lgl_bus_name": "BOARD OF REGENTS OF THE UNIVERSITY OF NEBRASKA",
  "org_prnt_uei_num": "",
  "org_uei_num": "HTQ6K6NJFHA6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Nebraska-Lincoln",
  "perf_str_addr": "312 N. 14th St, Alex Bldg West",
  "perf_city_name": "Lincoln",
  "perf_st_code": "NE",
  "perf_st_name": "Nebraska",
  "perf_zip_code": "685880430",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NE01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 397378.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Scientists have been leveraging advanced computing techniques and systems to conduct scientific modelings and simulations in unprecedented scales and details. The design of new visualization techniques must adapt to the need for timely discovery from complex and extremely large data sets and emerging hardware and software trends. In this project, we have investigated new algorithms to capture essential information from scientific data. We have leveraged the extracted knowledge to generate new compact data representations to address the critical performance bottlenecks and develop scalable visualization algorithms to support high-performance and high-resolution exploration of large-scale scientific applications. We have made the following main contributions from four aspects:</p>\n<p>First, we have developed novel algorithms to extract and characterize important information from time-varying multivariate scientific simulation data:</p>\n<ul>\n<li>A new distributed spatial data structure (parallel distance tree) to manage the level sets of data and facilitate data reduction and indexing for large-scale applications,&nbsp;</li>\n<li>A method, named particle flow, to capture the inherently complex dynamics of time-varying scientific datasets and generate compressed data representations for visualization and analytics,</li>\n<li>&nbsp;A novel autoencoder based approach to extract features from temporal-spatial chucks of data and create a compressed volume representation.</li>\n</ul>\n<p>Second, we have developed approaches to understanding complex system behaviors and data communication patterns from large-scale parallel programs:</p>\n<ul>\n<li>New distributed algorithms to improve the accuracy and the scalability of parallel community detection,&nbsp;</li>\n<li>Scalable graph visualization algorithms to effectively reveal intricate communication patterns for performance optimization,</li>\n<li>A visual analytics technique, named CommGram, in support of interactive exploration of communication activities of massively parallel programs.&nbsp; </li>\n</ul>\n<p>Third, we have exploited the extracted knowledge from scientific applications and system behaviors and presented several performance optimization solutions:</p>\n<ul>\n<li>A scientific data analytics framework on heterogeneous architectures using the Legion runtime system,</li>\n<li>A general performance optimization framework, named Dice, to schedule hybrid jobs for big data analytics,&nbsp;</li>\n<li>An adaptive data placement approach to address asynchronous interaction and coupling behaviors of scientific application workflows,</li>\n<li>New application-user-aware data management policies to address the I/O latency challenge for interactive visualization on scientific data.&nbsp;</li>\n</ul>\n<p>Fourth, we have developed new user interface techniques and visual analytics systems for real-world applications, including:</p>\n<ul>\n<li>A novel tool, named Tweether, a web-based visualization of real-time Twitter and weather simulations to interactively show the possible correlation between the feelings of current users and the weather,</li>\n<li>A new visualization approach, named Boundary-Structure-Aware Transfer Functions, to combine the advantages of the boundary-based and structure-based methods for volume classification,&nbsp;</li>\n<li>A visualization framework by employing the interface automata theory to visualize scientific geohydrologic datasets,&nbsp;</li>\n<li>A scalable approach that facilitates the scientific analysis of voluminous and diverse geoscience data in a distributed environment,&nbsp;</li>\n<li>An uncertainty visualization platform for exploring nitrogen leaching to soil and groundwater.</li>\n</ul>\n<p>These new techniques and systems have been demonstrated at peer-reviewed journal and conference papers in premier venues and helped scientists in different domains to gain effective and efficient visualizations for their scientific applications, such as turbulent combustion, geohydrologic studies, climate simulations, geophysical analysis, environmental modeling, and so on. The project has partially supported ten graduate students (including five female students) with cutting-edge research topics. We have employed interactive scientific visualization to promote interdisciplinary computer technology and research in various outreach events, such as Hour of Code event for K-12 students, Nebraska State FFA Convention tours for future farmers of America, and Introduce a Girl to Engineering Day for Nebraska girls in grades 3-12.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/14/2020<br>\n\t\t\t\t\tModified by: Hongfeng&nbsp;Yu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nScientists have been leveraging advanced computing techniques and systems to conduct scientific modelings and simulations in unprecedented scales and details. The design of new visualization techniques must adapt to the need for timely discovery from complex and extremely large data sets and emerging hardware and software trends. In this project, we have investigated new algorithms to capture essential information from scientific data. We have leveraged the extracted knowledge to generate new compact data representations to address the critical performance bottlenecks and develop scalable visualization algorithms to support high-performance and high-resolution exploration of large-scale scientific applications. We have made the following main contributions from four aspects:\n\nFirst, we have developed novel algorithms to extract and characterize important information from time-varying multivariate scientific simulation data:\n\nA new distributed spatial data structure (parallel distance tree) to manage the level sets of data and facilitate data reduction and indexing for large-scale applications, \nA method, named particle flow, to capture the inherently complex dynamics of time-varying scientific datasets and generate compressed data representations for visualization and analytics,\n A novel autoencoder based approach to extract features from temporal-spatial chucks of data and create a compressed volume representation.\n\n\nSecond, we have developed approaches to understanding complex system behaviors and data communication patterns from large-scale parallel programs:\n\nNew distributed algorithms to improve the accuracy and the scalability of parallel community detection, \nScalable graph visualization algorithms to effectively reveal intricate communication patterns for performance optimization,\nA visual analytics technique, named CommGram, in support of interactive exploration of communication activities of massively parallel programs.  \n\n\nThird, we have exploited the extracted knowledge from scientific applications and system behaviors and presented several performance optimization solutions:\n\nA scientific data analytics framework on heterogeneous architectures using the Legion runtime system,\nA general performance optimization framework, named Dice, to schedule hybrid jobs for big data analytics, \nAn adaptive data placement approach to address asynchronous interaction and coupling behaviors of scientific application workflows,\nNew application-user-aware data management policies to address the I/O latency challenge for interactive visualization on scientific data. \n\n\nFourth, we have developed new user interface techniques and visual analytics systems for real-world applications, including:\n\nA novel tool, named Tweether, a web-based visualization of real-time Twitter and weather simulations to interactively show the possible correlation between the feelings of current users and the weather,\nA new visualization approach, named Boundary-Structure-Aware Transfer Functions, to combine the advantages of the boundary-based and structure-based methods for volume classification, \nA visualization framework by employing the interface automata theory to visualize scientific geohydrologic datasets, \nA scalable approach that facilitates the scientific analysis of voluminous and diverse geoscience data in a distributed environment, \nAn uncertainty visualization platform for exploring nitrogen leaching to soil and groundwater.\n\n\nThese new techniques and systems have been demonstrated at peer-reviewed journal and conference papers in premier venues and helped scientists in different domains to gain effective and efficient visualizations for their scientific applications, such as turbulent combustion, geohydrologic studies, climate simulations, geophysical analysis, environmental modeling, and so on. The project has partially supported ten graduate students (including five female students) with cutting-edge research topics. We have employed interactive scientific visualization to promote interdisciplinary computer technology and research in various outreach events, such as Hour of Code event for K-12 students, Nebraska State FFA Convention tours for future farmers of America, and Introduce a Girl to Engineering Day for Nebraska girls in grades 3-12.\n\n\t\t\t\t\tLast Modified: 06/14/2020\n\n\t\t\t\t\tSubmitted by: Hongfeng Yu"
 }
}