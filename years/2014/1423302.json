{
 "awd_id": "1423302",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Cooperative Memory Expansion (COMEX) for Networked Computing Systems via Remote Direct Memory Access",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yuanyuan Yang",
 "awd_eff_date": "2014-07-15",
 "awd_exp_date": "2018-06-30",
 "tot_intn_awd_amt": 460000.0,
 "awd_amount": 476000.0,
 "awd_min_amd_letter_date": "2014-07-09",
 "awd_max_amd_letter_date": "2015-08-14",
 "awd_abstract_narration": "Legacy and emerging applications with large working sets and, when executed on commodity servers, \r\nmay exhibit poor performance due to frequent page faults which rely on the slow disk swap partition. \r\nThis research aims to establish immense memory collectively across nodes of a networked computing system for holding pages \r\nevicted from the main memory of any participating nodes during application runs with large working sets, \r\nrealizing cooperative memory expansion (COMEX).  It has a great promise to advance technical understanding \r\nand scientific frontiers of networked computing systems. \r\n\r\n\tGiven its wide adoption by operating systems and networking gear vendors nowadays, \r\nthe remote direct memory access (RDMA) technology is adopted by COMEX for ultra-low latencies in page transfer \r\nbetween nodes whose OS kernel and CPU can be totally bypassed.  \r\nThis project deals with five technical challenges and the solution approaches to those challenges together \r\nwill constitute the basis of the COMEX Handler, able to enhance execution performance and system throughput \r\nvia better utilizing overall system DRAM memory on-demand.  \r\nThe project will also improve the research and educational activities on computer systems and distributed computing \r\non the University of Louisiana at Lafayette campus, with its outcomes helping to integrate research and education for enriched teaching, \r\ntraining, and learning experience and to educate quality future workforce critical to the NSF mission, the state of Louisiana and the nation.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nian-Feng",
   "pi_last_name": "Tzeng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nian-Feng Tzeng",
   "pi_email_addr": "tzeng@louisiana.edu",
   "nsf_id": "000311035",
   "pi_start_date": "2014-07-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Louisiana at Lafayette",
  "inst_street_address": "104 E UNIVERSITY AVE",
  "inst_street_address_2": "",
  "inst_city_name": "LAFAYETTE",
  "inst_state_code": "LA",
  "inst_state_name": "Louisiana",
  "inst_phone_num": "3374825811",
  "inst_zip_code": "705032014",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "LA03",
  "org_lgl_bus_name": "UNIVERSITY OF LOUISIANA AT LAFAYETTE",
  "org_prnt_uei_num": "C169K7T4QZ96",
  "org_uei_num": "C169K7T4QZ96"
 },
 "perf_inst": {
  "perf_inst_name": "University of Louisiana at Lafayette",
  "perf_str_addr": "301 East Lewis Street",
  "perf_city_name": "Lafayette",
  "perf_st_code": "LA",
  "perf_st_name": "Louisiana",
  "perf_zip_code": "705044330",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "LA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 460000.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Processing big data effectively to ensure high throughput and  energy-efficiency with real-time responses has emerged as the new  data-intensive computation paradigm. Such a new paradigm urgently calls for innovative solutions to computing system design and implementation. To that end, this project has investigated an effective solution for establishing immense memory  collectively across nodes of a networked computing system to accelerate big data processing, by taking advantage of common system software support for remote direct memory access (RDMA) and of widespread adoption of RDMA-capable networking gear, which exhibits extremely low latency and offers remote operating system (OS) bypassing for rapid data transfer between connected nodes.&nbsp; In essence, the proposed solution relies on OS page tables for tracking remote physical memory (in other connected nodes) allocated to an application on-demand during its execution, particularly beneficial to the application with its working sets larger than the physical memory size of a node. A software system prototype has been designed and implemented in this project by OS kernel extensions, with a loadable kernel module added to realize network  functionalities.&nbsp; It has been evaluated extensively using 10 applications with large execution memory footprints (of 16.1 ~ 30.8 GB) from two benchmark suites, run on a testbed composed of twelve Dell PowerEdge 1950 servers networked by a Mellanox 12-Port 10GbE RDMA-enabled switch (Model SX1012X).&nbsp; Collected evaluation results demonstrate that the proposed approach accelerates benchmark execution trememdously, ranging from 97X to 7.5X under mono-tasking (where one benchmark is executed on a networked node), and it achieves equally impressive speedups of 76X to 5.4X under multi-tasking (where different benchmarks are execution on multiple connected nodes concurrently).&nbsp; Considerable execution speedups usually result from the proposed solution, provided that the aggregate working set sizes of concurrent execution runs stay below the combined memory capacity of all connected nodes.</p>\n<p>Meanwhile, the project has been expanded to investigate into chip  multiprocessors (CMPs) and networks on chips (NoCs),  \t\t\t\t\twhich could serve as the building blocks of large-scale distributed  systems,  \t\t\t\t\twhere the developed software system can be applied to  establish an environment that permits massive in-memory processing.   \t\t\t\t\t \t\t\t\t\tThe goals of expanded research include  \t\t\t\t\t(1) heightening cache coherence directory storage efficiency for  better CMP scalability and  \t\t\t\t\t(2) developing and assessing Deflection Containment (DeC) in  bufferless NoCs for performance improvement and power reduction.&nbsp; Design details and performance outcomes of the expanded research activities have been published in key IEEE Transactions or presented in relevant conferences for sharing.&nbsp; A dedicated website (https://people.cmix.louisiana.edu/~pxs5888/comex/) has been maintained, with its contents kept up-to-dated for wide dissemination to the public.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/27/2018<br>\n\t\t\t\t\tModified by: Nian-Feng&nbsp;Tzeng</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nProcessing big data effectively to ensure high throughput and  energy-efficiency with real-time responses has emerged as the new  data-intensive computation paradigm. Such a new paradigm urgently calls for innovative solutions to computing system design and implementation. To that end, this project has investigated an effective solution for establishing immense memory  collectively across nodes of a networked computing system to accelerate big data processing, by taking advantage of common system software support for remote direct memory access (RDMA) and of widespread adoption of RDMA-capable networking gear, which exhibits extremely low latency and offers remote operating system (OS) bypassing for rapid data transfer between connected nodes.  In essence, the proposed solution relies on OS page tables for tracking remote physical memory (in other connected nodes) allocated to an application on-demand during its execution, particularly beneficial to the application with its working sets larger than the physical memory size of a node. A software system prototype has been designed and implemented in this project by OS kernel extensions, with a loadable kernel module added to realize network  functionalities.  It has been evaluated extensively using 10 applications with large execution memory footprints (of 16.1 ~ 30.8 GB) from two benchmark suites, run on a testbed composed of twelve Dell PowerEdge 1950 servers networked by a Mellanox 12-Port 10GbE RDMA-enabled switch (Model SX1012X).  Collected evaluation results demonstrate that the proposed approach accelerates benchmark execution trememdously, ranging from 97X to 7.5X under mono-tasking (where one benchmark is executed on a networked node), and it achieves equally impressive speedups of 76X to 5.4X under multi-tasking (where different benchmarks are execution on multiple connected nodes concurrently).  Considerable execution speedups usually result from the proposed solution, provided that the aggregate working set sizes of concurrent execution runs stay below the combined memory capacity of all connected nodes.\n\nMeanwhile, the project has been expanded to investigate into chip  multiprocessors (CMPs) and networks on chips (NoCs),  \t\t\t\t\twhich could serve as the building blocks of large-scale distributed  systems,  \t\t\t\t\twhere the developed software system can be applied to  establish an environment that permits massive in-memory processing.   \t\t\t\t\t \t\t\t\t\tThe goals of expanded research include  \t\t\t\t\t(1) heightening cache coherence directory storage efficiency for  better CMP scalability and  \t\t\t\t\t(2) developing and assessing Deflection Containment (DeC) in  bufferless NoCs for performance improvement and power reduction.  Design details and performance outcomes of the expanded research activities have been published in key IEEE Transactions or presented in relevant conferences for sharing.  A dedicated website (https://people.cmix.louisiana.edu/~pxs5888/comex/) has been maintained, with its contents kept up-to-dated for wide dissemination to the public.\n\n\t\t\t\t\tLast Modified: 09/27/2018\n\n\t\t\t\t\tSubmitted by: Nian-Feng Tzeng"
 }
}