{
 "awd_id": "1440033",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Collaborative Research: Inference by social sampling",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Richard Brown",
 "awd_eff_date": "2014-01-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 175762.0,
 "awd_amount": 182262.0,
 "awd_min_amd_letter_date": "2014-03-19",
 "awd_max_amd_letter_date": "2014-06-05",
 "awd_abstract_narration": "Learning and inference in distributed settings is an important from both a scientific and engineering perspective.  A typical instance of the problem is a network of individual sensors or agents attempting to infer a global distribution that governs their local observations.  By passing messages the agents can individually make inference about a global phenomenon.  This research investigates communication and networking paradigms that can enable a network of individual agents to collaboratively estimate distributions over high dimensional spaces, even when individual observations are severely limited in accuracy, space, or time. \r\n\r\nIn particular, the investigators study how individual decision makers can integrate two kinds of information: local observations and messages from their neighbors in the network.  Both observation and messaging can be thought of as sampling : individuals sample their own environment and sample the opinions of their neighbors.  Central to the approach is that the agents generate simple messages at random from an internal estimate of the global distribution of interest.  The first major goal of this project is to develop a mathematical framework and analysis techniques to understand if and when this limited form of learning and communication is sufficient for an individual to estimate and learn distributions and/or global parameters governing the observations of all nodes.   The technical approach is a blend of analysis techniques ranging from stochastic approximation, randomized algorithms, and statistical physics.  \r\n\r\nApplications for this work range from mathematical modeling of messages and opinion formation in social networks, communication protocols for distributed optimization, and estimation of parameters in data networks.  The work will cover several related problems : estimating high-dimensional histograms of data held in the network, parametric estimation using a mix of Bayesian and non-Bayesian techniques, and estimation of more complex generative models.  The final part of the work is to apply these methods to peer-peer networks and social network modeling.  The broader impact of this work is to further develop the interdisciplinary field of network science, which impacts both quantitative social sciences and engineering.  The PIs will develop educational materials and organize research activities to help bring together different research communities interested in networks and social learning.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anand",
   "pi_last_name": "Sarwate",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Anand D Sarwate",
   "pi_email_addr": "anand.sarwate@rutgers.edu",
   "nsf_id": "000608994",
   "pi_start_date": "2014-03-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "",
  "perf_city_name": "New Brunswick",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "089018559",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7797",
   "pgm_ref_txt": "COMM & INFORMATION FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 175762.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 6500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Social learning refers to a process by which groups of individuals can make collective inferences or decisions. Individual agents can observe their environment, take actions, observe the actions taken by other agents, and exchange messages to facilitate this objective. In an engineering context, these agents might be individual sensors arranged in a network that dictates which agents can communicate. A canonical problem in this setting would be to infer some global parameter or variable that governs the agents' observations. Social learning is beneficial because each agents' observations, or local data, may be insufficient to infer the parameter: communication and message passing is necessary to allow global convergence.</p>\n<p>This project developed algorithms for social learning problems in which individual agents' observations are severely limited in accuracy, space, or time. Agents have two sources of information: local observations about their environment and messages from other agents in the network.</p>\n<ul>\n<li>If agents can take very few local observations, they must leverage communication with others to achieve global estimates. At the same time, in many settings the complexity of the message is severely constrained. This work proposed a model for this problem in which agents sample the opinions of their neighbors. Agents must balance, over time, their trust in their own estimate versus the sampled information they receive from their neighbors. This project showed how a combination of self-censorship and increased self-trust can allow accurate inference by all agents.</li>\n</ul>\n<ul>\n<li>In other cases, agents may be able to take many observations of their environment but still be unable to make accurate global inferences because they are only able to partially observe the underlying phenomenon. In this case, collaboration with other agents is necessary. This project proposed an communication protocol and inference algorithm for this setting in which agents communicate their beliefs about the underlying distribution rather than their observed data. This work identified a new network measure, called network divergence, which quantifies the correlation between the quality of an agent's observations and their influence in the network. A large divergence means fast convergence; a network with influential agents having good observations will reach consensus quickly.</li>\n</ul>\n<ul>\n<li>Social learning algorithms are, at their heart, methods for solving an optimization problem in a decentralized way. Efficient optimization involves balancing communication between agents and local computation by agents. If the agents are observing data from the same source, then this tradeoff will depend on properties of that source. This project made two connections to this problem. The first was to characterize data-dependent tradeoffs between communication and computation. The second was to build a connection between the social sampling and inference algorithms and a popular optimization approach known as coordinate descent.&nbsp;</li>\n</ul>\n<p>The intellectural merit of this project was threefold: (a) it developed novel social learning protocols for fast and accurate inference in distributed systems, (b) to brought mathematical tools from stochastic approximation and large deviations analysis to identify new measures quantifying the performance of social learning, and (c) it connected work in social learning to problems in machine learning and distributed optimization. The broader impacts of this work were through training, dissemination, and outreach to new communities. This work supported graduate researchers as well as diversity-focused undergraduate research programs. The outcomes were disseminated at engineering conferences and workshops with preprints made publicly available. Ideas from this project have found their way into work in machine learning and optimization and were presented in interdisciplinary workshop on collective behavior phenomena.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/28/2017<br>\n\t\t\t\t\tModified by: Anand&nbsp;Sarwate</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSocial learning refers to a process by which groups of individuals can make collective inferences or decisions. Individual agents can observe their environment, take actions, observe the actions taken by other agents, and exchange messages to facilitate this objective. In an engineering context, these agents might be individual sensors arranged in a network that dictates which agents can communicate. A canonical problem in this setting would be to infer some global parameter or variable that governs the agents' observations. Social learning is beneficial because each agents' observations, or local data, may be insufficient to infer the parameter: communication and message passing is necessary to allow global convergence.\n\nThis project developed algorithms for social learning problems in which individual agents' observations are severely limited in accuracy, space, or time. Agents have two sources of information: local observations about their environment and messages from other agents in the network.\n\nIf agents can take very few local observations, they must leverage communication with others to achieve global estimates. At the same time, in many settings the complexity of the message is severely constrained. This work proposed a model for this problem in which agents sample the opinions of their neighbors. Agents must balance, over time, their trust in their own estimate versus the sampled information they receive from their neighbors. This project showed how a combination of self-censorship and increased self-trust can allow accurate inference by all agents.\n\n\nIn other cases, agents may be able to take many observations of their environment but still be unable to make accurate global inferences because they are only able to partially observe the underlying phenomenon. In this case, collaboration with other agents is necessary. This project proposed an communication protocol and inference algorithm for this setting in which agents communicate their beliefs about the underlying distribution rather than their observed data. This work identified a new network measure, called network divergence, which quantifies the correlation between the quality of an agent's observations and their influence in the network. A large divergence means fast convergence; a network with influential agents having good observations will reach consensus quickly.\n\n\nSocial learning algorithms are, at their heart, methods for solving an optimization problem in a decentralized way. Efficient optimization involves balancing communication between agents and local computation by agents. If the agents are observing data from the same source, then this tradeoff will depend on properties of that source. This project made two connections to this problem. The first was to characterize data-dependent tradeoffs between communication and computation. The second was to build a connection between the social sampling and inference algorithms and a popular optimization approach known as coordinate descent. \n\n\nThe intellectural merit of this project was threefold: (a) it developed novel social learning protocols for fast and accurate inference in distributed systems, (b) to brought mathematical tools from stochastic approximation and large deviations analysis to identify new measures quantifying the performance of social learning, and (c) it connected work in social learning to problems in machine learning and distributed optimization. The broader impacts of this work were through training, dissemination, and outreach to new communities. This work supported graduate researchers as well as diversity-focused undergraduate research programs. The outcomes were disseminated at engineering conferences and workshops with preprints made publicly available. Ideas from this project have found their way into work in machine learning and optimization and were presented in interdisciplinary workshop on collective behavior phenomena.\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 11/28/2017\n\n\t\t\t\t\tSubmitted by: Anand Sarwate"
 }
}