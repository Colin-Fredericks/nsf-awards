{
 "awd_id": "1405906",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CI-P: Computer System Failure Data Repository to Enable Data-Driven Dependability Research",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2014-07-15",
 "awd_exp_date": "2016-06-30",
 "tot_intn_awd_amt": 49891.0,
 "awd_amount": 65891.0,
 "awd_min_amd_letter_date": "2014-07-17",
 "awd_max_amd_letter_date": "2015-04-15",
 "awd_abstract_narration": "Dependability is a requirement for computer systems; however, research\r\non dependable systems is hampered by a lack of real and publicly\r\navailable failure data.  This can result in productive paths of\r\nresearch being closed to most researchers and, conversely,\r\nunproductive research being performed due to faulty assumptions about\r\nthe manner in which real systems fail.  The goal of this project is to\r\nplan a collaborative effort to collect, curate, and provide public\r\naccess to failure data for large scale computer systems through a\r\ncommunity repository.  One challenge is that failure data is\r\nconsidered sensitive by the owners.  The ultimate goal of this project\r\nis to collect the data from some of the NSF-funded large\r\ncyberinfrastructure projects, such as NEES, LIGO, XSEDE, and NRAO.\r\n\r\nThe specific goal of this planning project is to collect requirements\r\nfrom potential praticipants (both users and contributors of data sets)\r\nand seed a prototype repository with data sets from two of the largest\r\nand latest clusters at Purdue. The data sets will comprise static\r\ninformation, dynamic information about the workloads, and failure\r\ninformation, for both planned and unplanned outages.\r\n\r\nThe broader impact in the project will be achieved through the\r\ndissemination of the data sets to a wide variety of researchers, and\r\nperhaps even, practitioners. The datasets will let people run their\r\ncampus clusters more efficiently, i.e., with fewer failures, at higher\r\nutilization and energy efficiency.\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Saurabh",
   "pi_last_name": "Bagchi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Saurabh Bagchi",
   "pi_email_addr": "sbagchi@purdue.edu",
   "nsf_id": "000309372",
   "pi_start_date": "2014-07-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Xiaohui Carol",
   "pi_last_name": "Song",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaohui Carol Song",
   "pi_email_addr": "cxsong@purdue.edu",
   "nsf_id": "000298986",
   "pi_start_date": "2014-07-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "465 Northwestern Avenue",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072035",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 49891.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We collected user input for an annotated modern comprehensive dataset for supercomputing systems to facilitate advances in resilience research. We then started our effort at creating such a dataset, which is publicly accessible. Such a repository helps the community in multiple ways:</p>\n<p>&bull;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; to characterize faults, in extreme-scale systems, based on root or most probable cause, likelihood of detection, frequency of occurrence, timescales for resultant system impact, and efficiency of error recovery.</p>\n<p>&bull;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; to determine new instrumentation, to support fault detection and recovery as well as a means of improving the quality of data collected by the system.</p>\n<p>&bull;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; to recommend at what levels of the system hierarchy (e.g., hardware infrastructure, operating system, runtime systems, and/or application software) one should place cost-effective error detection and/or recovery mechanisms.</p>\n<p>Through our requirements gathering exercise &ndash; through online surveys and the Bird of Feather session at Supercomputing 2015 &ndash; we attempted to collect answers to various questions including:</p>\n<p>1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; What examples can you bring that demonstrate use of failure data analysis to guide design of future systems?</p>\n<p>2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; What insights would you expect to get from analyzing field failure data?</p>\n<p>3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; What kinds of data analysis tools would you find beneficial for analyzing failure and system usage data?</p>\n<p>We also created some tools to automate failure data preprocessing and analysis and some data analysis scripts to bring out important metrics and insights from them. As an example the UIUC team in the project developed LogDiver, an open source tool developed at UIUC to facilitate analysis and measurement of system- and application-level resiliency in extreme-scale environments. The LogDiver approach is to create a unique dataset encapsulating events that are central in conducting resiliency and performability measurements. The tool allows precise identification of the reasons behind application termination, relates system errors and failures (e.g., network fabric errors, GPU errors, and file-system failures) to application failures, and provides a unified representation of the workload/error/failure logs, permitting workload-failure analysis and computation of a range of quantitative performance and dependability metrics.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/10/2016<br>\n\t\t\t\t\tModified by: Saurabh&nbsp;Bagchi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWe collected user input for an annotated modern comprehensive dataset for supercomputing systems to facilitate advances in resilience research. We then started our effort at creating such a dataset, which is publicly accessible. Such a repository helps the community in multiple ways:\n\n&bull;             to characterize faults, in extreme-scale systems, based on root or most probable cause, likelihood of detection, frequency of occurrence, timescales for resultant system impact, and efficiency of error recovery.\n\n&bull;             to determine new instrumentation, to support fault detection and recovery as well as a means of improving the quality of data collected by the system.\n\n&bull;             to recommend at what levels of the system hierarchy (e.g., hardware infrastructure, operating system, runtime systems, and/or application software) one should place cost-effective error detection and/or recovery mechanisms.\n\nThrough our requirements gathering exercise &ndash; through online surveys and the Bird of Feather session at Supercomputing 2015 &ndash; we attempted to collect answers to various questions including:\n\n1.            What examples can you bring that demonstrate use of failure data analysis to guide design of future systems?\n\n2.            What insights would you expect to get from analyzing field failure data?\n\n3.            What kinds of data analysis tools would you find beneficial for analyzing failure and system usage data?\n\nWe also created some tools to automate failure data preprocessing and analysis and some data analysis scripts to bring out important metrics and insights from them. As an example the UIUC team in the project developed LogDiver, an open source tool developed at UIUC to facilitate analysis and measurement of system- and application-level resiliency in extreme-scale environments. The LogDiver approach is to create a unique dataset encapsulating events that are central in conducting resiliency and performability measurements. The tool allows precise identification of the reasons behind application termination, relates system errors and failures (e.g., network fabric errors, GPU errors, and file-system failures) to application failures, and provides a unified representation of the workload/error/failure logs, permitting workload-failure analysis and computation of a range of quantitative performance and dependability metrics.\n\n\t\t\t\t\tLast Modified: 10/10/2016\n\n\t\t\t\t\tSubmitted by: Saurabh Bagchi"
 }
}