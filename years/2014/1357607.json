{
 "awd_id": "1357607",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Computational Methods for Inference in Nonstandard Testing Problems",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927269",
 "po_email": "ceavey@nsf.gov",
 "po_sign_block_name": "Cheryl Eavey",
 "awd_eff_date": "2014-07-01",
 "awd_exp_date": "2017-11-30",
 "tot_intn_awd_amt": 183797.0,
 "awd_amount": 183797.0,
 "awd_min_amd_letter_date": "2014-06-14",
 "awd_max_amd_letter_date": "2014-06-14",
 "awd_abstract_narration": "This research will develop novel inference procedures for nonstandard hypothesis testing problems that have garnered significant interest among econometricians and statisticians.  The first type of nonstandard problems on which it will focus is broadly applicable in fields ranging from industrial organization to finance.  Examples include comparisons of competing forecasting models and inference in moment inequality models that seek to reduce heavy assumptions imposed by the researcher.  The second type on which it will focus is applicable in nearly all applied fields of the social sciences.  For instance, some form of model selection typically is used before a researcher reports the relationships between economic variables estimated from a linear regression model.  The pervasiveness of both types of these problems presents substantial challenges to inference in practice.  However, their nonstandard nature often is ignored by applied researchers, in part due to the computational complexity required of valid inference.  By introducing computationally simplifying techniques founded in new theoretical results, the methods to be developed in this project should further broaden the scope of interest in these nonstandard problems among both econometric theorists and applied researchers, because they will avail sophisticated test construction methods to end-users.\r\n\r\nThis project focuses on two leading classes of nonstandard hypothesis testing problems in econometrics characterized by parameter-discontinuous limit distributions.  Though much progress has been made with regard to introducing procedures that uniformly control asymptotic size in these contexts, the computational burden of such procedures can be a major obstacle to their implementation.  This research seeks to develop methods to overcome this practical limitation.  The first class of these testing problems involves a null hypothesis characterized by a finite number of inequalities. In order to maintain correct asymptotic size and maximize a power criterion, existing approaches to test construction in this context require repeated maximization over an uncountably infinite number of simulated null rejection probabilities. This research will establish theoretical results that substantially reduce the computational burden of test construction by reducing the required search space of null rejection probabilities to a finite set of points. The second class of testing problems involves inference after model selection in the linear regression model. Asymptotically valid tests are to be constructed quite differently under conservative and consistent model selection and the computation of tests under consistent selection can be substantially simpler. The project seeks to exploit the relative computational ease of testing after consistent model selection and establish computationally feasible, powerful, and size-correct testing procedures for inference after model selection.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Adam",
   "pi_last_name": "McCloskey",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Adam McCloskey",
   "pi_email_addr": "adam.mccloskey@colorado.edu",
   "nsf_id": "000651528",
   "pi_start_date": "2014-06-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "Office of Sponsored Projects",
  "perf_city_name": "Providence",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029129093",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132000",
   "pgm_ele_name": "Economics"
  },
  {
   "pgm_ele_code": "133300",
   "pgm_ele_name": "Methodology, Measuremt & Stats"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 183797.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project developed methods for testing economic and other forms of statistical hypotheses in contexts for which the size of the test is difficult to control.&nbsp; The size of a hypothesis test is the maximal probability of falsely rejecting a true (null) hypothesis.&nbsp; Controlling the size of a hypothesis at a pre-specified level, say 5%, is crucial for the test to be informative.&nbsp; Yet size is very difficult to control in many empirically-relevant settings when working with economic models and data.&nbsp; Examples of these settings include conducting hypothesis tests after using the data to select a model of interest, testing whether a set of inequalities on functions of model parameters hold and conducting a hypothesis test when the variability in the data is not substantial enough to strongly \"pin down\" (identify) model parameters.&nbsp; These three settings are pervasive in applied work in economics and other social and physical sciences.</p>\n<p>In order to control size in these three hypothesis testing environments, this project developed new methods for constructing data-dependent critical values, the values to which a test statistic is compared to determine whether to accept or reject a hypothesis.&nbsp; The critical value construction methods advanced in this project have two main appealing features: they are easier to compute than many of those previously available in the literature and they lead to tests with high discriminatory power for rejecting false (null) hypotheses.&nbsp; In conjunction with standard test statistics, an applied researcher may now use the critical values developed in this project to conduct tests of economics hypotheses with theoretical assurances that the tests will not overly reject true null hypotheses, at least when they have a large enough data set.&nbsp; In addition, the tests using these critical values will correctly reject false null hypotheses with high probability.&nbsp; Thus applied economists, as well as researchers in other fields, may use the methods developed in this project to perform informative statistical analyses in contexts for which the data or modeling approach can make this quite difficult.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/25/2018<br>\n\t\t\t\t\tModified by: Adam&nbsp;Mccloskey</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project developed methods for testing economic and other forms of statistical hypotheses in contexts for which the size of the test is difficult to control.  The size of a hypothesis test is the maximal probability of falsely rejecting a true (null) hypothesis.  Controlling the size of a hypothesis at a pre-specified level, say 5%, is crucial for the test to be informative.  Yet size is very difficult to control in many empirically-relevant settings when working with economic models and data.  Examples of these settings include conducting hypothesis tests after using the data to select a model of interest, testing whether a set of inequalities on functions of model parameters hold and conducting a hypothesis test when the variability in the data is not substantial enough to strongly \"pin down\" (identify) model parameters.  These three settings are pervasive in applied work in economics and other social and physical sciences.\n\nIn order to control size in these three hypothesis testing environments, this project developed new methods for constructing data-dependent critical values, the values to which a test statistic is compared to determine whether to accept or reject a hypothesis.  The critical value construction methods advanced in this project have two main appealing features: they are easier to compute than many of those previously available in the literature and they lead to tests with high discriminatory power for rejecting false (null) hypotheses.  In conjunction with standard test statistics, an applied researcher may now use the critical values developed in this project to conduct tests of economics hypotheses with theoretical assurances that the tests will not overly reject true null hypotheses, at least when they have a large enough data set.  In addition, the tests using these critical values will correctly reject false null hypotheses with high probability.  Thus applied economists, as well as researchers in other fields, may use the methods developed in this project to perform informative statistical analyses in contexts for which the data or modeling approach can make this quite difficult.\n\n\t\t\t\t\tLast Modified: 01/25/2018\n\n\t\t\t\t\tSubmitted by: Adam Mccloskey"
 }
}