{
 "awd_id": "1431063",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Making words disappear or appear: A neurocognitive and behavioral investigation of effects of speech rate on spoken word perception",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2014-08-15",
 "awd_exp_date": "2018-07-31",
 "tot_intn_awd_amt": 246997.0,
 "awd_amount": 246997.0,
 "awd_min_amd_letter_date": "2014-08-14",
 "awd_max_amd_letter_date": "2015-02-26",
 "awd_abstract_narration": "Understanding how humans comprehend speech is an unsolved and challenging problem, in part because factors such as different speakers, dialects, and speaking rates introduce a great deal of temporal and spectral variability into the speech signal. The focus of this research is on the influence of temporal context on perception of segments, syllables, and words. Results of the research may offer insights into treatment of disorders that involve disruption of speech rate (e.g., dysarthria, stuttering, Parkinson's disease, and aphasia), inform approaches to improve speech technology applications (e.g., enhanced automatic speech recognition, more natural sounding computer-generated speech), and lead to new discoveries related to brain mechanisms involved in understanding spoken language. The investigators will also involve students in the research, including those from a primarily undergraduate institution collaborating on the project.\r\n\r\nThe investigators will test different accounts of temporal phenomena in the perception of speech. They propose two interacting cognitive mechanisms controlling phenomena at lexical and phonetic levels, each driven by a different neural timing mechanism. The hypothesis is that effects of lexical rate primarily stem from top-down, speech-specific temporal expectancies, while phonetic rate effects originate in bottom-up, transient rhythmic expectations that are not specific to speech. This hypothesis will be assessed using psychoacoustic studies, non-invasive measures of brain activity, and theoretical modeling in order to identify the processing characteristics revealed by neural representations of temporal properties of speech.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Laura",
   "pi_last_name": "Dilley",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Laura C Dilley",
   "pi_email_addr": "ldilley@msu.edu",
   "nsf_id": "000399856",
   "pi_start_date": "2014-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Devin",
   "pi_last_name": "McAuley",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Devin McAuley",
   "pi_email_addr": "dmcauley@msu.edu",
   "nsf_id": "000196788",
   "pi_start_date": "2014-08-14",
   "pi_end_date": "2015-02-26"
  }
 ],
 "inst": {
  "inst_name": "Michigan State University",
  "inst_street_address": "426 AUDITORIUM RD RM 2",
  "inst_street_address_2": "",
  "inst_city_name": "EAST LANSING",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "5173555040",
  "inst_zip_code": "488242600",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MI07",
  "org_lgl_bus_name": "MICHIGAN STATE UNIVERSITY",
  "org_prnt_uei_num": "VJKZC4D1JN36",
  "org_uei_num": "R28EKN92ZTZ9"
 },
 "perf_inst": {
  "perf_inst_name": "Michigan State University",
  "perf_str_addr": "",
  "perf_city_name": "East Lansing",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "488243413",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "MI",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "7298",
   "pgm_ref_txt": "COLLABORATIVE RESEARCH"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 246997.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project addressed how human communication via spoken language succeeds in spite of tremendous ambiguity in the sound patterns of words. Pronunciations of words by talkers producing connected spoken messages are often not carefully articulated, nor is the acoustic information in many spoken words uniquely identifiable as a single intended word or meaning. It is a challenging scientific problem to understand how listeners can perceive the identity of an intended spoken word in spite of minimal acoustic evidence of the word?s presence, and in spite of blending of sounds across words and syllables. This project capitalized on a recent discovery that the timing and rate of information flow of context speech influences which words human listeners identify in nearby speech material, and whether some words are heard at all. That is, earlier research showed that the same acoustic chunk of audio information could be perceived as having different numbers of words, depending on the rate of speech information around that chunk. We tested the circumstances under which timing information from context speech was useful in speech understanding. We further investigated the neural and cognitive processes underlying how human listeners understand words in connected phrases and sentences by testing hypotheses about how context timing and rate information are used to perceive and understand words.</p>\n<p>Some of our most significant findings are as follows. First, experimental manipulation of timing and rate cues in the speech signal can have a large and significant effect on the words that listeners hear, where these cues can be more influential than knowledge of the grammar of a sentence, essentially overriding information about grammar (Morrill, Baese-Berk, Heffner, &amp; Dilley, 2015). Further, the neural and cognitive mechanisms at work in using context timing and rate cues in sentences to understand words are not the same ones which are involved in general perceptual-cognitive slowing under normal aging processes for older listeners (Heffner, Newman, Dilley, &amp; Idsardi, 2015). In addition, variation in timing and rate cues in context speech can only be used by listeners to perceive words in nearby speech when those timing and rate cues occur as part of intelligible speech material (Pitt, Szostak &amp; Dilley, 2016); critically, this suggested that language prediction processes in the brain must generate a set of possible sentence continuations, in order for subsequent timing information in speech to be meaningfully interpreted as words. We found evidence using recorded speech from a database of speech from talkers in Ohio, as well as from Neil Armstrong's communication from the moon in 1969, which supported a hypothesis that listeners collect statistical information on timing and rate information of words over their lifetimes and use these statistics as a source of information for understanding words (Baese-Berk et al., 2016). In addition, we found that context timing and rate information influences how a great many diverse words and syllables are understood, suggesting that such effects have a powerful influence on speech understanding (Baese-Berk et al., 2019).</p>\n<p>This project produced more than 36 published articles, conference proceedings, theses, book chapters, and/or conference presentations. Overall, the project produced dozens of studies and experiments which were shared with the scientific community. Further, the project provided scientific training, job and educational opportunities, and career experiences for 21 undergraduate students and five advanced trainees (two master?s students, two Ph.D. students, and one post-doctoral scholar). The research has had a significant impact on science within the discipline, as shown by over 30 citations to our work in peer-reviewed journal articles and book chapters authored by outside researchers within the field during the project period. This research also had a significant impact on the field of neuroscience, as revealed by over 10 citations in neuroscientific journals within the project period, and on the fields of speech-language pathology and second language studies, consistent with multiple citations to our work during the project period by researchers from those fields as well. &nbsp;</p>\n<p>The project contributed to improved scientific understanding of how the human brain comprehends speech, in spite of sound pattern ambiguity. This research has high potential to lead to advances in computer speech recognition and synthesis technology. There is also applicability to developing enhanced assessment protocols, treatments, and therapies for communicative disorders in which speech rate and timing are disrupted, including for Parkinson?s disease, apraxia of speech, stuttering, and dyslexia.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/29/2019<br>\n\t\t\t\t\tModified by: Laura&nbsp;Dilley</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project addressed how human communication via spoken language succeeds in spite of tremendous ambiguity in the sound patterns of words. Pronunciations of words by talkers producing connected spoken messages are often not carefully articulated, nor is the acoustic information in many spoken words uniquely identifiable as a single intended word or meaning. It is a challenging scientific problem to understand how listeners can perceive the identity of an intended spoken word in spite of minimal acoustic evidence of the word?s presence, and in spite of blending of sounds across words and syllables. This project capitalized on a recent discovery that the timing and rate of information flow of context speech influences which words human listeners identify in nearby speech material, and whether some words are heard at all. That is, earlier research showed that the same acoustic chunk of audio information could be perceived as having different numbers of words, depending on the rate of speech information around that chunk. We tested the circumstances under which timing information from context speech was useful in speech understanding. We further investigated the neural and cognitive processes underlying how human listeners understand words in connected phrases and sentences by testing hypotheses about how context timing and rate information are used to perceive and understand words.\n\nSome of our most significant findings are as follows. First, experimental manipulation of timing and rate cues in the speech signal can have a large and significant effect on the words that listeners hear, where these cues can be more influential than knowledge of the grammar of a sentence, essentially overriding information about grammar (Morrill, Baese-Berk, Heffner, &amp; Dilley, 2015). Further, the neural and cognitive mechanisms at work in using context timing and rate cues in sentences to understand words are not the same ones which are involved in general perceptual-cognitive slowing under normal aging processes for older listeners (Heffner, Newman, Dilley, &amp; Idsardi, 2015). In addition, variation in timing and rate cues in context speech can only be used by listeners to perceive words in nearby speech when those timing and rate cues occur as part of intelligible speech material (Pitt, Szostak &amp; Dilley, 2016); critically, this suggested that language prediction processes in the brain must generate a set of possible sentence continuations, in order for subsequent timing information in speech to be meaningfully interpreted as words. We found evidence using recorded speech from a database of speech from talkers in Ohio, as well as from Neil Armstrong's communication from the moon in 1969, which supported a hypothesis that listeners collect statistical information on timing and rate information of words over their lifetimes and use these statistics as a source of information for understanding words (Baese-Berk et al., 2016). In addition, we found that context timing and rate information influences how a great many diverse words and syllables are understood, suggesting that such effects have a powerful influence on speech understanding (Baese-Berk et al., 2019).\n\nThis project produced more than 36 published articles, conference proceedings, theses, book chapters, and/or conference presentations. Overall, the project produced dozens of studies and experiments which were shared with the scientific community. Further, the project provided scientific training, job and educational opportunities, and career experiences for 21 undergraduate students and five advanced trainees (two master?s students, two Ph.D. students, and one post-doctoral scholar). The research has had a significant impact on science within the discipline, as shown by over 30 citations to our work in peer-reviewed journal articles and book chapters authored by outside researchers within the field during the project period. This research also had a significant impact on the field of neuroscience, as revealed by over 10 citations in neuroscientific journals within the project period, and on the fields of speech-language pathology and second language studies, consistent with multiple citations to our work during the project period by researchers from those fields as well.  \n\nThe project contributed to improved scientific understanding of how the human brain comprehends speech, in spite of sound pattern ambiguity. This research has high potential to lead to advances in computer speech recognition and synthesis technology. There is also applicability to developing enhanced assessment protocols, treatments, and therapies for communicative disorders in which speech rate and timing are disrupted, including for Parkinson?s disease, apraxia of speech, stuttering, and dyslexia.\n\n \n\n\t\t\t\t\tLast Modified: 03/29/2019\n\n\t\t\t\t\tSubmitted by: Laura Dilley"
 }
}