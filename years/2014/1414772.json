{
 "awd_id": "1414772",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "EAPSI: Investigating methods for improving the alignment of augmented reality in see-through head-mounted displays",
 "cfda_num": "47.079",
 "org_code": "01090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Anne Emig",
 "awd_eff_date": "2014-06-01",
 "awd_exp_date": "2015-05-31",
 "tot_intn_awd_amt": 5070.0,
 "awd_amount": 5070.0,
 "awd_min_amd_letter_date": "2014-05-29",
 "awd_max_amd_letter_date": "2014-05-29",
 "awd_abstract_narration": "Augmented Reality (AR) refers to the use of computer-generated content to enhance a person's view of the surrounding environment. Transparent head-mounted displays increase the effectiveness of these applications by providing the user a hands-free experience, while maintaining an unobstructed view of the world in front of them. An essential aspect of AR using a head-mounted display is proper alignment between the computer-generated elements and visible features in the world. This project will investigate the current methods used to correct misalignment in AR for see-through displays, and work toward reducing error and improving the accuracy of these techniques. This study will be conducted at the Nara Institute of Science and Technology (NAIST) in Japan in collaboration with Dr. Christian Sandor, a leading researcher in AR and Virtual Reality development. Results will aid AR developers seeking to use transparent display technologies for services ranging from the indication of bombs located around a soldier on the battlefield to overlaying MRI data onto a patient during an operation in order to help surgeons locate tumors.\r\n \r\nAugmented Reality systems typically employ one of two approaches to combine computer graphics with a real world view. Video See-Through AR, commonly employed on mobile devices, superimposes computer generated images over a camera feed. The second approach uses semi-transparent displays to overlay computer images directly onto a user's view of the world. Systems utilizing this see-through technology cannot directly access the view from the user's eye and therefore must use other methods to calibrate the placement of onscreen computed geometry. Common calibration procedures for these displays rely on user feedback to estimate the corrections needed. These methods, however, are prone to inaccuracies from system and environmental sources, such as tracking, human, and screen alignment error. This work will seek to measure the error contribution from individual sources and work toward the formulation of a general model for predicting and correcting misalignment errors automatically. This NSF EAPSI award is funded in collaboration with the Japan Society for the Promotion of Science.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "O/D",
 "org_dir_long_name": "Office Of The Director",
 "div_abbr": "OISE",
 "org_div_long_name": "Office of International Science and Engineering",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kenneth",
   "pi_last_name": "Moser",
   "pi_mid_init": "R",
   "pi_sufx_name": "II",
   "pi_full_name": "Kenneth R Moser",
   "pi_email_addr": "",
   "nsf_id": "000658475",
   "pi_start_date": "2014-05-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Moser                   Kenneth        R",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "Meridian",
  "inst_state_code": "MS",
  "inst_state_name": "Mississippi",
  "inst_phone_num": "",
  "inst_zip_code": "393019160",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "MS03",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "University of South Australia",
  "perf_str_addr": null,
  "perf_city_name": "Adelaide SA",
  "perf_st_code": "",
  "perf_st_name": "RI REQUIRED",
  "perf_zip_code": "",
  "perf_ctry_code": "AS",
  "perf_cong_dist": "",
  "perf_st_cong_dist": "",
  "perf_ctry_name": "Australia",
  "perf_ctry_flag": "0"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "731600",
   "pgm_ele_name": "EAPSI"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5921",
   "pgm_ref_txt": "JAPAN"
  },
  {
   "pgm_ref_code": "5978",
   "pgm_ref_txt": "EAST ASIA AND PACIFIC PROGRAM"
  },
  {
   "pgm_ref_code": "7316",
   "pgm_ref_txt": "EAPSI"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 5070.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Augmented Reality (AR) refers to the use of computer-generated content to enhance a person's view of the surrounding environment. Transparent head-mounted displays, such as the recently developed Google GLASS and Epson Moverio, increase the effectiveness of these applications by providing the user a hands-free experience, while maintaining an unobstructed view of the world in front of them. An essential aspect of AR using a head-mounted display is proper alignment between the computer-generated elements and visible features in the world. The goals of this project were to investigate current methods for correcting misalignment in AR for see-through displays, and work toward reducing error and improving the accuracy of these calibration techniques.</p>\n<p>Working in conjunction with Dr. Christian Sandor and Professor Hirokazu Kato, leading researchers in the field of Augmented Reality development at the Nara Institute of Science and Technology (NAIST) in Japan, a user study was conducted to compare the effectiveness of standard calibration methods against newly introduced procedures which incorporate eye tracking cameras to remove user error and improve accuracy. A set of metrics to gauge alignment accuracy were developed, and a series of independent tasks implemented in order to compare the performance of corrective actions in a real world setting.</p>\n<p>The results of the project have shown that the newly developed eye tracking procedures are able to perform equally well, and in some instances superior to, the more commonly used corrective actions. Participants perceived on-screen objects to be at the correct location more often, and with greater accuracy, when error correction using eye tracking was employed over traditional methods.</p>\n<p>Our findings will be of direct use to software and hardware developers of augmented reality systems seeking to enhance the accuracy of their products. With the growing availability of small high resolution cameras, the ability of AR display manufacturers to equip their devices with the needed hardware to facilitate eye tracking capabilities is ever increasing. The incorporation of these new error correction techniques will greatly enhance the speed at which augmented reality is able to be adopted&nbsp;for use in military, industrial, educational, and consumer settings.&nbsp;The complete findings from this work will be presented at the 2015 IEEE Virtual Reality conference, and are published in the April 2015 issue of the IEEE Transactions on Visualization and Computer Graphics journal.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/22/2015<br>\n\t\t\t\t\tModified by: Kenneth&nbsp;R&nbsp;Moser</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2015/1414772/1414772_10305748_1424647249112_camera_setup--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2015/1414772/1414772_10305748_1424647249112_camera_setup--rgov-800width.jpg\" title=\"Eye Tracking Camera-Display Assembly\"><img src=\"/por/images/Reports/POR/2015/1414772/1414772_10305748_1424647249112_camera_setup--rgov-66x44.jpg\" alt=\"Eye Tracking Camera-Display Assembly\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">(a) Front view of HMD with cameras labeled. Tracking camera rigidly attached to the top of the display. Eye imaging performed via camera mounted beneath the left eye piece. (b) View of eye imaging camera. (c) Right eye piece covered by black opaque cloth</div>\n<div class=\"image...",
  "por_txt_cntn": "\nAugmented Reality (AR) refers to the use of computer-generated content to enhance a person's view of the surrounding environment. Transparent head-mounted displays, such as the recently developed Google GLASS and Epson Moverio, increase the effectiveness of these applications by providing the user a hands-free experience, while maintaining an unobstructed view of the world in front of them. An essential aspect of AR using a head-mounted display is proper alignment between the computer-generated elements and visible features in the world. The goals of this project were to investigate current methods for correcting misalignment in AR for see-through displays, and work toward reducing error and improving the accuracy of these calibration techniques.\n\nWorking in conjunction with Dr. Christian Sandor and Professor Hirokazu Kato, leading researchers in the field of Augmented Reality development at the Nara Institute of Science and Technology (NAIST) in Japan, a user study was conducted to compare the effectiveness of standard calibration methods against newly introduced procedures which incorporate eye tracking cameras to remove user error and improve accuracy. A set of metrics to gauge alignment accuracy were developed, and a series of independent tasks implemented in order to compare the performance of corrective actions in a real world setting.\n\nThe results of the project have shown that the newly developed eye tracking procedures are able to perform equally well, and in some instances superior to, the more commonly used corrective actions. Participants perceived on-screen objects to be at the correct location more often, and with greater accuracy, when error correction using eye tracking was employed over traditional methods.\n\nOur findings will be of direct use to software and hardware developers of augmented reality systems seeking to enhance the accuracy of their products. With the growing availability of small high resolution cameras, the ability of AR display manufacturers to equip their devices with the needed hardware to facilitate eye tracking capabilities is ever increasing. The incorporation of these new error correction techniques will greatly enhance the speed at which augmented reality is able to be adopted for use in military, industrial, educational, and consumer settings. The complete findings from this work will be presented at the 2015 IEEE Virtual Reality conference, and are published in the April 2015 issue of the IEEE Transactions on Visualization and Computer Graphics journal.\n\n\t\t\t\t\tLast Modified: 02/22/2015\n\n\t\t\t\t\tSubmitted by: Kenneth R Moser"
 }
}