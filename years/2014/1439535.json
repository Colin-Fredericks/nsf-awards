{
 "awd_id": "1439535",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps:  Application of Local Wireless Tracking Technology to 3D User Interfaces",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rathindra DasGupta",
 "awd_eff_date": "2014-06-01",
 "awd_exp_date": "2015-11-30",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2014-05-05",
 "awd_max_amd_letter_date": "2014-05-05",
 "awd_abstract_narration": "This I-Corps team has developed a wireless indoor tracking technology, and its unique properties will enable a plethora of new applications in many different areas including intelligent home automation, location based security, sports training, fine-grained indoor navigation, robotics, digital arts, education, entertainment systems, and body motion tracking for biomedical applications and film making.\r\n\r\nThe existing local wireless tracking techniques are computing and resource intensive, provide a limited tracking speed, and require a line-of-sight (LOS) channel for achieving a reasonable spatial resolution. The wireless tracking technique proposed is unique because of its non-line-of-sight (NLOS) capability, low power requirement, and excellent spatial and temporal resolutions make it an excellent candidate for an intuitive 3D man-machine interface in different applications including home automation, security, robotics and entertainment systems. Mobile smart devices penetrated the market largely because of their intuitive and easy-to-use 2D touch-screen interface; however, the industry is badly looking for an intuitive 3D user interface solution for maximizing user experience and market expansion. The proposed technology will provide a solution for a truly natural, intuitive, and immersive 3D user interface.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Byunghoo",
   "pi_last_name": "Jung",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Byunghoo Jung",
   "pi_email_addr": "jungb@purdue.edu",
   "nsf_id": "000381997",
   "pi_start_date": "2014-05-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "465 Northwestern Ave",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072035",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Through the course of the project, the team has identified 3-dimensional input solution for mobile virtual reality as the target area of commercialization. Through the meetings with several industry leaders in virtual reality area, the team has identified the commercial and technical needs of the intended product.&nbsp;</p>\n<p>The entrepreneurial lead (EL) and primary investigator (PI) have exclusively licensed the intellectual property from Purdue University and founded a startup to commercialize the personal area tracking technology for virtual reality applications.</p>\n<p>The EL also participated in the annual Burton Morgan D Business Plan competition and won the third place with a $7,500 cash prize. The PI also applied for the Elevate Purdue Foundry Fund that supports Purdue technology based startups and has awarded a $20,000 commercialization fund. The team also got a $50,000 matching grant from Elevate Ventures. During the course of the project, the team has successfully developed a series of prototypes including hardware, firmware, software development kit (SDK), and example mobile virtual reality apps. The latest prototype provides a high positional tracking accuracy (&lt;1mm), a high tracking speed (&gt;100 positional readings per second), a low power consumption (&lt;50mW for receiver), a low latency (&lt;20msec), and a wide tracking range (3 ~ 5 meters). The prototype is completely untethered and powered by a USB battery, which is crucial for mobile applications. The prototype supports both Bluetooth and USB links. The developed software development kit (SDK) supports a wide range of platforms including Windows, Android, and Unity. An example mobile VR app incorporating the user&rsquo;s head and hand positions as inputs has been developed. The team presented the prototype and the example mobile VR app to several leading mobile virtual reality (VR) headset and 3D motion capture system manufacturers.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/11/2016<br>\n\t\t\t\t\tModified by: Byunghoo&nbsp;Jung</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2016/1439535/1439535_10301627_1457728837423_Screenshot2016-03-1115.36.19--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1439535/1439535_10301627_1457728837423_Screenshot2016-03-1115.36.19--rgov-800width.jpg\" title=\"3D Input System\"><img src=\"/por/images/Reports/POR/2016/1439535/1439535_10301627_1457728837423_Screenshot2016-03-1115.36.19--rgov-66x44.jpg\" alt=\"3D Input System\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">3D input system for mobile virtual reality.The system consists of a transmitter, a tracking module, and a paired computing unit (mobile phone).</div>\n<div class=\"imageCredit\">Mohit Singh and Byunghoo Jung</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Byunghoo&nbsp;Jung</div>\n<div class=\"imageTitle\">3D Input System</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThrough the course of the project, the team has identified 3-dimensional input solution for mobile virtual reality as the target area of commercialization. Through the meetings with several industry leaders in virtual reality area, the team has identified the commercial and technical needs of the intended product. \n\nThe entrepreneurial lead (EL) and primary investigator (PI) have exclusively licensed the intellectual property from Purdue University and founded a startup to commercialize the personal area tracking technology for virtual reality applications.\n\nThe EL also participated in the annual Burton Morgan D Business Plan competition and won the third place with a $7,500 cash prize. The PI also applied for the Elevate Purdue Foundry Fund that supports Purdue technology based startups and has awarded a $20,000 commercialization fund. The team also got a $50,000 matching grant from Elevate Ventures. During the course of the project, the team has successfully developed a series of prototypes including hardware, firmware, software development kit (SDK), and example mobile virtual reality apps. The latest prototype provides a high positional tracking accuracy (&lt;1mm), a high tracking speed (&gt;100 positional readings per second), a low power consumption (&lt;50mW for receiver), a low latency (&lt;20msec), and a wide tracking range (3 ~ 5 meters). The prototype is completely untethered and powered by a USB battery, which is crucial for mobile applications. The prototype supports both Bluetooth and USB links. The developed software development kit (SDK) supports a wide range of platforms including Windows, Android, and Unity. An example mobile VR app incorporating the user\u00c6s head and hand positions as inputs has been developed. The team presented the prototype and the example mobile VR app to several leading mobile virtual reality (VR) headset and 3D motion capture system manufacturers. \n\n\t\t\t\t\tLast Modified: 03/11/2016\n\n\t\t\t\t\tSubmitted by: Byunghoo Jung"
 }
}