{
 "awd_id": "1417323",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER:CCF: Transient Architectures for Energy Efficient Computation",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tao Li",
 "awd_eff_date": "2014-03-01",
 "awd_exp_date": "2017-02-28",
 "tot_intn_awd_amt": 299998.0,
 "awd_amount": 299998.0,
 "awd_min_amd_letter_date": "2014-02-18",
 "awd_max_amd_letter_date": "2014-02-18",
 "awd_abstract_narration": "To sustain performance scaling with the continued progression of Moore?s Law in deep nanometer nodes, we must seek new and innovative advances in energy efficient computing architectures.  Such advances are central to the effective operation of all modern processors in platforms ranging from mobile devices to data centers and high-performance computing (HPC) machines that drive national initiatives in key areas such as science, finance, and defense. The major determinants of power consumption are voltage and frequency. The continuing need to scale energy efficiency in the presence of time-varying application workloads increases the number of fine grained power states as well as the frequency of power state transitions in future processors.  However, rapid and fine-grained power state transitions increases the time spent in power state transitions as a percentage of the execution time. Thus unchallenged, designers will soon be faced with an impossible choice between energy efficiency (increasing frequency of transitions) and performance loss (time spent in making transitions). However, sustaining performance scaling will need concurrent advances in both.\r\n\r\nTransient architectures developed in this proposal aim to address this challenge. These are processor microarchitectures that can continue to perform useful computation during power state transitions. The challenges lay in the fact that during power state transitions the supply voltage received by a logic circuit is not stable for a finite duration. Conventionally, a synchronous digital circuit cannot operate correctly when the supply voltage is varying, making execution unreliable during this unstable period. The transient architectures aim to perform useful computation even under unstable supply during these power state transitions by employing a unique combination of innovative power regulation circuits, adaptive computational circuits, and processor microarchitecture technologies. The key concepts enable computational circuits to ramp up to full speed operation in concert with supply voltage transition thereby performing useful computation during power state transitions. The operational principles underlying transient architectures will be demonstrated via silicon test chips and micro-architectural simulations. \r\n\r\nThis departure from conventional thinking can transform the state of the practice in the design of power and energy efficient processor microarchitectures leading to new ultra-low power designs with superior energy-performance tradeoffs than the state of the practice.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sudhakar",
   "pi_last_name": "Yalamanchili",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sudhakar Yalamanchili",
   "pi_email_addr": "sudha@ece.gatech.edu",
   "nsf_id": "000161439",
   "pi_start_date": "2014-02-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Saibal",
   "pi_last_name": "Mukhopadhyay",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Saibal Mukhopadhyay",
   "pi_email_addr": "saibal@ece.gatech.edu",
   "nsf_id": "000083185",
   "pi_start_date": "2014-02-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Hyesoon",
   "pi_last_name": "Kim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hyesoon Kim",
   "pi_email_addr": "hyesoon@cc.gatech.edu",
   "nsf_id": "000084212",
   "pi_start_date": "2014-02-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institite of Technology",
  "perf_str_addr": "266 Ferst Drive",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 299998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>With the end of Dennard scaling, energy efficiency and power efficiency have become dominant design goals for all matter of computing devices ranging from simple devices known as Internet of Things (IoT), through mobile devices such as smart phones, to the full-scale data centers operated by companies such as Google and Amazon. Continued growth in performance of computing in the future is irrevocably tied to improvements in power and energy efficiency.&nbsp; A dominant technique for operating processors with better power and energy efficiency is to change the operating voltage and frequency of the core processors &ndash; each setting being referred to as a power state. Power state transitions incur overheads. Consequently, the more often they are employed in an effort to improve power efficiency, the less efficient the technique becomes. This program explored a contrarian view of power management referred to as transient architectures where processors continued to compute as much as possible through power state transitions. As part of this process, the program discovered a rich design space of options leading to new co-design strategies for power efficient computing. &nbsp;</p>\n<p>&nbsp;Our initial goal was to understand the impact of the design power delivery circuits on the system level performance of high performance processors so as to develop new, optimized solutions for transient operation and the minimization of the overhead of power state transitions. &nbsp;At the circuit level, we observed that transient operation is feasible and can improve performance, but necessitated novel circuit techniques due its impact on other aspects of circuit operation such as timing. As a consequence of these observations, at the architecture level we discovered that in order to reduce the negative impact of power state transition we need to coordinate the operation of several components - such as power delivery circuits, processors, and memories. &nbsp;A fundamental understanding of the delivery, consumption (compute), and extraction (cooling) of power will be a driving force in the design of computing systems at all levels from IoT devices to high end servers. Historically, these disciplines were pursued in a loosely collaborative fashion leading to many inefficiencies. Our initial analysis led to the insight of using the co-design of power management and power delivery systems as a productive design strategy. In this program, we have pursued and developed such co-design techniques that span computer architecture, circuit design, and system design. Such coordination was supported by new design techniques that led to power efficiency improvements. We were able to assess such system-architecture-circuit solutions by enhancing and applying full system modeling and simulation techniques where real applications (not models) can execute on clock cycle-level simulation models. These simulation tools have been made available in open source form to encourage similar, as well as new companion research efforts. Circuit level projections were validated with test chips available from companion research programs.</p>\n<p class=\"p1\">This program through its training of several graduate students contributes to workforce development in this area of national need. Further, the program is founded on inter-disciplinary research - understanding and applying interactions between physics (e.g., power dissipation), architecture, and circuits. The ability to navigate complex design problems across multiple disciplines is very important. In the past, practice in these disciplines was relatively independent and only loosely coordinated. Moving into the future this can no longer be the case. Thus, one of the broader impacts of this program is to fill an important national need in training graduate students with the interdisciplinary&nbsp; intellectual and engineering skills that industry and academia needs for designing the next generation of computing systems.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/24/2017<br>\n\t\t\t\t\tModified by: Sudhakar&nbsp;Yalamanchili</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWith the end of Dennard scaling, energy efficiency and power efficiency have become dominant design goals for all matter of computing devices ranging from simple devices known as Internet of Things (IoT), through mobile devices such as smart phones, to the full-scale data centers operated by companies such as Google and Amazon. Continued growth in performance of computing in the future is irrevocably tied to improvements in power and energy efficiency.  A dominant technique for operating processors with better power and energy efficiency is to change the operating voltage and frequency of the core processors &ndash; each setting being referred to as a power state. Power state transitions incur overheads. Consequently, the more often they are employed in an effort to improve power efficiency, the less efficient the technique becomes. This program explored a contrarian view of power management referred to as transient architectures where processors continued to compute as much as possible through power state transitions. As part of this process, the program discovered a rich design space of options leading to new co-design strategies for power efficient computing.  \n\n Our initial goal was to understand the impact of the design power delivery circuits on the system level performance of high performance processors so as to develop new, optimized solutions for transient operation and the minimization of the overhead of power state transitions.  At the circuit level, we observed that transient operation is feasible and can improve performance, but necessitated novel circuit techniques due its impact on other aspects of circuit operation such as timing. As a consequence of these observations, at the architecture level we discovered that in order to reduce the negative impact of power state transition we need to coordinate the operation of several components - such as power delivery circuits, processors, and memories.  A fundamental understanding of the delivery, consumption (compute), and extraction (cooling) of power will be a driving force in the design of computing systems at all levels from IoT devices to high end servers. Historically, these disciplines were pursued in a loosely collaborative fashion leading to many inefficiencies. Our initial analysis led to the insight of using the co-design of power management and power delivery systems as a productive design strategy. In this program, we have pursued and developed such co-design techniques that span computer architecture, circuit design, and system design. Such coordination was supported by new design techniques that led to power efficiency improvements. We were able to assess such system-architecture-circuit solutions by enhancing and applying full system modeling and simulation techniques where real applications (not models) can execute on clock cycle-level simulation models. These simulation tools have been made available in open source form to encourage similar, as well as new companion research efforts. Circuit level projections were validated with test chips available from companion research programs.\nThis program through its training of several graduate students contributes to workforce development in this area of national need. Further, the program is founded on inter-disciplinary research - understanding and applying interactions between physics (e.g., power dissipation), architecture, and circuits. The ability to navigate complex design problems across multiple disciplines is very important. In the past, practice in these disciplines was relatively independent and only loosely coordinated. Moving into the future this can no longer be the case. Thus, one of the broader impacts of this program is to fill an important national need in training graduate students with the interdisciplinary  intellectual and engineering skills that industry and academia needs for designing the next generation of computing systems.\n\n \n\n\t\t\t\t\tLast Modified: 04/24/2017\n\n\t\t\t\t\tSubmitted by: Sudhakar Yalamanchili"
 }
}