{
 "awd_id": "1417674",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Extreme-scale algorithms for geometric graphical data models in imaging, social and network science",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Christopher Stark",
 "awd_eff_date": "2014-08-01",
 "awd_exp_date": "2018-12-31",
 "tot_intn_awd_amt": 299999.0,
 "awd_amount": 299999.0,
 "awd_min_amd_letter_date": "2014-07-24",
 "awd_max_amd_letter_date": "2016-08-24",
 "awd_abstract_narration": "Big data is important right now; and extreme scale hardware, programming models and storage solutions are being developed. However the connection between transformational algorithms and the big data sets needs to be addressed.  Researchers talk often about the upcoming \"big data problem,\" yet skim over the relevant algorithms that can truly attack the problems in a concrete fashion, often because the traditional means of data analysis are not prevalent in the high-performance computing (HPC) world, and in concert, the HPC expertise is not prevalent in the data world. This project will solidify this connection, making the \"big data\" problem real by attacking the issues through identifiable concrete algorithmic research and by implementing the methods on the latest hardware platforms. Recently the principal investigator has developed scalable desktop algorithms that bridge that gap, leveraging fast spectral solvers to compute solutions of sparse classification problems for big data.  This project will build on these scalable algorithms to implement them on several large-scale platforms and will address important application areas, for which desktop computing is insufficient.  Examples of application areas for this project include high dimensional hyperspectral video data for chemical and biological agents, a problem of importance to homeland security, and statistical analysis of spatio-temporal multimodal crime data, and large-scale social network analysis.\r\n\r\nThis project focuses on a new class of data-clustering algorithms that are designed to solve variants of the minimum cut problem on graphs for big data applications such as hyperspectral video data analysis, statistical analysis of spatio-temporal multimodal crime data, and large-scale social network analysis.  Semi-supervised and unsupervised machine learning problems are included in the class of problems considered.  The graph mincut problem is equivalent to total variation minimization on a graph and is a popular model for machine learning applications, except for its computational complexity.  Building on ideas such as diffuse interfaces and dynamic thresholding, originally developed for physical sciences models and subsequently transferred to low dimensional image processing applications, this project will develop methods to solve the true graph cut problem by leveraging recent advances in scalable spectral graph algorithms.  New codes for these methods will be developed for large parallel architectures.  The research will advance both theoretical algorithmic issues and application areas.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Andrea",
   "pi_last_name": "Bertozzi",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Andrea L Bertozzi",
   "pi_email_addr": "bertozzi@math.ucla.edu",
   "nsf_id": "000107633",
   "pi_start_date": "2014-07-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles",
  "perf_str_addr": "6363 Math Sciences Building",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900951555",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8084",
   "pgm_ref_txt": "CDS&E"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 149999.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 100000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Intellectual Merit: This project developed new algorithms and related theory for classification of high dimensional data.&nbsp; The research program built on methodology from computational partial differential equations, specifically those equations used for geometric curve evolution for tasks such as image segmentation in low dimensions.&nbsp; Analogues of geometric motion were developed for high-dimensional data represented on a graph, such as a similarity graph.&nbsp; The graph Laplacian takes the place of the classical Laplace operator in Euclidean space.&nbsp; One computational challenge is the fact that similarity graphs involve pairwise comparisons between pieces of data - leading to N<sup>2</sup> operations for N pieces of data.&nbsp; A low rank approximation of the graph Laplacian can yield useful results for this problem - one outcome of the project was the optimization of a well-known approximation - called the Nystrom extension - for an exascale-ready platform at a national laboratory supercomputer.&nbsp; Another outcome was the modification of these algorithms to work with sparse graphs using efficient k-nearest neighbor algorithms.&nbsp; The project developed new algorithms for a number of optimization problems involving graph cut metrics, and applied them to real-world datasets.&nbsp; The optimization problems include the Cheeger cut problem, modularity optimization, stochastic block models, and semi-supervised learning.&nbsp; For semi-supervised learning, we developed a Bayesian model for uncertainty quantification of the classifier.&nbsp; Theory developed for this project included convergence estimates, a proof of global optimality, and proof of monotonicity for energy metrics.&nbsp;Some of the code developed has been published online and is available to the public.</p>\n<p>Broader Impacts: The project studied a diverse set of applications of importance to society, including hyperspectral imagery for remote sensing, data fusion, cardiac ultrasound data, email traffic and social media, and classification of activity from video taken from body worn cameras.&nbsp; &nbsp; The project also trained a number of PhD students who are now in careers in academia and industry.&nbsp; The project involved collaborations with senior scientists at Lawrence Berkeley National Laboratory, Caltech, Univ. Edinburgh, Univ. of Bergen (Norway), Univ. of Grenoble, Univ. Southern California, &nbsp;the Naval Air Weapons Center at China Lake, and ENS Cachan in Paris.&nbsp; These collaborations provided broadening experiences for student training.&nbsp;&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/31/2019<br>\n\t\t\t\t\tModified by: Andrea&nbsp;L&nbsp;Bertozzi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIntellectual Merit: This project developed new algorithms and related theory for classification of high dimensional data.  The research program built on methodology from computational partial differential equations, specifically those equations used for geometric curve evolution for tasks such as image segmentation in low dimensions.  Analogues of geometric motion were developed for high-dimensional data represented on a graph, such as a similarity graph.  The graph Laplacian takes the place of the classical Laplace operator in Euclidean space.  One computational challenge is the fact that similarity graphs involve pairwise comparisons between pieces of data - leading to N2 operations for N pieces of data.  A low rank approximation of the graph Laplacian can yield useful results for this problem - one outcome of the project was the optimization of a well-known approximation - called the Nystrom extension - for an exascale-ready platform at a national laboratory supercomputer.  Another outcome was the modification of these algorithms to work with sparse graphs using efficient k-nearest neighbor algorithms.  The project developed new algorithms for a number of optimization problems involving graph cut metrics, and applied them to real-world datasets.  The optimization problems include the Cheeger cut problem, modularity optimization, stochastic block models, and semi-supervised learning.  For semi-supervised learning, we developed a Bayesian model for uncertainty quantification of the classifier.  Theory developed for this project included convergence estimates, a proof of global optimality, and proof of monotonicity for energy metrics. Some of the code developed has been published online and is available to the public.\n\nBroader Impacts: The project studied a diverse set of applications of importance to society, including hyperspectral imagery for remote sensing, data fusion, cardiac ultrasound data, email traffic and social media, and classification of activity from video taken from body worn cameras.    The project also trained a number of PhD students who are now in careers in academia and industry.  The project involved collaborations with senior scientists at Lawrence Berkeley National Laboratory, Caltech, Univ. Edinburgh, Univ. of Bergen (Norway), Univ. of Grenoble, Univ. Southern California,  the Naval Air Weapons Center at China Lake, and ENS Cachan in Paris.  These collaborations provided broadening experiences for student training.  \n\n \n\n\t\t\t\t\tLast Modified: 03/31/2019\n\n\t\t\t\t\tSubmitted by: Andrea L Bertozzi"
 }
}