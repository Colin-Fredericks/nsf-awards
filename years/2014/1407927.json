{
 "awd_id": "1407927",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Medium: Collaborative Research: Collective Opinion Fraud Detection: Identifying and Integrating Cues from Language, Behavior, and Networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 299994.0,
 "awd_amount": 299994.0,
 "awd_min_amd_letter_date": "2014-08-01",
 "awd_max_amd_letter_date": "2014-08-01",
 "awd_abstract_narration": "Precision modeling tools for realistic and complex human social interaction are not available today. First-person videos provide a unique opportunity to capture social interaction at unprecedented precision. In contrast, current third person surveillance video only records the few distance views of the interaction passively at a much reduced spatial resolution. This exploratory research project proposes to harness multiple first-person cameras as one collective instrument to capture, model, and predict social behaviors. The proposed research transforms the way we construct realistic social interaction models, while also advancing first-person video recognition. If successful, the envisioned computational model can act as a coach who learns what constitutes successful interactions and failures, thus being able to find solutions to mediate and prevent potential conflicts. \r\n\r\nThe proposed research will model dynamic social interactions in 3D space from multiple personal perspectives. Recognition and prediction of complex social group interactions are challenging because people in the group can carry out unexpected actions intentionally or by mistake. In addition, due to variances in individuals' preferences and abilities, the same activities could be carried out in different ways. First-person videos can be highly jittery, resulting in fast and unpredictable object motions in the field of view. Building on PI's recent work establishing computational foundations for modeling social (people-people) and personal (people-scene) interactions using first-person cameras, this research will explore the novel concept the duality between social attention and roles: social attention provides a cue for recognizing social roles, and social roles facilitate the predictions of dynamic social formation change and its associated social attention. The formal foundation of the 3D model is based on constructing a visual memory that stores first-person social experiences in three forms: (a) geometric social formation, (b) visual image of first-person view, and (c) first-person seen by nearby third person views. As a proof-of-concept, the 3D space model capturing social interactions will be tested on collaborative social tasks such as assembling (Ikea) furniture, or building a block house with a group of friends. This research will construct a labeled dataset capturing the interactions, and perform analysis on both accuracy in recognizing social roles and precision in predicting spatial movements of the members in that social interaction. The results of this project, including papers and dataset, will be disseminated to the public through our project website (http://www.andrew.cmu.edu/user/lakoglu/PROJECTS/OPINION_FRAUD/). The software created under this project will be made available to the public through GitHub, a web-based Git repository hosting service",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bing",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bing Liu",
   "pi_email_addr": "liub@uic.edu",
   "nsf_id": "000315760",
   "pi_start_date": "2014-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Chicago",
  "inst_street_address": "809 S MARSHFIELD AVE M/C 551",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3129962862",
  "inst_zip_code": "606124305",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "IL07",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "W8XEAJDKMXH3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Chicago",
  "perf_str_addr": "851 South Morgan Street",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606077053",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "IL07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 299994.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Fake opinions are wide-spread on social media. To ensure that the social media information can be trusted, we must detect such fake opinions and other forms of disinformation. In terms of applications, since social media posts are increasingly used by businesses, organizations, social sciences, and health sciences, detecting disinformation or spamming becomes very urgent. In this project, our goal is to propose a collective detection framework via synergistic integration of multiple information sources: linguistics, user behavior, and network effects to detect fake reviews and fake reviewers (also called opinion spammers). We have used this framework in our proposed algorithms. My group at the University of Illinois at Chicago pioneered the research area of detecting fake reviews and reviewers by publishing the first paper on the topic in 2008. Over the years, we have contributed many useful algorithms. This project continued to contribute significantly to this effort.&nbsp;Below, we highlight three major outcomes or discoveries of this project.</p>\n<ol>\n<li>Bimodal posting rate: For the first time, we discovered that reviewers&rsquo; posting rates (number of reviews written in a period of time) follow an interesting distribution pattern, which has not been reported before. That is, their posting rates are bimodal. Furthermore, multiple spammers tend to collectively and actively post reviews to the same set of products within a short time frame, which we call co-bursting. We also found some other interesting patterns in individual reviewers&rsquo; temporal dynamics and their co-bursting behaviors with other reviewers. Inspired by these findings, we proposed a two-mode Labeled Hidden Markov Model to model spamming using only individual reviewers&rsquo; review posting times. We then extend it to the Coupled Hidden Markov Model to capture both reviewer posting behaviors and co-bursting signals to detect review spammers.</li>\n<li>Changed-hand account: As many review hosting sites are actively detecting fake reviews and reviewers (spammers), it has become difficult to post fake reviews. Spammers began to buy reputable accounts to post fake opinions to avoid detection, or to raise their own accounts by behaving like genuine reviewers for a period of time and then use these &ldquo;trustworthy&rdquo; accounts to launch spam campaigns. Such accounts are called raised accounts (like raising a child) which behave normally in a period of time to gain credibility but are then used later to write fake reviews or opinions. Before this research, this problem was not studied by the research community. This project conducted a comprehensive study of this new type of spammers (or spam accounts) and proposed an effective technique for their detection. We call such accounts changed-hand accounts. </li>\n<li>Hidden campaign promoter: Some spammers work together to secretly promote some target products or services by influencing people&rsquo;s behaviors/opinions/decisions in a latent manner so that the readers are not aware that the messages they are seeing are strategic campaign posts aimed at persuading them to buy some target products/services. Readers take such campaign posts (often opinionated) as just other organic posts from the general public. It is thus important to discover such campaigns, their promoter accounts, and how the campaigns are organized and executed. In this project, we studied this problem on the Twitter platform. Given a set of tweets streamed from Twitter based on a set of keywords representing a particular topic, our technique can identify user accounts that are involved in promotion. We formulated the problem as a relational classification problem and solved it using typed Markov Random Fields (T-MRF), which is a generalization of the classic Markov Random Fields.</li>\n</ol>\n<p>We believe that these discoveries and associated detection techniques are all very useful in practice and will help ensure the social media to be a trusted source of information.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/01/2018<br>\n\t\t\t\t\tModified by: Bing&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nFake opinions are wide-spread on social media. To ensure that the social media information can be trusted, we must detect such fake opinions and other forms of disinformation. In terms of applications, since social media posts are increasingly used by businesses, organizations, social sciences, and health sciences, detecting disinformation or spamming becomes very urgent. In this project, our goal is to propose a collective detection framework via synergistic integration of multiple information sources: linguistics, user behavior, and network effects to detect fake reviews and fake reviewers (also called opinion spammers). We have used this framework in our proposed algorithms. My group at the University of Illinois at Chicago pioneered the research area of detecting fake reviews and reviewers by publishing the first paper on the topic in 2008. Over the years, we have contributed many useful algorithms. This project continued to contribute significantly to this effort. Below, we highlight three major outcomes or discoveries of this project.\n\nBimodal posting rate: For the first time, we discovered that reviewers? posting rates (number of reviews written in a period of time) follow an interesting distribution pattern, which has not been reported before. That is, their posting rates are bimodal. Furthermore, multiple spammers tend to collectively and actively post reviews to the same set of products within a short time frame, which we call co-bursting. We also found some other interesting patterns in individual reviewers? temporal dynamics and their co-bursting behaviors with other reviewers. Inspired by these findings, we proposed a two-mode Labeled Hidden Markov Model to model spamming using only individual reviewers? review posting times. We then extend it to the Coupled Hidden Markov Model to capture both reviewer posting behaviors and co-bursting signals to detect review spammers.\nChanged-hand account: As many review hosting sites are actively detecting fake reviews and reviewers (spammers), it has become difficult to post fake reviews. Spammers began to buy reputable accounts to post fake opinions to avoid detection, or to raise their own accounts by behaving like genuine reviewers for a period of time and then use these \"trustworthy\" accounts to launch spam campaigns. Such accounts are called raised accounts (like raising a child) which behave normally in a period of time to gain credibility but are then used later to write fake reviews or opinions. Before this research, this problem was not studied by the research community. This project conducted a comprehensive study of this new type of spammers (or spam accounts) and proposed an effective technique for their detection. We call such accounts changed-hand accounts. \nHidden campaign promoter: Some spammers work together to secretly promote some target products or services by influencing people?s behaviors/opinions/decisions in a latent manner so that the readers are not aware that the messages they are seeing are strategic campaign posts aimed at persuading them to buy some target products/services. Readers take such campaign posts (often opinionated) as just other organic posts from the general public. It is thus important to discover such campaigns, their promoter accounts, and how the campaigns are organized and executed. In this project, we studied this problem on the Twitter platform. Given a set of tweets streamed from Twitter based on a set of keywords representing a particular topic, our technique can identify user accounts that are involved in promotion. We formulated the problem as a relational classification problem and solved it using typed Markov Random Fields (T-MRF), which is a generalization of the classic Markov Random Fields.\n\n\nWe believe that these discoveries and associated detection techniques are all very useful in practice and will help ensure the social media to be a trusted source of information.\n\n \n\n\t\t\t\t\tLast Modified: 12/01/2018\n\n\t\t\t\t\tSubmitted by: Bing Liu"
 }
}