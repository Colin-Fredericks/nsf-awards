{
 "awd_id": "1419754",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Inference After Predictor Selection",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2017-07-31",
 "tot_intn_awd_amt": 139999.0,
 "awd_amount": 139999.0,
 "awd_min_amd_letter_date": "2014-01-27",
 "awd_max_amd_letter_date": "2014-01-27",
 "awd_abstract_narration": "There are three goals for this project.  The first goal is to develop data-driven assessments of the complexity of data generators and data-driven assessments of the complexity of the predictive techniques to be used for a data generator and then relate them to each other.   It is expected that a complexity matching principle between data generators and their predictors will be established.  The motivation is to speed the search for predictors that have low generalization error.  The second goal is to develop techniques to derive modeling information from good predictors.  The motivation is to be able to make statements about the data generator beyond numerical prediction.  The third goal is to use these techniques on a complex data set for which a predictive approach is essential because the extreme complexity of the data means it defies conventional modeling.  The motivation is to verify that the complexity based techniques give reliable inferences for an important question such as `which of those who have suffered a traumatic event are likely to get post- traumatic stress disorder'.\r\n\r\nThe motivation for the overall project is to find ways to get information out of data that is so complex conventional techniques are ineffective.   Such data is becoming increasingly common as the number of data types increases and as data bases become more comprehensive.  The problem with conventional techniques seems to be that they assume a model that means something physically before there is a strong enough basis even to propose one.   The approach here is significant because it is overtly predictive:  Instead of proposing models, one can propose predictors that are easier to test and then study the predictors to make statements about whatever it was that generated the data.  This reverses the usual approach in which one models first and then predicts.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "BERTRAND",
   "pi_last_name": "CLARKE",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "BERTRAND S CLARKE",
   "pi_email_addr": "bclarke3@unl.edu",
   "nsf_id": "000577074",
   "pi_start_date": "2014-01-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Nebraska-Lincoln",
  "inst_street_address": "2200 VINE ST # 830861",
  "inst_street_address_2": "",
  "inst_city_name": "LINCOLN",
  "inst_state_code": "NE",
  "inst_state_name": "Nebraska",
  "inst_phone_num": "4024723171",
  "inst_zip_code": "685032427",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NE01",
  "org_lgl_bus_name": "BOARD OF REGENTS OF THE UNIVERSITY OF NEBRASKA",
  "org_prnt_uei_num": "",
  "org_uei_num": "HTQ6K6NJFHA6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Nebraska-Lincoln",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NE",
  "perf_st_name": "Nebraska",
  "perf_zip_code": "685880430",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NE01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 139999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;</p>\n<p>The goal of this project was to develop and evaluate predictors from a</p>\n<p>complexity perspective and study their interpretability.&nbsp; This is important</p>\n<p>because usually the best predictors are complex and do not readily admit an</p>\n<p>interpretation, i.e., there is a tradeoff berween interpretability and</p>\n<p>performance.</p>\n<p>&nbsp;</p>\n<p>The single biggest outcome was to the development of a technique to</p>\n<p>select a model because models are often used can to give predictions.&nbsp;</p>\n<p>The technique is based on a form of complexity called the Vapnik-</p>\n<p>Chervonenkis dimension that arises from statistical theory. &nbsp; We operationalize</p>\n<p>its use and show it is effective in numerous problems.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Another major outcome was showing that many of the best and most used</p>\n<p>predictors can be regarded as instances of a `Bayes model averge' or `Bayes</p>\n<p>classifier'.&nbsp; Both of these are optimal in various senses.&nbsp; This sort of result</p>\n<p>is useful because it identifies and narrrows the class of predictors that has</p>\n<p>to be searched to find a good one.&nbsp;&nbsp; This is important because many</p>\n<p>of the best predictors are ensemble predictors that pool the</p>\n<p>predictions from a variety of predictors, hopefully in an optimal way.&nbsp; Thus, in</p>\n<p>many cases, the process of finding a predictor may be simplified.</p>\n<p>&nbsp;</p>\n<p>We also established properties of specific predictor classes.&nbsp; For the Shtarkov</p>\n<p>predictor, we showed it often outperforms a variety of other predictors in</p>\n<p>empirical error, sometimes by a wide margin.&nbsp; Interestingly, this complexity</p>\n<p>based predictor often performs worse when `too much' information, including</p>\n<p>extraneous information, is used to form it.&nbsp; We also established conceptual</p>\n<p>interpretations for it.&nbsp;&nbsp; The value of these contributions rests on future</p>\n<p>research.</p>\n<p>&nbsp;</p>\n<p>Stacking is another ensemble predictor.&nbsp; It is distinctive because of its</p>\n<p>generality -- it can be used to pool the predictions from any class of</p>\n<p>predictors and the weights it assigns to the predictions are more</p>\n<p>data-driven than for other predictors.&nbsp; We have shown a variety of</p>\n<p>results on this class of predictors providing conditions under which they</p>\n<p>are optimal, and showing that the weights, although flexible, are also</p>\n<p>optimal in a specific sense.</p>\n<p>&nbsp;</p>\n<p>For `kernel' based predictors, we first showed they behave well in the sense</p>\n<p>of giving good prediction when sample size increases.&nbsp; Then, we were</p>\n<p>able to show that they could be expressed in terms of functions derived</p>\n<p>from the kernels and therefore could be well-approximated in many cases</p>\n<p>by routine methods.&nbsp; We hope that practitioners who are reluctant to use</p>\n<p>techniques they cannot interpret (such as kernel based predictors) will</p>\n<p>recognize that our results provide an approximate interpretation.&nbsp; Thus,</p>\n<p>practitioners will be more willing to use this class of predictors that often</p>\n<p>gives extremely good performance.</p>\n<p>&nbsp;</p>\n<p>We have a variety of other results of a similar nature for other predictors.</p>\n<p>&nbsp;</p>\n<p>Taken together, our results show that not only is predictive performance</p>\n<p>a good criterion to invoke in statistical analyses, it is computationally feasible,</p>\n<p>often permits interpretation i.e., often permits at least a partial physical</p>\n<p>understanding of the problem being addressed, and can be conceptually</p>\n<p>understood in terms of familiar quantities.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/06/2017<br>\n\t\t\t\t\tModified by: Bertrand&nbsp;Clarke</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \n\nThe goal of this project was to develop and evaluate predictors from a\n\ncomplexity perspective and study their interpretability.  This is important\n\nbecause usually the best predictors are complex and do not readily admit an\n\ninterpretation, i.e., there is a tradeoff berween interpretability and\n\nperformance.\n\n \n\nThe single biggest outcome was to the development of a technique to\n\nselect a model because models are often used can to give predictions. \n\nThe technique is based on a form of complexity called the Vapnik-\n\nChervonenkis dimension that arises from statistical theory.   We operationalize\n\nits use and show it is effective in numerous problems. \n\n \n\nAnother major outcome was showing that many of the best and most used\n\npredictors can be regarded as instances of a `Bayes model averge' or `Bayes\n\nclassifier'.  Both of these are optimal in various senses.  This sort of result\n\nis useful because it identifies and narrrows the class of predictors that has\n\nto be searched to find a good one.   This is important because many\n\nof the best predictors are ensemble predictors that pool the\n\npredictions from a variety of predictors, hopefully in an optimal way.  Thus, in\n\nmany cases, the process of finding a predictor may be simplified.\n\n \n\nWe also established properties of specific predictor classes.  For the Shtarkov\n\npredictor, we showed it often outperforms a variety of other predictors in\n\nempirical error, sometimes by a wide margin.  Interestingly, this complexity\n\nbased predictor often performs worse when `too much' information, including\n\nextraneous information, is used to form it.  We also established conceptual\n\ninterpretations for it.   The value of these contributions rests on future\n\nresearch.\n\n \n\nStacking is another ensemble predictor.  It is distinctive because of its\n\ngenerality -- it can be used to pool the predictions from any class of\n\npredictors and the weights it assigns to the predictions are more\n\ndata-driven than for other predictors.  We have shown a variety of\n\nresults on this class of predictors providing conditions under which they\n\nare optimal, and showing that the weights, although flexible, are also\n\noptimal in a specific sense.\n\n \n\nFor `kernel' based predictors, we first showed they behave well in the sense\n\nof giving good prediction when sample size increases.  Then, we were\n\nable to show that they could be expressed in terms of functions derived\n\nfrom the kernels and therefore could be well-approximated in many cases\n\nby routine methods.  We hope that practitioners who are reluctant to use\n\ntechniques they cannot interpret (such as kernel based predictors) will\n\nrecognize that our results provide an approximate interpretation.  Thus,\n\npractitioners will be more willing to use this class of predictors that often\n\ngives extremely good performance.\n\n \n\nWe have a variety of other results of a similar nature for other predictors.\n\n \n\nTaken together, our results show that not only is predictive performance\n\na good criterion to invoke in statistical analyses, it is computationally feasible,\n\noften permits interpretation i.e., often permits at least a partial physical\n\nunderstanding of the problem being addressed, and can be conceptually\n\nunderstood in terms of familiar quantities.\n\n \n\n \n\n \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 08/06/2017\n\n\t\t\t\t\tSubmitted by: Bertrand Clarke"
 }
}