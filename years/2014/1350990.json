{
 "awd_id": "1350990",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Network modulation of cortical neuron computation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2021-05-31",
 "tot_intn_awd_amt": 513758.0,
 "awd_amount": 513758.0,
 "awd_min_amd_letter_date": "2014-08-25",
 "awd_max_amd_letter_date": "2017-09-19",
 "awd_abstract_narration": "The function of sensory neurons is typically defined by the relationship between sensory stimuli and their responses; however, in the cortex of awake animals, sensory responses account for only a fraction of neural activity. While activity not driven by the stimulus is often considered \"noise\" and neglected in experiments, such ongoing cortical activity has been linked to a number of processes related to cognition, and can be influenced by attention, tasks, and perception itself. It remains unclear how to relate such ongoing cortical activity to the processing of sensory stimuli, and more generally why it appears to play such a prominent role in sensory neuron function. \r\n\r\nThe goal of this project is to establish a new framework for understanding stimulus processing in the context of ongoing cortical activity, and thereby derive a much richer understanding of sensory neuron function. This work will leverage the wealth of information about activity within the cortical network that is now typically available from multi-electrode recordings, using experiments performed by collaborating laboratories in the awake visual cortex using tailored visual stimuli. The first aim is to develop new statistical approaches for identifying relevant modulatory signals detectable from these multi-electrode recordings, and perform detailed characterizations of stimulus processing in the context of these signals. The second aim is to study specific contexts where cortical activity is shaped by known network inputs, such as during saccadic eye movements, in order to directly link the modulation of stimulus processing to larger descriptions of sensory neuron function.\r\n\r\nThis work will provide potentially transformative insights into the relationship between sensory processing and cognitive function. The educational component of this proposal will integrate computational and quantitative approaches into general neuroscience coursework, and involve students at the graduate, undergraduate, and high school levels, in computational analyses of complex neurophysiological data.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Butts",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel A Butts",
   "pi_email_addr": "dab@umd.edu",
   "nsf_id": "000515420",
   "pi_start_date": "2014-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "1210 Biology-Psychology Building",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425815",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "MD",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "727500",
   "pgm_ele_name": "Cross-BIO Activities"
  },
  {
   "pgm_ele_code": "732700",
   "pgm_ele_name": "CRCNS-Computation Neuroscience"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "771300",
   "pgm_ele_name": "Activation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "8750",
   "pgm_ref_txt": "Bio & Comp Shared Princ (BCSP)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 294996.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 218762.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>How we process sensory information often depends on the context: we might not hear someone speaking to us when looking for our keys, and only notice our keys on the counter when specifically looking for them. It has become increasingly clear over the last decade that sensory neurons themselves process stimuli differently depending on the context. Unfortunately, understanding how context influences sensory processing requires leaving behind classical approaches that use simple stimuli presented to passive or anesthetized animals, and moving to situations where behavior and context shape the sensory experience. Interpreting the complex data resulting from such situations requires new computational tools, and this grant has supported advances in data-driven modeling of sensory processing, coupled with applications to visual neuroscience.</p>\n<p>To measure how sensory processing changes with context, my laboratory first built \"data-driven\" models (i.e., models that can be directly fit to neural data) that could accurately capture the complex computations that neurons perform on sensory stimuli. We focused on multiple stages of visual processing where neurons are known to be nonlinear. My work in this area culminated in an invited review in 2019: \"Data-driven approaches to understanding visual neuron activity\". In addition to more accurately describing the responses of neurons to sensory stimulation, the development of this data-driven modeling framework was essential for the goals of the grant, because it is necessary to make sense of neural activity where the experimental variables are observable but uncontrolled: for example when sensory stimulation itself depends on the behavior of the animal.</p>\n<p>The second branch of the work supported by this grant developed methods to measure the sources of sensory modulation. Modulation of recorded neurons is almost always governed by inputs from other [unobserved] neurons in the brain that carry information about relevant behavior and brain state. Although such modulation variables might be unobserved (or \"latent\"), they can in principle be inferred through their effects on the observed neurons, and we developed new latent variable methods that fit into the same framework of data-driven modeling that leverage the increasingly large-scale recordings being performed in sensory systems. We used these methods to infer variability of visual cortical activity using network inputs, as well as find variables representing task structure, brain state, and motor behavior that modulated sensory neurons in the somatosensory cortex. This body of work also culminated in an invited review in 2019: \"The quest for interpretable models of population activity\".</p>\n<p>Putting these two types of models together now provides a foundation for solving some of the most pressing questions in sensory neuroscience, and led to new collaborations to carry this work forward: its initial stages supported by this grant. First, while nearly all visual neuroscience experiments are performed when the gaze is fixed, we have begun characterizing visual processing in the context of natural \"free-viewing\", where the eye movements themselves control the stimulus. In this case, other motor and behavioral factors strongly modulate visual processing and results in a stable perception that is unaware of eye movements. Second, we are working on behavioral paradigms where we can determine the effects of attention and task-specific goals through direct measurements of sensory neuron activity, and link the resulting modulation to how well an animal performs a task. Both future projects leverage our methods, as well as recent advances within the field of neurophysiology (large-scale neural recordings) and computation (machine learning and deep neural networks).&nbsp;</p>\n<p>Mirroring these advances in the field, the interface of neurophysiology and computation has become increasingly central to the broad field of systems neuroscience. This award also supported the development of quantitative neuroscience courses taught with the goal of making undergraduate and graduate neuroscientists at the University of Maryland (UMD) fluent in relevant quantitative and computational methods: both to apply to their own research, and to understand cutting-edge neuroscience research more broadly. First, my graduate Computational Neuroscience course has been established as a core course for the UMD graduate program. I recently developed a follow-up course called \"Neural Coding\" targeting all systems neuroscientists (across departments and programs), which focuses on the interactions of sensory processing and behavior. At the undergraduate level, I have developed a new quantitative undergraduate neuroscience course, as well as now teach a large core neuroscience course using \"model-based\" methodology. Finally, involvement in the work funded by this work has contributed to the careers of several undergraduate students (now in graduate neuroscience programs, and graduate students (now in postdoctoral fellowships and beyond). Thus, in addition to supporting my own career, this funding has had a long-term impact in growing human capital at the interface of experimental and computational neuroscience, which will go well beyond the funding period and my lab.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/16/2021<br>\n\t\t\t\t\tModified by: Daniel&nbsp;A&nbsp;Butts</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nHow we process sensory information often depends on the context: we might not hear someone speaking to us when looking for our keys, and only notice our keys on the counter when specifically looking for them. It has become increasingly clear over the last decade that sensory neurons themselves process stimuli differently depending on the context. Unfortunately, understanding how context influences sensory processing requires leaving behind classical approaches that use simple stimuli presented to passive or anesthetized animals, and moving to situations where behavior and context shape the sensory experience. Interpreting the complex data resulting from such situations requires new computational tools, and this grant has supported advances in data-driven modeling of sensory processing, coupled with applications to visual neuroscience.\n\nTo measure how sensory processing changes with context, my laboratory first built \"data-driven\" models (i.e., models that can be directly fit to neural data) that could accurately capture the complex computations that neurons perform on sensory stimuli. We focused on multiple stages of visual processing where neurons are known to be nonlinear. My work in this area culminated in an invited review in 2019: \"Data-driven approaches to understanding visual neuron activity\". In addition to more accurately describing the responses of neurons to sensory stimulation, the development of this data-driven modeling framework was essential for the goals of the grant, because it is necessary to make sense of neural activity where the experimental variables are observable but uncontrolled: for example when sensory stimulation itself depends on the behavior of the animal.\n\nThe second branch of the work supported by this grant developed methods to measure the sources of sensory modulation. Modulation of recorded neurons is almost always governed by inputs from other [unobserved] neurons in the brain that carry information about relevant behavior and brain state. Although such modulation variables might be unobserved (or \"latent\"), they can in principle be inferred through their effects on the observed neurons, and we developed new latent variable methods that fit into the same framework of data-driven modeling that leverage the increasingly large-scale recordings being performed in sensory systems. We used these methods to infer variability of visual cortical activity using network inputs, as well as find variables representing task structure, brain state, and motor behavior that modulated sensory neurons in the somatosensory cortex. This body of work also culminated in an invited review in 2019: \"The quest for interpretable models of population activity\".\n\nPutting these two types of models together now provides a foundation for solving some of the most pressing questions in sensory neuroscience, and led to new collaborations to carry this work forward: its initial stages supported by this grant. First, while nearly all visual neuroscience experiments are performed when the gaze is fixed, we have begun characterizing visual processing in the context of natural \"free-viewing\", where the eye movements themselves control the stimulus. In this case, other motor and behavioral factors strongly modulate visual processing and results in a stable perception that is unaware of eye movements. Second, we are working on behavioral paradigms where we can determine the effects of attention and task-specific goals through direct measurements of sensory neuron activity, and link the resulting modulation to how well an animal performs a task. Both future projects leverage our methods, as well as recent advances within the field of neurophysiology (large-scale neural recordings) and computation (machine learning and deep neural networks). \n\nMirroring these advances in the field, the interface of neurophysiology and computation has become increasingly central to the broad field of systems neuroscience. This award also supported the development of quantitative neuroscience courses taught with the goal of making undergraduate and graduate neuroscientists at the University of Maryland (UMD) fluent in relevant quantitative and computational methods: both to apply to their own research, and to understand cutting-edge neuroscience research more broadly. First, my graduate Computational Neuroscience course has been established as a core course for the UMD graduate program. I recently developed a follow-up course called \"Neural Coding\" targeting all systems neuroscientists (across departments and programs), which focuses on the interactions of sensory processing and behavior. At the undergraduate level, I have developed a new quantitative undergraduate neuroscience course, as well as now teach a large core neuroscience course using \"model-based\" methodology. Finally, involvement in the work funded by this work has contributed to the careers of several undergraduate students (now in graduate neuroscience programs, and graduate students (now in postdoctoral fellowships and beyond). Thus, in addition to supporting my own career, this funding has had a long-term impact in growing human capital at the interface of experimental and computational neuroscience, which will go well beyond the funding period and my lab.\n\n\t\t\t\t\tLast Modified: 07/16/2021\n\n\t\t\t\t\tSubmitted by: Daniel A Butts"
 }
}