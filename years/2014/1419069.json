{
 "awd_id": "1419069",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Implicit sampling methods and their applications",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leland Jameson",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 287063.0,
 "awd_amount": 287063.0,
 "awd_min_amd_letter_date": "2014-08-26",
 "awd_max_amd_letter_date": "2016-08-24",
 "awd_abstract_narration": "Data assimilation incorporates the observations, which can be real-time data, into a  computational model of a real system.  The output of this process is the adjusted states of the system based on both computational model and the observations. These adjusted states are better than those that could be obtained using just the data or model alone. Data assimilation is required in many fields such as  statistical signal processing, oceanography, meteorology, hydrology, geosciences, econometrics, and finance. Due to the large-scale and nonlinear properties of the models in those  applications, commonly used methods rely on unrealistic assumptions. The PI and her collaborators develop an efficient data assimilation method without those unrealistic assumptions. As one example, successful application of this method to reservoir history matching will greatly benefit the reservoir management.  This project involves undergraduate and graduate students. The PI  has outreach for successful participation of underrepresented group in STEM-related disciplines.\r\n\r\nData-driven computations, such as data assimilation, need to identify the state of a system and/or unknown parameters in the system from an uncertain model supplemented by a stream of noisy and incomplete data. The Bayesian framework is a standard approach for such problems and it involves characterizing the posterior distribution of the state and/or parameters in terms of given prior distribution and data. Commonly used methods, like ensemble Kalman filter-type and variational methods, rely on assumptions of Gaussianity or near Gaussianity. By contrast, the implicit sampling methods obtain high qualify samples of the posterior density by using importance sampling with good proposal density and can be applied to more general non-Gaussian situations. These samples are independent and focus on the high probability regions. The first step in the implicit sampling methods usually requires solving an optimization problem, which is the most time-consuming part of the methods. The proposed research is to develop and analyze preconditioners using domain decomposition methods, a widely-used paradigm for parallel computation, combined with efficient nonlinear solvers to accelerate this procedure and make it suitable for high performance computation. The PI and her collaborators apply these newly developed implicit sampling methods to data assimilation and uncertainty quantification in subsurface flow applications including reservoir history matching.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xuemin",
   "pi_last_name": "Tu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xuemin Tu",
   "pi_email_addr": "xtu@math.ku.edu",
   "nsf_id": "000582101",
   "pi_start_date": "2014-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Kansas Center for Research Inc",
  "inst_street_address": "2385 IRVING HILL RD",
  "inst_street_address_2": "",
  "inst_city_name": "LAWRENCE",
  "inst_state_code": "KS",
  "inst_state_name": "Kansas",
  "inst_phone_num": "7858643441",
  "inst_zip_code": "660457563",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "KS01",
  "org_lgl_bus_name": "UNIVERSITY OF KANSAS CENTER FOR RESEARCH INC",
  "org_prnt_uei_num": "SSUJB3GSH8A5",
  "org_uei_num": "SSUJB3GSH8A5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Kansas Center for Research Inc",
  "perf_str_addr": "1460 Jayhawk Blvd, Snow Hall",
  "perf_city_name": "Lawrence",
  "perf_st_code": "KS",
  "perf_st_name": "Kansas",
  "perf_zip_code": "660457594",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "KS01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8396",
   "pgm_ref_txt": "Clean Energy Technology"
  },
  {
   "pgm_ref_code": "8609",
   "pgm_ref_txt": "Other Energy Research"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 92139.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 95632.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 99292.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><br />Data assimilation/Uncertain quantification techniques are widely used in the geosciences, weather forecasting, hydrology, digital communication, finance, and engineering, where the state or parameters of a system must be identified from an uncertain equation supplemented by a stream of data with noise. A number of Bayesian data assimilation techniques are currently in use, but most of them rely on assumptions of linearity or near-linearity as well as Gaussianity or near Gaussianity, which do not hold for most applications. The PI and her collaborators developed the implicit sampling methods which can be applied to general nonlinear non-Gaussian problems. In details, the implicit sampling methods have been applied to the parameter estimation and uncertainty quantification and the results&nbsp;show that the Gaussian approximation approach can over-estimate the uncertainty. With the development of the computational power, more detailed simulations are requested in the applications. To save computational work, model reductions are used intensively in data assimilation. The PI and her collaborators studied different model reduction methods used in data assimilation. The study shows that&nbsp;it&nbsp; is important to represent the model error for the reduced models and take it into account in the data assimilation algorithms.&nbsp; The&nbsp;data assimilation could be improved significantly if one can characterize the model error and improve the forward model.<br /><br /><br />Parallel and distributed computing systems are increasing wide spread and they are now often used in many fields. Designing numerical algorithms that are suitable for parallel and distributed computing systems, and&nbsp;providing theoretical support for them become crucial in the high performance computation. Domain decomposition algorithms reduce large problems into collections of smaller problems by decomposing computational domains into smaller subdomains. Computationally, these subdomain-based smaller problems are easier to solve than the original problem, and most or all of them can be solved independently. Domain decomposition algorithms have become a common paradigm for&nbsp;large-scale simulation on massively parallel, hierarchical memory computers.&nbsp;The PI and her collaborators developed a class of domain decomposition methods for saddle point problems arising from computational fluid dynamics. These algorithms allow more general discretization methods such as the non-conforming discretizations.&nbsp;&nbsp;The components of these algorithms are simpler and more computationally efficient than existing algorithms of this type.&nbsp; In order to further&nbsp; control the number of the Krylov iterations to be any given fixed number,&nbsp;&nbsp;in addition to the standard constraints, the coarse space includes adaptive primal constraints obtained from the solutions of local generalized eigenvalue problems.&nbsp; These additional constraints cost extra localflops and nearest neighbor communication during the setup of the preconditioners. However,&nbsp; they reduced&nbsp; the number of global synchronization steps and matrix vector multiplications in the Krylov&nbsp;iterations, which is crucial for the parallel efficiency of the algorithms.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/21/2018<br>\n\t\t\t\t\tModified by: Xuemin&nbsp;Tu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nData assimilation/Uncertain quantification techniques are widely used in the geosciences, weather forecasting, hydrology, digital communication, finance, and engineering, where the state or parameters of a system must be identified from an uncertain equation supplemented by a stream of data with noise. A number of Bayesian data assimilation techniques are currently in use, but most of them rely on assumptions of linearity or near-linearity as well as Gaussianity or near Gaussianity, which do not hold for most applications. The PI and her collaborators developed the implicit sampling methods which can be applied to general nonlinear non-Gaussian problems. In details, the implicit sampling methods have been applied to the parameter estimation and uncertainty quantification and the results show that the Gaussian approximation approach can over-estimate the uncertainty. With the development of the computational power, more detailed simulations are requested in the applications. To save computational work, model reductions are used intensively in data assimilation. The PI and her collaborators studied different model reduction methods used in data assimilation. The study shows that it  is important to represent the model error for the reduced models and take it into account in the data assimilation algorithms.  The data assimilation could be improved significantly if one can characterize the model error and improve the forward model.\n\n\nParallel and distributed computing systems are increasing wide spread and they are now often used in many fields. Designing numerical algorithms that are suitable for parallel and distributed computing systems, and providing theoretical support for them become crucial in the high performance computation. Domain decomposition algorithms reduce large problems into collections of smaller problems by decomposing computational domains into smaller subdomains. Computationally, these subdomain-based smaller problems are easier to solve than the original problem, and most or all of them can be solved independently. Domain decomposition algorithms have become a common paradigm for large-scale simulation on massively parallel, hierarchical memory computers. The PI and her collaborators developed a class of domain decomposition methods for saddle point problems arising from computational fluid dynamics. These algorithms allow more general discretization methods such as the non-conforming discretizations.  The components of these algorithms are simpler and more computationally efficient than existing algorithms of this type.  In order to further  control the number of the Krylov iterations to be any given fixed number,  in addition to the standard constraints, the coarse space includes adaptive primal constraints obtained from the solutions of local generalized eigenvalue problems.  These additional constraints cost extra localflops and nearest neighbor communication during the setup of the preconditioners. However,  they reduced  the number of global synchronization steps and matrix vector multiplications in the Krylov iterations, which is crucial for the parallel efficiency of the algorithms. \n\n\t\t\t\t\tLast Modified: 10/21/2018\n\n\t\t\t\t\tSubmitted by: Xuemin Tu"
 }
}