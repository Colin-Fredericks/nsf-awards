{
 "awd_id": "1354544",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Objective Measures and Implicit Bias in Evaluating Public Officials",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Mark Hurwitz",
 "awd_eff_date": "2014-03-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 171244.0,
 "awd_amount": 204847.0,
 "awd_min_amd_letter_date": "2014-02-24",
 "awd_max_amd_letter_date": "2016-08-03",
 "awd_abstract_narration": "The mechanism for differential evaluation of men and women judges has not been specified.  This project hypotheses that implicit bias could shape the evaluation of judges in judicial performance evaluations.  Implicit bias mobilizes people's images of who should be holding a position, allowing non-normative people in a position to be evaluated more harshly because they do not fit a stereotype.  People may unconsciously penalize judges who do not fit the normative image of a judge. They may frame their evaluations of certain characteristics like courteousness, knowledge, and efficiency based on stereotypes, for example. Unconscious bias would result in lower scores for women and minority judges in judicial performance evaluations, regardless the race and gender of their evaluators. Previous research has not evaluated discrepancies in performance evaluation scores controlling for objective measures of job performance.  This project assembles data from judicial performance evaluations across 10 states. It compares the scores of female and minority judges with those of their white male counterparts. It also looks at the relationship between the gender/race gap in scores and the gender and race of those who are evaluating the judges. The results will contribute to understanding whether implicit bias could be a factor in assessing public officials. \r\nThis project will contribute to improving measures of performance of judges, important in the accountability of public officials. The investigator will make the resulting data base on judicial performance evaluations available to judges, policy makers, researchers and state judicial performance commissions.  The investigator will also present the information to the public in an interactive website.  The investigator will also share a summary of best practices for performance evaluations with policymakers, allowing them to revise performance evaluations based in empirical data.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rebecca",
   "pi_last_name": "Gill",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Rebecca D Gill",
   "pi_email_addr": "rebecca.gill@unlv.edu",
   "nsf_id": "000649530",
   "pi_start_date": "2014-02-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Nevada Las Vegas",
  "inst_street_address": "4505 S MARYLAND PKWY",
  "inst_street_address_2": "",
  "inst_city_name": "LAS VEGAS",
  "inst_state_code": "NV",
  "inst_state_name": "Nevada",
  "inst_phone_num": "7028951357",
  "inst_zip_code": "891549900",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NV01",
  "org_lgl_bus_name": "BOARD OF REGENTS OF NEVADA SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "F995DBS4SRN3",
  "org_uei_num": "DLUTVJJ15U66"
 },
 "perf_inst": {
  "perf_inst_name": "University of Nevada Las Vegas",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NV",
  "perf_st_name": "Nevada",
  "perf_zip_code": "891541055",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NV01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "137200",
   "pgm_ele_name": "LSS-Law And Social Sciences"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 85206.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 86038.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 33603.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project built upon the theory of implicit social cognition by exploring whether and why men and women in public office are evaluated differently. Specifically, this project looked for patterns in the formal evaluations of sitting judges done by state government commissions and bar associations. These judicial performance evaluations (JPEs) and related data were collected and assembled in the <em>American Judicial Performance Evaluation Database</em>&nbsp;(AJPE Database).</p>\n<p>Using these data, this project uncovered important insights about how we assess the quality and performance of our public officials. This project reveals that the surveys used by JPE systems are very similar across jurisdictions, and they tend not to distinguish well between different dimensions of performance. However, many of the surveys result in significantly lower scores for women, people of color, and particularly women of color. These differences cannot be explained using other measures of judicial performance, but instead indicate that judges from traditionally underrepresented demographic groups suffer a small but significant penalty in these evaluations.</p>\n<p>Importantly, although these processes may disadvantage women and people of color, the results of this project show that voters do not appear to &ldquo;pile on&rdquo; additional penalties; instead, analyses of aggregate voting patterns shows that traditionally underrepresented judges are only disadvantaged at the ballot box inasmuch as voters rely upon biased JPE results. In those states where JPEs are either mostly unbiased or largely ignored, election returns do not reveal any systematic bias against these judges.</p>\n<p>This project and the data it has generated will provide scholars across several related disciplines with insights and tools to help them investigate important political, legal, and sociological questions. In addition, the results of this project provide important practical insights for the politicians and administrators who design, implement, and maintain systems to evaluated public officials. This project has also provided important training and professional development for a number of emerging scholars. The results have been published in a number of scholarly outlets and presented at academic conferences and meetings of practitioners.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/04/2017<br>\n\t\t\t\t\tModified by: Rebecca&nbsp;Gill</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project built upon the theory of implicit social cognition by exploring whether and why men and women in public office are evaluated differently. Specifically, this project looked for patterns in the formal evaluations of sitting judges done by state government commissions and bar associations. These judicial performance evaluations (JPEs) and related data were collected and assembled in the American Judicial Performance Evaluation Database (AJPE Database).\n\nUsing these data, this project uncovered important insights about how we assess the quality and performance of our public officials. This project reveals that the surveys used by JPE systems are very similar across jurisdictions, and they tend not to distinguish well between different dimensions of performance. However, many of the surveys result in significantly lower scores for women, people of color, and particularly women of color. These differences cannot be explained using other measures of judicial performance, but instead indicate that judges from traditionally underrepresented demographic groups suffer a small but significant penalty in these evaluations.\n\nImportantly, although these processes may disadvantage women and people of color, the results of this project show that voters do not appear to \"pile on\" additional penalties; instead, analyses of aggregate voting patterns shows that traditionally underrepresented judges are only disadvantaged at the ballot box inasmuch as voters rely upon biased JPE results. In those states where JPEs are either mostly unbiased or largely ignored, election returns do not reveal any systematic bias against these judges.\n\nThis project and the data it has generated will provide scholars across several related disciplines with insights and tools to help them investigate important political, legal, and sociological questions. In addition, the results of this project provide important practical insights for the politicians and administrators who design, implement, and maintain systems to evaluated public officials. This project has also provided important training and professional development for a number of emerging scholars. The results have been published in a number of scholarly outlets and presented at academic conferences and meetings of practitioners. \n\n \n\n\t\t\t\t\tLast Modified: 10/04/2017\n\n\t\t\t\t\tSubmitted by: Rebecca Gill"
 }
}