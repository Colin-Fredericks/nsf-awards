{
 "awd_id": "1351748",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER:  Action Binding During Long-term Sequential Skill Learning: Computational and Neural Mechanisms",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jonathan Fritz",
 "awd_eff_date": "2014-06-01",
 "awd_exp_date": "2020-09-30",
 "tot_intn_awd_amt": 507835.0,
 "awd_amount": 507835.0,
 "awd_min_amd_letter_date": "2014-01-24",
 "awd_max_amd_letter_date": "2017-07-21",
 "awd_abstract_narration": "How does someone learn a complex skill that unfolds over time, such as learning to play a piano sonata? This ability entails interacting processing levels, including conceptual knowledge (e.g., the notes of the melody on the sheet of music) and motor production (e.g., the actions of physically pressing the piano keys). This research program will combine computational models, neuroimaging, and brain stimulation methods to explore how these two levels of sequential skill knowledge are acquired by interacting brain systems. The work takes  advantage of the fact that motor learning leaves a signature in the timing movements, called \"chunking.\" \r\n\r\nThe impact of this project extends from clinical rehabilitation to basic models of brain function. A hallmark symptom of some neurodegenerative conditions, like Parkinson's disease, is a difficulty in learning new skills. Understanding how skill learning occurs in the healthy brain can provide critical insights into how it is affected in neurological conditions. Scientifically, this research program will also attempt to bridge two largely independent literatures in cognitive science (sequential skill learning) and neuroscience (basal ganglia plasticity), providing a biologically meaningful foundation for well established psychological phenomena. Finally, by producing new tools and novel data sets that will be made publicly available, the work will integrate with the broader open-science community that seeks to foster the scientific enterprise by improving access to tools and data.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "Verstynen",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy D Verstynen",
   "pi_email_addr": "timothyv@andrew.cmu.edu",
   "nsf_id": "000597667",
   "pi_start_date": "2014-01-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 Forbes Avenue",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152132683",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169900",
   "pgm_ele_name": "Cognitive Neuroscience"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1699",
   "pgm_ref_txt": "COGNEURO"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 40485.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 206222.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 157942.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 103186.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>During this no cost extension phase, this award supported critical work on two theoretical fronts of the project objectives. First, we expanded the cortico-basal ganglia-thalamic (CBGT) computational model that we previously published (Dunovan et al. 2019) to include dopaminergic plasticity to resolve the credit assignment problem (Rubin et al. 2020). We also more clearly elucidated the computational dynamics of this sort of dopaminergic plasticity (Vich et al. 2020). This allowed for the model to learn simple sequences of reinforced actions in a biologically realistic manner. The core development of this model was driven by a graduate student in the Program in Neural Computation at Carnegie Mellon University who was supported during this no-cost extension period, as well as a part time research assistant.</p>\n<p>&nbsp;</p>\n<p>The second significant outcome from this period was the development and finalization of an artificial intelligence (AI) agent, premised off of the hierarchical organization of prefrontal CBGT pathways, that uses imaginative play to learn heuristics for complex skill learning (in this case, playing a game theory task known as Wythoff?s game)(Peterson et al. 2020). This novel AI is able to achieve what even the most cutting-edge deep reinforcement learning models cannot: an optimal, generalizable strategy for effective sequences of actions. Indeed, when pitted against the best deep learning methods available, our biologically inspired AI performed better and with far greater computational efficiency, than the current state of the art.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/27/2020<br>\n\t\t\t\t\tModified by: Timothy&nbsp;D&nbsp;Verstynen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDuring this no cost extension phase, this award supported critical work on two theoretical fronts of the project objectives. First, we expanded the cortico-basal ganglia-thalamic (CBGT) computational model that we previously published (Dunovan et al. 2019) to include dopaminergic plasticity to resolve the credit assignment problem (Rubin et al. 2020). We also more clearly elucidated the computational dynamics of this sort of dopaminergic plasticity (Vich et al. 2020). This allowed for the model to learn simple sequences of reinforced actions in a biologically realistic manner. The core development of this model was driven by a graduate student in the Program in Neural Computation at Carnegie Mellon University who was supported during this no-cost extension period, as well as a part time research assistant.\n\n \n\nThe second significant outcome from this period was the development and finalization of an artificial intelligence (AI) agent, premised off of the hierarchical organization of prefrontal CBGT pathways, that uses imaginative play to learn heuristics for complex skill learning (in this case, playing a game theory task known as Wythoff?s game)(Peterson et al. 2020). This novel AI is able to achieve what even the most cutting-edge deep reinforcement learning models cannot: an optimal, generalizable strategy for effective sequences of actions. Indeed, when pitted against the best deep learning methods available, our biologically inspired AI performed better and with far greater computational efficiency, than the current state of the art.\n\n \n\n\t\t\t\t\tLast Modified: 10/27/2020\n\n\t\t\t\t\tSubmitted by: Timothy D Verstynen"
 }
}