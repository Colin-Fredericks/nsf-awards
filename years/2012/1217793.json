{
 "awd_id": "1217793",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Fundamental High-Dimensional Algorithms based on Convex Geometry and Spectral Methods",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 420000.0,
 "awd_amount": 420000.0,
 "awd_min_amd_letter_date": "2012-07-19",
 "awd_max_amd_letter_date": "2012-07-19",
 "awd_abstract_narration": "This project seeks to discover new algorithms and develop algorithmic tools to address fundamental open problems in the theory of algorithms under the following focus topics: (1) Rounding. The power of affine transformations in the design of algorithms and in their analysis, including for solving LP's in strongly polynomial time and approximately sandwiching convex bodies. (2) Learning. Algorithms for learning polyhedra, learning subspace juntas and identifying planted cliques in random graphs. (3) Isoperimetric inequalities. Extensions of Cheeger's method to higher eigenvalues and multi-partitions, and the KLS hyperplane conjecture. (4) Lattices and convex geometry. Optimization and sampling problems over lattices, including: (a) the complexity of integer programming (determining whether a convex body intersects a given lattice), (b) the complexity of cutting plane methods, and (c) conditions under which lattice points in a convex body be sampled efficiently.\r\n\r\nThe problems explored are of a basic nature, and originate from many areas, including optimization (both discrete and continuous), sampling, machine learning and data mining. With the increasing availability of high-dimensional data in important application areas, efficient tools to handle such data are a necessity. This award addresses some of the most basic questions arising from this need. \r\n\r\nThe PI, an active member of the Algorithms and Randomness Center (ARC), served as its founding director and continues in-depth collaborations with scientists from various fields to identify problems and ideas that could play a fundamental role in understanding the complexity of computation. The project will contribute to graduate courses with online notes, textbooks and up-to-date survey articles.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Santosh",
   "pi_last_name": "Vempala",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Santosh S Vempala",
   "pi_email_addr": "vempala@cc.gatech.edu",
   "nsf_id": "000215458",
   "pi_start_date": "2012-07-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "266 Ferst Drive",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "7929",
   "pgm_ref_txt": "COMPUTATIONAL GEOMETRY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 420000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Data in high dimension is now ubiquitous. The need for efficient algorithms for high-dimensional problems is pressing. This project investigated some of the most basic questions in the theory of algorithms motivated by high dimension. These include optimization (finding the mininum or maximum), learning, clustering, sampling and volume computation. For each of them, in important and well-known contexts, the project resulted in the discovery of novel algorithms and algorithmic techniques.&nbsp;</p>\n<p>For optimization over integers, a powerful and commonly-used method is Gomory's cutting plane method, which proceeds by maintaining a linear program as a lower bound on the optimum integer value and iteratively adding constraints to it. In spite of much success in practice and a sophisticated theory of applicability there were almost no analysis of its efficiency. During the course of this project we found a polynomial-time guarantee in the archetypal setting of maximum weight matching, where the cutting planes are Edmonds' blossom inequalities. Related to integer programming, we found faster deterministic algorithms for the shortest and closest lattice vector problems in high dimension in arbitrary norms.&nbsp;</p>\n<p>For clustering, we generalized the classical isoperimetric inequality of Cheeger for graphs, connecting the expansion of a graph and the smallest eigenvalue of its Laplacian, to partitioning into k subsets and connecting the k-way expansion to the k'th smallest eigenvalue.&nbsp;</p>\n<p>For volume computation, we found an algorithm whose complexity is cubic in the dimension (improving by a factor of n on a long line of previous work) for any well-rounded convex body. The resulting algorithm is practical (the first practical one in more than 10 dimensions) and scales to thousands of dimensions. The program implementing the algorithm is available publicly and can be used for sampling as well as integration of logconcave functions.</p>\n<p>For learning, we formulated a framework for brain computation by requiring that cortical algorithms use little synchrony and global control in their operations. We introduced a new primitive called Predictive Join (PJOIN), which captures the essential role of feedback (prediction) in learning, and enables robust pattern memorization in a distributed manner with each unit operating independently. &nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/02/2017<br>\n\t\t\t\t\tModified by: Santosh&nbsp;S&nbsp;Vempala</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nData in high dimension is now ubiquitous. The need for efficient algorithms for high-dimensional problems is pressing. This project investigated some of the most basic questions in the theory of algorithms motivated by high dimension. These include optimization (finding the mininum or maximum), learning, clustering, sampling and volume computation. For each of them, in important and well-known contexts, the project resulted in the discovery of novel algorithms and algorithmic techniques. \n\nFor optimization over integers, a powerful and commonly-used method is Gomory's cutting plane method, which proceeds by maintaining a linear program as a lower bound on the optimum integer value and iteratively adding constraints to it. In spite of much success in practice and a sophisticated theory of applicability there were almost no analysis of its efficiency. During the course of this project we found a polynomial-time guarantee in the archetypal setting of maximum weight matching, where the cutting planes are Edmonds' blossom inequalities. Related to integer programming, we found faster deterministic algorithms for the shortest and closest lattice vector problems in high dimension in arbitrary norms. \n\nFor clustering, we generalized the classical isoperimetric inequality of Cheeger for graphs, connecting the expansion of a graph and the smallest eigenvalue of its Laplacian, to partitioning into k subsets and connecting the k-way expansion to the k'th smallest eigenvalue. \n\nFor volume computation, we found an algorithm whose complexity is cubic in the dimension (improving by a factor of n on a long line of previous work) for any well-rounded convex body. The resulting algorithm is practical (the first practical one in more than 10 dimensions) and scales to thousands of dimensions. The program implementing the algorithm is available publicly and can be used for sampling as well as integration of logconcave functions.\n\nFor learning, we formulated a framework for brain computation by requiring that cortical algorithms use little synchrony and global control in their operations. We introduced a new primitive called Predictive Join (PJOIN), which captures the essential role of feedback (prediction) in learning, and enables robust pattern memorization in a distributed manner with each unit operating independently.  \n\n\t\t\t\t\tLast Modified: 02/02/2017\n\n\t\t\t\t\tSubmitted by: Santosh S Vempala"
 }
}