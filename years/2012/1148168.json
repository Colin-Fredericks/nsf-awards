{
 "awd_id": "1148168",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SI2-SSE: Development of a GPU Accelerated Gibbs Ensemble Monte Carlo Simulation Engine",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rajiv Ramnath",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 320000.0,
 "awd_amount": 336000.0,
 "awd_min_amd_letter_date": "2012-08-28",
 "awd_max_amd_letter_date": "2013-06-07",
 "awd_abstract_narration": "This award supports the development of a general purpose Gibbs Ensemble Monte Carlo (GEMC) simulation engine that uses low-cost graphics processing units (GPU) for acceleration.   The primary objectives of this work are to develop and implement: 1) GPU accelerated configurational-bias methods, 2) efficient algorithms for the computation of Ewald sums on the GPU and 3) automated tuning of the code for different GPUs.  This work builds on the PIs? existing particle-based GPU-GEMC engine and will introduce functionality that enables the simulation of biological processes and adsorption in porous materials.  The code will be written to maintain compatibility with the file formats used by the software packages NAMD and VMD, simplifying simulation setup and data analysis.  The resulting simulation engine will be released under the GNU General Public License v3 (GPLv3) and made available to users via the Internet.  \r\n\r\nThe software tools developed with support from this award will enable high throughput computational screening of materials for CO2 sequestration, improved materials for the stabilization of drug dispersions, and provide molecular level insight to fundamental biological processes such as membrane fusion.  The use of graphics processors for the bulk of the computational effort is expected to provide one to two orders of magnitude reduction in computational time compared to traditional serial, CPU bound code, which will allow for the simulation of systems of greater size and complexity than with existing tools.  The development of the proposed GPU-accelerated Monte Carlo simulation engine will enhance the cyber-infrastructure of the biology chemistry, chemical engineering, materials science and physics communities.  The GPU-GEMC simulation engine will be promoted through conference presentations at national and international meetings, via a dedicated website, and through publication in peer-reviewed literature.\r\n\r\nThis award will enhance education at the graduate and undergraduate levels.   Research topics from this work will be integrated into existing courses on GPU computing and molecular simulation.  Graduate and undergraduate students will have the opportunity to work as part of a multidisciplinary team composed of engineers and computer scientists.  Students will be recruited from groups traditionally underrepresented in STEM fields.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeffrey",
   "pi_last_name": "Potoff",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Jeffrey J Potoff",
   "pi_email_addr": "jpotoff@wayne.edu",
   "nsf_id": "000319533",
   "pi_start_date": "2012-08-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Loren",
   "pi_last_name": "Schwiebert",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Loren J Schwiebert",
   "pi_email_addr": "loren@wayne.edu",
   "nsf_id": "000310239",
   "pi_start_date": "2012-08-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Wayne State University",
  "inst_street_address": "5700 CASS AVE STE 4900",
  "inst_street_address_2": "",
  "inst_city_name": "DETROIT",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "3135772424",
  "inst_zip_code": "482023692",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "MI13",
  "org_lgl_bus_name": "WAYNE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M6K6NTJ2MNE5"
 },
 "perf_inst": {
  "perf_inst_name": "Wayne State University",
  "perf_str_addr": "5050 Anthony Wayne Dr",
  "perf_city_name": "Detroit",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "482023930",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "MI13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "125300",
   "pgm_ele_name": "OFFICE OF MULTIDISCIPLINARY AC"
  },
  {
   "pgm_ele_code": "163300",
   "pgm_ele_name": "MATERIALS AND SURFACE ENG"
  },
  {
   "pgm_ele_code": "171200",
   "pgm_ele_name": "DMR SHORT TERM SUPPORT"
  },
  {
   "pgm_ele_code": "199100",
   "pgm_ele_name": "CHEMISTRY PROJECTS"
  },
  {
   "pgm_ele_code": "800400",
   "pgm_ele_name": "Software Institutes"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1253",
   "pgm_ref_txt": "OFFICE OF MULTIDISCIPLINARY AC"
  },
  {
   "pgm_ref_code": "1633",
   "pgm_ref_txt": "MATERIALS AND SURFACE ENG"
  },
  {
   "pgm_ref_code": "1712",
   "pgm_ref_txt": "DMR SHORT TERM SUPPORT"
  },
  {
   "pgm_ref_code": "1982",
   "pgm_ref_txt": "BIOLOGICAL CHEMISTRY"
  },
  {
   "pgm_ref_code": "1991",
   "pgm_ref_txt": "Chemistry Projects"
  },
  {
   "pgm_ref_code": "7237",
   "pgm_ref_txt": "NANO NON-SOLIC SCI & ENG AWD"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7569",
   "pgm_ref_txt": "CYBERINFRASTRUCTURE/SCIENCE"
  },
  {
   "pgm_ref_code": "7573",
   "pgm_ref_txt": "BIO-RELATED MATERIALS RESEARCH"
  },
  {
   "pgm_ref_code": "8004",
   "pgm_ref_txt": "Software Institutes"
  },
  {
   "pgm_ref_code": "8005",
   "pgm_ref_txt": "Scientific Software Elements"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 320000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The use of molecular simulation to study complex physical phenomena at the atomic level has grown exponentially over the last decade with increasing CPU power and the development of parallel molecular dynamics codes that scale efficiently over thousands of processors. While systems containing &gt;100,000 atoms are routinely simulated with molecular dynamics, Monte Carlo simulations are typically limited to systems containing fewer than 5,000 atoms. In addition, there have been significantly fewer development efforts with respect to Monte Carlo codes. Despite the limitations of code availability and lack of parallel capability, the Monte Carlo method continues to see widespread use in science and engineering. In particular, problems requiring an open system (changing number of particles) can only be simulated using Monte Carlo.</p>\n<p>This award supported the development of a general purpose Gibbs Ensemble Monte Carlo (GEMC) simulation engine for molecular systems that uses low-cost graphics processing units (GPU) for parallel computation.&nbsp;&nbsp; This code allows researchers to predict phase equilibria for a wide variety of substances from knowledge of interactions between atoms in molecules, potentially enabling advances in, for example, the development of new materials for the sequestration of carbon dioxide, and improving our understanding of biological processes, such as membrane fusion.</p>\n<p>The majority of the research effort was focused on the development of an open-source, object-oriented C++ code that comprised the core simulation engine.&nbsp; Algorithms were developed for the efficient parallelization of the calculation of non-bonded Lennard-Jones and electrostatic interactions on the GPU.&nbsp; The greatest performance enhancements were observed for the calculation of electrostatic energies.&nbsp;&nbsp; Speedups of over two orders of magnitude were obtained on an NVIDIA K40 compared to identical calculations performed on a single core of an Intel I5-3570 CPU.&nbsp; Additional support for parallel computation on multicore processors has been included through OpenMP.&nbsp; The code was written to maintain compatibility with the file formats used by the software packages NAMD and VMD, simplifying simulation setup and data analysis for users.&nbsp; The resulting simulation engine, known as GPU Optimized Monte Carlo (GOMC), was released under the GNU General Public License v3 (GPLv3) and was made available to the public via a project webpage: <a href=\"http://gomc.eng.wayne.edu/\">http://gomc.eng.wayne.edu</a> and a GitHub repository: <a href=\"https://github.com/GOMC-WSU\">https://github.com/GOMC-WSU</a>.</p>\n<p>GOMC has a broad feature set and supports simulations in the canonical, isobaric-isothermal, grand canonical and Gibbs ensembles.&nbsp; GOMC includes histogram-reweighting methods and advanced configurational-bias Monte Carlo methods, such as the coupled-decoupled method.&nbsp; A variety of all-atom and united-atom force fields based on Lennard-Jones plus point charge potentials are supported, including, for example, CHARMM, OPLS, TraPPE, and the coarse-grained MARTINI.&nbsp; The code also supports the use of Mie potentials, which offer significant accuracy gains over the Lennard-Jones potential when combined with united-atom models.</p>\n<p>GOMC was also used to advance domain science as new functionality was added to the code.&nbsp; Molecular models for the accurate prediction of vapor-liquid coexistence for noble gases, alkenes, alkynes, and branched alkanes were developed.&nbsp; Data mining techniques were used to automate components of the parameter optimization process, reducing significantly the amount of human effort needed for model development.&nbsp; A new heat-mapping technique was created to identify graphically all local and global minima produced by the objective function used in the optimization process.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/07/2016<br>\n\t\t\t\t\tModified by: Jeffrey&nbsp;J&nbsp;Potoff</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2016/1148168/1148168_10207076_1480517811367_GOMC_overview_2016--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1148168/1148168_10207076_1480517811367_GOMC_overview_2016--rgov-800width.jpg\" title=\"Overview of GOMC\"><img src=\"/por/images/Reports/POR/2016/1148168/1148168_10207076_1480517811367_GOMC_overview_2016--rgov-66x44.jpg\" alt=\"Overview of GOMC\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Overview of the capabilities of GOMC (http://gomc.eng.wayne.edu/), an open-source Monte Carlo code for the simulation of phase behavior and physical properties of molecular systems.</div>\n<div class=\"imageCredit\">Jeffrey Potoff</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Jeffrey&nbsp;J&nbsp;Potoff</div>\n<div class=\"imageTitle\">Overview of GOMC</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe use of molecular simulation to study complex physical phenomena at the atomic level has grown exponentially over the last decade with increasing CPU power and the development of parallel molecular dynamics codes that scale efficiently over thousands of processors. While systems containing &gt;100,000 atoms are routinely simulated with molecular dynamics, Monte Carlo simulations are typically limited to systems containing fewer than 5,000 atoms. In addition, there have been significantly fewer development efforts with respect to Monte Carlo codes. Despite the limitations of code availability and lack of parallel capability, the Monte Carlo method continues to see widespread use in science and engineering. In particular, problems requiring an open system (changing number of particles) can only be simulated using Monte Carlo.\n\nThis award supported the development of a general purpose Gibbs Ensemble Monte Carlo (GEMC) simulation engine for molecular systems that uses low-cost graphics processing units (GPU) for parallel computation.   This code allows researchers to predict phase equilibria for a wide variety of substances from knowledge of interactions between atoms in molecules, potentially enabling advances in, for example, the development of new materials for the sequestration of carbon dioxide, and improving our understanding of biological processes, such as membrane fusion.\n\nThe majority of the research effort was focused on the development of an open-source, object-oriented C++ code that comprised the core simulation engine.  Algorithms were developed for the efficient parallelization of the calculation of non-bonded Lennard-Jones and electrostatic interactions on the GPU.  The greatest performance enhancements were observed for the calculation of electrostatic energies.   Speedups of over two orders of magnitude were obtained on an NVIDIA K40 compared to identical calculations performed on a single core of an Intel I5-3570 CPU.  Additional support for parallel computation on multicore processors has been included through OpenMP.  The code was written to maintain compatibility with the file formats used by the software packages NAMD and VMD, simplifying simulation setup and data analysis for users.  The resulting simulation engine, known as GPU Optimized Monte Carlo (GOMC), was released under the GNU General Public License v3 (GPLv3) and was made available to the public via a project webpage: http://gomc.eng.wayne.edu and a GitHub repository: https://github.com/GOMC-WSU.\n\nGOMC has a broad feature set and supports simulations in the canonical, isobaric-isothermal, grand canonical and Gibbs ensembles.  GOMC includes histogram-reweighting methods and advanced configurational-bias Monte Carlo methods, such as the coupled-decoupled method.  A variety of all-atom and united-atom force fields based on Lennard-Jones plus point charge potentials are supported, including, for example, CHARMM, OPLS, TraPPE, and the coarse-grained MARTINI.  The code also supports the use of Mie potentials, which offer significant accuracy gains over the Lennard-Jones potential when combined with united-atom models.\n\nGOMC was also used to advance domain science as new functionality was added to the code.  Molecular models for the accurate prediction of vapor-liquid coexistence for noble gases, alkenes, alkynes, and branched alkanes were developed.  Data mining techniques were used to automate components of the parameter optimization process, reducing significantly the amount of human effort needed for model development.  A new heat-mapping technique was created to identify graphically all local and global minima produced by the objective function used in the optimization process.\n\n \n\n\t\t\t\t\tLast Modified: 12/07/2016\n\n\t\t\t\t\tSubmitted by: Jeffrey J Potoff"
 }
}