{
 "awd_id": "1149299",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER: Deep sparse dictionary context models and their application to image parsing and neuron tracking for connectomics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 409406.0,
 "awd_amount": 409406.0,
 "awd_min_amd_letter_date": "2012-08-30",
 "awd_max_amd_letter_date": "2012-08-30",
 "awd_abstract_narration": "The research objective of this proposal is to create novel computational algorithms and image processing tools that will make it possible for biologists to reconstruct large-scale neural circuits from electron microscopy volumes. Electron microscopy is a key technology in reconstruction of neural circuits at the level of individual neurons and synapses, also known as connectomics. While an important motivation of connectomics is providing anatomical ground truth for neural circuit models, the ability to decipher neural wiring maps at the individual cell level is also important in studies of many neurodegenerative diseases. State-of-the-art image analysis solutions are still far from the accuracy and robustness of human vision and biologists are still limited to studying small neural circuits using mostly manual analysis. The proposed computational models will provide biologists a tool for segmenting individual neurons and detecting other structures such as synapses in very large electron microscopy volumes, and proof reading these automatically produced results in a time efficient manner.\r\n\r\nReconstruction of a neural circuit from an electron microscopy volume involves pixel-by-pixel annotation of these images into classes such as cell membrane, mitochondria and synaptic vesicles and the segmentation of individual neurons in three dimensions. This task demands extremely high accuracy. Even with 99% pixel accuracy, an acceptable accuracy for many other applications, it is virtually certain that almost every neuron in a volume will be incorrectly segmented due to their global, tree-like structure and correspondingly large surface area. Therefore, lack of reliable automated solutions is a critical bottleneck in the field of connectomics. In this project, a novel hierarchical model will be created by combining the representation power of sparse dictionaries and their ease of learning with an inference and proof reading capability. Human experts will contribute to the process by providing ground truth for supervised learning and proof reading of automatically produced results. The combination of deep sparse dictionaries with inference using connection weights from conditional probabilities can provide a very fast way to learn hierarchical models. Several variants of the model will be studied for understanding the relative importance of feature representation, inference, symmetric connections, deep and lateral connections. The model will be applied to general object classification and image parsing problems in computer vision as well as connectomics datasets. Success will be evaluated on real datasets annotated by experts.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tolga",
   "pi_last_name": "Tasdizen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tolga Tasdizen",
   "pi_email_addr": "tolga@sci.utah.edu",
   "nsf_id": "000109998",
   "pi_start_date": "2012-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "72 South Central Campus Dr",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841129200",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 409406.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Connectomics at the microscopic level is the complete mapping of all individual neurons and their synaptic contacts in a region of the neuropil to create its canonical network map. Electron microscopy has sufficient detail for the identification of individual neurons and their synaptic connections required for this task. While electron microscopy images provide rich datasets for connectomics, they also pose formidable challenges to due to their size and complexity. Electron microscopy image datasets for connectomics can reach hundreds of terabytes. Manual analysis of even the smallest connectomics datasets costs years of effort by experts. Therefore, automation of the electron microscopy pipeline is imperative. On the other hand, the images are complex with densely packed neurons that have similar visual appearance. This creates significant challenges for automatic analysis. This project addressed the image analysis and machine learning challenges associated with connectomics. Specifically, we addressed the following challenges in this project:</p>\n<p>1) Volumes must be assembled from tens of thousands of individual EM images. To address this challenge, we developed computationally efficient methods for microscopy image registration.</p>\n<p>2) Image analysis and machine learning approaches promise to automate the connectomics pipeline; however, they also must face challenges regarding the complexity of the data. Experts have no problem delineating the boundaries of neurons in these datasets in general; however, teaching a computer to do the same requires state-of-the-art machine learning methods that can reason about ambiguities in the data. To address this challenge we developed the contextual hierarchical model for cell membrane detection and the merge tree algorithm for image segmentation.</p>\n<p>3) State-of-the art machine learning methods require large amounts of expert annotated training data that can be costly to generate. This is especially true for image segmentation methods that need training data at a fine-grained resolution. To alleviate this problem, we developed novel approaches to semi-supervised machine learning that can produce accurate results with smaller sets of expert generated training data. Our approaches to semi-supervised learning formulate cost functions using the principles of mutual exclusivity between classes of objects and the stability of the classifier output under perturbations to its input.</p>\n<p>4) Machine learning methods such as artificial neural networks can also be costly in terms of computer time. To address this challenge, we developed a novel classifier that we named the logistic disjunctive normal network which can be trained faster than a regular neural network. We further adopted this model for shape representations and segmentation.</p>\n<p>5) Even the best machine learning algorithms can not be 100% accurate. To address this challenge, we developed efficient proof reading approaches for experts to correct the results of the automatic analysis algorithms.</p>\n<p>The broader outcomes and impacts of this project include:</p>\n<p>1) Five Ph.D. students were trained supported in part by funds from this project. These students have graduated and found research and engineering positions in top machine learning research laboratories including Google Research and NVIDIA Corporation.</p>\n<p>2) We have created a webpage dedicated to this project which includes brief descriptions of the outcomes as well as the research papers published. We have also made the software for our models publicly available, free of charge, on our website.</p>\n<p>3) As part of outreach efforts supported by this grant, we have worked with high school students on image analysis and machine learning based projects. One of these high school students placed first in the Intermountain Junior Science and Humanities Symposium with his project titled &ldquo;Analysis of Montane Rainforest Dwellings with Computer Vision&rdquo; which aimed to count the number of houses in the Gishwati Rainforest area and eventually correlate this to the approximate number of people in the area and change in rainforest cover.</p>\n<p>4) We have used the research supported by this grant to enrich courses in the University of Utah Electrical and Computer Engineering Department&rsquo;s curriculum and to develop new courses.</p>\n<p>5) The software we have developed is being used at the National Center for Microscopy and Imaging Research in San Diego for analyzing the electron microscopy images they collect.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/16/2017<br>\n\t\t\t\t\tModified by: Tolga&nbsp;Tasdizen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nConnectomics at the microscopic level is the complete mapping of all individual neurons and their synaptic contacts in a region of the neuropil to create its canonical network map. Electron microscopy has sufficient detail for the identification of individual neurons and their synaptic connections required for this task. While electron microscopy images provide rich datasets for connectomics, they also pose formidable challenges to due to their size and complexity. Electron microscopy image datasets for connectomics can reach hundreds of terabytes. Manual analysis of even the smallest connectomics datasets costs years of effort by experts. Therefore, automation of the electron microscopy pipeline is imperative. On the other hand, the images are complex with densely packed neurons that have similar visual appearance. This creates significant challenges for automatic analysis. This project addressed the image analysis and machine learning challenges associated with connectomics. Specifically, we addressed the following challenges in this project:\n\n1) Volumes must be assembled from tens of thousands of individual EM images. To address this challenge, we developed computationally efficient methods for microscopy image registration.\n\n2) Image analysis and machine learning approaches promise to automate the connectomics pipeline; however, they also must face challenges regarding the complexity of the data. Experts have no problem delineating the boundaries of neurons in these datasets in general; however, teaching a computer to do the same requires state-of-the-art machine learning methods that can reason about ambiguities in the data. To address this challenge we developed the contextual hierarchical model for cell membrane detection and the merge tree algorithm for image segmentation.\n\n3) State-of-the art machine learning methods require large amounts of expert annotated training data that can be costly to generate. This is especially true for image segmentation methods that need training data at a fine-grained resolution. To alleviate this problem, we developed novel approaches to semi-supervised machine learning that can produce accurate results with smaller sets of expert generated training data. Our approaches to semi-supervised learning formulate cost functions using the principles of mutual exclusivity between classes of objects and the stability of the classifier output under perturbations to its input.\n\n4) Machine learning methods such as artificial neural networks can also be costly in terms of computer time. To address this challenge, we developed a novel classifier that we named the logistic disjunctive normal network which can be trained faster than a regular neural network. We further adopted this model for shape representations and segmentation.\n\n5) Even the best machine learning algorithms can not be 100% accurate. To address this challenge, we developed efficient proof reading approaches for experts to correct the results of the automatic analysis algorithms.\n\nThe broader outcomes and impacts of this project include:\n\n1) Five Ph.D. students were trained supported in part by funds from this project. These students have graduated and found research and engineering positions in top machine learning research laboratories including Google Research and NVIDIA Corporation.\n\n2) We have created a webpage dedicated to this project which includes brief descriptions of the outcomes as well as the research papers published. We have also made the software for our models publicly available, free of charge, on our website.\n\n3) As part of outreach efforts supported by this grant, we have worked with high school students on image analysis and machine learning based projects. One of these high school students placed first in the Intermountain Junior Science and Humanities Symposium with his project titled \"Analysis of Montane Rainforest Dwellings with Computer Vision\" which aimed to count the number of houses in the Gishwati Rainforest area and eventually correlate this to the approximate number of people in the area and change in rainforest cover.\n\n4) We have used the research supported by this grant to enrich courses in the University of Utah Electrical and Computer Engineering Department?s curriculum and to develop new courses.\n\n5) The software we have developed is being used at the National Center for Microscopy and Imaging Research in San Diego for analyzing the electron microscopy images they collect. \n\n\t\t\t\t\tLast Modified: 11/16/2017\n\n\t\t\t\t\tSubmitted by: Tolga Tasdizen"
 }
}