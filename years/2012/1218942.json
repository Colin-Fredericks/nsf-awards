{
 "awd_id": "1218942",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: III: Small: High-Dimensional Linear Models? Bring 'Em On!",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Cozzens",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 167543.0,
 "awd_amount": 167543.0,
 "awd_min_amd_letter_date": "2012-09-11",
 "awd_max_amd_letter_date": "2012-09-11",
 "awd_abstract_narration": "One of the fundamental problems in statistical data analysis is to learn the relationship between the samples of a dependent variable (e.g., the malignancy of a tumor) and the samples of predictor variables (e.g., the expression data of genes). This problem was relatively easy in the data-starved world of yesteryears. Our inability to observe too many variables meant that a single sample had dimensions in the tens or hundreds. Times have changed. We now live in a data-rich world. DNA microarrays, for example, can provide us with the expression data for hundreds of thousands of genes (predictors) per tissue sample. This is just one of the countless examples in modern statistics where a single sample comprises thousands or billions of predictors, while there are only hundreds or thousands of samples available for analysis. Computational and analytical tools developed in the 20th century, however, were not designed to work in such high-dimensional settings. The challenge then is developing new sets of computationally efficient methods that analyze the high-dimensional data in an optimal manner.\r\n\r\nThis research addresses the challenge of high-dimensional data analysis within the context of linear models by developing low-complexity inference methods based on marginal correlations of predictors with the response variable. One of the distinguishing features of this research is its emphasis on mathematical characterization of the performance of developed methods in the most general of terms. This is accomplished by drawing connections with the literature on finite frame theory. Because of the fairly general nature of this research, it significantly advances the state-of-the-art in inference problems arising in myriad areas, such as genomics, tumor classification, network monitoring and computer tomography. In addition, the frame-theoretic focus of this research lays the foundations for future cross-fertilization of ideas between statistical inference and frame theory.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Waheed",
   "pi_last_name": "Bajwa",
   "pi_mid_init": "U",
   "pi_sufx_name": "",
   "pi_full_name": "Waheed U Bajwa",
   "pi_email_addr": "waheed.bajwa@rutgers.edu",
   "nsf_id": "000601209",
   "pi_start_date": "2012-09-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "3 Rutgers Plaza",
  "perf_city_name": "New Brunswick",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "089018559",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 167543.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div>\n<p><span style=\"font-family: Calibri; font-size: small;\">Our world is undergoing a profound shift in terms of how we, as a society, make different decisions, which range from the mundane (e.g., approval of credit card applications) to the critical (e.g., early detection of cancer). The key reason for this shift is our increasing ability to cheaply gather and digitize all sorts of data, ranging from spending habits of consumers to gene expression data of patients. Unfortunately, gathering of too much data comes with its own unique set of challenges. In this project, we addressed one of those challenges, which arises in the context of statistical analysis of large datasets. We in particular focused on the setting of high-dimensional linear models, in which a linear relationship exists (or is assumed) between the samples of a dependent or response variable (e.g., the malignancy of a tumor, the health of a network) and the samples of independent or predictor variables (e.g., the expression data of genes, the traffic data in the network). Our research findings in relation to statistical data analysis under high-dimensional linear models included the following:</span></p>\n<p><span style=\"font-family: Calibri; font-size: small;\">-- We described a new methodology for rapid and accurate estimation of regression level sets in high-dimensional linear models. The key defining characteristic of the proposed method, called the projective level set estimator, is its ability to estimate the regression level sets without an intermediate reconstruction step. This leads to significantly faster computation relative to heuristic &ldquo;plug-in&rdquo; methods that first solve the regression problem, typically with an iterative algorithm, and then threshold the result.</span></p>\n<p><span style=\"font-family: Calibri; font-size: small;\">-- We investigated the asymptotic behavior of posterior distributions of regression coefficients in high-dimensional linear models as the number of dimensions grows with the number of observations. We showed that the posterior distribution concentrates in neighborhoods of the true parameter under simple sufficient conditions. These conditions hold under popular shrinkage priors given some sparsity assumptions.</span></p>\n<p><span style=\"font-family: Calibri; font-size: small;\">-- We investigated the problem of linear regression in high-dimensional models for the case of predictors that tend to follow &ldquo;block&rdquo; (or &ldquo;group&rdquo;) structures. Our results are fundamentally different from prior work because (i) they provide conditions that can be explicitly computed in polynomial time, and (ii) the given conditions translate into near-optimal scaling of the number of predictors in the problem as a function of the number of observations for a large class of problems.</span></p>\n<p><span style=\"font-family: Calibri; font-size: small;\">-- We investigated computational techniques, often referred to as &ldquo;screening,&rdquo; that significantly reduce the computing time in large-scale statistical data analysis by cheaply getting rid of the data that do not influence the final decision. Our results (some of which are unpublished as of today) derive verifiable conditions that lead to provable screening of large-scale datasets.</span></p>\n<p><span style=\"font-family: Calibri; font-size: small;\">In addition to our efforts focused on basic research involving statistical data analysis, we also strived to ensure both the scientific community and our society can benefit from our efforts. In particular:</span></p>\n<p><span style=\"font-family: Calibri; font-size: small;\">-- We leveraged the findings of this research to initiate a project on early epithelial cancer detection using </span><em><span style=\"font-family: Calibri; font-size: small;\">in vivo</span></em><span style=\"font-family: Calibri; font-size: small;\"> &ldquo;optical biopsy,&rdquo; which is expected to eliminate the need for invasive and costly biopsies in a great number of high-risk patients.</span></p>\n<p><span style=\"font-family: Calibri; font-size: small;\">-- We trained several undergraduate and graduate students in the field of &ldquo;data science&rdquo; during the course of this project.</span></p>\n<p><span style=\"font-family: Calibri; font-size: small;\">-- We offered data-centric courses at Rutgers University whose curricula matched the needs of the future workforce.</span></p>\n<p><span style=\"font-family: Calibri; font-size: small;\">-- We disseminated our research findings to the broader research community through a book chapter, conference papers and presentations, seminars, journal articles, and public sharing of research code.</span></p>\n<p><span style=\"font-family: Calibri; font-size: small;\">-- We delivered a three-hour tutorial to researchers interested in high-dimensional data analysis at IEEE ICASSP, the premier signal processing conference, in 2015.</span></p>\n<strong></strong><em></em></div><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/01/2016<br>\n\t\t\t\t\tModified by: Waheed&nbsp;U&nbsp;Bajwa</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nOur world is undergoing a profound shift in terms of how we, as a society, make different decisions, which range from the mundane (e.g., approval of credit card applications) to the critical (e.g., early detection of cancer). The key reason for this shift is our increasing ability to cheaply gather and digitize all sorts of data, ranging from spending habits of consumers to gene expression data of patients. Unfortunately, gathering of too much data comes with its own unique set of challenges. In this project, we addressed one of those challenges, which arises in the context of statistical analysis of large datasets. We in particular focused on the setting of high-dimensional linear models, in which a linear relationship exists (or is assumed) between the samples of a dependent or response variable (e.g., the malignancy of a tumor, the health of a network) and the samples of independent or predictor variables (e.g., the expression data of genes, the traffic data in the network). Our research findings in relation to statistical data analysis under high-dimensional linear models included the following:\n\n-- We described a new methodology for rapid and accurate estimation of regression level sets in high-dimensional linear models. The key defining characteristic of the proposed method, called the projective level set estimator, is its ability to estimate the regression level sets without an intermediate reconstruction step. This leads to significantly faster computation relative to heuristic \"plug-in\" methods that first solve the regression problem, typically with an iterative algorithm, and then threshold the result.\n\n-- We investigated the asymptotic behavior of posterior distributions of regression coefficients in high-dimensional linear models as the number of dimensions grows with the number of observations. We showed that the posterior distribution concentrates in neighborhoods of the true parameter under simple sufficient conditions. These conditions hold under popular shrinkage priors given some sparsity assumptions.\n\n-- We investigated the problem of linear regression in high-dimensional models for the case of predictors that tend to follow \"block\" (or \"group\") structures. Our results are fundamentally different from prior work because (i) they provide conditions that can be explicitly computed in polynomial time, and (ii) the given conditions translate into near-optimal scaling of the number of predictors in the problem as a function of the number of observations for a large class of problems.\n\n-- We investigated computational techniques, often referred to as \"screening,\" that significantly reduce the computing time in large-scale statistical data analysis by cheaply getting rid of the data that do not influence the final decision. Our results (some of which are unpublished as of today) derive verifiable conditions that lead to provable screening of large-scale datasets.\n\nIn addition to our efforts focused on basic research involving statistical data analysis, we also strived to ensure both the scientific community and our society can benefit from our efforts. In particular:\n\n-- We leveraged the findings of this research to initiate a project on early epithelial cancer detection using in vivo \"optical biopsy,\" which is expected to eliminate the need for invasive and costly biopsies in a great number of high-risk patients.\n\n-- We trained several undergraduate and graduate students in the field of \"data science\" during the course of this project.\n\n-- We offered data-centric courses at Rutgers University whose curricula matched the needs of the future workforce.\n\n-- We disseminated our research findings to the broader research community through a book chapter, conference papers and presentations, seminars, journal articles, and public sharing of research code.\n\n-- We delivered a three-hour tutorial to researchers interested in high-dimensional data analysis at IEEE ICASSP, the premier signal processing conference, in 2015.\n\n\n\t\t\t\t\tLast Modified: 12/01/2016\n\n\t\t\t\t\tSubmitted by: Waheed U Bajwa"
 }
}