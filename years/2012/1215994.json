{
 "awd_id": "1215994",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ICES: Small: Auction Games",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2012-08-21",
 "awd_max_amd_letter_date": "2012-08-21",
 "awd_abstract_narration": "Many auctions used in practice are extremely simple, but do not satisfy the usual standards of mechanism design.  These auctions are referred to as \"auction games. \"  The Internet provides an environment running millions of auctions, an environment where simplicity is more important than ever before.  The \"ideal\" of mechanism design is the single item Vickrey auction (second price auction), selling a single item to the highest bidder at the second highest price. This auction has all the desired features combining simplicity with efficiency: the auction has simple and intuitive rules; it has simple bidding strategies, as truthfully reporting the agent's value as the bid is dominant strategy; and it leads to efficient allocation. A main theme in mechanism design has been designing such truthful and efficient auctions in settings other than the single item auction. Unfortunately, truthfulness and efficiency often come at a price: the resulting mechanisms can be too complex for many environments.\r\n \r\nThe goal of this project is to develop tools to understand outcomes of auction games, such as Ad-Auctions (a multi-billion-dollar game played by Internet service providers and advertisers), and to quantify the expected efficiency and revenue.   The Principal Investigator will investigate this goal under various models of the information structure of the game, as well as under various assumptions on the rationality of the agents.\r\n \r\nThe broader impact of the proposal is in developing the basic tools needed to understand many natural auctions, such as the auctions typically being used in practice. Such understanding will lead to simple and intuitive auctions in different environments that result in good quality outcomes.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eva",
   "pi_last_name": "Tardos",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eva Tardos",
   "pi_email_addr": "eva@cs.cornell.edu",
   "nsf_id": "000443465",
   "pi_start_date": "2012-08-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "4130 Upson Hall",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148533801",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "805200",
   "pgm_ele_name": "Inter Com Sci Econ Soc S (ICE)"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7932",
   "pgm_ref_txt": "COMPUT GAME THEORY & ECON"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project resulted in better understanding in auction outcomes in complex environments. We worked on quantifying the inefficiency of different auction types typically used online. Our theoretical analysis made some assumptions on the behavior of the auction participants. In a paper that won the best paper award at the 2015 ACM Economics and Computation conference, we have examined these assumptions on data from Microsoft Ad-Auctions.</p>\n<p>Online auction environments require the systems to be simple both for users to understand, and for the system to run well, and be able to run the huge volume of auctions that ad-auction systems need to run. This simplicity requirement results on suboptimal auction design. The goal of the project was to develop methods to evaluate the loss of efficiency inherent in the system. This evaluation is an important step in understanding the potential benefits of developing more complex, harder to run and understand systems. The price of anarchy is suggested as a measure of this efficiency loss, the ratio between the auction outcome, and the best possible solution.</p>\n<ul>\n<li>In our paper &ldquo;Composable and Efficient Mechanism&rdquo; that appeared in the ACM Symposium on Theory of Computing, we show that if players each participate in multiple mechanism, and each are shown to have low price of anarchy with the now standard &ldquo;smoothness argument&rdquo;, then the composed mechanism also has to price of anarchy, assuming players don&rsquo;t have complements across the different mechanism. This result shows an important strength of the simple mechanisms typically analyzed via price of anarchy. Most participants in auctions participate in many mechanisms: e.g., advertisers bid for ads in more than one platform. The optimal mechanism run by each platform in isolation fails to have such composability property, while the simple and close to efficient mechanism remain close to efficient when run together with other mechanisms. In most of the price of anarchy work, including the paper just mentioned, we model players as agents that use learning algorithms. This is especially appropriate in cases where the stakes at each individual auction are small, with the aggregate over time payoff really being of primary importance. Typical players will experiment in the market and try to optimize their bid over time by using their past experience as a proxy for future rewards, this is modeled by learning. &nbsp;</li>\n<li>In our paper &ldquo;Econometrics for Learning Agents&rdquo; we undertake the task of testing some of the above theory on data. To do so, we need to inference of player valuations from observed data on their bidding behavior. Existing work in Economics on inferring agent values from data relies on the assumption that all participant strategies are best responses of the observed play of other players, i.e. they constitute a Nash equilibrium. In the above paper, we show how to perform inference relying on a weaker assumption instead: assuming that players are using some form of no-regret learning. We apply our techniques to a dataset from Microsoft&rsquo;s sponsored search ad auction system. This paper won the best paper award at the 2015 ACM Economics and Computation conference.</li>\n<li>The paper &ldquo;Learning and Efficiency in Games with Dynamic Population&rdquo; &nbsp;consider a large class of games including auctions where player population is not stable. An important trait of learning behavior is its versatility to changing environments, and indeed many online environments, from auctions to packet routing are dynamic. The price of anarchy analysis of previous work, including our own work reported above, makes the unrealistic assumption that the environment is stable. In this paper we show that, in large classes of games, if players choose their strategies in a way that guarantees low adaptive regret, high social welfare is en...",
  "por_txt_cntn": "\nThe project resulted in better understanding in auction outcomes in complex environments. We worked on quantifying the inefficiency of different auction types typically used online. Our theoretical analysis made some assumptions on the behavior of the auction participants. In a paper that won the best paper award at the 2015 ACM Economics and Computation conference, we have examined these assumptions on data from Microsoft Ad-Auctions.\n\nOnline auction environments require the systems to be simple both for users to understand, and for the system to run well, and be able to run the huge volume of auctions that ad-auction systems need to run. This simplicity requirement results on suboptimal auction design. The goal of the project was to develop methods to evaluate the loss of efficiency inherent in the system. This evaluation is an important step in understanding the potential benefits of developing more complex, harder to run and understand systems. The price of anarchy is suggested as a measure of this efficiency loss, the ratio between the auction outcome, and the best possible solution.\n\nIn our paper \"Composable and Efficient Mechanism\" that appeared in the ACM Symposium on Theory of Computing, we show that if players each participate in multiple mechanism, and each are shown to have low price of anarchy with the now standard \"smoothness argument\", then the composed mechanism also has to price of anarchy, assuming players don\u00c6t have complements across the different mechanism. This result shows an important strength of the simple mechanisms typically analyzed via price of anarchy. Most participants in auctions participate in many mechanisms: e.g., advertisers bid for ads in more than one platform. The optimal mechanism run by each platform in isolation fails to have such composability property, while the simple and close to efficient mechanism remain close to efficient when run together with other mechanisms. In most of the price of anarchy work, including the paper just mentioned, we model players as agents that use learning algorithms. This is especially appropriate in cases where the stakes at each individual auction are small, with the aggregate over time payoff really being of primary importance. Typical players will experiment in the market and try to optimize their bid over time by using their past experience as a proxy for future rewards, this is modeled by learning.  \nIn our paper \"Econometrics for Learning Agents\" we undertake the task of testing some of the above theory on data. To do so, we need to inference of player valuations from observed data on their bidding behavior. Existing work in Economics on inferring agent values from data relies on the assumption that all participant strategies are best responses of the observed play of other players, i.e. they constitute a Nash equilibrium. In the above paper, we show how to perform inference relying on a weaker assumption instead: assuming that players are using some form of no-regret learning. We apply our techniques to a dataset from Microsoft\u00c6s sponsored search ad auction system. This paper won the best paper award at the 2015 ACM Economics and Computation conference.\nThe paper \"Learning and Efficiency in Games with Dynamic Population\"  consider a large class of games including auctions where player population is not stable. An important trait of learning behavior is its versatility to changing environments, and indeed many online environments, from auctions to packet routing are dynamic. The price of anarchy analysis of previous work, including our own work reported above, makes the unrealistic assumption that the environment is stable. In this paper we show that, in large classes of games, if players choose their strategies in a way that guarantees low adaptive regret, high social welfare is ensured, even under very frequent changes.\n\n\nThe PI Eva Tardos was also developed and ran repeatedly a MOOC on networks (together with David Easley and Jon Kleinberg) tha..."
 }
}