{
 "awd_id": "1218349",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Algorithms for computing aggregate functions of matrices with applications to Lattice QCD",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jack S. Snoeyink",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2012-07-30",
 "awd_max_amd_letter_date": "2012-07-30",
 "awd_abstract_narration": "One of the most computationally challenging tasks in Numerical Linear \r\nAlgebra (NLA) is the estimation of the trace or the determinant of functions \r\nof matrices. The computational difficulty arises for very large matrices \r\nwhere the computation of the entire spectrum is infeasible. Traditionally, \r\nthis problem is approached through stochastic techniques, such as Monte \r\nCarlo, where each step involves the solution of a linear system of equations. \r\nDeterministic techniques could provide approximations much faster but \r\nintroduce bias in the result. This research will employ a combination of \r\nthese techniques. Deterministic techniques involve novel uses of \r\ntraditional NLA tools such as low rank approximations, deflation, and \r\npreconditioners, not only for speeding the solution of linear systems but also \r\nfor reducing the variance of the stochastic process. The team plans to use Hadamard \r\nvectors, which are popular in coding theory, with an ordering induced by \r\nhierarchical graph-coloring, to produce a deterministic sequence of sampling \r\nvectors for Monte Carlo that exploits the structure of the matrix.\r\n\r\nAlthough most of these techniques address the general NLA problem, the \r\nmotivating application is lattice quantum chromodynamics (LQCD). The goal \r\nof LQCD is to calculate the properties, structure, and interactions of hadrons,\r\nthe basic constituents of matter. Computation of observables in LQCD entails \r\naveraging of correlation functions over an ensemble of gauge fields. \r\nThese correlation functions often require the trace of the inverse of a large \r\nsparse matrix, or the ratio of determinants of two such matrices. \r\n\r\nIt is increasingly clear that there is an opportunity for real gains by \r\nharnessing the synergy between randomized and deterministic techniques.\r\nBased on such an approach, this research will advance the current \r\nstate-of-the-art in NLA, while transforming some of the standard computational \r\npractices in LQCD. It will also be useful in other disciplines, as the \r\nproblem  is common in many statistical applications, in data mining, \r\nin uncertainty quantification, as well as in quantum physics applications \r\nsuch as quantum Monte Carlo.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Andreas",
   "pi_last_name": "Stathopoulos",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andreas Stathopoulos",
   "pi_email_addr": "andreas@cs.wm.edu",
   "nsf_id": "000346145",
   "pi_start_date": "2012-07-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kostas",
   "pi_last_name": "Orginos",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kostas Orginos",
   "pi_email_addr": "kostas@wm.edu",
   "nsf_id": "000110491",
   "pi_start_date": "2012-07-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "College of William and Mary",
  "inst_street_address": "1314 S MOUNT VERNON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "WILLIAMSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "7572213965",
  "inst_zip_code": "23185",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "VA08",
  "org_lgl_bus_name": "COLLEGE OF WILLIAM AND MARY",
  "org_prnt_uei_num": "EVWJPCY6AD97",
  "org_uei_num": "EVWJPCY6AD97"
 },
 "perf_inst": {
  "perf_inst_name": "College of William and Mary",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "231878795",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "VA01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7933",
   "pgm_ref_txt": "NUM, SYMBOL, & ALGEBRA COMPUT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>One of the most computationally challenging tasks in Numerical Linear Algebra (NLA) is the estimation of the trace of functions of matrices. &nbsp;The computational difficulty arises for very large matrices where the computation of the entire spectrum is infeasible. Examples abound in statistics, uncertainty quantification, as well as in calculations from quantum mechanics and high energy physics. Most commonly, the trace of the inverse of a matrix is needed. Traditionally, this problem is approached through stochastic techniques, such as Monte Carlo (MC), where each step involves the solution of a linear system of equations. &nbsp;The computational challenge, therefore, is (i) to reduce the large number of such steps required, and (ii) speedup the solution of the linear systems.<br /><br />To reduce the number of MC steps, we need to reduce the variance of the estimator. We have focused on deterministic methods that are combined with stochastic ones so that our estimators remain unbiased. Classical probing is a technique that uses matrix-vector multiplications to identify the most important structure of the inverse of A, whose contribution to the MC variance can then be removed. This is performed by coloring the graph of powers A^k, which becomes computationally intractable for large k.<br /><br />One of our main contributions was the development of Hierarchical Probing. On a lattice, coloring A^k can be achieved with an approximate but efficient manner. Moreover, the colorings can be hierarchical, i.e., nodes that share the same color for some k, they also share colors for smaller k. This allows for extremely efficient implementations that maintain all the advantages of the classical probing. Hierarchical probing has found broad use in the area of Lattice Quantum Chromodynamics where are collaborators report significant speedups. For general matrices where classical probing would work if it were tractable, we have developed a multilevel method that performs probing based on coloring successively coarsified versions of A^k and thus can be performed much more efficiently.<br /><br />A second contribution of this work is the use of deflation techniques for variance reduction but also as a way to speed up the solution of the linear systems. Deflation means to project out from the matrix its singular vector space with singular values near zero. Then we can split our trace computation into one in the deflation space, which can be performed easily, and one for the deflated matrix which should have much smaller variance for the MC process. Our research overcame two obstacles, one theoretical and one computational.&nbsp;<br /><br />Based on random matrix theory, we showed the surprising theoretical result that for Hermitian matrices variance reduces only if their singular value distribution increases faster than linearly, while for non-Hermitian matrices it always reduces. We further quantified the improvements in variance with relation to the singular value distribution. When applied to our motivating Lattice QCD application, we observed that deflation works in a complementary way with Hierarchical probing, together yielding speedups of close to two orders of magnitude.<br /><br />The computational problem that had to be solved was the efficient computation of a relatively large part of the near zero singular spectrum. Realizing that current software was not sufficient for our purposes, we developed new algorithms and extensions to our state-of-the-art eigensolver PRIMME, addressing a host of issues relating to interior eigenvalues and high accuracy computations. Moreover, we interfaced with a multigrid Lattice QCD preconditioner that speeds up PRIMME by a factor of 30.&nbsp;<br /><br />We have also made several other contributions, such as using deflation and preconditioners with interpolation to find the diagonal of the matrix inverse, applying our methods in a variety of other applications from Big Data, and improving the state-of-the-art in eigenvalue and singular value software. Overall, this project has given rise to new methods, algorithms, and software that are important on their own for Numerical Linear Algebra. In addition, they have enabled and continue to enable large scale calculations in Lattice QCD, and possibly many other applications.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/14/2016<br>\n\t\t\t\t\tModified by: Andreas&nbsp;Stathopoulos</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOne of the most computationally challenging tasks in Numerical Linear Algebra (NLA) is the estimation of the trace of functions of matrices.  The computational difficulty arises for very large matrices where the computation of the entire spectrum is infeasible. Examples abound in statistics, uncertainty quantification, as well as in calculations from quantum mechanics and high energy physics. Most commonly, the trace of the inverse of a matrix is needed. Traditionally, this problem is approached through stochastic techniques, such as Monte Carlo (MC), where each step involves the solution of a linear system of equations.  The computational challenge, therefore, is (i) to reduce the large number of such steps required, and (ii) speedup the solution of the linear systems.\n\nTo reduce the number of MC steps, we need to reduce the variance of the estimator. We have focused on deterministic methods that are combined with stochastic ones so that our estimators remain unbiased. Classical probing is a technique that uses matrix-vector multiplications to identify the most important structure of the inverse of A, whose contribution to the MC variance can then be removed. This is performed by coloring the graph of powers A^k, which becomes computationally intractable for large k.\n\nOne of our main contributions was the development of Hierarchical Probing. On a lattice, coloring A^k can be achieved with an approximate but efficient manner. Moreover, the colorings can be hierarchical, i.e., nodes that share the same color for some k, they also share colors for smaller k. This allows for extremely efficient implementations that maintain all the advantages of the classical probing. Hierarchical probing has found broad use in the area of Lattice Quantum Chromodynamics where are collaborators report significant speedups. For general matrices where classical probing would work if it were tractable, we have developed a multilevel method that performs probing based on coloring successively coarsified versions of A^k and thus can be performed much more efficiently.\n\nA second contribution of this work is the use of deflation techniques for variance reduction but also as a way to speed up the solution of the linear systems. Deflation means to project out from the matrix its singular vector space with singular values near zero. Then we can split our trace computation into one in the deflation space, which can be performed easily, and one for the deflated matrix which should have much smaller variance for the MC process. Our research overcame two obstacles, one theoretical and one computational. \n\nBased on random matrix theory, we showed the surprising theoretical result that for Hermitian matrices variance reduces only if their singular value distribution increases faster than linearly, while for non-Hermitian matrices it always reduces. We further quantified the improvements in variance with relation to the singular value distribution. When applied to our motivating Lattice QCD application, we observed that deflation works in a complementary way with Hierarchical probing, together yielding speedups of close to two orders of magnitude.\n\nThe computational problem that had to be solved was the efficient computation of a relatively large part of the near zero singular spectrum. Realizing that current software was not sufficient for our purposes, we developed new algorithms and extensions to our state-of-the-art eigensolver PRIMME, addressing a host of issues relating to interior eigenvalues and high accuracy computations. Moreover, we interfaced with a multigrid Lattice QCD preconditioner that speeds up PRIMME by a factor of 30. \n\nWe have also made several other contributions, such as using deflation and preconditioners with interpolation to find the diagonal of the matrix inverse, applying our methods in a variety of other applications from Big Data, and improving the state-of-the-art in eigenvalue and singular value software. Overall, this project has given rise to new methods, algorithms, and software that are important on their own for Numerical Linear Algebra. In addition, they have enabled and continue to enable large scale calculations in Lattice QCD, and possibly many other applications.\n\n\t\t\t\t\tLast Modified: 11/14/2016\n\n\t\t\t\t\tSubmitted by: Andreas Stathopoulos"
 }
}