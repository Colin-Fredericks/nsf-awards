{
 "awd_id": "1218411",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CGV: Small: Collaborative Research: Diffractive masks and algorithms for light field capture",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2012-07-31",
 "awd_max_amd_letter_date": "2012-07-31",
 "awd_abstract_narration": "Diffractive masks and algorithms for light field capture\r\nPIs: Ramesh Raskar, MIT Media Lab\t\tAlyosha Molnar, Cornell ECE\r\n\r\nAdvanced imaging and display technology requires integrated, low cost systems able to efficiently capture and characterize light from 3-D scenes. In particular, a 3-D scene can be described by the collection of light rays it generates, called the light field.  This research combines concepts from mask-based light-field imaging with angle sensitive pixels (ASPs).  While mask-based light-field capture is much better understood mathematically, and masks are cheaper to manufacture and more easily modified on-the-fly, diffractive ASPs provide smaller, denser light field sensors, and provide naturally compressible outputs.  This project combines the physics and signal processing of these approaches to enable optical imaging systems that capture more information than normal cameras while reducing the system's complexity.  This work broadly impacts diverse applications spanning consumer imaging and displays, machine vision and automation, scientific/medical imaging and displays, robotic surgery, surveillance and remote sensing.\r\n\r\n3-D images and video can be captured by measuring the combined spatial and angular distribution of light (the light field).  This research combines two techniques for light-field capture: mask-based light-field imaging and diffractive angle sensitive pixels (ASPs).  A critical element of this work is the development of a mathematical framework that maps between conventional geometric light fields and the diffractive optics upon which ASPs rely.  A second element is constructing hybrid systems based on this mathematics, leveraging diffractive effects in mask design, and combining masks with ASPs in single light-field cameras.  This work also combines formalisms in existing light field methods with knowledge about real 3-D scene statistics to develop optimal (in the sense of usability and compressibility) basis sets for sampling and encoding the light-field. All of these aspects combine to reduce the size, cost and complexity of light field cameras, while simultaneously enhancing their capabilities.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ramesh",
   "pi_last_name": "Raskar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ramesh Raskar",
   "pi_email_addr": "raskar@media.mit.edu",
   "nsf_id": "000502041",
   "pi_start_date": "2012-07-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Ave",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Light field imaging gives people the ability to capture images that better represent the world around us, whether it is capturing more beautiful vacation photos with perfect bokeh, tracking your hands to create next-generation user interfaces, or helping biologists map the genome of new organisms to cure disease and develop our fundamental understanding of biology. However, light field imaging systems have been resolution constrained, limiting their abilities in practice. With diffractive imaging it is possible to break the resolution constraints that have prevented the adoption of this critical technology. We developed a framework for capturing full-resolution light fields using diffractive angle sensitive pixels (ASP). We combine ASP hardware with modern techniques for compressive light field reconstruction and other processing modes to achieve an unprecedented amount of flexibility in computational light field imaging. By using these techniques it is possible to capture light field images at a higher resolution, to achieve conventional 2D image reconstructions, to quickly reconstruct low-resolution 4D light fields, and to create also more computationally intensive, sparsity-constrained reconstructions of high-resolution 4D light fields.&nbsp;Our work has been published in peer reviewed journals and conferences, and won a best paper award at IEEE ICCP 2014.&nbsp;</p>\n<p>We hope to inspire the community to follow similar strategies for other applications and unlock the true potential of next-generation computational cameras.</p>\n<p><span>&nbsp;</span></p>\n<blockquote>\n<div class=\"gmail_extra\">\n<div class=\"gmail_quote\">\n<blockquote class=\"gmail_quote\">\n<div>\n<blockquote>\n<div dir=\"ltr\"><br />\n<blockquote></blockquote>\n</div>\n</blockquote>\n</div>\n</blockquote>\n</div>\n</div>\n</blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/20/2015<br>\n\t\t\t\t\tModified by: Ramesh&nbsp;Raskar</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nLight field imaging gives people the ability to capture images that better represent the world around us, whether it is capturing more beautiful vacation photos with perfect bokeh, tracking your hands to create next-generation user interfaces, or helping biologists map the genome of new organisms to cure disease and develop our fundamental understanding of biology. However, light field imaging systems have been resolution constrained, limiting their abilities in practice. With diffractive imaging it is possible to break the resolution constraints that have prevented the adoption of this critical technology. We developed a framework for capturing full-resolution light fields using diffractive angle sensitive pixels (ASP). We combine ASP hardware with modern techniques for compressive light field reconstruction and other processing modes to achieve an unprecedented amount of flexibility in computational light field imaging. By using these techniques it is possible to capture light field images at a higher resolution, to achieve conventional 2D image reconstructions, to quickly reconstruct low-resolution 4D light fields, and to create also more computationally intensive, sparsity-constrained reconstructions of high-resolution 4D light fields. Our work has been published in peer reviewed journals and conferences, and won a best paper award at IEEE ICCP 2014. \n\nWe hope to inspire the community to follow similar strategies for other applications and unlock the true potential of next-generation computational cameras.\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 11/20/2015\n\n\t\t\t\t\tSubmitted by: Ramesh Raskar"
 }
}