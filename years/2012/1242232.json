{
 "awd_id": "1242232",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER:  TheDesignExchange: Characterizing, Mapping and Interacting with Industry on User-Focused Design Methods",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Christiaan Paredis",
 "awd_eff_date": "2012-07-01",
 "awd_exp_date": "2014-06-30",
 "tot_intn_awd_amt": 73535.0,
 "awd_amount": 73535.0,
 "awd_min_amd_letter_date": "2012-06-16",
 "awd_max_amd_letter_date": "2012-06-16",
 "awd_abstract_narration": "The research objective of this EArly-Concept Grant for Exploratory Research (EAGER)award is to explore, characterize, and map the use of user-centric design methods and tools.  TheDesignExchange will provide a mechanism for investigators to answer questions pertaining to the motivation for the choice of and use of a particular design method for a design problem.  TheDesignExchange will offer a centralized venue where human-centered design methods will be shared, discussed and disseminated, so that the research community can then engage in research to provide explanations as to how the various methods within the design process relate to each other.  TheDesignExchange will increase researchers' understanding of structured design processes, and will also be an invaluable resource to train novice and professional engineers and designers.\r\n\r\nIf successful, the outcomes of this award will result in an interactive web portal to facilitate the capture, analysis and widespread use of human-centered design methods, together with the insights as to how these methods will be best used for maximum success of the design venture.  TheDesignExchange will be powered by a multidisciplinary community contributed database, which will allow practitioners and researchers to more deeply understand the use of design methods in practice and will facilitate the exchange of information between industry and academia.  A workshop will be held in conjunction with this work at the 2012 NSF CMMI Grantees Conference. The outcomes of this workshop will form the basis of the research agenda for TheDesignExchange platform, including hypotheses for an ontology that maps human-centered design methods to real-world design problems, which will be made available to both industry and the research community.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alice",
   "pi_last_name": "Agogino",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Alice M Agogino",
   "pi_email_addr": "agogino@berkeley.edu",
   "nsf_id": "000751593",
   "pi_start_date": "2012-06-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sara",
   "pi_last_name": "Beckman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sara Beckman",
   "pi_email_addr": "beckman@haas.berkeley.edu",
   "nsf_id": "000443609",
   "pi_start_date": "2012-06-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947201764",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "146400",
   "pgm_ele_name": "ESD-Eng & Systems Design"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "067E",
   "pgm_ref_txt": "DESIGN TOOLS"
  },
  {
   "pgm_ref_code": "068E",
   "pgm_ref_txt": "DESIGN THEORY"
  },
  {
   "pgm_ref_code": "073E",
   "pgm_ref_txt": "OPTIMIZATION & DECISION MAKING"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 73535.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><em>TheDesignExchange</em> is envisioned as an interactive web portal to facilitate the capture, analysis and widespread use of human-centered design methods that have shown to be successful in practice. The portal is intended to support the entire life-cycle of the human-centered design process, providing educators and practitioners alike with access to the largest public library of proven design methods and tools. This seed funding EAGER grant was used to conduct workshops to develop guidelines for a larger proposal to NSF and to develop a &ldquo;proof of concept&rdquo; database and website.</p>\n<p><strong>Workshops</strong></p>\n<p>Two workshops were held in 2012 with a total of 50 attendees at the NSF CMMI Grantees Conference in Boston and ASME&rsquo;s IDETC/CIE Conference in Chicago).<em> </em>At these workshops, the PIs<em> </em>and IDEO.org&rsquo;s <em>HCD Connect</em> worked together to explore communication between researchers and practitioners; to identify features and functionality they&rsquo;d find useful; and to develop a research agenda for <em>theDesignExchange.</em>1) Attendees were interested in how to port human-centered design methods to new disciplines, such as civil engineering. 2) Attendees were interested in the gap between theory (classroom) and practice (industry), and the lack of formalism in practice. 3) Attendees were interested in when methods/processes failed, as well as when they succeeded.</p>\n<p><strong>Computational Research</strong></p>\n<p>To develop potential method recommendation algorithms for <em>TheDesignExchange</em>, we began initial development using a series of 432 case studies provided by the users of HCD Connect (IDEO.org). In each of these case studies, users described a particular design problem they faced, and then listed a set of methods that they used to solve the problem. An overview of the frequency of methods used in the corpus can be seen in Fig. 1. A portion of these cases was identified with an additional set of human-provided context labels to determine if expert-provided labels would increase the recommendation performance. The research goal was then to identify possible algorithms that would be able to make the same decisions as a human evaluator; notably, would it recommend the same methods for a given problem that a human would? Initial tests involved using the expert-given labels inside a series of simple models that assume linear independence. The models evaluated included Support Vector Machines, Logistic Regression, Na&iuml;ve Bayes classifiers, and Decision Tree classifiers. The performance metric of interest in this case was a Precision-Recall curve that trades off two quantities: precision and recall. Precision is the percentage of recommended methods that were actually used in a case (e.g., if the algorithm recommends 10 methods, but only 5 of those 10 were used in the case study, the precision was 50%) Recall is the percentage of methods actually used in a case that were recommended by the algorithm (e.g., if the case actually used 8 methods, and the algorithm only correctly recommended 6 of those methods, then the recall was 75%). This curve essentially summarizes how well the algorithm presented users with meaningful methods for their design problem. (Companies such as Google use similar metrics to evaluate performance for related tasks like web-page ranking.)</p>\n<p>The two baseline performance measures were randomly recommending methods, as well as recommending methods in order of decreasing popularity. As can be seen in Fig. 2, the models using expert labeled data for each case study were not able to significantly outperform popular ranking, implying the models using only the current expert provided labels may not be able to fully predict which methods were used. Collaborative filtering uniformly outperformed both the popularity baseline as well as the text-based content features. We expect ...",
  "por_txt_cntn": "\nTheDesignExchange is envisioned as an interactive web portal to facilitate the capture, analysis and widespread use of human-centered design methods that have shown to be successful in practice. The portal is intended to support the entire life-cycle of the human-centered design process, providing educators and practitioners alike with access to the largest public library of proven design methods and tools. This seed funding EAGER grant was used to conduct workshops to develop guidelines for a larger proposal to NSF and to develop a \"proof of concept\" database and website.\n\nWorkshops\n\nTwo workshops were held in 2012 with a total of 50 attendees at the NSF CMMI Grantees Conference in Boston and ASME\u00c6s IDETC/CIE Conference in Chicago). At these workshops, the PIs and IDEO.org\u00c6s HCD Connect worked together to explore communication between researchers and practitioners; to identify features and functionality they\u00c6d find useful; and to develop a research agenda for theDesignExchange.1) Attendees were interested in how to port human-centered design methods to new disciplines, such as civil engineering. 2) Attendees were interested in the gap between theory (classroom) and practice (industry), and the lack of formalism in practice. 3) Attendees were interested in when methods/processes failed, as well as when they succeeded.\n\nComputational Research\n\nTo develop potential method recommendation algorithms for TheDesignExchange, we began initial development using a series of 432 case studies provided by the users of HCD Connect (IDEO.org). In each of these case studies, users described a particular design problem they faced, and then listed a set of methods that they used to solve the problem. An overview of the frequency of methods used in the corpus can be seen in Fig. 1. A portion of these cases was identified with an additional set of human-provided context labels to determine if expert-provided labels would increase the recommendation performance. The research goal was then to identify possible algorithms that would be able to make the same decisions as a human evaluator; notably, would it recommend the same methods for a given problem that a human would? Initial tests involved using the expert-given labels inside a series of simple models that assume linear independence. The models evaluated included Support Vector Machines, Logistic Regression, Na&iuml;ve Bayes classifiers, and Decision Tree classifiers. The performance metric of interest in this case was a Precision-Recall curve that trades off two quantities: precision and recall. Precision is the percentage of recommended methods that were actually used in a case (e.g., if the algorithm recommends 10 methods, but only 5 of those 10 were used in the case study, the precision was 50%) Recall is the percentage of methods actually used in a case that were recommended by the algorithm (e.g., if the case actually used 8 methods, and the algorithm only correctly recommended 6 of those methods, then the recall was 75%). This curve essentially summarizes how well the algorithm presented users with meaningful methods for their design problem. (Companies such as Google use similar metrics to evaluate performance for related tasks like web-page ranking.)\n\nThe two baseline performance measures were randomly recommending methods, as well as recommending methods in order of decreasing popularity. As can be seen in Fig. 2, the models using expert labeled data for each case study were not able to significantly outperform popular ranking, implying the models using only the current expert provided labels may not be able to fully predict which methods were used. Collaborative filtering uniformly outperformed both the popularity baseline as well as the text-based content features. We expect that future research will uncover differ different content features that positively affect performance when combined with a collaborative filtering algorithm.\n\nDatabase, Website and Publications\n\nOne major outc..."
 }
}