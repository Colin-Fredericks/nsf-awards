{
 "awd_id": "1161731",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CGV: Medium: Collaborative Research: Understanding Translucency: Physics, Perception, and Computation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 395000.0,
 "awd_amount": 395000.0,
 "awd_min_amd_letter_date": "2012-08-29",
 "awd_max_amd_letter_date": "2012-08-29",
 "awd_abstract_narration": "People care greatly about the appearance of translucent materials such as food, skin, soap, and marble, and they are able to distinguish subtle differences in these materials based on their appearance.  The translucent appearance of these materials is caused by internal volumetric scattering, which is challenging to simulate, especially because humans are so sensitive to their subtleties.  Since in the natural world scattering materials are the norm, not the exception, it makes sense that the human visual system is so well engineered to analyze them.  However, very little is known about how this analysis is achieved because the perception of volumetric translucency is almost unstudied.\r\n\r\nThis collaborative project, involving faculty from three universities with complementary expertise in computer graphics, human vision, machine learning, and computer vision, addresses the fundamental unsolved problem of understanding translucency for graphics.  The PIs will develop a perceptually-motivated pipeline for translucency, contributing new scattering representations, perceptual dimensions, and computational algorithms to computer graphics.  The scattering representations, based on a polydispersion model, will provide analytic expressions for wavelength-dependent bulk scattering properties of translucent media; this will significantly expand the range of materials that can be simulated with high visual fidelity.  Finding perceptual knobs that relate physical scattering parameters with visual appearance will be achieved by coupling large-scale computation (using cloud computing) with controlled perceptual studies.  Novel acquisition approaches that employ hyperspectral imaging will be created, as will editing and rendering applications that use the new perceptual representations of translucency.  Low-dimensional models to represent scattering media will be developed and used to enable efficient and accurate acquisition and rendering.  A suite of test materials and scenes will be developed to evaluate the fidelity of rendered images based on the developed theory and computational applications.\r\n\r\nBroader Impacts:   Currently, the simulation of translucency presents challenges in terms of both computation and visual fidelity.  This restricts the ability of practical algorithms to predictively simulate translucent materials, thus fundamentally limiting the use of graphics in real applications. By building the computational tools to characterize, study, and use knowledge of translucency perception, this research will fundamentally change the graphics pipeline for translucent materials. and will potentially revolutionizing industrial design, interior design, skin care and cosmetics, and entertainment.\r\n\r\nThe project includes an education program that is tightly coupled to the research program.  The PIs have already been meeting twice a week for more than six months, and their graduate students already share data, code, and equipment.  During the activity, the students will make week-long and month-long visits to each other's laboratories to collaborate, and in this way the project will produce a generation of researchers who are \"T-shaped\" in the sense of being both deep in their respective fields and able to work effectively across these synergistic disciplines.  The PIs also plan to organize a workshop that will brins together researchers in vision science, computer graphics, and computer vision, so that the important ties between these fields are strengthened even further.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Edward",
   "pi_last_name": "Adelson",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Edward H Adelson",
   "pi_email_addr": "adelson@csail.mit.edu",
   "nsf_id": "000332297",
   "pi_start_date": "2012-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 395000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The visual and tactile properties of objects and materials are a central part of human experience and commerce. A manufacturer of fabric needs to specify and control the visual appearance of the fabric in terms of its texture, color, and opacity, as well as the tactile properties such as roughness, slipperiness, and flexibility. This project developed methods in computer vision for analyzing the visual qualities of materials, and methods in computer graphics for synthesizing images of materials with specified visual qualities. This will help a manufacturer who wishes to create materials of a given visual quality, as well as photographers, artists, and designers who wish to create images that replicate a given visual quality. In addition, the project developed techniques for analyzing the tactile qualities of materials. This will help a manufacturer create materials that fit a tactile specification. The research will also be helpful in robotics, making robots more capable in both factories and domestic settings. For example, a robot that is preparing food for a disabled or elderly person will have to understand the way the food looks and feels in order to know whether it is properly prepared. A domestic robot that is helping with laundry needs to have both visual and tactile sensitivity in order to understand whether the clothing is properly cleaned, dried, and pressed. We have developed algorithms that will be useful in the visual and tactile analysis needed for these tasks.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/25/2022<br>\n\t\t\t\t\tModified by: Edward&nbsp;H&nbsp;Adelson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe visual and tactile properties of objects and materials are a central part of human experience and commerce. A manufacturer of fabric needs to specify and control the visual appearance of the fabric in terms of its texture, color, and opacity, as well as the tactile properties such as roughness, slipperiness, and flexibility. This project developed methods in computer vision for analyzing the visual qualities of materials, and methods in computer graphics for synthesizing images of materials with specified visual qualities. This will help a manufacturer who wishes to create materials of a given visual quality, as well as photographers, artists, and designers who wish to create images that replicate a given visual quality. In addition, the project developed techniques for analyzing the tactile qualities of materials. This will help a manufacturer create materials that fit a tactile specification. The research will also be helpful in robotics, making robots more capable in both factories and domestic settings. For example, a robot that is preparing food for a disabled or elderly person will have to understand the way the food looks and feels in order to know whether it is properly prepared. A domestic robot that is helping with laundry needs to have both visual and tactile sensitivity in order to understand whether the clothing is properly cleaned, dried, and pressed. We have developed algorithms that will be useful in the visual and tactile analysis needed for these tasks.\n\n\t\t\t\t\tLast Modified: 06/25/2022\n\n\t\t\t\t\tSubmitted by: Edward H Adelson"
 }
}