{
 "awd_id": "1218758",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF-Small: Robust Methodologies for Effective Data Center Management",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2012-06-01",
 "awd_exp_date": "2017-02-28",
 "tot_intn_awd_amt": 490816.0,
 "awd_amount": 490816.0,
 "awd_min_amd_letter_date": "2012-05-16",
 "awd_max_amd_letter_date": "2012-06-01",
 "awd_abstract_narration": "Despite the ubiquity of data centers, little is known about their effective management. Consolidation of multiple applications with diverse and changing resource requirements is common in data centers as hardware resources are abundant and opportunities for better system usage are plenty, as are opportunities to degrade individual application performance due to unregulated performance interference between applications and system resources.  Is it possible to maximize resource usage  while respecting individual application performance targets or is it an oxymoron to simultaneously meet such conflicting measures? In this project, a solution methodology to the above difficult problem  is proposed using a three-pronged approach.\r\n\r\nFirst,  a detailed large scale performance study on several thousands of data center servers within a time period that spans two years is going to be conducted. This study provides a micro and macro view of current workload requirements, of workload resource demands on\r\nbasic resource components including CPU, memory, disk, and their temporal evolution. This analysis provides a baseline for the development of scalable and efficient resource management in data centers.\r\n\r\nSecond, extensive experimentation on basic components of data centers is going to quantify performance interference among different classes of applications  due to  consolidation. This experimentation drives the development of a light-weight profiler that is system- and application-agnostic. The methodology captures application resource demands via non-intrusive  low-level measurements that are provided via standard tools.The experimental observations have the potential to drive the development of resource allocation policies in data centers both at the micro level (i.e., at specific hardware components that are used as data center building blocks) and  at the macro level (i.e., at the data center as a whole).\r\n\r\nThird, a queueing-theory based tool is developed that uses as input the resource demands measured by the profiler to accurately predict application scalability under homogeneous and heterogeneous consolidations. The model can be used to predict the application and system performance under virtualized environments at the micro and macro levels, and provide consolidation suggestions such that pre-defined user- or system-specified performance targets are met.\r\n\r\nThe proposed methodologies have the potential to improve the effectiveness of resource allocation in data centers that operate under complex workloads and show excellent potential for allocation solutions that meet pre-defined user and system performance targets. This research will affect the state-of-the-practice via industrial collaborations, especially IBM Research and NEC Research Labs. More broadly, this research has the potential to make a strong impact in management of in-production data centers. Through this project,  several students will be prepared to better meet industry demands in the areas of performance modeling and resource allocation in complex environments.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Evgenia",
   "pi_last_name": "Smirni",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Evgenia Smirni",
   "pi_email_addr": "esmirni@cs.wm.edu",
   "nsf_id": "000346140",
   "pi_start_date": "2012-05-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "College of William and Mary",
  "inst_street_address": "1314 S MOUNT VERNON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "WILLIAMSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "7572213965",
  "inst_zip_code": "23185",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "VA08",
  "org_lgl_bus_name": "COLLEGE OF WILLIAM AND MARY",
  "org_prnt_uei_num": "EVWJPCY6AD97",
  "org_uei_num": "EVWJPCY6AD97"
 },
 "perf_inst": {
  "perf_inst_name": "College of William and Mary",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "231878795",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "VA01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 490816.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>With the advancement of virtualization technologies and the benefit of economies of scale,&nbsp;data centers are a sustainable IT solution to a broad range of customers and applications.&nbsp;Despite the ubiquity of data centers, little is known about their effective management. This project developed methodologies and policies for more effective usage of data centers. More specifically, the subgoals of this project that were tackled &nbsp;are as follows:</p>\n<p><strong>Workload Characterization in Production Data Centers</strong></p>\n<p><strong>&nbsp;</strong>Prerequisite to the development of any policies aiming at better data center usage, is a good understanding of how data centers are used. Thanks to our collaboration with IBM, we analyzed traces from all IBM data centers that operate in a private cloud setting.&nbsp;Our characterizations focused on the temporal aspect: how virtual machines are employed in such centers and how the physical utilizations&nbsp;of servers change across time. Our work has characterized in detail the \"state of the practice\" in data centers. The emphasis has been on different resources including the storage system, as well as on developing prediction techniques for the center's usage time series of different hard ware components.</p>\n<p><strong>Consolidating Virtual Machines in Data Centers</strong></p>\n<p><strong>&nbsp;</strong>We have developed a first proof of concept that it is indeed possible to use queueing networks to predict the effect of consolidation in&nbsp;data centers. We used the SPEC and DaCapo benchmarks, as well as RuBis and TPC-W, two multi-tier benchmarks. In addition, we have considered a deep neural-network application. Our results illustrated that queuing networks can indeed capture performance interference of consolidated applications in data center environments.</p>\n<p><strong>Methodologies</strong><br />We developed a load balancing algorithm for data centers and a methodology to predict delays when interleaving multiple jobs to maximize&nbsp;system usage. We &nbsp;developped novel queuing network and machine learning models that can predict performance under different load conditions based on optimization, we also developed machine learning models to predict time series of workload metrics. The above models were used to develop storage system policies that can schedule effectiveley data analytics work with performance guarantees, serving deep-neural network applications with performance guarantees, and scheduling MapReduce applications on heterogeneous processors.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/08/2017<br>\n\t\t\t\t\tModified by: Evgenia&nbsp;Smirni</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWith the advancement of virtualization technologies and the benefit of economies of scale, data centers are a sustainable IT solution to a broad range of customers and applications. Despite the ubiquity of data centers, little is known about their effective management. This project developed methodologies and policies for more effective usage of data centers. More specifically, the subgoals of this project that were tackled  are as follows:\n\nWorkload Characterization in Production Data Centers\n\n Prerequisite to the development of any policies aiming at better data center usage, is a good understanding of how data centers are used. Thanks to our collaboration with IBM, we analyzed traces from all IBM data centers that operate in a private cloud setting. Our characterizations focused on the temporal aspect: how virtual machines are employed in such centers and how the physical utilizations of servers change across time. Our work has characterized in detail the \"state of the practice\" in data centers. The emphasis has been on different resources including the storage system, as well as on developing prediction techniques for the center's usage time series of different hard ware components.\n\nConsolidating Virtual Machines in Data Centers\n\n We have developed a first proof of concept that it is indeed possible to use queueing networks to predict the effect of consolidation in data centers. We used the SPEC and DaCapo benchmarks, as well as RuBis and TPC-W, two multi-tier benchmarks. In addition, we have considered a deep neural-network application. Our results illustrated that queuing networks can indeed capture performance interference of consolidated applications in data center environments.\n\nMethodologies\nWe developed a load balancing algorithm for data centers and a methodology to predict delays when interleaving multiple jobs to maximize system usage. We  developped novel queuing network and machine learning models that can predict performance under different load conditions based on optimization, we also developed machine learning models to predict time series of workload metrics. The above models were used to develop storage system policies that can schedule effectiveley data analytics work with performance guarantees, serving deep-neural network applications with performance guarantees, and scheduling MapReduce applications on heterogeneous processors.\n\n \n\n\t\t\t\t\tLast Modified: 03/08/2017\n\n\t\t\t\t\tSubmitted by: Evgenia Smirni"
 }
}