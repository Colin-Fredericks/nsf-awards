{
 "awd_id": "1234749",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Enabling Productive, High-Performance Data Analytics",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rudolf Eigenmann",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 1113993.0,
 "awd_amount": 1226000.0,
 "awd_min_amd_letter_date": "2012-09-05",
 "awd_max_amd_letter_date": "2014-03-06",
 "awd_abstract_narration": "This award provides funding for Sherlock, a Cray YarcData uRiKA data appliance consisting of a next-generation Cray XMT supercomputer (NG-XMT) running the uRiKA application architecture and augmented by Cray XT5 compute nodes to broaden the range of relevant applications to address the challenges of graph-based data analytics.  The system will be deployed at the Pittsburgh Supercomputing Center (PSC).  The Cray NG-XMT is a massively multithreaded supercomputer, based on the Cray XT5 infrastructure and specialized for analytics. Its Cray-proprietary Threadstorm 4.0 processors implement multiple, powerful features to support lightweight multithreading, latency hiding, and advanced memory interfaces with AMD HyperTransport-attached SeaStar2 interconnect chips to provide a flat, globally-addressable memory. This will be the first system of its kind to be available to the NSF research community.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Levine",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Michael J Levine",
   "pi_email_addr": "levine@psc.edu",
   "nsf_id": "000311748",
   "pi_start_date": "2012-09-05",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Nicholas",
   "pi_last_name": "Nystrom",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nicholas Nystrom",
   "pi_email_addr": "nystrom@psc.edu",
   "nsf_id": "000216722",
   "pi_start_date": "2012-09-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "118900",
   "pgm_ele_name": "Major Research Instrumentation"
  },
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  },
  {
   "pgm_ele_code": "768400",
   "pgm_ele_name": "CESER-Cyberinfrastructure for"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7684",
   "pgm_ref_txt": "STRATEGIC TECHNOLOGIES FOR CI"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 963962.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 227993.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 34045.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goals of this project were to deploy a YarcData Urika data appliance with project-specific customizations, which we named <em>Sherlock</em> (see photo), to establish a set of test-bed research projects, to provide those research groups with training, and to gain community experience with the Urika architecture for large-scale graph analytics.</p>\n<p>Urika embodies a novel approach to graph analytics. Graph analytics leverages graph structures to understand, codify, and visualize relationships that exist between people or devices in a network. Graph analytics, built on the mathematics of graph theory, is used to model pairwise relationships between people, objects, or nodes in a network.</p>\n<p>The novelty of the Urika platform required unusually great outreach to make users aware of its approach and capabilities. We therefore reached out to users through workshops, in-person presentations, and the PSC website, to XSEDE staff through an ECSS Symposium and discussions, and to non-academic institutions through additional briefings. PSC introduced the field of graph analytics and <em>Sherlock </em>as a specific implementation to undergraduate classes and interns, graduate students, faculty, PSC and XSEDE staff, other labs, government, and the commercial sector. Outreach spanned education, training, and professional development. PSC staff have developed significant depth in graph analytics, and two undergraduate interns obtained valuable experience through REU funding. PSC&rsquo;s Big Data workshops filled beyond their planned capacity and introduced graph analytics and <em>Sherlock </em>to 417 workshop participants at 16 institutions nationwide.</p>\n<p>Significant effort was spent helping users to consider and develop data analytic approaches involving <em>Sherlock</em>. Twelve research groups involving 20 users requested and were granted accounts on<em> Sherlock</em>. The researchers who were most active overall were from the Software Engineering Institute, who aimed to apply <em>Sherlock </em>to interactively analyze network flow data to identify security threats and patterns, and a PSC intern who went on to work with CMU computer scientists working on tensor decompositions using SPARQL for linked data. Other researchers who made significant efforts were from the University of Pittsburgh&rsquo;s School of Information Science, who are developing a distributed, crowd-sourcing approach to integration and fusion of world history data and envisioning using <em>Sherlock </em>to identify large-scale similarity joins, and the University of Pittsburgh&rsquo;s Department of Biomedical Informatics, who are working with The Cancer Genome Atlas and other genomic repositories to advance cancer genomics.</p>\n<p>In all cases, user support required unusually high PSC staff involvement to adapt the Urika user environment to a multi-user, multi-project research environment and to interface with YarcData. The Urika environment, as it was initially provided by YarcData, was intended to run a single database at a time, preferably by only one group of users since there were no built-in tools for limiting access to databases by user or group. Working closely with YarcData, PSC developed technologies and techniques to adapt Urika to a multiuser research environment and further improved several features of the Urika environment. These improved the system&rsquo;s security and ease of use for users and systems administrators.</p>\n<p>The <em>Sherlock </em>project provided extensive opportunities for the community to learn about, and gain experience with, a hardware-accelerated approach to graph analytics expressed using RDF and SPARQL. Focusing attention on graph analytics and their role in larger analytic workflows enabled users working with big data to develop approaches that accelerated their research, not necessarily with Urika, but through being informed by what they learned through inv...",
  "por_txt_cntn": "\nThe goals of this project were to deploy a YarcData Urika data appliance with project-specific customizations, which we named Sherlock (see photo), to establish a set of test-bed research projects, to provide those research groups with training, and to gain community experience with the Urika architecture for large-scale graph analytics.\n\nUrika embodies a novel approach to graph analytics. Graph analytics leverages graph structures to understand, codify, and visualize relationships that exist between people or devices in a network. Graph analytics, built on the mathematics of graph theory, is used to model pairwise relationships between people, objects, or nodes in a network.\n\nThe novelty of the Urika platform required unusually great outreach to make users aware of its approach and capabilities. We therefore reached out to users through workshops, in-person presentations, and the PSC website, to XSEDE staff through an ECSS Symposium and discussions, and to non-academic institutions through additional briefings. PSC introduced the field of graph analytics and Sherlock as a specific implementation to undergraduate classes and interns, graduate students, faculty, PSC and XSEDE staff, other labs, government, and the commercial sector. Outreach spanned education, training, and professional development. PSC staff have developed significant depth in graph analytics, and two undergraduate interns obtained valuable experience through REU funding. PSC\u00c6s Big Data workshops filled beyond their planned capacity and introduced graph analytics and Sherlock to 417 workshop participants at 16 institutions nationwide.\n\nSignificant effort was spent helping users to consider and develop data analytic approaches involving Sherlock. Twelve research groups involving 20 users requested and were granted accounts on Sherlock. The researchers who were most active overall were from the Software Engineering Institute, who aimed to apply Sherlock to interactively analyze network flow data to identify security threats and patterns, and a PSC intern who went on to work with CMU computer scientists working on tensor decompositions using SPARQL for linked data. Other researchers who made significant efforts were from the University of Pittsburgh\u00c6s School of Information Science, who are developing a distributed, crowd-sourcing approach to integration and fusion of world history data and envisioning using Sherlock to identify large-scale similarity joins, and the University of Pittsburgh\u00c6s Department of Biomedical Informatics, who are working with The Cancer Genome Atlas and other genomic repositories to advance cancer genomics.\n\nIn all cases, user support required unusually high PSC staff involvement to adapt the Urika user environment to a multi-user, multi-project research environment and to interface with YarcData. The Urika environment, as it was initially provided by YarcData, was intended to run a single database at a time, preferably by only one group of users since there were no built-in tools for limiting access to databases by user or group. Working closely with YarcData, PSC developed technologies and techniques to adapt Urika to a multiuser research environment and further improved several features of the Urika environment. These improved the system\u00c6s security and ease of use for users and systems administrators.\n\nThe Sherlock project provided extensive opportunities for the community to learn about, and gain experience with, a hardware-accelerated approach to graph analytics expressed using RDF and SPARQL. Focusing attention on graph analytics and their role in larger analytic workflows enabled users working with big data to develop approaches that accelerated their research, not necessarily with Urika, but through being informed by what they learned through involvement in this project.\n\nFor some disciplines it was found, despite considerable effort, that limitations of SPARQL required complementary or hybrid approaches that introduced complexity..."
 }
}