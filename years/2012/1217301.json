{
 "awd_id": "1217301",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EXP: Deepening Conceptual Understanding with Hands-on, Augmented-Reality Experimentation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925126",
 "po_email": "abaylor@nsf.gov",
 "po_sign_block_name": "Amy Baylor",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 524051.0,
 "awd_amount": 524051.0,
 "awd_min_amd_letter_date": "2012-08-31",
 "awd_max_amd_letter_date": "2012-08-31",
 "awd_abstract_narration": "This project team, led by a learning scientist and a computer graphics and augmented reality expert are working together to design a new kind of science laboratory environment that uses augmented reality (AR) to make invisible scientific phenomena visible and continuously reinforce the conceptual principles at work during hands-on scientific experimentation. The envisioned technology visually captures the what students see as they are physically carrying out experiments, interactively processes the imagery to make key aspects available for analysis and exploration, and, in real time, automatically augments the imagery with visualizations that overlay visualizations of scientific phenomena on the real-world phenomena students are experiencing, allowing students to experience real-world phenomena and the conceptual models that describe those phenomena simultaneously. The base technology is a camera-equipped tablet. Initial content is on force, work, and motion. The technological innovation includes, first, recognizing the components in a scene, even when the lighting is bad and people and other objects occlude some of it, and second, calculating the positions of the objects so that the virtual imagery can be transformed to match the real-world positions. Foundations for the innovation can be found in what is known about the affordances of integrating multiple representations in reasoning and problem solving and the challenges and difficulties in doing that. The aim is to overcome those challenges so that the affordances of multiple representations, each of which can communicate different things, can be taken advantage of by learners. Scientists do this regularly, and a visceral understanding of how this is done by scientists is expected to help students better understand what scientists do and what counts as evidence. Research addresses how students' thinking processes and domain understanding are influenced by the addition of augmented reality visualizations to their hands-on scientific investigations. \r\n\r\nThere is broad agreement that the current state of educational preparedness of students in STEM areas is inadequate and that improvement in these areas is critical both for American technological leadership and for an informed, policy-making citizenry. This research works to improve science education with engaging tools that tackle one of the most difficult science educational issues: deep conceptual understanding applied to real-world situations. This project team applies an elegant technological approach to an helping learners connect the abstract science concepts they are learning about to the real world they live in. Computer vision and augmented reality will be integrated and refined in a way that addresses the needs of learners. The team will make the programs and curriculum freely and broadly available via Web-based distribution and access.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Johnson",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "David E Johnson",
   "pi_email_addr": "dejohnso@cs.utah.edu",
   "nsf_id": "000402926",
   "pi_start_date": "2012-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kirsten",
   "pi_last_name": "Butcher",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Kirsten R Butcher",
   "pi_email_addr": "kirsten.butcher@utah.edu",
   "nsf_id": "000429818",
   "pi_start_date": "2012-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "50 S. Central Campus Drive",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841129205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  },
  {
   "pgm_ref_code": "8841",
   "pgm_ref_txt": "Exploration Projects"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0412",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001213DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 524051.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Project Outcomes Final Report</strong></p>\n<p><strong>Title:&nbsp; EXP: Deepening Conceptual Understanding with Hands-on, Augmented-Reality Experimentation </strong></p>\n<p><strong>Award # 1217301</strong>&nbsp;</p>\n<p><strong>Overview</strong></p>\n<p>This project focused on two interrelated goals: a computer science development goal and a learning research goal. The <strong>computer science goal</strong> focused on advancing visual technologies to develop an augmented-reality experimentation lab that supplements real time views of hands-on experiments in physics (e.g., a cart rolling down a ramp) with visual overlays that depict the abstract (invisible) forces operating on object motion in the real world (see Figure 1). The <strong>learning research goal</strong> was to better understand when and how augmented-reality videos for physics learning could promote effective learning processes and meaningful knowledge outcomes. Combined, this project developed new computational techniques for creating augmented reality videos for physics learning and identified key forms of scaffolding for digital learning environments that integrate augmented reality videos.</p>\n<p><strong>Research</strong></p>\n<p>Computer science research developed a series of techniques to extract information from a typical physics lab environment using tablet devices. Printed markers were used to help identify components of the lab equipment to the augmented reality camera system and to position those components in a three-dimensional map of the world. The moving parts of the lab equipment were tracked and the position over time used to derive velocity and acceleration. The position tracking system was slightly noisy and derived accelerations exaggerated that error. Significant effort went into filtering and smoothing this data so that meaningful and informative overlays could be presented to the users of the system.</p>\n<p>Learning science research used a series of studies to examine how students learn with augmented reality videos and identify the impact of varied instructional scaffolds for effective online study of augmented reality videos. Instructional scaffolds focuses on promoting meaningful cognitive processing and positive learning outcomes. Learning studies included: 1) one study of students' spontaneous processing of and learning from augmented reality videos in physics; 2) two studies that examined the impact of visual and verbal cues in promoting deeper explanations of augmented reality videos; 3) one study that examined the impact of temporal cues and visual comparisons on meaningful explanations and deep learning outcomes when studying augmented reality videos, and 4) one study on the type and frequency of errors during self- and peer-explanation of augmented reality videos.</p>\n<p><strong>Findings</strong></p>\n<p>Computer science research supported by this grant found that while tablet computers were capable of tracking motion of components of physics labs and integrating virtual overlays into a video of a scene, there remains difficulty with the accuracy of the tracking and even more so for derived information of interest, such as object acceleration. Newer devices with additional augmented reality support and improved camera and video systems show promise for alleviating some of these issues.</p>\n<p>Learning science research supported by this grant found that augmented reality videos can help students identify and encode information about underlying forces during hands-on physics experiments. Conceptual overlays in physics videos significantly improved students' abilities to identify the invisible forces at play in applied settings, with particular improvement in ability to identify underlying forces in new, real-world settings. However, spontaneous explanations about augmented reality videos often focus on superficial features of the depicted situation. Findings show that instructional cues (both visual and verbal) can improve the depth of student understanding by increasing the quality of their explanations (in terms of specificity and conceptual focus). A combination of temporal cueing and visual comparison (where correct overlays are explained in contrast to incorrect overlays) was particularly effective in spurring deeper explanations that were better aligned to physics principles. Results also showed that students benefitted equally from explaining augmented reality videos to themselves or to peers, demonstrating that varied instructional approaches may utilize augmented reality videos for STEM learning.</p>\n<p><strong>Conclusions</strong></p>\n<p>The results from this project help us understand when and how video-based, online materials can play a significant role in science learning. Results suggest best practices for implementation of video-based learning scaffolds in instructional technology, as well as offering preliminary guidelines for teachers and learners on the types of features that are needed for students to process augmented reality videos deeply and accurately.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/28/2017<br>\n\t\t\t\t\tModified by: David&nbsp;Johnson</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1217301/1217301_10209777_1511897387201_ScreenShot2017-11-28at12.27.46PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1217301/1217301_10209777_1511897387201_ScreenShot2017-11-28at12.27.46PM--rgov-800width.jpg\" title=\"Figure 1\"><img src=\"/por/images/Reports/POR/2017/1217301/1217301_10209777_1511897387201_ScreenShot2017-11-28at12.27.46PM--rgov-66x44.jpg\" alt=\"Figure 1\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An example visual overlay depicting object velocity during a hands-on physics experiment.</div>\n<div class=\"imageCredit\">David Johnson</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">David&nbsp;Johnson</div>\n<div class=\"imageTitle\">Figure 1</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nProject Outcomes Final Report\n\nTitle:  EXP: Deepening Conceptual Understanding with Hands-on, Augmented-Reality Experimentation \n\nAward # 1217301 \n\nOverview\n\nThis project focused on two interrelated goals: a computer science development goal and a learning research goal. The computer science goal focused on advancing visual technologies to develop an augmented-reality experimentation lab that supplements real time views of hands-on experiments in physics (e.g., a cart rolling down a ramp) with visual overlays that depict the abstract (invisible) forces operating on object motion in the real world (see Figure 1). The learning research goal was to better understand when and how augmented-reality videos for physics learning could promote effective learning processes and meaningful knowledge outcomes. Combined, this project developed new computational techniques for creating augmented reality videos for physics learning and identified key forms of scaffolding for digital learning environments that integrate augmented reality videos.\n\nResearch\n\nComputer science research developed a series of techniques to extract information from a typical physics lab environment using tablet devices. Printed markers were used to help identify components of the lab equipment to the augmented reality camera system and to position those components in a three-dimensional map of the world. The moving parts of the lab equipment were tracked and the position over time used to derive velocity and acceleration. The position tracking system was slightly noisy and derived accelerations exaggerated that error. Significant effort went into filtering and smoothing this data so that meaningful and informative overlays could be presented to the users of the system.\n\nLearning science research used a series of studies to examine how students learn with augmented reality videos and identify the impact of varied instructional scaffolds for effective online study of augmented reality videos. Instructional scaffolds focuses on promoting meaningful cognitive processing and positive learning outcomes. Learning studies included: 1) one study of students' spontaneous processing of and learning from augmented reality videos in physics; 2) two studies that examined the impact of visual and verbal cues in promoting deeper explanations of augmented reality videos; 3) one study that examined the impact of temporal cues and visual comparisons on meaningful explanations and deep learning outcomes when studying augmented reality videos, and 4) one study on the type and frequency of errors during self- and peer-explanation of augmented reality videos.\n\nFindings\n\nComputer science research supported by this grant found that while tablet computers were capable of tracking motion of components of physics labs and integrating virtual overlays into a video of a scene, there remains difficulty with the accuracy of the tracking and even more so for derived information of interest, such as object acceleration. Newer devices with additional augmented reality support and improved camera and video systems show promise for alleviating some of these issues.\n\nLearning science research supported by this grant found that augmented reality videos can help students identify and encode information about underlying forces during hands-on physics experiments. Conceptual overlays in physics videos significantly improved students' abilities to identify the invisible forces at play in applied settings, with particular improvement in ability to identify underlying forces in new, real-world settings. However, spontaneous explanations about augmented reality videos often focus on superficial features of the depicted situation. Findings show that instructional cues (both visual and verbal) can improve the depth of student understanding by increasing the quality of their explanations (in terms of specificity and conceptual focus). A combination of temporal cueing and visual comparison (where correct overlays are explained in contrast to incorrect overlays) was particularly effective in spurring deeper explanations that were better aligned to physics principles. Results also showed that students benefitted equally from explaining augmented reality videos to themselves or to peers, demonstrating that varied instructional approaches may utilize augmented reality videos for STEM learning.\n\nConclusions\n\nThe results from this project help us understand when and how video-based, online materials can play a significant role in science learning. Results suggest best practices for implementation of video-based learning scaffolds in instructional technology, as well as offering preliminary guidelines for teachers and learners on the types of features that are needed for students to process augmented reality videos deeply and accurately.\n\n\t\t\t\t\tLast Modified: 11/28/2017\n\n\t\t\t\t\tSubmitted by: David Johnson"
 }
}