{
 "awd_id": "1140562",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Quantitative Literacy and Reasoning Assessment (QLRA)",
 "cfda_num": "47.076",
 "org_code": "11040200",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Haddock",
 "awd_eff_date": "2012-02-15",
 "awd_exp_date": "2015-01-31",
 "tot_intn_awd_amt": 193253.0,
 "awd_amount": 193253.0,
 "awd_min_amd_letter_date": "2012-02-21",
 "awd_max_amd_letter_date": "2012-02-21",
 "awd_abstract_narration": "The Quantitative Literacy Reasoning Assessment (QLRA) project is developing a non-proprietary QLR instrument, piloting it at several participating institutions across the country to begin the creation of a database of QLR abilities, and establishing an online resource portal for QLR assessment.  Quantitative Literacy/Reasoning is a relatively new and growing field, with many institutions replacing traditional math requirements with various introductory QLR-requirements such as Liberal Arts Mathematics and Finite Math.  The current developmental/introductory math program in this country is undergoing a profound paradigm shift, as focus moves from traditional algebra based curricula to the development of the quantitative skills and habits of mind required for decision making in our personal, civic and workplace lives.  Underrepresented groups in STEM (minorities and women) are often disproportionately overrepresented in these traditional developmental courses.  The mathematics point-of-entry for these underrepresented groups is a crucial time to nurture interest and engagement with mathematics that could lead to further STEM involvement.  The QLRA project provides the needed assessment for curriculum innovation and coherence of these point-of-entry courses.  Dissemination via the online portal allows institutions to easily adapt the non-proprietary instrument to their own needs.  The QLRA Project provides the necessary assessment infrastructure and a collaborative platform as QLR requirements evolve around the nation.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DUE",
 "org_div_long_name": "Division Of Undergraduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Gaze",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eric Gaze",
   "pi_email_addr": "egaze@bowdoin.edu",
   "nsf_id": "000590832",
   "pi_start_date": "2012-02-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Linda",
   "pi_last_name": "Misener",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Linda Misener",
   "pi_email_addr": "lmisener@smccME.edu",
   "nsf_id": "000592766",
   "pi_start_date": "2012-02-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Bowdoin College",
  "inst_street_address": "255 MAINE ST",
  "inst_street_address_2": "",
  "inst_city_name": "BRUNSWICK",
  "inst_state_code": "ME",
  "inst_state_name": "Maine",
  "inst_phone_num": "2077253767",
  "inst_zip_code": "040113343",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "ME01",
  "org_lgl_bus_name": "BOWDOIN COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "JE5WBLZJUME7"
 },
 "perf_inst": {
  "perf_inst_name": "Bowdoin College",
  "perf_str_addr": "5700 College Station",
  "perf_city_name": "Brunswick",
  "perf_st_code": "ME",
  "perf_st_name": "Maine",
  "perf_zip_code": "040118448",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "ME01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "153600",
   "pgm_ele_name": "S-STEM-Schlr Sci Tech Eng&Math"
  },
  {
   "pgm_ele_code": "751300",
   "pgm_ele_name": "TUES-Type 1 Project"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0412",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001213DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "13XX",
   "app_name": "H-1B FUND, EHR, NSF",
   "app_symb_id": "045176",
   "fund_code": "1300XXXXDB",
   "fund_name": "H-1B FUND, EDU, NSF",
   "fund_symb_id": "045176"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 193253.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Quantitative Literacy/Reasoning (QLR) has been in the academic landscape for over two decades.&nbsp; For the latter half of this period, academic institutions across the US have been shifting the focus of introductory/general education math undergraduate courses toward QLR, emphasizing the quantitative tools that students will need for successful decision making in their personal, professional, and civic lives.</p>\n<p>While QLR courses and curricula are finding wide dissemination, assessment of QLR (in terms of skills of individual students, and the effectiveness of curricula) remains primarily a local activity. There have been publications such as Achieving QL, and the AACU QL VALUE rubric; most current assessment efforts however, are localized to a single campus, a single course, or even a single classroom. This is due, in part, to the difficulties involved with assessment of QLR skills. Even at locations where QLR tests are implemented for placement purposes, tests are not being used for end-result assessment.</p>\n<p>Bowdoin College, Colby-Sawyer College, and Wellesley College have existing instruments that provided a starting point for this project. &nbsp;However, none of these instruments allow for easy comparison across institutions since the instruments have only been administered locally. For example, Colby-Sawyer College developed and administered its QLR test to freshmen and seniors to assess and evaluate the impact of an NSF supported <em>QL Across the Curriculum</em> initiative. At the end of the four-year evaluation process, the lack of national data on student QLR abilities left the Colby-Sawyer community to wonder about the level of the impact of the initiative.&nbsp; This dilemma is not new, nor is it restricted to Colby-Sawyer; Rita Colwell expressed this succinctly in when she stated:</p>\n<p>&ldquo;We do not really know if we are making progress [since]...we do not have genuine benchmarks for what constitutes quantitative literacy.&rdquo;</p>\n<p>This sentiment was echoed in 2008 in a paper in the American Mathematical Monthly which again stressed that most of these internal assessment tools have no national norms to compare to and the actual construct of &ldquo;quantitatively literate&rdquo; remains undeveloped.&nbsp; The QLR project described here aims to meet these needs by developing a valid and reliable test of QLR skills.&nbsp; In particular, the goals set forth in this NSF-supported project (NSF Grant DUE #1140562) were to design a QLR instrument that:</p>\n<ol>\n<li><strong>&nbsp; &nbsp; &nbsp;&nbsp;</strong>is non-proprietary,</li>\n<li><strong>&nbsp; &nbsp; &nbsp;&nbsp;</strong>provides a baseline of national QLR-scores from a variety of &nbsp; &nbsp;educational environments,</li>\n<li><strong>&nbsp; &nbsp; &nbsp;&nbsp;</strong>is reliable, and</li>\n<li><strong>&nbsp; &nbsp; &nbsp;&nbsp;</strong>has content validity.</li>\n</ol>\n<p>&nbsp;</p>\n<p>The QLRA test was created and piloted across the country by diverse institutions. &nbsp;</p>\n<ul>\n<li>In 2012 we had 10 schools pilot the test with 1,659 students.</li>\n<li>In 2013 11 institutions and 2,172 students piloted the refined version of the QLRA and 5 schools used our online test site. &nbsp;</li>\n<li>In 2014 we continued to offer the online test site through our 1 year no cost extension. &nbsp;The online site had 24 unique schools, 58 separate uses, and 2,169 students take the test. &nbsp;In addition we had at least 15 more schools using the test on their campuses (not all schools shared data as the pilot period of the grant was over), with more than 2,000 additional students.</li>\n<li>In 2015 we did not receive funding for our phase 2 proposal so have had to discontinue the online site. &nbsp;Most schools have switched to administering the test using software such as Blackboard and Moodle. &nbsp;As of March 19, 2015 we have had 18 new requests for use of the test.</li>\n</ul>\n<p>We wrote and...",
  "por_txt_cntn": "\nQuantitative Literacy/Reasoning (QLR) has been in the academic landscape for over two decades.  For the latter half of this period, academic institutions across the US have been shifting the focus of introductory/general education math undergraduate courses toward QLR, emphasizing the quantitative tools that students will need for successful decision making in their personal, professional, and civic lives.\n\nWhile QLR courses and curricula are finding wide dissemination, assessment of QLR (in terms of skills of individual students, and the effectiveness of curricula) remains primarily a local activity. There have been publications such as Achieving QL, and the AACU QL VALUE rubric; most current assessment efforts however, are localized to a single campus, a single course, or even a single classroom. This is due, in part, to the difficulties involved with assessment of QLR skills. Even at locations where QLR tests are implemented for placement purposes, tests are not being used for end-result assessment.\n\nBowdoin College, Colby-Sawyer College, and Wellesley College have existing instruments that provided a starting point for this project.  However, none of these instruments allow for easy comparison across institutions since the instruments have only been administered locally. For example, Colby-Sawyer College developed and administered its QLR test to freshmen and seniors to assess and evaluate the impact of an NSF supported QL Across the Curriculum initiative. At the end of the four-year evaluation process, the lack of national data on student QLR abilities left the Colby-Sawyer community to wonder about the level of the impact of the initiative.  This dilemma is not new, nor is it restricted to Colby-Sawyer; Rita Colwell expressed this succinctly in when she stated:\n\n\"We do not really know if we are making progress [since]...we do not have genuine benchmarks for what constitutes quantitative literacy.\"\n\nThis sentiment was echoed in 2008 in a paper in the American Mathematical Monthly which again stressed that most of these internal assessment tools have no national norms to compare to and the actual construct of \"quantitatively literate\" remains undeveloped.  The QLR project described here aims to meet these needs by developing a valid and reliable test of QLR skills.  In particular, the goals set forth in this NSF-supported project (NSF Grant DUE #1140562) were to design a QLR instrument that:\n\n      is non-proprietary,\n      provides a baseline of national QLR-scores from a variety of    educational environments,\n      is reliable, and\n      has content validity.\n\n\n \n\nThe QLRA test was created and piloted across the country by diverse institutions.  \n\nIn 2012 we had 10 schools pilot the test with 1,659 students.\nIn 2013 11 institutions and 2,172 students piloted the refined version of the QLRA and 5 schools used our online test site.  \nIn 2014 we continued to offer the online test site through our 1 year no cost extension.  The online site had 24 unique schools, 58 separate uses, and 2,169 students take the test.  In addition we had at least 15 more schools using the test on their campuses (not all schools shared data as the pilot period of the grant was over), with more than 2,000 additional students.\nIn 2015 we did not receive funding for our phase 2 proposal so have had to discontinue the online site.  Most schools have switched to administering the test using software such as Blackboard and Moodle.  As of March 19, 2015 we have had 18 new requests for use of the test.\n\n\nWe wrote and published a paper, Towards Developing a Quantitative Literacy and Reasoning Assessment Instrument, summarizing our results from the first two years of the pilot project.  This was published in the Numeracy journal in July 2014,  http://scholarcommons.usf.edu/numeracy/vol7/iss2/art4/.  We were able to establish the content validity and reliability of the instrument.  We were able to establish a baseline of national QR scores for institutions..."
 }
}