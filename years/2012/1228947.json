{
 "awd_id": "1228947",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC: Medium: Collaborative: Foundations of Application-Sensitive Access Control Evaluation",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Nan Zhang",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 653259.0,
 "awd_amount": 653259.0,
 "awd_min_amd_letter_date": "2012-08-17",
 "awd_max_amd_letter_date": "2013-04-24",
 "awd_abstract_narration": "Access control schemes are traditionally compared in terms of raw expressive power (i.e., the policies they can encode and how those policies can be changed); however, such comparisons ignore the needs of the application within which a scheme will be deployed.  For some applications, the most expressive scheme may be overly complex and not necessarily the best fit. To this end, this project investigates the suitability analysis problem: Given a system's access control workload, a set of candidate access control schemes, and a set of application-specific cost metrics, which scheme best meets the needs of the system?\r\n\r\nThe goal is to create a suitability-analysis framework that is sufficiently rigorous to be useful to researchers and theoreticians, while remaining accessible to security practitioners. Such a framework will help formalize an access control scheme's application-specific strengths and limitations, enable researchers to precisely describe the scenarios for which a scheme is best suited, allow assessment of the novelty and utility of proposed schemes, and help analysts diagnose shortcomings in existing systems.  In particular, the project will develop (1) an application-specific, workload-based framework for analyzing the suitability of access control schemes that is sufficiently rich to compare logical, extensional, and hybrid schemes in both sequential and concurrent systems; (2) a cost analysis component that quantifies a scheme's suitability using custom metrics; and (3) tools that automate a range of suitability analysis tasks.  A real-world security workload, PKI-based authentication and authorization on the web, will be used to evaluate the results.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lenore",
   "pi_last_name": "Zuck",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Lenore D Zuck",
   "pi_email_addr": "zuck@uic.edu",
   "nsf_id": "000118794",
   "pi_start_date": "2013-04-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "Hinrichs",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy L Hinrichs",
   "pi_email_addr": "hinrichs@uic.edu",
   "nsf_id": "000582672",
   "pi_start_date": "2012-08-17",
   "pi_end_date": "2013-04-24"
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Lenore",
   "pi_last_name": "Zuck",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Lenore D Zuck",
   "pi_email_addr": "zuck@uic.edu",
   "nsf_id": "000118794",
   "pi_start_date": "2012-08-17",
   "pi_end_date": "2013-04-24"
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Chicago",
  "inst_street_address": "809 S MARSHFIELD AVE M/C 551",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3129962862",
  "inst_zip_code": "606124305",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "IL07",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "W8XEAJDKMXH3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Chicago",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606077053",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "IL07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 653259.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>1. We developed methodologies and tools to guarantee access control, from the server&rsquo;s end, on access request. &nbsp;The basic approach is for the server to create views that take into account the permissions of a user, and only allow for access to the view.</span></p>\n<p>2. We studied &nbsp;how to impose access control policies that are common to non-IT people, e.g., those that restrict the path that led to data. &nbsp;We studied some comparison between relational and graph-based data bases with respect to search efficiency.&nbsp;</p>\n<p>3. We abstracted the mobility aspects of the the IPv6 protocols and analyzed it using a combination of techniques, revealing that (as was shown in earlier works) forwarding cycles may exist, however that there are not a problem, that is, &nbsp;if the system stabilizes for long enough, all forwarding cycles disappear. In effect we obtained a new simulation-based proof methodology that combines model checking and process algebraic ideas, and allows showing one system simulates another at the limit, for which we can derive some (infinitary) properties. &nbsp;We used this method to verify some properties of other protocols (such as TOR). We further identified a class of systems that are behaviorally self-similar and exhibit resilience to adversarial behavior. The results of this line of work were published in TGC 2015, HVC 2015, and EXPRESS 2016. There are still some unpublished results (an exercise in formal verification of a simple protocol whose proof isn't.)</p>\n<p>&nbsp;</p>\n<p>4. Memory access errors such as buffer overruns are notorious security vulnerabilities. There has been considerable interest in having a compiler ensure the safety of compiled code either through static verification or through instrumented runtime checks. While certifying compilation has shown much promise, it has not been practical, leaving code instrumentation as the next best strategy for compilation.We term such compilers Memory Error SanitizationCompilers (MESCs). MESCs are available as part of GCC, LLVM and MSVC suites. Due to practical limitations, MESCs typically apply instrumentation even-handedly and indiscriminately to every memory access, and are consequently prohibitively expensive and practical to only small code bases. We developed a methodology that applies state-of-the-art static analysis techniques to eliminate unnecessary runtime checks, resulting in more efficient and scalable defenses. The methodology was implemented on LLVMs Safecode, Integer Overflow, and Address Sanitizer passes, using static analysis of Frama-C and Codesurfer. The benchmarks demonstrate an improvement in runtime performance that makes incorporation of runtime checks a viable option for defenses.</p>\n<p>5. Our novel idea to verify probability 1 properties of probabilistic parametrized system is to postpone the \"de-probabilization\" to as a late stage as possible. &nbsp;This is in contrast to the leading approaches that have been used before, where the probabilistic elements (coin flips) were replaced by deterministic and non-deterministic ones. E.g., several years ago we proposed to replace coin flips by non-determinism, and occasionally (infinitely many times), for a consecutive bounded coin flips, have the coin tosses predetermined. This was approach was termed \"planner.\" Later works have used a \"pattern\" which is a variant on the planner. After the probabilistic selections are removed the system is purely non-deterministic and can be verified using a variety of methods. Yet, the planners/patterns are often elusive and some recent work attempt to derive them automatically. Our main observation is that they are not necessary. That is, if the goal is to verify a parameterized probabilistic system, then the planner approach is sound, however, they are not necessary. That is, that the original probabilistic parameterized systems can be abstracted directly into smaller probabilistic systems, &nbsp;and only then apply &nbsp;Markov-reasoning or any other tool to prove its correct &nbsp;(with probability 1)&nbsp;termination.&nbsp;</p>\n<p>We developed the theory of doing that using counter abstraction, which is a type of predicate abstraction that had been proven to be simple yet powerful in verification of parameterized systems. While developing the method we applied it on several very different examples (such as Ittai and Rodeh's leader election in a ring &nbsp;and self stabilization protocols) and it turned out to deal well even with systems that seem to be more suitable for regular model checking approach, which we found surprising. &nbsp;We were delighted (but not surprised!) to see that our method allowed for an easy automatic generation of a family of planners. Finally, it turned out that our method is also suitable to verify some properties that hold with a probability that depends on the system's parameter. E.g., Rabin's Choice Coordination protocol and P2P protocols for aggregation of values.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/05/2017<br>\n\t\t\t\t\tModified by: Lenore&nbsp;D&nbsp;Zuck</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n1. We developed methodologies and tools to guarantee access control, from the server?s end, on access request.  The basic approach is for the server to create views that take into account the permissions of a user, and only allow for access to the view.\n\n2. We studied  how to impose access control policies that are common to non-IT people, e.g., those that restrict the path that led to data.  We studied some comparison between relational and graph-based data bases with respect to search efficiency. \n\n3. We abstracted the mobility aspects of the the IPv6 protocols and analyzed it using a combination of techniques, revealing that (as was shown in earlier works) forwarding cycles may exist, however that there are not a problem, that is,  if the system stabilizes for long enough, all forwarding cycles disappear. In effect we obtained a new simulation-based proof methodology that combines model checking and process algebraic ideas, and allows showing one system simulates another at the limit, for which we can derive some (infinitary) properties.  We used this method to verify some properties of other protocols (such as TOR). We further identified a class of systems that are behaviorally self-similar and exhibit resilience to adversarial behavior. The results of this line of work were published in TGC 2015, HVC 2015, and EXPRESS 2016. There are still some unpublished results (an exercise in formal verification of a simple protocol whose proof isn't.)\n\n \n\n4. Memory access errors such as buffer overruns are notorious security vulnerabilities. There has been considerable interest in having a compiler ensure the safety of compiled code either through static verification or through instrumented runtime checks. While certifying compilation has shown much promise, it has not been practical, leaving code instrumentation as the next best strategy for compilation.We term such compilers Memory Error SanitizationCompilers (MESCs). MESCs are available as part of GCC, LLVM and MSVC suites. Due to practical limitations, MESCs typically apply instrumentation even-handedly and indiscriminately to every memory access, and are consequently prohibitively expensive and practical to only small code bases. We developed a methodology that applies state-of-the-art static analysis techniques to eliminate unnecessary runtime checks, resulting in more efficient and scalable defenses. The methodology was implemented on LLVMs Safecode, Integer Overflow, and Address Sanitizer passes, using static analysis of Frama-C and Codesurfer. The benchmarks demonstrate an improvement in runtime performance that makes incorporation of runtime checks a viable option for defenses.\n\n5. Our novel idea to verify probability 1 properties of probabilistic parametrized system is to postpone the \"de-probabilization\" to as a late stage as possible.  This is in contrast to the leading approaches that have been used before, where the probabilistic elements (coin flips) were replaced by deterministic and non-deterministic ones. E.g., several years ago we proposed to replace coin flips by non-determinism, and occasionally (infinitely many times), for a consecutive bounded coin flips, have the coin tosses predetermined. This was approach was termed \"planner.\" Later works have used a \"pattern\" which is a variant on the planner. After the probabilistic selections are removed the system is purely non-deterministic and can be verified using a variety of methods. Yet, the planners/patterns are often elusive and some recent work attempt to derive them automatically. Our main observation is that they are not necessary. That is, if the goal is to verify a parameterized probabilistic system, then the planner approach is sound, however, they are not necessary. That is, that the original probabilistic parameterized systems can be abstracted directly into smaller probabilistic systems,  and only then apply  Markov-reasoning or any other tool to prove its correct  (with probability 1) termination. \n\nWe developed the theory of doing that using counter abstraction, which is a type of predicate abstraction that had been proven to be simple yet powerful in verification of parameterized systems. While developing the method we applied it on several very different examples (such as Ittai and Rodeh's leader election in a ring  and self stabilization protocols) and it turned out to deal well even with systems that seem to be more suitable for regular model checking approach, which we found surprising.  We were delighted (but not surprised!) to see that our method allowed for an easy automatic generation of a family of planners. Finally, it turned out that our method is also suitable to verify some properties that hold with a probability that depends on the system's parameter. E.g., Rabin's Choice Coordination protocol and P2P protocols for aggregation of values. \n\n \n\n \n\n\t\t\t\t\tLast Modified: 01/05/2017\n\n\t\t\t\t\tSubmitted by: Lenore D Zuck"
 }
}