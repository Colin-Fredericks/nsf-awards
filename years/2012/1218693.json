{
 "awd_id": "1218693",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Real-Time Computing Using GPUs",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2012-08-15",
 "awd_exp_date": "2015-07-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2012-08-27",
 "awd_max_amd_letter_date": "2012-08-27",
 "awd_abstract_narration": "The computing industry recently experienced a major shift in CPU architectures with the advent of multicore chips.  This shift has necessitated the adoption of new programming models, algorithms, and analysis methods to fully exploit the parallelism inherent in multicore chip designs.  While advances in these areas are well underway, industry has already begun yet another architectural shift towards systems with heterogeneous processing elements.  Heterogeneity creates new challenges because the availability of different types of processing elements means that nontrivial choices must be made when allocating hardware resources to software components.\r\n \r\n\r\nOne of the most successful applications of heterogeneity today is in architectures in which powerful graphics processing units (GPUs) are used alongside general-purpose CPUs.  Though originally intended as special-purpose graphics accelerators, GPUs are now being widely used for non-graphics processing in numerous application domains, including many domains in which real-time constraints (e.g., deadline requirements) exist.  For example, envisioned automated automotive systems will require real-time sensing and tracking features that GPUs can accelerate.  The goal of this project is to determine which resource allocation methods best facilitate the support of such real-time applications on heterogeneous platforms that may have multiple CPUs and GPUs.  This goal is being met by undertaking a broad study of issues affecting the deployment and analysis of real-time applications implemented on GPU-enabled multicore platforms.  Broader impacts include joint research with industry colleagues, and the development of publicly-available open-source software that can be used by other institutions for research and teaching purposes.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanjoy",
   "pi_last_name": "Baruah",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Sanjoy K Baruah",
   "pi_email_addr": "Baruah@wustl.edu",
   "nsf_id": "000762080",
   "pi_start_date": "2012-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Anderson",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "James H Anderson",
   "pi_email_addr": "anderson@cs.unc.edu",
   "nsf_id": "000481767",
   "pi_start_date": "2012-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "201 S. Columbia St",
  "perf_city_name": "Chapel Hill",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275993175",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Real-time systems are systems in which some computations have deadline constraints. &nbsp;For example, when the brake pedal of a car is depressed, the car should begin to slow within a specified number of milliseconds. &nbsp;The computations that must be supported within a real-time system are usually called \"tasks.\" &nbsp;(A task is essentially just a computer program.) &nbsp;To save on hardware costs, it is often the case that many tasks with separate deadline requirements have to be supported on the same hardware platform. &nbsp;To ensure that each task meets its deadline requirements, a real-time scheduler must be used within the operating system that is cognizant of task deadlines and schedules tasks accordingly.</p>\n<p><br />From the perspective of designing and realizing real-time systems, one of the most profound recent developments in the computing arena is the advent of multicore computers. &nbsp;Such computers actually consist of multiple processors. &nbsp;Thus, a multicore computer can execute many tasks in parallel, i.e., at the same time. &nbsp;The introduction of parallelism greatly complicates the design of real-time schedulers and the analysis required for validating deadline requirements.</p>\n<p><br />In many applications domains, there is interest in augmenting ordinary computers with specialized computers that can accelerate certain computations. &nbsp;One particular kind of accelerator in which there is much current interest is a computational device called a graphics processing unit (GPU). &nbsp;GPUs were originally designed to accelerate graphics computations (such as the computations that produce the visual scenes that are displayed in computer gaming applications). &nbsp;However, the matrix-based mathematical nature of such computations is also seen in other settings, so the breadth of application domains where GPUs could be of use is expanding. &nbsp;For example, many high-end automobiles today employ cameras to monitor following distances, lane-keeping, etc. &nbsp;Computer vision algorithms are used to process the information from such cameras. &nbsp;The mathematical techniques employed by such algorithms are also matrix-based and can be sped up by using GPUs.</p>\n<p><br />For GPUs to be used alongside multicore computers &nbsp;in an application domain such as this, new resource allocation infrastructure, in the form of real-time schedulers and associated analysis for validating deadline requirements, is needed that takes into account the unique requirements and characteristics of GPUs. &nbsp;This project has been devoted to the development and evaluation of such infrastructure.</p>\n<p><br />This infrastructure has been produced in the form of a highly configurable system called GPUSync. &nbsp;GPUSync is used alongside existing real-time schedulers to enable tasks to share GPUs. &nbsp;GPUSync has over 9,000 configurations; a given configuration is defined by setting certain parameters. &nbsp;The main intellectual contributions of this project are threefold. &nbsp;First, GPUSync was conceived and implemented. &nbsp;Second, experiments were conducted to identify the \"best\" GPUSync configurations. &nbsp;Third, these best configurations were further evaluated in the context of a case study involving computer vision algorithms as used in automotive systems.</p>\n<p><br />In terms of broader impacts, the investigators presented talks on this work at numerous institutions, conferences, workshops, etc. &nbsp;Additionally, the results of this project formed the basis of the dissertations of two graduate students. &nbsp;The development of GPUSync has also led to follow-up work with researchers at General Motors Corp. on the usage of GPUs in automotive systems.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/12/2015<br>\n\t\t\t\t\tModified by: Sanjoy&nbsp;K&nbsp;Baruah</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nReal-time systems are systems in which some computations have deadline constraints.  For example, when the brake pedal of a car is depressed, the car should begin to slow within a specified number of milliseconds.  The computations that must be supported within a real-time system are usually called \"tasks.\"  (A task is essentially just a computer program.)  To save on hardware costs, it is often the case that many tasks with separate deadline requirements have to be supported on the same hardware platform.  To ensure that each task meets its deadline requirements, a real-time scheduler must be used within the operating system that is cognizant of task deadlines and schedules tasks accordingly.\n\n\nFrom the perspective of designing and realizing real-time systems, one of the most profound recent developments in the computing arena is the advent of multicore computers.  Such computers actually consist of multiple processors.  Thus, a multicore computer can execute many tasks in parallel, i.e., at the same time.  The introduction of parallelism greatly complicates the design of real-time schedulers and the analysis required for validating deadline requirements.\n\n\nIn many applications domains, there is interest in augmenting ordinary computers with specialized computers that can accelerate certain computations.  One particular kind of accelerator in which there is much current interest is a computational device called a graphics processing unit (GPU).  GPUs were originally designed to accelerate graphics computations (such as the computations that produce the visual scenes that are displayed in computer gaming applications).  However, the matrix-based mathematical nature of such computations is also seen in other settings, so the breadth of application domains where GPUs could be of use is expanding.  For example, many high-end automobiles today employ cameras to monitor following distances, lane-keeping, etc.  Computer vision algorithms are used to process the information from such cameras.  The mathematical techniques employed by such algorithms are also matrix-based and can be sped up by using GPUs.\n\n\nFor GPUs to be used alongside multicore computers  in an application domain such as this, new resource allocation infrastructure, in the form of real-time schedulers and associated analysis for validating deadline requirements, is needed that takes into account the unique requirements and characteristics of GPUs.  This project has been devoted to the development and evaluation of such infrastructure.\n\n\nThis infrastructure has been produced in the form of a highly configurable system called GPUSync.  GPUSync is used alongside existing real-time schedulers to enable tasks to share GPUs.  GPUSync has over 9,000 configurations; a given configuration is defined by setting certain parameters.  The main intellectual contributions of this project are threefold.  First, GPUSync was conceived and implemented.  Second, experiments were conducted to identify the \"best\" GPUSync configurations.  Third, these best configurations were further evaluated in the context of a case study involving computer vision algorithms as used in automotive systems.\n\n\nIn terms of broader impacts, the investigators presented talks on this work at numerous institutions, conferences, workshops, etc.  Additionally, the results of this project formed the basis of the dissertations of two graduate students.  The development of GPUSync has also led to follow-up work with researchers at General Motors Corp. on the usage of GPUs in automotive systems.\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 08/12/2015\n\n\t\t\t\t\tSubmitted by: Sanjoy K Baruah"
 }
}