{
 "awd_id": "1140191",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Transforming the Understanding, Assessment and Prediction of Teamwork Effectiveness in Software Engineering Education using Machine Learning",
 "cfda_num": "47.076",
 "org_code": "11040200",
 "po_phone": "7032922832",
 "po_email": "ptymann@nsf.gov",
 "po_sign_block_name": "Paul Tymann",
 "awd_eff_date": "2012-06-01",
 "awd_exp_date": "2015-05-31",
 "tot_intn_awd_amt": 33650.0,
 "awd_amount": 33650.0,
 "awd_min_amd_letter_date": "2012-05-22",
 "awd_max_amd_letter_date": "2012-05-22",
 "awd_abstract_narration": "In response to demands of the software engineering industry, this project is developing powerful machine learning-based methods to understand, assess and predict student learning of software engineering teamwork across globally-distributed teams. The project includes the following activities.  Objective and quantitative teamwork data are being collected on student activities in ongoing, jointly-taught undergraduate computer science classes at three geographically-distant institutions (San Francisco State, Florida Atlantic, and Fulda Universities). Novel machine learning tools are being applied to these data to discover models, rules and metrics that define student success in acquiring teamwork skills and that facilitate early intervention for teams at risk by identifying predictors of teamwork outcomes. With input from external evaluators, the methods and tools developed in this project are being refined and disseminated to educators for early adoption.   \r\n\r\nThe project advances the field of software engineering with new tools for assessing student software engineering teamwork skills. This project is the first to apply novel machine learning techniques to assess and predict student learning of these skills. In the era of global collaboration, the project is also assessing the impact of developing teamwork skills within globally-distributed teams. The participating US universities serve highly-diverse student populations; thus the project is preparing large numbers of students underrepresented in STEM fields to enter the software engineering profession and to successfully meet the challenges of communicating effectively in globally-distributed teams. As a result, the project is contributing both to diversifying and to maintaining the competitiveness of the US software engineering workforce.\r\n\r\nA training workshop for software engineering educators from across the California State University system and from a San Francisco community college is part of the project.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DUE",
 "org_div_long_name": "Division Of Undergraduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shihong",
   "pi_last_name": "Huang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shihong Huang",
   "pi_email_addr": "shihong@fau.edu",
   "nsf_id": "000407515",
   "pi_start_date": "2012-05-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Florida Atlantic University",
  "inst_street_address": "777 GLADES RD",
  "inst_street_address_2": "",
  "inst_city_name": "BOCA RATON",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "5612970777",
  "inst_zip_code": "334316424",
  "inst_country_name": "United States",
  "cong_dist_code": "23",
  "st_cong_dist_code": "FL23",
  "org_lgl_bus_name": "FLORIDA ATLANTIC UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "Q266L2NDAVP1"
 },
 "perf_inst": {
  "perf_inst_name": "Florida Atlantic University",
  "perf_str_addr": "777 Glades Road",
  "perf_city_name": "Boca Raton",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "334310991",
  "perf_ctry_code": "US",
  "perf_cong_dist": "23",
  "perf_st_cong_dist": "FL23",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "153600",
   "pgm_ele_name": "S-STEM-Schlr Sci Tech Eng&Math"
  },
  {
   "pgm_ele_code": "751300",
   "pgm_ele_name": "TUES-Type 1 Project"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0412",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001213DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "13XX",
   "app_name": "H-1B FUND, EHR, NSF",
   "app_symb_id": "045176",
   "fund_code": "1300XXXXDB",
   "fund_name": "H-1B FUND, EDU, NSF",
   "fund_symb_id": "045176"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 33650.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;A novel machine learning (ML) approach for assessing and, most importantly, predicting of learning outcomes in software engineering (SE) has been developed and validated. The approach is based on data from our joint software engineering classes concurrently taught at San Francisco State University (SFSU), Florida Atlantic University (FAU) and Fulda University, Germany (Fulda).</p>\n<p>Key activities related to the overall goals of the project include:&nbsp;</p>\n<ul>\n<li>Data collection from our joint software engineering classes at SFSU, FAU and Fulda, from Fall 2012 to Spring 2015</li>\n<li>Collected full set of data that consist of objective and quantifiable measures (e.g. time spent, counts of events/issues, tool usage like e-mails, hangout, postings etc.) suitable to more advanced data analysis techniques and those motivated by our teaching and teamwork evaluation experience</li>\n<li>Organizing the data into ML Training Database</li>\n<li>Development of ML software data analysis pipeline</li>\n<li>Running pilot ML experiment on small training database to test the concept </li>\n<li>Weekly project meetings at SFSU and bi-monthly or monthly Skype calls between SFSU, Fulda and FAU</li>\n<li>Meeting of SFSU team with external evaluators to check progress and get advise on next steps</li>\n<li>PIs&rsquo; visit to collaborator universities to give seminars on our projects</li>\n<li>Dissemination results in peer reviewed conferences and journals</li>\n</ul>\n<p>Key project outcomes:</p>\n<ul>\n<li>The system (methods and software implementation) for data collection and creation of ML training database is fully operational</li>\n<li>Deployed continuous data collection for three concurrent software engineering classes at SFSU, FAU and Fulda with more than 100 students, about 20 teams (both local and global) each year</li>\n<li>Collected student team activity data: basic data (student and team activity measures) have been collected from 12 global teams (SFSU - Fulda and SFSU - FAU) and 46 local teams from SFSU, comprising of over 300 students from Fall 2012 to Spring 2015</li>\n<li>For each of the 58 teams (local teams of 5 students, global team of 6 students), we collect over 50 Team Activity Measures (TAMs) derived from Student Activity Measures (SAMs). SAMs in turn consist of weekly time cards with several inputs each, logs of tool usage, and various counts such as submissions to source code repository, hence total of several thousand data points. This effort required close cooperation among all three schools (SFSU, FAU, Fulda) and complex management of software and infrastructure for data collection (done at SFSU).</li>\n<li>ML analysis system (algorithms, software) based on Random Forest (RF) is fully operational as well.</li>\n<li>Developed a ML analysis \"pipeline\" consisting of chosen ML techniques, accuracy measures and their robust estimations and create a set of software tools</li>\n<li>Initial results show that RF is able to predict with good accuracy performance of teams</li>\n<li>We discovered that the time used in team meetings and length and uniqueness of subject line comments for code submissions to code repository are powerful factors. These factors have strong predication value vs. final software deliveries. This was a surprising result but an intuitive one, which is consistent with our observations (which we verified after we discovered this). Hence we pay more attention to this in our teaching.</li>\n<li>Instead of using only Out of Bag (OOB) error estimate, commonly provided by RF, we also used recall in detecting teams that fail, at high precision operating points. By having two accuracy measures and verifying consistency in prediction, we can achieve better results.</li>\n</ul>\n<p>This project has provided opportunities for training and professional development for both students and faculty involved. During the project, we have produced Master&rsquo;s theses, pro...",
  "por_txt_cntn": "\n A novel machine learning (ML) approach for assessing and, most importantly, predicting of learning outcomes in software engineering (SE) has been developed and validated. The approach is based on data from our joint software engineering classes concurrently taught at San Francisco State University (SFSU), Florida Atlantic University (FAU) and Fulda University, Germany (Fulda).\n\nKey activities related to the overall goals of the project include: \n\nData collection from our joint software engineering classes at SFSU, FAU and Fulda, from Fall 2012 to Spring 2015\nCollected full set of data that consist of objective and quantifiable measures (e.g. time spent, counts of events/issues, tool usage like e-mails, hangout, postings etc.) suitable to more advanced data analysis techniques and those motivated by our teaching and teamwork evaluation experience\nOrganizing the data into ML Training Database\nDevelopment of ML software data analysis pipeline\nRunning pilot ML experiment on small training database to test the concept \nWeekly project meetings at SFSU and bi-monthly or monthly Skype calls between SFSU, Fulda and FAU\nMeeting of SFSU team with external evaluators to check progress and get advise on next steps\nPIs\u00c6 visit to collaborator universities to give seminars on our projects\nDissemination results in peer reviewed conferences and journals\n\n\nKey project outcomes:\n\nThe system (methods and software implementation) for data collection and creation of ML training database is fully operational\nDeployed continuous data collection for three concurrent software engineering classes at SFSU, FAU and Fulda with more than 100 students, about 20 teams (both local and global) each year\nCollected student team activity data: basic data (student and team activity measures) have been collected from 12 global teams (SFSU - Fulda and SFSU - FAU) and 46 local teams from SFSU, comprising of over 300 students from Fall 2012 to Spring 2015\nFor each of the 58 teams (local teams of 5 students, global team of 6 students), we collect over 50 Team Activity Measures (TAMs) derived from Student Activity Measures (SAMs). SAMs in turn consist of weekly time cards with several inputs each, logs of tool usage, and various counts such as submissions to source code repository, hence total of several thousand data points. This effort required close cooperation among all three schools (SFSU, FAU, Fulda) and complex management of software and infrastructure for data collection (done at SFSU).\nML analysis system (algorithms, software) based on Random Forest (RF) is fully operational as well.\nDeveloped a ML analysis \"pipeline\" consisting of chosen ML techniques, accuracy measures and their robust estimations and create a set of software tools\nInitial results show that RF is able to predict with good accuracy performance of teams\nWe discovered that the time used in team meetings and length and uniqueness of subject line comments for code submissions to code repository are powerful factors. These factors have strong predication value vs. final software deliveries. This was a surprising result but an intuitive one, which is consistent with our observations (which we verified after we discovered this). Hence we pay more attention to this in our teaching.\nInstead of using only Out of Bag (OOB) error estimate, commonly provided by RF, we also used recall in detecting teams that fail, at high precision operating points. By having two accuracy measures and verifying consistency in prediction, we can achieve better results.\n\n\nThis project has provided opportunities for training and professional development for both students and faculty involved. During the project, we have produced Master\u00c6s theses, providing students with independent studies, and published and prepared conference papers and journal papers.\n\nThe questions we try to answer in this research are: \"how people work in teams\", \"how to objectively assess team progress\" and \"how predict teamwork's outcome\". The answers t..."
 }
}