{
 "awd_id": "1217423",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Local Computation Algorithms",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Balasubramanian Kalyanasundaram",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2012-08-01",
 "awd_max_amd_letter_date": "2012-08-01",
 "awd_abstract_narration": "The ubiquitousness of massive data sets presents\r\ngreat challenges.  The difficulty of dealing with massive data\r\nsets is especially formidable when attempting to\r\nsolve computational problems in which both the inputs\r\nand the outputs to the computation are large.\r\nIn such a situation, it would be useful if one could find\r\nfaster ways of computing just the portion of the output that is required\r\nby the user.\r\n\r\nThis project aims to study \"local computation algorithms\",\r\nnamely algorithms that quickly compute only the portions of the\r\noutput that are required by the user,\r\nwithout performing the full computation.\r\nIn particular, local computation algorithms\r\nview only a miniscule portion of the input.\r\nThe PI considers a broad based approach, studying the application of\r\nlocal computation algorithms to a range of problems and\r\nsettings within algorithm design.\r\nThe focus of this research is on the question of when local computations\r\ncan be done in time that is sub-linear in the size of the input and output.\r\nThe proposed research will  develop techniques for constructing\r\nsuch algorithms and for understanding when such algorithms are\r\nnot possible.\r\n\r\nThe project will leverage known results from sub-linear time\r\nalgorithms, which for the most part have focused on the somewhat\r\ndifferent setting of  computational\r\nproblems in which the inputs are large but the outputs are small.\r\nIn addition, the project will investigate well-studied\r\nclasses of algorithmic techniques and focus on modifying them for\r\nuse in this new setting.   Such classes include algorithmic techniques\r\nfirst developed for parallel and distributed algorithms, as well as the\r\nextensively used greedy method.\r\nProblems from combinatorial optimization, graph theory and compressibility\r\nof strings  will be studied.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ronitt",
   "pi_last_name": "Rubinfeld",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ronitt Rubinfeld",
   "pi_email_addr": "ronitt@csail.mit.edu",
   "nsf_id": "000322655",
   "pi_start_date": "2012-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Avenue",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><pre>Classical models of algorithmic analysis assume that the algorithm reads an input,performs a computation and writes the answer to an output tape.&nbsp;&nbsp; <br />On massive data sets, such computations may not be feasible, as both the input and output may be too large for a single processor to process.&nbsp; <br />In such a situation, it would be useful if one could find faster ways of computing just the portion of the output that is required<br />by the user. <br /><br />In this project, we investigate the model of \"local computation algorithms\", which support queries such that after each query by the user to a specified location, the local computation algorithm quickly outputs the value of the output at that location (without knowledge of future requests). When more than one legal output exists for an input,&nbsp; <br />the local computation algorithm&nbsp; must answer queries in such a way that is consistent with a single legal output over time. For a given problem, the hope is that the query time and<br />space complexity of a local computation&nbsp; algorithm&nbsp; is proportional to the amount of the solution that is requested by the user. That is, the time and<br />space complexity should be sublinear in the size of the input and output to the problem, and should not require storing the history of all previous queries and answers.&nbsp;&nbsp; <br />It is furthermore desirable that the techniques are amenable to parallelization, that is, that different copies of the local computation algorithms can run, accessing the same<br />input, but without requiring coordinationg among their answers. Local computation algorithms satisfying these properties are useful for performing<br />cloud computations on large datasets.<br /><br />This research project develops standard techniques for constructing local computation algorithms.&nbsp; Much of the focus is on<br />combinatorial optimization problems such as algorithms for maintaining connectivity and low diameter of networks, and finding sparse connected subgraphs.&nbsp; In addition,<br />algorithms for locally decompressing data and correcting sample data are developed. <br />\n</pre><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/14/2014<br>\n\t\t\t\t\tModified by: Ronitt&nbsp;Rubinfeld</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Classical models of algorithmic analysis assume that the algorithm reads an input,performs a computation and writes the answer to an output tape.   \nOn massive data sets, such computations may not be feasible, as both the input and output may be too large for a single processor to process.  \nIn such a situation, it would be useful if one could find faster ways of computing just the portion of the output that is required\nby the user. \n\nIn this project, we investigate the model of \"local computation algorithms\", which support queries such that after each query by the user to a specified location, the local computation algorithm quickly outputs the value of the output at that location (without knowledge of future requests). When more than one legal output exists for an input,  \nthe local computation algorithm  must answer queries in such a way that is consistent with a single legal output over time. For a given problem, the hope is that the query time and\nspace complexity of a local computation  algorithm  is proportional to the amount of the solution that is requested by the user. That is, the time and\nspace complexity should be sublinear in the size of the input and output to the problem, and should not require storing the history of all previous queries and answers.   \nIt is furthermore desirable that the techniques are amenable to parallelization, that is, that different copies of the local computation algorithms can run, accessing the same\ninput, but without requiring coordinationg among their answers. Local computation algorithms satisfying these properties are useful for performing\ncloud computations on large datasets.\n\nThis research project develops standard techniques for constructing local computation algorithms.  Much of the focus is on\ncombinatorial optimization problems such as algorithms for maintaining connectivity and low diameter of networks, and finding sparse connected subgraphs.  In addition,\nalgorithms for locally decompressing data and correcting sample data are developed. \n\n\n\n\t\t\t\t\tLast Modified: 10/14/2014\n\n\t\t\t\t\tSubmitted by: Ronitt Rubinfeld"
 }
}