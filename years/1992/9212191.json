{
 "awd_id": "9212191",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "The Generality and Practicality of Reinforcement Learning   for Automatic Control",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Larry H. Reeker",
 "awd_eff_date": "1992-07-01",
 "awd_exp_date": "1994-12-31",
 "tot_intn_awd_amt": 59495.0,
 "awd_amount": 59495.0,
 "awd_min_amd_letter_date": "1992-06-29",
 "awd_max_amd_letter_date": "1993-05-28",
 "awd_abstract_narration": "Recent discoveries of the theoretical relationships between                     reinforcement learning and dynamic programming suggest exciting                 possibilities for developing automatic controllers that learn with              experience to follow optimal control strategies.  Combining                     reinforcement learning algorithms with the adaptive structure that              neural networks provide results in theoretically optimal                        controllers that have more flexibility, and thus are more general,              than current adaptive control techniques.  However, for                         reinforcement learning networks to be practical, the efficiency                 with which they learn must be improved. In previous work, the PI                identified one cause of slow learning to be difficulty of                       discovering useful features by the hidden units of the network.                 This difficulty has also been recognized within the                             supervisedlearning paradigm and a number of alternatives to the                 common error back propagation algorithm have been shown to                      significantly reduce learning time.  These ideas will be extended               to the reinforcement learning paradigm and their potential for                  reducing the learning time of reinforcement based networks will be              explored.  The objective is to alleviate the problem of training                hidden units and to identify any remaining limitations of                       reinforcement learning networks that restrict their generality and              practicality as real time control techniques.  The methods will                 include both simulation studies and implementations as controllers              of physical systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Charles",
   "pi_last_name": "Anderson",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Charles W Anderson",
   "pi_email_addr": "chuck.anderson@colostate.edu",
   "nsf_id": "000403856",
   "pi_start_date": "1992-07-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Colorado State University",
  "inst_street_address": "601 S HOWES ST",
  "inst_street_address_2": "",
  "inst_city_name": "FORT COLLINS",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "9704916355",
  "inst_zip_code": "805212807",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "COLORADO STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "LT9CXX8L19G1"
 },
 "perf_inst": {
  "perf_inst_name": "DATA NOT AVAILABLE",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "",
  "perf_st_name": "RI REQUIRED",
  "perf_zip_code": "",
  "perf_ctry_code": "",
  "perf_cong_dist": "",
  "perf_st_cong_dist": "",
  "perf_ctry_name": "",
  "perf_ctry_flag": "0"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "685600",
   "pgm_ele_name": "ARTIFICIAL INTELL & COGNIT SCI"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9264",
   "pgm_ref_txt": "RESEARCH INITIATION AWARD"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0193",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0193",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 1992,
   "fund_oblg_amt": 29461.0
  },
  {
   "fund_oblg_fiscal_yr": 1993,
   "fund_oblg_amt": 30034.0
  }
 ],
 "por": null
}