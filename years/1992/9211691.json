{
 "awd_id": "9211691",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Accelerated Vonvergence and Structure Determination         of the Backpropagation Neural Network",
 "cfda_num": "47.041",
 "org_code": "07020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Burka",
 "awd_eff_date": "1992-08-01",
 "awd_exp_date": "1996-01-31",
 "tot_intn_awd_amt": 99961.0,
 "awd_amount": 99961.0,
 "awd_min_amd_letter_date": "1992-05-20",
 "awd_max_amd_letter_date": "1993-02-04",
 "awd_abstract_narration": "Neural nets can identify and learn correlative patterns                         between sets of input data and corresponding target values.                     The most widely used neural net architecture, the back-                         propagation net, loosely mimics the human learning process and                  \"learns\" to recognize patterns relating input and output                        variables.  Such nets are trained by being repeatedly fed                       input data together with corresponding target outcomes.  After                  a sufficient number of training iterations, the net learns to                   recognize patterns in the data and, effectively, creates an                     internal model of the process governing the data.  The net can                  then use this internal model to make predictions for new input                  conditions.  Supervised training of back-propagation neural                     networks is usually achieved through the solution of an                         appropriate optimization problem.  Subsequently, training                       times are affected by the nonlinear programming algorithms                      used.  The training algorithm that is often used is the delta                   rule, which is a steepest descent derivative and as such                        exhibits a linear rate of convergence around a local minimum.                   This results in very long training time, often on the order of                  hours or days for practical problems.                                                                                                                           In this project the PI plans to: (1) accelerate training of                     the back-propagation network using Newton type algorithms, (2)                  determine network structure through the use of the singular                     value decomposition of the analytic hessian, (3) use the                        concept of a Minimal Spanning Network to derive a network of                    linear elements that will provide a performance lower bound on                  the neural network, and (4) impose appropriate bounds (or                       constraints) on design variables to enhance convergence.  He                    hopes that the results will significantly speed up the                          training of neural networks.  The structure of both the                         analytic gradients and the analytic hessian will be exploited                   in an implementation of the back-propagation algorithm on                       parallel computers, resulting in further increases in speed                     up.  With such speed up, it will be possible to tackle                          difficult industrially relevant problems in a reasonable time                   frame.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CBET",
 "org_div_long_name": "Division of Chemical, Bioengineering, Environmental, and Transport Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Luke",
   "pi_last_name": "Achenie",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Luke E Achenie",
   "pi_email_addr": "achenie@vt.edu",
   "nsf_id": "000107812",
   "pi_start_date": "1992-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Connecticut",
  "inst_street_address": "438 WHITNEY RD EXTENSION UNIT 1133",
  "inst_street_address_2": "",
  "inst_city_name": "STORRS",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "8604863622",
  "inst_zip_code": "062699018",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CT02",
  "org_lgl_bus_name": "UNIVERSITY OF CONNECTICUT",
  "org_prnt_uei_num": "",
  "org_uei_num": "WNTPS995QBM7"
 },
 "perf_inst": {
  "perf_inst_name": "DATA NOT AVAILABLE",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "",
  "perf_st_name": "RI REQUIRED",
  "perf_zip_code": "",
  "perf_ctry_code": "",
  "perf_cong_dist": "",
  "perf_st_cong_dist": "",
  "perf_ctry_name": "",
  "perf_ctry_flag": "0"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "136000",
   "pgm_ele_name": "EWFD-Eng Workforce Development"
  },
  {
   "pgm_ele_code": "140300",
   "pgm_ele_name": "Proc Sys, Reac Eng & Mol Therm"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9231",
   "pgm_ref_txt": "SUPPL FOR UNDERGRAD RES ASSIST"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 1992,
   "fund_oblg_amt": 89961.0
  },
  {
   "fund_oblg_fiscal_yr": 1993,
   "fund_oblg_amt": 10000.0
  }
 ],
 "por": null
}