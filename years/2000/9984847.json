{
 "awd_id": "9984847",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Developing and Evaluating a Spatio-temporal Representation for Analysis, Modeling, Recognition and Synthesis of Facial Expressions",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2000-07-01",
 "awd_exp_date": "2005-06-30",
 "tot_intn_awd_amt": 301106.0,
 "awd_amount": 301106.0,
 "awd_min_amd_letter_date": "2000-04-05",
 "awd_max_amd_letter_date": "2003-06-05",
 "awd_abstract_narration": "This is the first year of funding of a 4-year continuing award. The objective of this research is to lay the\r\ngroundwork for machines that are capable of accurate recognition and realistic synthesis of facial expressions. The approach is to develop and validate a dynamic spatio-temporal representation of facial movements, To this end, the PI will develop and evaluate methodologies for. robust analysis and modeling of facialmovements from video (so as to allow for unencumbered measurement in noninvasive interfaces). Facial activity is inherently dynamic in nature; therefore, automatic recognition of expressions from video and realistic animation of facial motion require a detailed dynamic representation of facial action. The PI will develop an analysissynthesis framework wherein model-based synthesis is used to analyze facial movement, to construct a spatio-temporal 3D representation of facial action that encodes the dynamics inherent in facialmotion. He will then evaluate the representation by analyzing videos of many human subjects making facial expressions, and by testing the synthesis of realistic facial motions. This research will provide a detailed scientific understanding of how people make facial expression and how recognition of facial expressions is possible, and thus will lay the foundation for systems that recognize human expressions and emotions, read lips, generate realistic facial animations, and code facial movements, which will form a vital component in the next generation of human-machine interfaces.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Irfan",
   "pi_last_name": "Essa",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Irfan A Essa",
   "pi_email_addr": "irfan@cc.gatech.edu",
   "nsf_id": "000307835",
   "pi_start_date": "2000-04-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Tech Research Corporation",
  "perf_str_addr": "926 DALNEY ST NW",
  "perf_city_name": "ATLANTA",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303186395",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "684500",
   "pgm_ele_name": "HUMAN COMPUTER INTER PROGRAM"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0100",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0100",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0101",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "app-0101",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0102",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0102",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0103",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0103",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2000,
   "fund_oblg_amt": 75493.0
  },
  {
   "fund_oblg_fiscal_yr": 2001,
   "fund_oblg_amt": 75127.0
  },
  {
   "fund_oblg_fiscal_yr": 2002,
   "fund_oblg_amt": 73169.0
  },
  {
   "fund_oblg_fiscal_yr": 2003,
   "fund_oblg_amt": 77317.0
  }
 ],
 "por": null
}