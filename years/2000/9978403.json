{
 "awd_id": "9978403",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Memory-Based Operant Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Edwina L. Rissland",
 "awd_eff_date": "1999-12-15",
 "awd_exp_date": "2004-11-30",
 "tot_intn_awd_amt": 338333.0,
 "awd_amount": 354483.0,
 "awd_min_amd_letter_date": "1999-12-15",
 "awd_max_amd_letter_date": "2003-05-29",
 "awd_abstract_narration": "The PI will develop a cognitively plausible reinforcement learning (RL) architecture as a model of instrumental learning in animals and robots.  Although RL was initially inspired by animal learning phenomena, the field has since developed mainly by addressing AI concerns.  A major limitation of current RL architectures as cognitive theories is the representation of state space.  Models that maintain explicit state representations (such as Q~tables) are limited to simple domains with only a few variables, while models that represent the state space implicitly (e.g., using a neural net function approximator) require large amounts of training data and unreasonably long training times compared to real animals.  The PI's approach is to develop specialized representations of state space that are appropriate for modeling animal behavior and can support desired generalizations.  The simulated animal's working memory will encode sensory stimuli, state change events, and the animal's own actions.  An explicit state representation would encode the conjunction of all these variables, generating a combinatorial explosion. The proposed alternative approach is for the model to form conjunctions of selected variables, allowing it to incrementally expand its state description while focusing on just those dimensions that are relevant to the task being learned.   Heuristics based on fast, single-layer neural net learning will be developed to select useful conjunctions as a function of recent experience.  The PI also will investigate matching the current state of working memory with records of entire past states, or episodes, in order to predict reward.  A flexible architecture will be developed for representing actions in a parameterized manner (so as to provide infinite variability), and with temporal duration (allowing stimuli and rewards to arrive in the midst of execution).   Finally, there will be mechanisms for coping with failure of an action to execute successfully or to produce an expected reward; this will provide the basis for modeling phenomena such as effects of partial reinforcement schedules and increased behavioral variability during extinction.   If successful, this work will advance the state of the art of reinforcement learning by introducing new techniques for handling complex state and action spaces.  This has important implications for theories of animal cognition, for robots that learn by exploration and experimentation, and for robots intended to learn from human teachers.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Touretzky",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "David S Touretzky",
   "pi_email_addr": "dst@cs.cmu.edu",
   "nsf_id": "000191816",
   "pi_start_date": "1999-12-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 FORBES AVE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "685600",
   "pgm_ele_name": "ARTIFICIAL INTELL & COGNIT SCI"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0100",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0100",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0101",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "app-0101",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0102",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0102",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0103",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0103",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2000,
   "fund_oblg_amt": 118085.0
  },
  {
   "fund_oblg_fiscal_yr": 2001,
   "fund_oblg_amt": 112760.0
  },
  {
   "fund_oblg_fiscal_yr": 2002,
   "fund_oblg_amt": 117488.0
  },
  {
   "fund_oblg_fiscal_yr": 2003,
   "fund_oblg_amt": 6150.0
  }
 ],
 "por": null
}