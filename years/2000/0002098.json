{
 "awd_id": "0002098",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Robust and Scalable On-Line NDP Designs and Applications to Semiconductor Process Optimization",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Paul Werbos",
 "awd_eff_date": "2000-10-01",
 "awd_exp_date": "2004-09-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2000-09-21",
 "awd_max_amd_letter_date": "2000-09-21",
 "awd_abstract_narration": "0002098\r\nSi\r\n\r\nDespite all the technical advances today in the fields of micro-processors and control system design, one key component is still missing, the design of a generic learning system (which will be referred to as a 'learner' hereafter in the proposal).  The learner will have a final product in the form of either software or hardware that learns to improve its performance through interactions with the environment.  In addition to the lack of an explicit model for the environment, explicit performance feedbacks are delayed, i.e., they are only available at the end of a long sequence of actions and consequences.  A problem of this nature is beyond the scope of classical adaptive control theory.\r\n\r\nIn recent decades, new schools of thinking represented by Reinforcement Learning (RL) based on Neural Dynamic Programming (NDP) have surfaced.  In this approach, the learner observes an input state (which can be the current state or a predicted future state) and then produces an 'action' or 'control' signal to apply back to the environment.  Consequently, an 'evaluation' signal is created by a critic network to comment on the effectiveness of the action taken .  The goal of learning is to generate optimal actions leading to a maximal reward.  Layered neural networks are the key implementation blocks for the learner.  Neural networks are used to provide both the action signal and the evaluation signal.\r\n\r\nLearners have demonstrated their effectiveness in a number of difficult tasks.  However, learners are usually neural networks performing predictive tasks such as generating action values or action evaluation values.  When little is known about the environment or the task, the learner must acquire a system level knowledge to first produce the action and then the evaluation.  This requires the components inside the learner to work together.  Furthermore, how can one implement a human-machine interface for different applications without 'cheating' by letting the learner truly learn on its own and 'on-the-fly'?\r\n\r\nThis project will address these basic issues, using problems from semiconductor manufacturing as a testbed.  It will seek reliable system designs in the form of mathematical learning algorithms.  It will try to achieve more stability and quicker outcomes from the learner, namely higher success rates with fewer learning trials.  Attention will be paid to the configuration, algorithm parameterization, system input-output and performance measure specification, and all other issues relevant to the learner design.  The learner will develop input releases and queuing policies for an industrial scale semiconductor manufacturing facility.  The purpose of this exercise is to examine the scalability, reliability, and generality of the learner design.\r\n\r\nA successful implementation of this research would represent a significant step toward a truly human-like system that learns on its own and improves its performance over time.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jennie",
   "pi_last_name": "Si",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jennie Si",
   "pi_email_addr": "si@asu.edu",
   "nsf_id": "000292573",
   "pi_start_date": "2000-09-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "660 S MILL AVENUE STE 204",
  "perf_city_name": "TEMPE",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852813670",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "150400",
   "pgm_ele_name": "GOALI-Grnt Opp Acad Lia wIndus"
  },
  {
   "pgm_ele_code": "151800",
   "pgm_ele_name": "CONTROL, NETWORKS, & COMP INTE"
  },
  {
   "pgm_ele_code": "151900",
   "pgm_ele_name": "INTEGRATIVE SYSTEMS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "1504",
   "pgm_ref_txt": "GRANT OPP FOR ACAD LIA W/INDUS"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0100",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0100",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2000,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": null
}