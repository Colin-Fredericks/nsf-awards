{
 "awd_id": "0083865",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Biocomplexity Incubation Activity:  Coordination of Perception and Spoken Language Processes",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Guy Van Orden",
 "awd_eff_date": "2000-09-15",
 "awd_exp_date": "2003-08-31",
 "tot_intn_awd_amt": 46243.0,
 "awd_amount": 29398.0,
 "awd_min_amd_letter_date": "2000-08-30",
 "awd_max_amd_letter_date": "2003-08-11",
 "awd_abstract_narration": "Human speech processing engages multiple neural resources, exhibits individual neural reorganization and variation in response to system perturbations/disorders, evolves along and is also constrained by temporal processes, and responds to statistical properties in the language environment.  Human speech perception comprises not only auditory perceptual processes but also visual ones.  For example, seeing a talker enhances the ability to accurately perceive speech in noise.  Auditory and visual processing of the speech signal is a biocomplex phenomenon.  During audiovisual speech perception, information is integrated across perceptual systems to give rise to unitary speech percepts.  This integration implies the coordination of perceptual, psycholinguistic, and possibly cognitive systems such as attention.  Perception emerges from processing at the levels of cortical and sub-cortical brain structures, but perception cannot be reduced simply to its underlying neural mechanisms, it must also be accounted for in behavioral terms.  Speech perception emerges across temporal scales, including the scale of development and the scales of communication.  Speech perception also is responsive to environmental demands, as is evident in the development of perceptual skills by expert deaf lipreaders.  This Biocomplexity Incubation Activity award will support a project that seeks to create a development context for researchers who might solve the problem of how the auditory and visual perceptual systems are integrated with the spoken language system, but who have not yet had the opportunity to learn enough about each other's fields and perspectives to propose a research program.  Researchers with expertise in visual psychophysics and perception, multimodal integration, auditory and visual speech perception, neuroanatomy and neurophysiology, and computational modeling will meet in a regularly scheduled research seminar covering visual and auditory perception in relation to spoken language processing.  The seminar will include demonstrations of relevant phenomena and experimental methods/apparatus.  Demonstrations for the seminar are intended to teach and also generate discussion.  They will include examples such as the McGurk effect, sinewave speech, point light speech, random-dot motion effects, structure from motion and others.  The research seminar will be assisted by an undergraduate student who will help to create the demonstrations.  These demonstrations will be made available on the House Ear Institute (HEI) Web site.  The seminar will develop hypotheses and methods to form the basis for future collaborative research.  The foci will be auditory perception, visual perception, audiovisual integration, and visual speech perception enhancement.  A workshop will conclude the research seminar.  Its purposes are to present the generated hypotheses and methods and to obtain feedback.  Presentations will outline the biocomplexity issues addressed in the seminar, the key lines of research identified to be of critical importance, and the experimental and computational approaches following those lines.  Expert panelists from other Southern California institutions will participate in the workshop.  A final report on the project and the workshop will be prepared for the HEI Web site.\r\n\r\nThe use of spoken language is a fundamental distinguishing characteristic of humans, but knowledge is incomplete regarding how humans accomplish it.  The particular focus of this project is to understand how the perceptual systems of vision and audition process linguistically relevant information.  A complete understanding of perception and language will need to comprise links between levels of explanation, from the neural to the behavioral.  Societal use of this fundamental knowledge will be in such areas as that of enhancing learning and teaching, ameliorating the effects of diseases such as stroke and impairments such as hearing loss, and developing artificial systems for processing language (e.g., automatic speech recognition and machine language translation).\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Edward",
   "pi_last_name": "Auer",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Edward T Auer",
   "pi_email_addr": "eauer@gwu.edu",
   "nsf_id": "000211491",
   "pi_start_date": "2003-08-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Lynne",
   "pi_last_name": "Bernstein",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Lynne E Bernstein",
   "pi_email_addr": "lbernste@gwu.edu",
   "nsf_id": "000575826",
   "pi_start_date": "2000-08-30",
   "pi_end_date": "2003-08-11"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Kello",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher T Kello",
   "pi_email_addr": "ckello@ucmerced.edu",
   "nsf_id": "000176884",
   "pi_start_date": "2000-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "House Ear Institute",
  "inst_street_address": "2100 West Third Street",
  "inst_street_address_2": "",
  "inst_city_name": "Los Angeles",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2134834431",
  "inst_zip_code": "900571922",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": null,
  "org_prnt_uei_num": null,
  "org_uei_num": null
 },
 "perf_inst": {
  "perf_inst_name": "House Ear Institute",
  "perf_str_addr": "2100 West Third Street",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900571922",
  "perf_ctry_code": "US",
  "perf_cong_dist": "34",
  "perf_st_cong_dist": "CA34",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "520900",
   "pgm_ele_name": "ENVIR SOCIAL & BEHAVIOR SCIENC"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "1366",
   "pgm_ref_txt": "BIOCOMPLEXITY"
  },
  {
   "pgm_ref_code": "5209",
   "pgm_ref_txt": "ENVIR SOCIAL & BEHAVIOR SCIENC"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0100",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0100",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2000,
   "fund_oblg_amt": 29398.0
  }
 ],
 "por": null
}