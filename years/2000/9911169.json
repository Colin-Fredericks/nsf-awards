{
 "awd_id": "9911169",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Learning Sequences in Dynamic Decision Tasks:  Focusing and Starting Small",
 "cfda_num": "47.075",
 "org_code": "04050100",
 "po_phone": "7032927263",
 "po_email": "roconnor@nsf.gov",
 "po_sign_block_name": "Robert O'Connor",
 "awd_eff_date": "2000-02-15",
 "awd_exp_date": "2004-02-29",
 "tot_intn_awd_amt": 110213.0,
 "awd_amount": 110213.0,
 "awd_min_amd_letter_date": "2000-02-28",
 "awd_max_amd_letter_date": "2004-01-08",
 "awd_abstract_narration": "9911169\r\nGibson, Faison\r\nLearning Sequences in Dynamic Decision Tasks: Focusing and Starting Small\r\n\r\nIn many fast-paced, repeated decisions, interpreting the sequence of events up to a given decision point is important for making good decisions. For instance, the order in which a person receives offers in an interactive bargaining session (e.g., a credit collector negotiating a deal with a debtor) often influences whether a given offer will be accepted or rejected. Starting offers too high or too low, or adding and subtracting conditions at different points in the process, can all influence the\r\noutcome. It is important for the person making the offers to understand this sequential structure. A grasp of the relevant sequential structure is similarly important for making good decisions in fast-paced tasks like air traffic control, police dispatch, and firefighting as well as commodity and financial markets. Evidence from experimental dynamic decision environments indicates that decision makers are at best slow in developing this ability. This research extends two learning\r\nmodels, stimulus-response (S-R) and simple recurrent neural networks (SRN), to derive competing recommendations for improving decision makers' learning under such dynamic conditions. These recommendations permit the predictions of the two models to be distinguished, a difficulty in past post-hoc analyses. The performance of the two simulation models will be compared experimentally with that of human subjects. The first experiment tests the S-R model's recommendation to focus\r\nthe options considered. Under the SRN model's assumptions, this recommendation actually increases the amount of information that must be processed for each decision, thereby hurting learning. The second experiment contrasts the S-R model's recommendation to focus on only the relevant sequences with the SRN model's recommendation to start training small with short sequences, not always the most relevant, first. Results will increase our understanding of which\r\nrecommendations improve learning most, as well as of how to model dynamic decision making appropriately.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Faison",
   "pi_last_name": "Gibson",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Faison P Gibson",
   "pi_email_addr": "fpgibson@umich.edu",
   "nsf_id": "000352465",
   "pi_start_date": "2000-02-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "Regents of the University of Michigan - Ann Arbor",
  "perf_str_addr": "1109 GEDDES AVE STE 3300",
  "perf_city_name": "ANN ARBOR",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091015",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132100",
   "pgm_ele_name": "Decision, Risk & Mgmt Sci"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0100",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0100",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2000,
   "fund_oblg_amt": 110213.0
  }
 ],
 "por": null
}