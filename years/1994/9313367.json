{
 "awd_id": "9313367",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Explanation-Based Neural Network Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Larry H. Reeker",
 "awd_eff_date": "1993-12-15",
 "awd_exp_date": "1997-10-31",
 "tot_intn_awd_amt": 355860.0,
 "awd_amount": 353181.0,
 "awd_min_amd_letter_date": "1994-01-05",
 "awd_max_amd_letter_date": "1997-06-10",
 "awd_abstract_narration": "This  research  seeks  to combine the two primary  paradigms  for  machine   learning: inductive and analytical learning.  Inductive  methods   such as instance-based and neural network learning  can  reliably   learn  simple functions from noisy data,  but  require  vast  numbers of  training examples in order to scale up to  very  complex  functions.  In  contrast,  analytical  methods  such  as  explanation-based learning  can learn complex functions from much  less  data, but rely upon strong prior knowledge on the  part  of  the learner.  Much current research in machine learning seeks  to  combine the best of both approaches, to obtain methods that learn  more  correct  generalizations from approximate  prior  knowledge  together with observed data.  The proposed research takes a novel  approach to  this problem:  unifying neural network learning  and  explanation-   based learning.  More specifically, this  research  will  build  on  the recently developed explanation-based  neural  network  (EBNN)  learning   method.   Preliminary  research   has  demonstrated experimentally that  EBNN can generalize better from  fewer  examples  than pure inductive learning if accurate  domain  knowledge is available, and that it degrades gracefully with  the  quality  of  the  learner's prior knowledge. This  research  will  explore  more  fully  the  space  of   combined  neural  net  and  explanation-based methods, focusing on issues such as scaling  up  to  more complex learning tasks, alternative types of information  that   can  be  extracted  from   explanations  based  on  neural  networks, operating robustly over the  entire spectrum from  very  strong   to   very   weak  prior  knowledge,   and    alternative  representations for the domain theory and target  function.  EBNN  learning  will  be  applied  to two different  task  domains.  If  successful,  this  research could produce learning  methods  that  scale  up  to  more practical problems, and lead  to  a   clearer  understanding of the  correspondence between symbolic  and  neural  network approaches.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tom",
   "pi_last_name": "Mitchell",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Tom M Mitchell",
   "pi_email_addr": "Tom.Mitchell@cs.cmu.edu",
   "nsf_id": "000167874",
   "pi_start_date": "1993-12-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 FORBES AVE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "685600",
   "pgm_ele_name": "ARTIFICIAL INTELL & COGNIT SCI"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0194",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0194",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0195",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0195",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0196",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0196",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0197",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0197",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 1994,
   "fund_oblg_amt": 116619.0
  },
  {
   "fund_oblg_fiscal_yr": 1995,
   "fund_oblg_amt": 115271.0
  },
  {
   "fund_oblg_fiscal_yr": 1996,
   "fund_oblg_amt": 86383.0
  },
  {
   "fund_oblg_fiscal_yr": 1997,
   "fund_oblg_amt": 34908.0
  }
 ],
 "por": null
}