{
 "awd_id": "9720145",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Complexity of Neural Networks for Applications",
 "cfda_num": "47.049",
 "org_code": "03040100",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Michael Steuerwalt",
 "awd_eff_date": "1997-08-15",
 "awd_exp_date": "2002-03-31",
 "tot_intn_awd_amt": 75000.0,
 "awd_amount": 75000.0,
 "awd_min_amd_letter_date": "1997-09-09",
 "awd_max_amd_letter_date": "2001-08-29",
 "awd_abstract_narration": "Kon  9720145       The investigator studies neural network architectures and  applications of wavelet techniques to investigate neural  networks' complexity.  Wavelets have been established as a rich  and useful family of expansion functions.  The investigator  studies further the recovery of functions (in particular  representations of visual images) from their wavelet transforms.  Issues of stability and complexity, which have not up to now been  addressed in his proof of the Marr conjecture and related  analysis of the Mallat conjecture, are studied.  An important  current question regards the complexity of such networks (i.e.,  their essential size) for the completion of desired tasks.  The  investigator studies two types, so-called functional and logical  networks.  Functional networks have received a good deal of  attention, and a coherent theory has established that they are  essentially orthogonal (or more general) expansion engines.  The  homology between the structure of networks and expansion tasks  has allowed establishing the connection of wavelet convergence  results with network complexity issues.  The investigator examines  the class of so-called logical networks as a needed completion of  available network architectures for the execution of intelligent  tasks.  In addition he works to show that wavelet-based neural  networks achieve lower bounds on complexities of neural nets for  given tasks.  These results move toward a general complexity  theory for neural nets on the order of current computational  complexity theory for serial and parallel computer architectures.  Such a complexity theory is expected to be a hybrid of current  discrete and continuous computational complexity theories.       The global purpose of this project is a mathematical study  of neural network architectures that implement some of the  theoretical complexity results that the investigator obtains.  Neural networks as models of parallel distributed computing are  currently the leading architectures holdi ng a promise of  artificially emulating intelligent systems, as has been indicated  in many of their current applications (including mortgage  decisions, commercial stock market analysis applications,  chemical and thermal homeostasis control systems, satellite image  analysis, etc.).  A major unanswered question in the development  of such systems is the fundamental issue of how large a network  needs to be in order to perform specific intelligent functions.  One type of task that current so-called \"functional\" neural  architectures have difficulty in dealing with is artificial  visual recognition and related tasks involved in the general area  of robotics.  This difficulty seems to be an inherent part of the  functional neural architectures under current study, and the  investigator develops architectures involving so-called \"logical\"  components, which act essentially as algorithmic engines.  In  particular such network architectures are necessary for  artificial vision tasks, and prototypes of such tasks are  simulated computationally with the aid of graduate students  working on the project.  Wavelets are currently considered to be  one of the most useful tools for representing the types of  input-output functions implemented in neural networks.  A more  general question regarding the complexity and size of neural  networks accomplishing real-world tasks is addressed through  application of wavelet techniques to network construction.  In  particular, functional neural networks may achieve their optimal  performance using wavelets as activation functions.  There is a  larger question here regarding whether wavelet techniques are the  best possible for the implementation of functional neural network  architectures, which is a conjecture the investigator has made  and investigates.  The computational aspects of the project are  aided by associated groups at Howard University and Bryn Mawr  College, the Howard group involving a number of graduate  students.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Kon",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Mark A Kon",
   "pi_email_addr": "mkon@bu.edu",
   "nsf_id": "000199671",
   "pi_start_date": "1997-09-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Trustees of Boston University",
  "inst_street_address": "1 SILBER WAY",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173534365",
  "inst_zip_code": "022151703",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "TRUSTEES OF BOSTON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "THL6A6JLE1S7"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of Boston University",
  "perf_str_addr": "1 SILBER WAY",
  "perf_city_name": "BOSTON",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "022151703",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126600",
   "pgm_ele_name": "APPLIED MATHEMATICS"
  },
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0197",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0197",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 1997,
   "fund_oblg_amt": 75000.0
  }
 ],
 "por": null
}