{
 "awd_id": "0415273",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Automated Tactilization of  Graphical Images: Full Access to Math, Science, and Engineering for Blind Students",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2004-08-15",
 "awd_exp_date": "2009-07-31",
 "tot_intn_awd_amt": 0.0,
 "awd_amount": 795988.0,
 "awd_min_amd_letter_date": "2004-08-03",
 "awd_max_amd_letter_date": "2008-05-30",
 "awd_abstract_narration": "Graphical images (line graphs, bar charts, diagrams, illustrations, etc.) are prevalent in math, science, and engineering (MSE) textbooks at all educational levels.  But while studies have shown that tactual perception is the best modality for comprehension of graphical images by people who are visually impaired, the graphical images found in textbooks typically aren't available in this format.  Visually impaired students' lack of full access to the contents of textbooks impedes their learning, development, and success in MSE careers, areas in which individuals with disabilities are underrepresented.  This project seeks to address this problem, by developing innovative ways to overcome obstacles to the timely translation of graphical images into a tactual format.  The needs of two user communities will be addressed: transcribers who translate graphical images into tactual formats within low- and high-production environments; and students who are in MSE classes at the K-12 and postsecondary education levels, are blind, and read Braille.  To these ends, the PI has assembled an interdisciplinary team with expertise in image processing, machine learning, IR, HCI, experiment design, and addressing the needs of students with disabilities.  The PI and his team will design and develop the Tactile Graphics Assistant (TG Assistant), a set of plug-ins for Adobe Photoshop and Illustrator, which will support transcribers in transforming, as automatically and intelligently as possible, graphical images into a high-quality tactual form that can be reproduced and then used by students who are blind.  Empirical studies will be conducted to better understand the perception of tactile graphics, and to inform the design of prediction models to estimate image comprehension time and comprehension accuracy, the application of machine learning techniques to classify images by their type, and the design of image processing algorithms to carry out the steps (appropriate for the image type) to translate an image into a tactual form.  A user-centered design approach will be followed during the development of the TG Assistant.  Project benefits will be documented by three proof-of-concept activities, wherein the TG Assistant will be used to provide access to textbook images to three students at the K-8, high school, and postsecondary education levels.  \r\n\r\nBroader Impact. Tactual access to graphical images will improve blind students' learning, performance, retention, and potential to succeed in MSE careers.  Project outcomes will include invaluable data on the tactual perception of tactile graphics, new image processing and classification algorithms, and a usable tool to streamline the translation of graphical images into a tactual format.  Research findings on the translation of graphical images will be summarized as a set of guidelines and distributed to transcribers. The PI will make an effort to incorporate the guidelines and TG Assistant into transcriber training programs.  The research team includes individuals from under-represented groups (women, minority, and disabled individuals.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Ladner",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Richard E Ladner",
   "pi_email_addr": "ladner@cs.washington.edu",
   "nsf_id": "000438222",
   "pi_start_date": "2004-08-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sheryl",
   "pi_last_name": "Burgstahler",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sheryl Burgstahler",
   "pi_email_addr": "sherylb@u.washington.edu",
   "nsf_id": "000430176",
   "pi_start_date": "2004-08-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rajesh",
   "pi_last_name": "Rao",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Rajesh P Rao",
   "pi_email_addr": "rao@cs.washington.edu",
   "nsf_id": "000491279",
   "pi_start_date": "2004-08-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Melody",
   "pi_last_name": "Ivory-Ndiaye",
   "pi_mid_init": "Y",
   "pi_sufx_name": "",
   "pi_full_name": "Melody Y Ivory-Ndiaye",
   "pi_email_addr": "myivory@u.washington.edu",
   "nsf_id": "000396967",
   "pi_start_date": "2004-08-03",
   "pi_end_date": "2005-10-06"
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "4333 BROOKLYN AVE NE",
  "perf_city_name": "SEATTLE",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981951016",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "684500",
   "pgm_ele_name": "HUMAN COMPUTER INTER PROGRAM"
  },
  {
   "pgm_ele_code": "684600",
   "pgm_ele_name": "UNIVERSAL ACCESS"
  },
  {
   "pgm_ele_code": "685000",
   "pgm_ele_name": "DIGITAL SOCIETY&TECHNOLOGIES"
  },
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9217",
   "pgm_ref_txt": "NATNL RESERCH & EDUCAT NETWORK"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0104",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0104",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0105",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0105",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0106",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2004,
   "fund_oblg_amt": 179371.0
  },
  {
   "fund_oblg_fiscal_yr": 2005,
   "fund_oblg_amt": 297184.0
  },
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 313433.0
  },
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 6000.0
  }
 ],
 "por": null
}