{
 "awd_id": "0434398",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MSPA-MCS:     3D Scene Digitization - A Novel Invariant Approach for Large-Scale Environment Capture",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Lawrence Rosenblum",
 "awd_eff_date": "2004-08-15",
 "awd_exp_date": "2008-07-31",
 "tot_intn_awd_amt": 0.0,
 "awd_amount": 506000.0,
 "awd_min_amd_letter_date": "2004-08-02",
 "awd_max_amd_letter_date": "2006-04-06",
 "awd_abstract_narration": "3D Scene Digitization  A Novel Invariant Approach for\r\nLarge-Scale Environment Capture\r\nDaniel G. Aliaga, Mireille Boutin, Carl Cowen\r\nPurdue University\r\nThe simulation of large real-world environments is a core challenge of computing technology\r\ntoday. Applications are numerous and diverse. For example, it would enable students to pay virtual\r\nvisits to famous historical sites such as museums, temples, battlefields, and distant cities; civil\r\nengineers to capture buildings and compare them to the original design or to simulations (e.g., to\r\ncompare as-built models and simulated models before and after a catastrophe); archeologists to\r\nvirtually preserve complex excavation sites such as trenches as they evolve over time; soldiers and fire\r\nfighters to train in simulated environments; real estate agents to show buyers the interiors of homes;\r\nand, people all over the world to enjoy virtual travel or multi-player 3D games.\r\nDespite tremendous increases in computational power and storage space, current acquisition\r\nmethods perform quite poorly. Even for small scenes, they usually fail to adequately capture many\r\ndetails. Manually created models, although popular, are extremely time-consuming and rendered\r\nimages are poor representations of reality. Alternatively, image-based modeling and rendering,\r\nproduces photorealistic images but only in the context of small and/or diffuse environments seen from\r\na limited range of viewpoints (e.g., QuickTime VR). Similarly, approaches which focus on recreating\r\nthe geometry of the scene such as the reconstruction methods developed in computer vision or the\r\nlaser-scanning approaches struggle with complex occlusions, specular surfaces and large data sets.\r\nThe research objective of this proposal is thus to develop the algorithms needed to capture and\r\nmanipulate visually rich computer models of large and complex real-world scenes. The proposal\r\nattacks this research problem with a new hybrid method combining both geometric and photometric\r\ninformation contained in the scene. More precisely, the approach captures a 3D environment by\r\ndensely sampling the space of viewpoints and uses this redundant data set to extract accurate models\r\nof the surface geometry and the reflectance properties of the scene. This is in contrast with most\r\ncurrent approaches where one acquires a sparse set of data and uses methods to interpolate missing\r\ninformation. The work replaces interpolation by the easier tasks of semi-automatic platform\r\nnavigation, data filtering, and working-set management. The key is the development of highly\r\neffective mathematical data processing techniques.\r\nThe main research contribution of the proposed approach is the merging of expertise from the\r\nMathematical and Computer Sciences to solve a difficult problem in computing technology today. In\r\nparticular, the research makes use of a novel geometry reconstruction method based on Lie group\r\ntheory which was recently developed by one of the co-PIs. This method uses a set of invariants of a\r\ngroup action to eliminate a number of superfluous unknowns normally included in the 3D\r\nreconstruction problem. These superfluous unknowns are exactly the ones that make the\r\nreconstruction equations nonlinear. By removing them, the method ends up with a simple set of sparse\r\nlinear equations involving a minimum number of unknowns which can be solved sequentially. This\r\nallows the project to quickly and robustly extract the geometric (and photometric) information of large\r\ndata sets and reconstruct large 3D environments.\r\nThe proposed research will have impact beyond the immediate reconstruction results. Never\r\nbefore have researchers had access to such large and dense samplings of environments. Aside from\r\npublications and making all software available, the research project will create a public repository to\r\nstore models for subsequent study (e.g., historically significant locations). The impact of the proposed\r\nwork is not an incrementally better method for capturing environments, but a bold new approach that\r\ncan significantly change how people think about computer simulation of large environments.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Aliaga",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel G Aliaga",
   "pi_email_addr": "aliaga@cs.purdue.edu",
   "nsf_id": "000483177",
   "pi_start_date": "2004-08-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Carl",
   "pi_last_name": "Cowen",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Carl C Cowen",
   "pi_email_addr": "ccowen@math.iupui.edu",
   "nsf_id": "000292188",
   "pi_start_date": "2004-08-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mireille",
   "pi_last_name": "Boutin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mireille Boutin",
   "pi_email_addr": "mboutin@purdue.edu",
   "nsf_id": "000385049",
   "pi_start_date": "2004-08-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "2550 NORTHWESTERN AVE # 1100",
  "perf_city_name": "WEST LAFAYETTE",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479061332",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "735200",
   "pgm_ele_name": "COMPUTING PROCESSES & ARTIFACT"
  },
  {
   "pgm_ele_code": "745400",
   "pgm_ele_name": "MSPA-INTERDISCIPLINARY"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7303",
   "pgm_ref_txt": "MATH SCI PRIORITY AREA: INTERDISCIPLINAR"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0104",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0104",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0106",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2004,
   "fund_oblg_amt": 500000.0
  },
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 6000.0
  }
 ],
 "por": null
}