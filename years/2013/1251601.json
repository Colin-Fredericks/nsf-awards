{
 "awd_id": "1251601",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Doctoral Dissertation Research:  The Time Course of Givenness Effects in Language Production Models",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Badecker",
 "awd_eff_date": "2013-04-01",
 "awd_exp_date": "2015-09-30",
 "tot_intn_awd_amt": 17632.0,
 "awd_amount": 17632.0,
 "awd_min_amd_letter_date": "2013-02-13",
 "awd_max_amd_letter_date": "2013-02-13",
 "awd_abstract_narration": "Speaking effectively requires producing multiple words in a row, smoothly and efficiently. The relative ease we experience while doing this belies its complexity. When planning what to say, we engage in processes like selecting words, choosing appropriate sounds for those words, and ensuring that each word receives enough attention to get produced quickly and accurately. Understanding these individual processes, and thus how people produce language, requires understanding the timing of each word. This project explores the relationship between basic processes in language production, such as choosing a word and its sounds, and the duration of that and surrounding words. \r\n\r\nThe experiments test the hypothesis that facilitating the process of selecting a word or selecting its sounds influences that word's duration. Further, they test whether this effect extends to each of the words surrounding the facilitated word.  The method modifies an established paradigm, the Picture-Word Interference (PWI) task, to investigate the timing and involvement of semantic and phonological processing. Participants name a picture while ignoring a spoken distractor. Distractors influence processing when they relate closely in meaning or sound, so the experiment controls these relationships. It also controls the relative timing of the appearance of the pictures and distracters, which influences processing as well. This tight control over timing and relatedness allows for a close investigation of how sub-processes of language production contribute to the duration of individual words. It will also show how facilitation of meaning-irrelevant processing affects the duration of surrounding words. \r\n\r\nUnderstanding the processes that underlie duration is fundamentally important for understanding speech production, because the duration of each word in a sentence reflects not only its own processing, but also how the production system manages multiple words simultaneously. This project will take the first steps toward understanding the relationship between processing and duration.  It will also support the scientific training of a promising scholar.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jennifer",
   "pi_last_name": "Arnold",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Jennifer E Arnold",
   "pi_email_addr": "jarnold@email.unc.edu",
   "nsf_id": "000455175",
   "pi_start_date": "2013-02-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jason",
   "pi_last_name": "Kahn",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jason Kahn",
   "pi_email_addr": "jmkahn@email.unc.edu",
   "nsf_id": "000623232",
   "pi_start_date": "2013-02-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "Dept. of Psychology, Davie Hall",
  "perf_city_name": "Chapel Hill",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275993270",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 17632.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;&nbsp;&nbsp;&nbsp; When people talk to each other, the way they pronounce the words they use varies a surprisingly large amount. If I hear you say \"science,\" for example, I may spend a little less time saying that word (i.e. shorten its spoken duration)&nbsp;when I mention it moments later. This project set out to help figure out why. Perhaps it's because the brain has recently processed similar meanings, or sounds, and on later pronunciations has an easier time finishing its work. We took this hypothesis and designed an experiment where participants spoke simple sentences out loud (which we recorded) after hearing words that were related, unrelated, or exactly the same as a word in that sentence. We also varied the timing of the interfering word to see whether variation in duration happens only when it was closely tied to the spoken target word in time. Each of these hypotheses is supported partly by previous work, but more robustly by the thought that the brain responds efficiently but also under tremendous time pressure, and so must make quick guesses about the most appropriate way to behave based on all of the possibly-relevant information it has. If it can reach a quicker solution because of something it encountered recently, it will capitalize on that experience.</p>\n<p><span style=\"white-space: pre;\">&nbsp;&nbsp;&nbsp;&nbsp; </span>For the experiments, participants were presented with a series of pictures and asked to describe what they saw. For example, a picture of an airplane might appear and spin around, which we asked them to describe as \"the airplane rotates.\" Each time this happened, another word was also spoken out loud, and was either related (e.g. \"helicopter\" for a meaning-related word, \"error\" for a sound-related word), unrelated (e.g. \"belt\"), or the same (\"airplane\"). Finally, the timing of this interfering word relative to when the picture appeared varied systematically. Each word in the utterance, as well as how long it took the participant to begin speaking, was measured by recording equipment.</p>\n<p><span style=\"white-space: pre;\">&nbsp;&nbsp;&nbsp;&nbsp; </span>Meaningfully-related interfering words made people take longer to begin their sentences, suggesting that they experienced some difficulty separating the meaning of the correct word from the interfering one.</p>\n<p><span style=\"white-space: pre;\"> </span>Sound-related words had the opposite effect. Sentences started earlier after them, suggesting that speakers felt more comfortable starting when they had some of the important upcoming sounds already processed. However, the duration of the object word (e.g. \"airplane\") was actually longer after sound-related words, most likely due to only-partial overlap in sound. \"Error\" and \"airplane\" only sound the same at the beginning of the word, and speakers needed a little bit of extra time to ensure that they chose the right end to the word.</p>\n<p><span style=\"white-space: pre;\">&nbsp;&nbsp;&nbsp;&nbsp; </span>Hearing the target word (\"airplane\") let speakers begin their sentences more quickly, and also reduced the spoken duration of the target word. This is a consistent result in studies like this, and has previously been explained as speakers recognizing that someone listening already has a representation of an airplane, and therefore needs less acoustic information from the speaker to call up that representation. The durational variation evident in these studies suggests that something else might be at work as well. After hearing a meaning- or sound-related word, a speaker may have a more difficult time sorting out which processing path to follow to completion, and consequently slows down. It may take them longer to finish planning the sentence, speaking individual words, or both. Hearing the same word may have the opposite effect, shortening time to begin speaking and word durations.</p>\n<p><span style=\"white-space: pre;\">&nbsp;&n...",
  "por_txt_cntn": "\n     When people talk to each other, the way they pronounce the words they use varies a surprisingly large amount. If I hear you say \"science,\" for example, I may spend a little less time saying that word (i.e. shorten its spoken duration) when I mention it moments later. This project set out to help figure out why. Perhaps it's because the brain has recently processed similar meanings, or sounds, and on later pronunciations has an easier time finishing its work. We took this hypothesis and designed an experiment where participants spoke simple sentences out loud (which we recorded) after hearing words that were related, unrelated, or exactly the same as a word in that sentence. We also varied the timing of the interfering word to see whether variation in duration happens only when it was closely tied to the spoken target word in time. Each of these hypotheses is supported partly by previous work, but more robustly by the thought that the brain responds efficiently but also under tremendous time pressure, and so must make quick guesses about the most appropriate way to behave based on all of the possibly-relevant information it has. If it can reach a quicker solution because of something it encountered recently, it will capitalize on that experience.\n\n     For the experiments, participants were presented with a series of pictures and asked to describe what they saw. For example, a picture of an airplane might appear and spin around, which we asked them to describe as \"the airplane rotates.\" Each time this happened, another word was also spoken out loud, and was either related (e.g. \"helicopter\" for a meaning-related word, \"error\" for a sound-related word), unrelated (e.g. \"belt\"), or the same (\"airplane\"). Finally, the timing of this interfering word relative to when the picture appeared varied systematically. Each word in the utterance, as well as how long it took the participant to begin speaking, was measured by recording equipment.\n\n     Meaningfully-related interfering words made people take longer to begin their sentences, suggesting that they experienced some difficulty separating the meaning of the correct word from the interfering one.\n\n Sound-related words had the opposite effect. Sentences started earlier after them, suggesting that speakers felt more comfortable starting when they had some of the important upcoming sounds already processed. However, the duration of the object word (e.g. \"airplane\") was actually longer after sound-related words, most likely due to only-partial overlap in sound. \"Error\" and \"airplane\" only sound the same at the beginning of the word, and speakers needed a little bit of extra time to ensure that they chose the right end to the word.\n\n     Hearing the target word (\"airplane\") let speakers begin their sentences more quickly, and also reduced the spoken duration of the target word. This is a consistent result in studies like this, and has previously been explained as speakers recognizing that someone listening already has a representation of an airplane, and therefore needs less acoustic information from the speaker to call up that representation. The durational variation evident in these studies suggests that something else might be at work as well. After hearing a meaning- or sound-related word, a speaker may have a more difficult time sorting out which processing path to follow to completion, and consequently slows down. It may take them longer to finish planning the sentence, speaking individual words, or both. Hearing the same word may have the opposite effect, shortening time to begin speaking and word durations.\n\n     This work brings us closer to understanding some of the fundamental operations of the systems that we use to speak. Meaning and sound relationships among words have a surprising, albeit subtle, influence on every word we say. The brain is tuned to pay attention to and react to these relationships, and the influence shows up in how we talk to each other. \n\n\t\t\t\t\tLast ..."
 }
}