{
 "awd_id": "1302517",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "HCC: Medium: Collaborative Research: Force Feedback for Fingertips",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2013-06-01",
 "awd_exp_date": "2017-05-31",
 "tot_intn_awd_amt": 399669.0,
 "awd_amount": 399669.0,
 "awd_min_amd_letter_date": "2013-05-30",
 "awd_max_amd_letter_date": "2015-05-29",
 "awd_abstract_narration": "Surface haptics is the creation of programmable haptic effects on physical surfaces such as touch screens and touch pads.  Unlike traditional force feedback devices that require the operator to grasp an end effector, surface haptic devices must provide feedback directly to the fingertips.  With the dramatic rise of touch screen interfaces in recent years, many approaches to surface haptics have been explored, including vibrotactile, shape morphing, and variable friction.  The PI and his team have pioneered an approach in which the surface generates controlled shear forces on each fingertip. Force Feedback for Fingertips (F3), gives fingertips the opportunity to interact with physics-based virtual environments, much like force feedback devices enable the whole hand to do.  With F3, fingers can interact with virtual objects that have mass, stiffness and damping as well as more complicated dynamics (e.g., collisions, mechanisms, and force fields).  By coordinating haptic effects at multiple fingertips, even more compelling illusions can be generated.\r\n\r\nThe technology, underlying science, and application of F3 are, however, still in their infancy.  F3 works by coupling lateral vibrations to some form of rectification.  For example, one approach involves high-frequency lateral vibrations of the surface synchronized with a friction reduction effect, resulting in a slip-push transition at each oscillation.  The friction is modulated by means of electrostatic forces or acoustical stimulation.  Current approaches work at ultrasonic frequencies, but little is known about the mechanical or electrical behavior of fingertips at these frequencies, or how energy transfer from a surface to the finger can be optimized.\r\n\r\nThis research will produce new knowledge in three main areas:  the physical underpinnings of F3, device design and interaction design.  First, both tribological and acoustic measurements will be made to elucidate the mechanisms by which shear forces are generated.  A high-bandwidth tribometer and optical imaging system will allow friction to be studied, and a custom-built exciter will allow the propagation of acoustic energy in the fingertip to be studied.  Laser Doppler vibrometry will be used to measure surface wave propagation while magnetic resonance elastography will be used to study shear wave propagation within the subcutaneous tissues.  Fractional calculus and finite element techniques will then be used to build biologically plausible models of fingertip tribology and mechanics that match the data.  Second, a new generation of high-performance F3 devices will be developed.  Armed with good models, it will be possible to design impedance-matched devices so that force production is maximized and energy wastage is minimized.  Additionally, these new devices will provide control over the force vector at each of multiple fingertip locations.  Thirdly, novel multi-finger interactions will be designed.  The key idea is that sophisticated percepts, such as \"objects\" that can be grasped and that feel as though they are moving relative to the surface, can emerge from properly coordinated fingertip forces due to Gestalt-like grouping principles.\r\n\r\nBroader Impacts:  Historically, the PI and his team have had greatest impact when providing technology to and collaborating with colleagues in human-computer interaction.  Inspired by this, an open source F3 kit will be developed and shared.  In addition, undergraduate and high school students will participate in the research, developing software routines and sample applications for the open source kit.  Finally, the kit will be integrated with two pedagogical innovations already implemented by the investigators: flipped classrooms and portable laboratories.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thomas",
   "pi_last_name": "Royston",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas J Royston",
   "pi_email_addr": "troyston@uic.edu",
   "nsf_id": "000277407",
   "pi_start_date": "2013-05-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Dieter",
   "pi_last_name": "Klatt",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dieter Klatt",
   "pi_email_addr": "dklatt@uic.edu",
   "nsf_id": "000629560",
   "pi_start_date": "2013-05-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Chicago",
  "inst_street_address": "809 S MARSHFIELD AVE M/C 551",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3129962862",
  "inst_zip_code": "606124305",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "IL07",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "W8XEAJDKMXH3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Chicago",
  "perf_str_addr": "851 South Morgan Street MC 063",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606077052",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "IL07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 134356.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 137967.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 127346.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This collaborative research project, led by Prof. Ed Colgate at Northwestern University, began with a vision for a new type of human-computer interface:&nbsp; very much like a touchscreen, yet having the added ability to control what a person using it actually felt through his or her fingertips.&nbsp; For instance, buttons might feel like they have shape so that a person could touch type, or a person with a vision impairment might be able to read using braille or something similar.&nbsp; On the strength of previous research, our team felt that this could be accomplished by developing &ldquo;active forcing&rdquo; technology.&nbsp; An active forcing interface can apply controlled forces to bare human fingertips in any direction along the surface.</p>\n<p>How does active forcing control what a person feels?&nbsp; The key is to make the forces dependent on the location and movement of the finger relative to graphical objects on the screen.&nbsp; For instance, to make a button feel like it has an indented shape, the force can be controlled so that it does nothing if the finger is right over the center of the button, but pushes the finger back toward the center if it strays away.&nbsp; The pattern of forces essentially fools the brain into believing that the button has shape.&nbsp; Other patterns of forces can be used to emulate buttons that bulge out of the surface, toggle switches, knobs, pathways (imagine tracing out a path on an image of a map and feeling that path guide the finger), and endless other items that a designer might imagine.</p>\n<p>Active forcing is accomplished by synchronizing high frequency in-plane vibrations of the touch surface with friction levels.&nbsp; The concept is simple enough:&nbsp; vibrate the touch surface in-plane, and increase the friction against the finger whenever that surface is moving in the desired pushing direction, while decreasing it when the surface moves in other directions.&nbsp; On average, the finger will be pushed in the desired direction.&nbsp; In practice, however, this is a challenging thing to do.&nbsp; It is necessary to modulate the friction very rapidly and over a wide range of magnitudes.&nbsp; This, in turn, requires a deep understanding of the friction modulation mechanics.</p>\n<p>In this research, a combination of theoretical and experimental studies led to a deep understanding of two different approaches to friction modulation.&nbsp; One approach, which fundamental research at UIC using scanning laser vibrometry contributed to, is based on out-of-plane surface vibrations, which are known to reduce friction.&nbsp; This work showed unequivocally that the finger \"bounces\" against the vibrating surface, and does not \"float\" has had been previously thought.&nbsp; The bounces, however, are cushioned by air, which is the key factor that leads to friction reduction.&nbsp; An additional result is that the dynamic properties &ndash; especially damping &ndash; of the fingertip itself, play a key role.</p>\n<p>Guided by these fundamental results, several active forcing systems were developed by the Northwestern group over the course of the research, culminating in a version &ndash; the UltraShiver &ndash; that is capable of producing large in-plane forces on the finger with no tactile, visual or audio artifact.&nbsp; In other words, although the touch surface appears not to be moving and is completely silent, it is capable of pushing the finger.&nbsp; This is an important result because it is the foundation upon which the vision described at the outset might practically be built.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/30/2017<br>\n\t\t\t\t\tModified by: Thomas&nbsp;J&nbsp;Royston</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis collaborative research project, led by Prof. Ed Colgate at Northwestern University, began with a vision for a new type of human-computer interface:  very much like a touchscreen, yet having the added ability to control what a person using it actually felt through his or her fingertips.  For instance, buttons might feel like they have shape so that a person could touch type, or a person with a vision impairment might be able to read using braille or something similar.  On the strength of previous research, our team felt that this could be accomplished by developing \"active forcing\" technology.  An active forcing interface can apply controlled forces to bare human fingertips in any direction along the surface.\n\nHow does active forcing control what a person feels?  The key is to make the forces dependent on the location and movement of the finger relative to graphical objects on the screen.  For instance, to make a button feel like it has an indented shape, the force can be controlled so that it does nothing if the finger is right over the center of the button, but pushes the finger back toward the center if it strays away.  The pattern of forces essentially fools the brain into believing that the button has shape.  Other patterns of forces can be used to emulate buttons that bulge out of the surface, toggle switches, knobs, pathways (imagine tracing out a path on an image of a map and feeling that path guide the finger), and endless other items that a designer might imagine.\n\nActive forcing is accomplished by synchronizing high frequency in-plane vibrations of the touch surface with friction levels.  The concept is simple enough:  vibrate the touch surface in-plane, and increase the friction against the finger whenever that surface is moving in the desired pushing direction, while decreasing it when the surface moves in other directions.  On average, the finger will be pushed in the desired direction.  In practice, however, this is a challenging thing to do.  It is necessary to modulate the friction very rapidly and over a wide range of magnitudes.  This, in turn, requires a deep understanding of the friction modulation mechanics.\n\nIn this research, a combination of theoretical and experimental studies led to a deep understanding of two different approaches to friction modulation.  One approach, which fundamental research at UIC using scanning laser vibrometry contributed to, is based on out-of-plane surface vibrations, which are known to reduce friction.  This work showed unequivocally that the finger \"bounces\" against the vibrating surface, and does not \"float\" has had been previously thought.  The bounces, however, are cushioned by air, which is the key factor that leads to friction reduction.  An additional result is that the dynamic properties &ndash; especially damping &ndash; of the fingertip itself, play a key role.\n\nGuided by these fundamental results, several active forcing systems were developed by the Northwestern group over the course of the research, culminating in a version &ndash; the UltraShiver &ndash; that is capable of producing large in-plane forces on the finger with no tactile, visual or audio artifact.  In other words, although the touch surface appears not to be moving and is completely silent, it is capable of pushing the finger.  This is an important result because it is the foundation upon which the vision described at the outset might practically be built.\n\n\t\t\t\t\tLast Modified: 08/30/2017\n\n\t\t\t\t\tSubmitted by: Thomas J Royston"
 }
}