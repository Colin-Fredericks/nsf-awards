{
 "awd_id": "1349153",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Boa: A Community Research Infrastructure for Mining Software Repositories",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 96408.0,
 "awd_amount": 96408.0,
 "awd_min_amd_letter_date": "2013-08-29",
 "awd_max_amd_letter_date": "2013-08-29",
 "awd_abstract_narration": "In today's software-centric world, ultra-large-scale software repositories, e.g. SourceForge (350,000+ projects), GitHub (250,000+ projects), and Google Code (250,000+ projects) are the new library of Alexandria. They contain an enormous corpus of software and information about software. Scientists and engineers alike are interested in analyzing this wealth of information both for curiosity as well as for testing important research hypotheses. However, the current barrier to entry is often prohibitive and only a few with well-established research infrastructure and deep expertise in mining software repositories can attempt such ultra-large-scale experiments.\r\nA facility called Boa has been prototyped: a domain-specific language and a BIGDATA repository containing 700,000+ open source projects for analyzing ultra-large scale software repositories to help with such experiments.\r\n\r\nThis experimental research infrastructure is of significant interest to a wide community of software engineering and programming language researchers. The main goal of this EAGER project is to examine the requirements for making Boa broadly available to the software engineering and programming language community, to work with an initial set of researchers to try to fulfill these requirements, and to take preliminary steps toward making Boa a community-sustained, scalable, and extensible research infrastructure. This is an enabling and transformative project. Its success will aid and accelerate scientific research in software engineering, allowing scientists and engineers to focus on the essential tasks. This advance will  primarily be achieved by significantly lowering the barrier to entry and thus enabling a larger and more ambitious line of data-intensive scientific discovery in this area.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hridesh",
   "pi_last_name": "Rajan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hridesh Rajan",
   "pi_email_addr": "hridesh@iastate.edu",
   "nsf_id": "000241383",
   "pi_start_date": "2013-08-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Tien",
   "pi_last_name": "Nguyen",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Tien N Nguyen",
   "pi_email_addr": "nguyen.n.tien@gmail.com",
   "nsf_id": "000340493",
   "pi_start_date": "2013-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Iowa State University",
  "inst_street_address": "1350 BEARDSHEAR HALL",
  "inst_street_address_2": "515 MORRILL ROAD",
  "inst_city_name": "AMES",
  "inst_state_code": "IA",
  "inst_state_name": "Iowa",
  "inst_phone_num": "5152945225",
  "inst_zip_code": "500112103",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IA04",
  "org_lgl_bus_name": "IOWA STATE UNIVERSITY OF SCIENCE AND TECHNOLOGY",
  "org_prnt_uei_num": "DQDBM7FGJPC5",
  "org_uei_num": "DQDBM7FGJPC5"
 },
 "perf_inst": {
  "perf_inst_name": "Iowa State University",
  "perf_str_addr": "1138 Pearson",
  "perf_city_name": "Ames",
  "perf_st_code": "IA",
  "perf_st_name": "Iowa",
  "perf_zip_code": "500112207",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "IA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "794400",
   "pgm_ele_name": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 96408.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Software is rapidly becoming one of the most fundamental building blocks of human interaction and activity. Ultra-large-scale software repositories, e.g. SourceForge (700k+projects), GitHub (7M+ projects), and Google Code (300k+projects) contain an enormous collection of software and information about software. These big-3 repositories amount to 1,000,000,000+ lines of code, 10,000,000+ revision logs,and 3,000,000+ issue reports. Scientists and engineers alike are interested in analyzing this wealthof information both for curiosity as well as for testing important hypotheses. However, the current barrier to entry is prohibitive and only a few with well-established infrastructure and deep expertise can attempt such ultra-large-scale analysis. Necessary expertise includes: programmatically accessing version control systems, data storage and retrieval, data mining, and parallelization. The need to have expertise in these four different areas significantly increases the cost of scientific research that attempts to answer research questions involving the ultra-large-scale software repositories. As a result, experiments are often irreproducible, reusability of experimental infrastructure low, and data associated and produced by such experiments is often lost and becomes inaccessible and obsolete, because there is no systematic curation.</p>\n<p><br />To solve these problems, the intellectual merit of this NSF project was in prototyping Boa, a virtual infrastructure for research that analyzes software and its evolution at a large scale. Boa is a research infrastructure available at the URL (http://boa.cs.iastate.edu) that consists of a domain-specific language, its compiler and data updating tools, terabytes (and growing) of raw data from open source repositories that contains 700,000+ open source projects as of this writing, a backend based on map-reduce to effectively analyze this dataset, a compute cluster, and a web-based frontend for writing analysis programs. Broader impacts of this NSF project has emanated from decreasing barrier to entry for this class of research and development projects. Within Boa, research questions concerning human and technical aspects of open source software development can be answered by writing, often short, programs that are automatically parallelized by the infrastructure to process already curated dataset. This significantly decreases the barrier to entry for such research, improves scalability, and lowers complexity and size of analysis programs, which allows researchers to focus on their essential tasks. Since standardized datasets are available within Boa, collaboration and comparison of research results is facilitated. Reproducing an experiment conducted using Boa is just a matter of re-running Boa programs provided by previous researchers. A preliminary prototype was made available at the end of this project and it is being used worldwide by researchers in over 20 countries.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/04/2015<br>\n\t\t\t\t\tModified by: Hridesh&nbsp;Rajan</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2015/1349153/1349153_10272614_1449262760469_ScreenShot2015-12-04at2.58.27PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2015/1349153/1349153_10272614_1449262760469_ScreenShot2015-12-04at2.58.27PM--rgov-800width.jpg\" title=\"Boa\"><img src=\"/por/images/Reports/POR/2015/1349153/1349153_10272614_1449262760469_ScreenShot201...",
  "por_txt_cntn": "\nSoftware is rapidly becoming one of the most fundamental building blocks of human interaction and activity. Ultra-large-scale software repositories, e.g. SourceForge (700k+projects), GitHub (7M+ projects), and Google Code (300k+projects) contain an enormous collection of software and information about software. These big-3 repositories amount to 1,000,000,000+ lines of code, 10,000,000+ revision logs,and 3,000,000+ issue reports. Scientists and engineers alike are interested in analyzing this wealthof information both for curiosity as well as for testing important hypotheses. However, the current barrier to entry is prohibitive and only a few with well-established infrastructure and deep expertise can attempt such ultra-large-scale analysis. Necessary expertise includes: programmatically accessing version control systems, data storage and retrieval, data mining, and parallelization. The need to have expertise in these four different areas significantly increases the cost of scientific research that attempts to answer research questions involving the ultra-large-scale software repositories. As a result, experiments are often irreproducible, reusability of experimental infrastructure low, and data associated and produced by such experiments is often lost and becomes inaccessible and obsolete, because there is no systematic curation.\n\n\nTo solve these problems, the intellectual merit of this NSF project was in prototyping Boa, a virtual infrastructure for research that analyzes software and its evolution at a large scale. Boa is a research infrastructure available at the URL (http://boa.cs.iastate.edu) that consists of a domain-specific language, its compiler and data updating tools, terabytes (and growing) of raw data from open source repositories that contains 700,000+ open source projects as of this writing, a backend based on map-reduce to effectively analyze this dataset, a compute cluster, and a web-based frontend for writing analysis programs. Broader impacts of this NSF project has emanated from decreasing barrier to entry for this class of research and development projects. Within Boa, research questions concerning human and technical aspects of open source software development can be answered by writing, often short, programs that are automatically parallelized by the infrastructure to process already curated dataset. This significantly decreases the barrier to entry for such research, improves scalability, and lowers complexity and size of analysis programs, which allows researchers to focus on their essential tasks. Since standardized datasets are available within Boa, collaboration and comparison of research results is facilitated. Reproducing an experiment conducted using Boa is just a matter of re-running Boa programs provided by previous researchers. A preliminary prototype was made available at the end of this project and it is being used worldwide by researchers in over 20 countries.\n\n \n\n\t\t\t\t\tLast Modified: 12/04/2015\n\n\t\t\t\t\tSubmitted by: Hridesh Rajan"
 }
}