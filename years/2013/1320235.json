{
 "awd_id": "1320235",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Multi-Version Concurrency Control (MVCC) for Main Memory and its Implications for Deterministic Concurrency",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2013-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 453734.0,
 "awd_amount": 469734.0,
 "awd_min_amd_letter_date": "2013-09-09",
 "awd_max_amd_letter_date": "2014-06-20",
 "awd_abstract_narration": "The objective of this project is to investigate version consistency, a new concurrent programming consistency model, as a means of enhancing the performance and scalability of concurrent systems. Under version consistency, which can be seen as a relaxation of release consistency, processes are guaranteed to see the same memory contents (only) if they are accessing the same version of the memory. Such versions are created, retrieved and/or merged through calls analogous with version control systems for source code.\r\n\r\nAn important class of applications that benefits substantially from version consistency is deterministic concurrency runtimes, where the goal is to ensure that a program produces the same output given the same input, independent of any non-deterministic timing effects. In prior work, the PI achieved up to 50% performance gain for the deterministic runtime DThreads, using version consistency. In this project, one of the goals is to achieve ``pthreads parity\" for a deterministic runtime, where enforcing determinism incurs only negligible performance impact. When and if this is achieved, ``determinism by default'' becomes a feasible option for mainstream computer systems.\r\n\r\nAs computer processors continue to evolve from a centralized single ``core'' architecture to highly distributed and parallel ``multi-core  systems'', writing correct programs that make efficient use of this extremely powerful hardware is becoming increasingly difficult. This results in a number of detrimental effects ranging from poor resource utilization, to seriously flawed programs where loss of data, or even loss of life may result. This project investigates (a) a means of reducing the complexity of programming highly parallel systems to combat these problems, and (b) a means of guaranteeing that even an incorrect parallel program produces the same result every time. This latter part will help programmers write correct programs, and to fix software flaws that may otherwise be intermittent and difficult to identify.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jakob",
   "pi_last_name": "Eriksson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jakob Eriksson",
   "pi_email_addr": "jakob@uic.edu",
   "nsf_id": "000537836",
   "pi_start_date": "2013-09-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Chicago",
  "inst_street_address": "809 S MARSHFIELD AVE M/C 551",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3129962862",
  "inst_zip_code": "606124305",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "IL07",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "W8XEAJDKMXH3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Chicago",
  "perf_str_addr": "851 S Morgan Street",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606077042",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "IL07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 453734.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>If you have ever thought \"it didn't do that last time\" when using a computer, you may have experienced a case of non-deterministic execution. Today, computers typically execute non-deterministically: due to timing effects in modern multi-core processors, programs may produce different outputs given exact same inputs.</p>\n<p>The objective of this project was to investigate means of making execution deterministic: to guarantee that programs produce the same output given the same input, every time. This has been done in the past, but only at very high performance cost. In this project, we were able to dramatically speed up deterministic execution, sometimes by a factor 100x, by leveraging a number of new techniques invented through the course of the project. One example of these technques is called version consistency, a new way to think about and access the main memory of a computer, that enables individual threads of execution to run more independently, with less interference if you will, than they have in the past. Another is high-performance delegation, which eschew's the current model of threads essentially fighting to use a shared resource, say a pen and a piece of paper used to put together a shopping list, and replaces it with a very efficient means for each thread slipping notes to a single \"server thread\", which does all the writing. While delegation has been proposed in the past, we were abel to demonstrate very large (10x or more) speedups using a careful, performance conscious design.</p>\n<p>Our work has been published in the world's most prestigious conferences in this line of work, and we are making the software available to the public, under an open source license. While we did not yet achieve our long term aspiration of deploying \"determinism by default\" in commodity operating systems, this project brought us much closer to that goal.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/09/2018<br>\n\t\t\t\t\tModified by: Jakob&nbsp;Eriksson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIf you have ever thought \"it didn't do that last time\" when using a computer, you may have experienced a case of non-deterministic execution. Today, computers typically execute non-deterministically: due to timing effects in modern multi-core processors, programs may produce different outputs given exact same inputs.\n\nThe objective of this project was to investigate means of making execution deterministic: to guarantee that programs produce the same output given the same input, every time. This has been done in the past, but only at very high performance cost. In this project, we were able to dramatically speed up deterministic execution, sometimes by a factor 100x, by leveraging a number of new techniques invented through the course of the project. One example of these technques is called version consistency, a new way to think about and access the main memory of a computer, that enables individual threads of execution to run more independently, with less interference if you will, than they have in the past. Another is high-performance delegation, which eschew's the current model of threads essentially fighting to use a shared resource, say a pen and a piece of paper used to put together a shopping list, and replaces it with a very efficient means for each thread slipping notes to a single \"server thread\", which does all the writing. While delegation has been proposed in the past, we were abel to demonstrate very large (10x or more) speedups using a careful, performance conscious design.\n\nOur work has been published in the world's most prestigious conferences in this line of work, and we are making the software available to the public, under an open source license. While we did not yet achieve our long term aspiration of deploying \"determinism by default\" in commodity operating systems, this project brought us much closer to that goal.\n\n\t\t\t\t\tLast Modified: 02/09/2018\n\n\t\t\t\t\tSubmitted by: Jakob Eriksson"
 }
}