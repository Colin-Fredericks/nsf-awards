{
 "awd_id": "1302338",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "HCC: Medium: Combining Crowdsourcing and Computer Vision for Street-level Accessibility",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2013-05-01",
 "awd_exp_date": "2019-04-30",
 "tot_intn_awd_amt": 1199034.0,
 "awd_amount": 1199034.0,
 "awd_min_amd_letter_date": "2013-05-16",
 "awd_max_amd_letter_date": "2013-05-16",
 "awd_abstract_narration": "Despite comprehensive civil rights legislation for Americans with disabilities, many city streets, sidewalks, and businesses remain inaccessible.  The problem is not just that street-level accessibility affects where and how people travel in cities but also that there are few, if any, mechanisms to determine accessible areas of a city a priori.  Traditionally, sidewalk assessment has been conducted via in-person street audits, which are labor intensive and costly, or via citizen call-in reports, which are done on a reactive basis.  And while efforts exist for visualizing the walk-ability, bike-ability, and availability of public transport in cities, there are no analogous efforts for accessibility.  Thus, wheelchair users, for example, often avoid going to new areas of a city where they don't know about accessible routes.  The PI plans to address this problem by means of a two-pronged approach in which he will first develop scalable data collection methods for acquiring sidewalk accessibility information using a combination of crowd-sourcing, computer vision, and online map imagery; he will then use the new data to develop and evaluate a novel set of navigation and map tools for accessibility.  To these ends, the PI and his team will collect and analyze interview and survey data both from mobility impaired persons and from ADA streetscape design experts, and will seek to understand how people with mobility impairments can make use of interactive mapping information to enhance mobility.  They will study methods for efficiently and effectively crowd-sourcing map labeling tasks, evaluating existing approaches empirically and designing novel, more effective approaches.  They will develop new computer vision algorithms for the analysis of street scenes, which will be used to help scale the data collection by focusing human labeling efforts on locations that are most likely to contain significant problems.   And they will design, implement and evaluate new accessible-aware map-based tools to aid people with mobility impairments in navigating their cities.  As appropriate for each phase of the research, user evaluations will include both lab and field studies.\r\n\r\nBroader Impacts:  Roughly 30.6 million individuals in the United States have physical disabilities that affect their ambulatory activities, and nearly half of these individuals report using an assistive aid such as a wheelchair, cane, crutches, or walker.  The outcomes from this research will have a significant impact on the ability of these Americans to travel independently, by transforming the ways in which accessibility information is collected and visualized for every sidewalk, street, and building fa\u00e7ade in America.  Project outcomes will include a publicly accessible web site where both the labeled data collected during this work and the new prototype tools developed will be made available for general use.   Furthermore, the PI and Co-PI will advise and mentor both graduate and undergraduate students throughout the course of the project, including two PhDs and two MS students who will obtain a cross-disciplinary education in human-computer interaction and computer vision.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jon",
   "pi_last_name": "Froehlich",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jon Froehlich",
   "pi_email_addr": "jonf@cs.washington.edu",
   "nsf_id": "000630231",
   "pi_start_date": "2013-05-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Jacobs",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "David W Jacobs",
   "pi_email_addr": "djacobs@cs.umd.edu",
   "nsf_id": "000315613",
   "pi_start_date": "2013-05-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425141",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 1199034.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Sidewalks significantly impact the mobility and quality of life of millions of Americans; however, there are currently few, if any, mechanisms to determine the locations of sidewalks in the US and their accessibility characteristics (<em>e.g., </em>presence of curb ramps, sidewalk obstructions). To address this problem, our NSF proposal described two interrelated threads of work: first, to develop scalable data collection methods for acquiring street-level accessibility information using a combination of crowdsourcing, machine learning, and online map imagery, and second, to use this data to design, develop, and evaluate a novel set of navigation and map tools for accessibility. Our overarching aim has been--and continues to be--to transform how sidewalk data is collected and visualized in order to: provide increased transparency and accountability about city accessibility, help people with mobility impairments assess and navigate their cities, and assist urban planners and policy makers in decision making about pedestrian infrastructure.</p>\n<p>In pursuit of these goals, our cross-disciplinary team has made research contributions to the fields of human-computer interaction, assistive technology, computer vision, and geographical information systems. Below, we first summarize key achievements before describing our research in more detail.</p>\n<p><strong>Key Achievements</strong></p>\n<ul>\n<li>We developed and deployed award-winning interactive software artifacts, including<em> </em><em><a href=\"http://projectsidewalk.io/\">Project Sidewalk</a></em> (an online crowdsourcing tool for collecting sidewalk accessibility information) and <em><a href=\"https://makeabilitylab.cs.washington.edu/project/accessvis/\">AccessVis</a></em><em> </em>(interactive visualizations of urban accessibility). All of our code is open source here: <a href=\"https://github.com/ProjectSidewalk\">https://github.com/ProjectSidewalk</a>.</li>\n<li>Our work has produced what we believe to be the largest open-source sidewalk accessibility dataset: over 300,000 geo-located sidewalk accessibility labels across three cities: <a href=\"http://projectsidewalk.io/api\">http://projectsidewalk.io/api</a> </li>\n<li>Our deployed tools have received substantial interest from government and accessibility organizations (e.g., DDOT, USDS, White House OSTP, AARP) as well as media coverage. </li>\n<li>We have published twenty scientific publications, including papers at top-tier venues such as CHI, ASSETS, and CVPR--two were honored with <em>Best Paper Awards </em>(Hara <em>et al., </em>ASSETS'13 and Saha <em>et al., </em>CHI'19) and one was selected for the <em>ACM Computing Reviews \"</em>Best of Computing 2014.\"</li>\n<li>PI Froehlich and Co-PI Jacobs have involved and mentored a diverse set of students from high school to undergrad and graduate students, including Kotaro Hara and Jin Sun's PhD dissertations, Ladan Najafizadeh's MS thesis, and multiple independent study projects with undergraduates. Our students have gone on to top industry positions and academic institutions such as UCLA, Stanford, and Cornell.</li>\n<li>While our original proposal focused primarily on people with mobility impairments, our work expanded to people who are blind or low-vision (<em>e.g.,</em>&nbsp;Hara <em>et al., </em>ASSETS'13 , which received the <em>Best Paper Award </em>and Hara, TACCESS'15)--demonstrating the generalizability of our methods.</li>\n</ul>\n<p><strong>Thread-1: Scalable Data Collection</strong></p>\n<p>In initial work, we showed how minimally trained remote crowdworkers can accurately label accessibility features in streetscape imagery (Figure 1; Hara <em>et al., </em>ASSETS'12; Hara <em>et al., </em>CHI'13). Later, we demonstrated the scalability of this approach via <em><a href=\"http://projectsidewalk.io/\">Project Sidewalk</a> </em>(Saha <em>et al., </em>CHI'19), an online tool where crowdworkers can remotely label pedestrian-related accessibility problems by <em>virtually</em> walking through city streets in Google Street View (Figure 2). In three test deployments, we have collected over 300,000 geo-located sidewalk accessibility labels (Figure 3).</p>\n<p>While the above approaches are promising and improve data collection efficiency, they still rely solely on <em>human </em>labor, which limits scalability. Thus, we pursued a parallel thread of work examining how humans + computers could work together to semi-automatically assess sidewalk accessibility in online images. Our initial work focused on identifying curb ramps or missing curb ramps (<em>e.g., </em>Hara <em>et al., </em>HCOMP'13; Hara <em>et al., </em>UIST'14; Sun and Jacobs, CVPR'17). Hara et al., UIST'14, for example, showed that a hybrid solution that incorporates both human labels plus machine learning could detect curb ramps at a rate similar to humans alone but at a 13% reduction in time cost (Figure 4). More recently, enabled by our large Project Sidewalk dataset, we show how a convolutional neural network can significantly improve on previous automated methods and, in some cases, meet or exceed human labeling performance (Weld <em>et al., </em>ASSETS'19).</p>\n<p><strong>Thread-2: Accessibility-Aware Mapping Tools</strong></p>\n<p>In this thread, we explored how people with mobility impairments assess and evaluate accessibility in the built environment and the role of current and emerging location-based technologies therein (Hara <em>et al., </em>CHI'16), developed an initial set of new accessibility-aware mapping tools enabled by our Project Sidewalk data (Figure 5; Hara <em>et al.</em>, CHI'16; Hara and Froehlich, SIGACCESS'15; Li <em>et al., </em>ASSETS'18), and interviewed key stakeholder groups about their reactions to our designs and the idea of crowdsourced accessibility data (Hara <em>et al.</em>, CHI'16; Saha <em>et al., </em>CHI'19). We also enumerated and defined a set of 'Grand Challenges' in the area of accessibility and mapping (Froehlich <em>et al., </em>Interactions'19). Our research findings distill key features and data qualities of accessibility-aware mapping tools, help define a design space for future tools, and have been used to produce our own interactive visualizations (<em>e.g., </em>AccessScore and AccessVis).</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/01/2019<br>\n\t\t\t\t\tModified by: Jon&nbsp;Froehlich</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684669173_Figure2_ProjectSidewalkScreenshot--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684669173_Figure2_ProjectSidewalkScreenshot--rgov-800width.jpg\" title=\"Project Sidewalk interface screenshot showing a pole being labeled as an 'obstacle in path'\"><img src=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684669173_Figure2_ProjectSidewalkScreenshot--rgov-66x44.jpg\" alt=\"Project Sidewalk interface screenshot showing a pole being labeled as an 'obstacle in path'\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 2. A screenshot of our Project Sidewalk tool (http://projectsidewalk.io), which uses a game design paradigm to engage crowdworkers in remotely labeling pedestrian-related accessibility problems by assigning \"game\" missions to virtually walking through city streets in Google Street View.</div>\n<div class=\"imageCredit\">Jon E. Froehlich</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Jon&nbsp;Froehlich</div>\n<div class=\"imageTitle\">Project Sidewalk interface screenshot showing a pole being labeled as an 'obstacle in path'</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684594056_Figure1_InitialCrowdworkResults--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684594056_Figure1_InitialCrowdworkResults--rgov-800width.jpg\" title=\"Initial results from our crowdworker sidewalk labeling experiments\"><img src=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684594056_Figure1_InitialCrowdworkResults--rgov-66x44.jpg\" alt=\"Initial results from our crowdworker sidewalk labeling experiments\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 1. In initial work, we showed how minimally trained remote crowdworkers can accurately label accessibility features in streetscape imagery. Here, we show Google Street View images with annotations from our experiments with Mechanical Turk workers.</div>\n<div class=\"imageCredit\">Jon E. Froehlich</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Jon&nbsp;Froehlich</div>\n<div class=\"imageTitle\">Initial results from our crowdworker sidewalk labeling experiments</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684776168_Figure3_ProjectSidewalkDCResults--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684776168_Figure3_ProjectSidewalkDCResults--rgov-800width.jpg\" title=\"Five top-down map visualizations of the 205,000+ sidewalk accessibility labels collected in the deployment of Project Sidewalk in Washington DC\"><img src=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684776168_Figure3_ProjectSidewalkDCResults--rgov-66x44.jpg\" alt=\"Five top-down map visualizations of the 205,000+ sidewalk accessibility labels collected in the deployment of Project Sidewalk in Washington DC\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 3. In an 18-month deployment study of Project Sidewalk in Washington DC, we collected over 205,000 sidewalk accessibility labels, including curb ramps, missing curb ramps sidewalk obstacles, and surface problems. Each dot above represents a geo-located label rendered at 50% translucency.</div>\n<div class=\"imageCredit\">Jon E. Froehlich</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Jon&nbsp;Froehlich</div>\n<div class=\"imageTitle\">Five top-down map visualizations of the 205,000+ sidewalk accessibility labels collected in the deployment of Project Sidewalk in Washington DC</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684875058_Figure4_TohmeExample--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684875058_Figure4_TohmeExample--rgov-800width.jpg\" title=\"Example results from Tohme\"><img src=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564684875058_Figure4_TohmeExample--rgov-66x44.jpg\" alt=\"Example results from Tohme\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 4. In Hara et al., UIST'14, we introduced Tohme, which combines machine learning, computer vision, and custom crowd interfaces to identify curb ramps in Google Street View streetscape imagery. Example output from our hybrid human+machine workflow shown above.</div>\n<div class=\"imageCredit\">Jon E. Froehlich</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Jon&nbsp;Froehlich</div>\n<div class=\"imageTitle\">Example results from Tohme</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564685095190_Figure5_VisualizationPrototypes--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564685095190_Figure5_VisualizationPrototypes--rgov-800width.jpg\" title=\"Two initial interactive geo-visualization prototypes of neighborhood accessibility for people with mobility impairments enabled by the Project Sidewalk API\"><img src=\"/por/images/Reports/POR/2019/1302338/1302338_10245912_1564685095190_Figure5_VisualizationPrototypes--rgov-66x44.jpg\" alt=\"Two initial interactive geo-visualization prototypes of neighborhood accessibility for people with mobility impairments enabled by the Project Sidewalk API\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 5. Two initial interactive geo-visualization prototypes of neighborhood accessibility for people with mobility impairments enabled by the Project Sidewalk API (http://projectsidewalk.io/api).</div>\n<div class=\"imageCredit\">Jon E. Froehlich</div>\n<div class=\"imageSubmitted\">Jon&nbsp;Froehlich</div>\n<div class=\"imageTitle\">Two initial interactive geo-visualization prototypes of neighborhood accessibility for people with mobility impairments enabled by the Project Sidewalk API</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nSidewalks significantly impact the mobility and quality of life of millions of Americans; however, there are currently few, if any, mechanisms to determine the locations of sidewalks in the US and their accessibility characteristics (e.g., presence of curb ramps, sidewalk obstructions). To address this problem, our NSF proposal described two interrelated threads of work: first, to develop scalable data collection methods for acquiring street-level accessibility information using a combination of crowdsourcing, machine learning, and online map imagery, and second, to use this data to design, develop, and evaluate a novel set of navigation and map tools for accessibility. Our overarching aim has been--and continues to be--to transform how sidewalk data is collected and visualized in order to: provide increased transparency and accountability about city accessibility, help people with mobility impairments assess and navigate their cities, and assist urban planners and policy makers in decision making about pedestrian infrastructure.\n\nIn pursuit of these goals, our cross-disciplinary team has made research contributions to the fields of human-computer interaction, assistive technology, computer vision, and geographical information systems. Below, we first summarize key achievements before describing our research in more detail.\n\nKey Achievements\n\nWe developed and deployed award-winning interactive software artifacts, including Project Sidewalk (an online crowdsourcing tool for collecting sidewalk accessibility information) and AccessVis (interactive visualizations of urban accessibility). All of our code is open source here: https://github.com/ProjectSidewalk.\nOur work has produced what we believe to be the largest open-source sidewalk accessibility dataset: over 300,000 geo-located sidewalk accessibility labels across three cities: http://projectsidewalk.io/api \nOur deployed tools have received substantial interest from government and accessibility organizations (e.g., DDOT, USDS, White House OSTP, AARP) as well as media coverage. \nWe have published twenty scientific publications, including papers at top-tier venues such as CHI, ASSETS, and CVPR--two were honored with Best Paper Awards (Hara et al., ASSETS'13 and Saha et al., CHI'19) and one was selected for the ACM Computing Reviews \"Best of Computing 2014.\"\nPI Froehlich and Co-PI Jacobs have involved and mentored a diverse set of students from high school to undergrad and graduate students, including Kotaro Hara and Jin Sun's PhD dissertations, Ladan Najafizadeh's MS thesis, and multiple independent study projects with undergraduates. Our students have gone on to top industry positions and academic institutions such as UCLA, Stanford, and Cornell.\nWhile our original proposal focused primarily on people with mobility impairments, our work expanded to people who are blind or low-vision (e.g., Hara et al., ASSETS'13 , which received the Best Paper Award and Hara, TACCESS'15)--demonstrating the generalizability of our methods.\n\n\nThread-1: Scalable Data Collection\n\nIn initial work, we showed how minimally trained remote crowdworkers can accurately label accessibility features in streetscape imagery (Figure 1; Hara et al., ASSETS'12; Hara et al., CHI'13). Later, we demonstrated the scalability of this approach via Project Sidewalk (Saha et al., CHI'19), an online tool where crowdworkers can remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View (Figure 2). In three test deployments, we have collected over 300,000 geo-located sidewalk accessibility labels (Figure 3).\n\nWhile the above approaches are promising and improve data collection efficiency, they still rely solely on human labor, which limits scalability. Thus, we pursued a parallel thread of work examining how humans + computers could work together to semi-automatically assess sidewalk accessibility in online images. Our initial work focused on identifying curb ramps or missing curb ramps (e.g., Hara et al., HCOMP'13; Hara et al., UIST'14; Sun and Jacobs, CVPR'17). Hara et al., UIST'14, for example, showed that a hybrid solution that incorporates both human labels plus machine learning could detect curb ramps at a rate similar to humans alone but at a 13% reduction in time cost (Figure 4). More recently, enabled by our large Project Sidewalk dataset, we show how a convolutional neural network can significantly improve on previous automated methods and, in some cases, meet or exceed human labeling performance (Weld et al., ASSETS'19).\n\nThread-2: Accessibility-Aware Mapping Tools\n\nIn this thread, we explored how people with mobility impairments assess and evaluate accessibility in the built environment and the role of current and emerging location-based technologies therein (Hara et al., CHI'16), developed an initial set of new accessibility-aware mapping tools enabled by our Project Sidewalk data (Figure 5; Hara et al., CHI'16; Hara and Froehlich, SIGACCESS'15; Li et al., ASSETS'18), and interviewed key stakeholder groups about their reactions to our designs and the idea of crowdsourced accessibility data (Hara et al., CHI'16; Saha et al., CHI'19). We also enumerated and defined a set of 'Grand Challenges' in the area of accessibility and mapping (Froehlich et al., Interactions'19). Our research findings distill key features and data qualities of accessibility-aware mapping tools, help define a design space for future tools, and have been used to produce our own interactive visualizations (e.g., AccessScore and AccessVis).\n\n \n\n\t\t\t\t\tLast Modified: 08/01/2019\n\n\t\t\t\t\tSubmitted by: Jon Froehlich"
 }
}