{
 "awd_id": "1250880",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Small: DA: Choosing a Needle in a Big Data Haystack",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2013-03-15",
 "awd_exp_date": "2019-03-31",
 "tot_intn_awd_amt": 674765.0,
 "awd_amount": 674765.0,
 "awd_min_amd_letter_date": "2013-03-28",
 "awd_max_amd_letter_date": "2018-03-07",
 "awd_abstract_narration": "This big data project develops tools and algorithms to support users in the task of choosing one (or a few) object(s) from a very large set, particularly when there is a great deal of complex data on which to base this choice.\r\n\r\nConsider a traveler looking at hotel options on a travel site, a scientist trying to identify proteins to investigate further based upon the results of a high throughput experiment, or an intelligence analyst trying to identify suspected terrorists.  In all of these cases we have a big data challenge in that there are likely to be hundreds, perhaps thousands or even millions, of options to choose from.  While there are some criteria that can be expressed as simple functions of attribute values, e.g. price for a hotel room, these criteria capture only a part of the objective function.  Other considerations, such as stylishness of a hotel, can be much harder to determine as a function of known attributes.  The user may be compelled to examine candidate options individually.  The computer's task is to help minimize the number of candidates examined, and to optimize the order of examination.  This project examines how best to accomplish this task.\r\n\r\nTechniques explored include supporting human specification of information need against a variety of big data sources and machine presentation of relevant results with the volume of big data.  The broader impact of this project is in effectively harnessing the power of big data in a variety of applications, including business, science, and national defense.\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hosagrahar",
   "pi_last_name": "Jagadish",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Hosagrahar V Jagadish",
   "pi_email_addr": "jag@umich.edu",
   "nsf_id": "000461011",
   "pi_start_date": "2013-03-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "2260 Hayward",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092121",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 674765.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Big Data is affecting almost every aspect of society today, and hence is a very important topic to study.&nbsp; Three dimensions have frequently been used to characterize big data: Volume, Variety, and Velocity.&nbsp; This project studied challenges in the first two dimensions.&nbsp; The project title conveys the basic idea: we have a huge &ldquo;haystack&rdquo; of items from among which we wish to find the &ldquo;needles&rdquo; of interest.&nbsp; Furthermore, each blade of hay is different, making the haystack highly heterogeneous.</p>\n<p>To address the volume challenge, we developed two approaches: one, to reduce the amount of data, somehow condensing it without losing important information; and two, to scale our ability to handle larger volumes of data.&nbsp; When we discuss scaling, computer scientists typically think about scaling the ability of computer systems to process larger volumes of data.&nbsp; We did study some issues along these lines in our project.&nbsp; But, more importantly, we also studied how to make it possible for humans to make sense of large volumes of data, keeping in mind that their ability does not scale.</p>\n<p>The variety challenge manifests itself in two distinct places: in the construction of a clean database from the heterogeneous raw data we have access to; and in the querying of a database with complex heterogeneous structure that the user is not fully conversant with.&nbsp; We addressed both problems.&nbsp; To construct a database with desired structure and format, we developed techniques to create transformation programs by example.&nbsp; In other words, the user would specify some examples of the end result they would like to see, and the system would generalize from these examples to develop programs that could correctly adjust format, modify structure, or fuse data from multiple sources.&nbsp; To assist users in querying unfamiliar databases, we developed interactive support for data exploration, and also support for queries expressed in plain English rather than as a computer program.</p>\n<p>Finally, given the huge impacts of Big Data on society today, we made the case for a new &ldquo;Values&rdquo; dimension for Big Data, and developed a research agenda in this dimension.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/19/2019<br>\n\t\t\t\t\tModified by: H.&nbsp;V&nbsp;Jagadish</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nBig Data is affecting almost every aspect of society today, and hence is a very important topic to study.  Three dimensions have frequently been used to characterize big data: Volume, Variety, and Velocity.  This project studied challenges in the first two dimensions.  The project title conveys the basic idea: we have a huge \"haystack\" of items from among which we wish to find the \"needles\" of interest.  Furthermore, each blade of hay is different, making the haystack highly heterogeneous.\n\nTo address the volume challenge, we developed two approaches: one, to reduce the amount of data, somehow condensing it without losing important information; and two, to scale our ability to handle larger volumes of data.  When we discuss scaling, computer scientists typically think about scaling the ability of computer systems to process larger volumes of data.  We did study some issues along these lines in our project.  But, more importantly, we also studied how to make it possible for humans to make sense of large volumes of data, keeping in mind that their ability does not scale.\n\nThe variety challenge manifests itself in two distinct places: in the construction of a clean database from the heterogeneous raw data we have access to; and in the querying of a database with complex heterogeneous structure that the user is not fully conversant with.  We addressed both problems.  To construct a database with desired structure and format, we developed techniques to create transformation programs by example.  In other words, the user would specify some examples of the end result they would like to see, and the system would generalize from these examples to develop programs that could correctly adjust format, modify structure, or fuse data from multiple sources.  To assist users in querying unfamiliar databases, we developed interactive support for data exploration, and also support for queries expressed in plain English rather than as a computer program.\n\nFinally, given the huge impacts of Big Data on society today, we made the case for a new \"Values\" dimension for Big Data, and developed a research agenda in this dimension.\n\n \n\n\t\t\t\t\tLast Modified: 07/19/2019\n\n\t\t\t\t\tSubmitted by: H. V Jagadish"
 }
}