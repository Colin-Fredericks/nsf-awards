{
 "awd_id": "1311043",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "NSF East Asia and Pacific Summer Institute (EAPSI) for FY 2013 in China",
 "cfda_num": "47.079",
 "org_code": "01090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Anne Emig",
 "awd_eff_date": "2013-06-01",
 "awd_exp_date": "2014-05-31",
 "tot_intn_awd_amt": 5070.0,
 "awd_amount": 5070.0,
 "awd_min_amd_letter_date": "2013-05-15",
 "awd_max_amd_letter_date": "2013-05-15",
 "awd_abstract_narration": "This action funds Samuel Fuller Dodge of Arizona State University to conduct a research project in the Computer and Information Science and Engineering area during the summer of 2013 at Peking University in Beijing, China.  The project title is \"Biologically Inspired Computer Vision: Using Attention to Efficiently Process Visual Entities.\" The host scientist is Dr. Yizhou Wang.\r\n\r\nThis project studies the usefulness of biologically inspired visual attention models in computer vision applications. The human visual system is able to process a large amount of information using relatively few physiological resources by selectively focusing attention on the most salient areas of a scene. This same manner of information processing can be useful in computer vision systems that are under similar computational constraints. To this aim, this project investigates the relative influence of simple bottom-up attention and more complicated top-down attention for the applications of object recognition and scene understanding. Bottom-up attention is formed from low-level features that attract our attention such as a red dot in a sea of blue dots. Top-down attention stems from higher level cognitive processing, such as detecting a face in the scene. Together these two factors can yield a more appropriate attention model for use in computer vision recognition tasks.\r\n\r\nBroader impacts of an EAPSI fellowship include providing the Fellow a first-hand research experience outside the U.S.; an introduction to the science, science policy, and scientific infrastructure of the respective location; and an orientation to the society, culture and language.   These activities meet the NSF goal to educate for international collaborations early in the career of its scientists, engineers, and educators, thus ensuring a globally aware U.S. scientific workforce.  Furthermore, the results of this research will be disseminated in a top computer vision conference, so that this research can find use in practical application areas such as automation, healthcare, and intelligent systems. The fellow is working with Chinese graduate and undergraduate students to improve their professional English, so that they will be more prepared for conferences.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "O/D",
 "org_dir_long_name": "Office Of The Director",
 "div_abbr": "OISE",
 "org_div_long_name": "Office of International Science and Engineering",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Samuel",
   "pi_last_name": "Dodge",
   "pi_mid_init": "F",
   "pi_sufx_name": "",
   "pi_full_name": "Samuel F Dodge",
   "pi_email_addr": "",
   "nsf_id": "000630699",
   "pi_start_date": "2013-05-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Dodge                   Samuel         F",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "Scottsdale",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "",
  "inst_zip_code": "852541950",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "AZ01",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "Dodge                   Samuel         F",
  "perf_str_addr": null,
  "perf_city_name": "Scottsdale",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852541950",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "AZ01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "731600",
   "pgm_ele_name": "EAPSI"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5978",
   "pgm_ref_txt": "EAST ASIA AND PACIFIC PROGRAM"
  },
  {
   "pgm_ref_code": "7316",
   "pgm_ref_txt": "EAPSI"
  },
  {
   "pgm_ref_code": "9200",
   "pgm_ref_txt": "US CHINA COOP IN BASIC SCIENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 5070.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>When we open our eyes, our visual system is bombarded with a deluge of visual information. The amount of visual information is simply too much to process all at once. Our vision system therefore must employ a selectivity mechanism to choose which portions of the scene to process. Computational modeling of this process is important to both the psychology and computer vision communities. The goal of this project was to design a better experiment to gauge the performance of these attention models. This project was performed as part of the EAPSI project at Peking University in Beijing, China in the summer of 2013.</p>\n<p>&nbsp;</p>\n<p>In previous work, visual attention models are evaluated using eye tracking data. Subjects are ask to look at images of varying scenes while their gaze is tracked. A model is evaluated by how well it can predict human gaze on these images. However, the eye tracking data itself has several inherent problems. Visual attention can be divided into two types: overt attention and covert attention. Overt attention is manifested by eye movements, and covert attention can be directed independent of eye movements. Overt attention is often influenced by higher level cognitive processes, whereas covert attention is influenced by lower level features such as edges and color differences. Eye tracking data cannot measure the covert attention. However, it is desirable to measure this because covert attention more accurately represents the bottom-up component of visual attention.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Previous work at Peking University has developed a method to measure this covert attention. In this experiment subjects look at an image for 50ms. In such a short time frame, there can be no top-down higher level influences. However no eye movements can be made. Thus, a method is needed to measure attention in absence of eye movements. To measure attention, an oriented texture pattern is shown at a random location on a grid over the&nbsp; image for 50ms. If the subject is able to determine the correct orientation of the pattern (left or right), then that area of the image is deemed more salient.</p>\n<p>&nbsp;</p>\n<p>The primary limitation of this experiment is the amount of time it takes to collect the data. Because of this limitation, in the original experiment the output ground truth attention map is very low resolution. These low resolution images are not useful to evaluate saliency models. It is possible to obtain higher resolution ground truth maps, however the number of subjects and amount of time each subject must spend on the experiment is prohibitive. We proposed a solution to this problem by bringing this experiment to the internet. With this crowdsourcing, we are able to test on many subjects, however additional problems arise. A controlled setting is missing in internet experiments, because each subject will necessarily have a different computer setup. We argue that we can overcome this problem by introducing a notion of relative saliency. For each subject, we only consider the relative discrimination ability of that subject. This relative notion will cancel out any affects of screen size, brightness, etc. However from these relative measurements we must obtain a global ranking of saliency. We use the mathematical theory of HodgeRank to go from pairwise relative measurements to a global notion of saliency.&nbsp;</p>\n<p>&nbsp;</p>\n<p>During this project, we designed and implemented this experiment and tested the viability of using HodgeRank. In a lab setting, we showed that relative saliency with HodgeRank can give an adequate saliency map under different experimental conditions. We are continuing to work on this project and hope to submit a publication with our results in the near future.</p>\n<p>&nbsp;</p>\n<p>In addition to the scientific results, a large goal of the EAPSI program lies in broader cultural exchange with China. In preparation t...",
  "por_txt_cntn": "\nWhen we open our eyes, our visual system is bombarded with a deluge of visual information. The amount of visual information is simply too much to process all at once. Our vision system therefore must employ a selectivity mechanism to choose which portions of the scene to process. Computational modeling of this process is important to both the psychology and computer vision communities. The goal of this project was to design a better experiment to gauge the performance of these attention models. This project was performed as part of the EAPSI project at Peking University in Beijing, China in the summer of 2013.\n\n \n\nIn previous work, visual attention models are evaluated using eye tracking data. Subjects are ask to look at images of varying scenes while their gaze is tracked. A model is evaluated by how well it can predict human gaze on these images. However, the eye tracking data itself has several inherent problems. Visual attention can be divided into two types: overt attention and covert attention. Overt attention is manifested by eye movements, and covert attention can be directed independent of eye movements. Overt attention is often influenced by higher level cognitive processes, whereas covert attention is influenced by lower level features such as edges and color differences. Eye tracking data cannot measure the covert attention. However, it is desirable to measure this because covert attention more accurately represents the bottom-up component of visual attention. \n\n \n\nPrevious work at Peking University has developed a method to measure this covert attention. In this experiment subjects look at an image for 50ms. In such a short time frame, there can be no top-down higher level influences. However no eye movements can be made. Thus, a method is needed to measure attention in absence of eye movements. To measure attention, an oriented texture pattern is shown at a random location on a grid over the  image for 50ms. If the subject is able to determine the correct orientation of the pattern (left or right), then that area of the image is deemed more salient.\n\n \n\nThe primary limitation of this experiment is the amount of time it takes to collect the data. Because of this limitation, in the original experiment the output ground truth attention map is very low resolution. These low resolution images are not useful to evaluate saliency models. It is possible to obtain higher resolution ground truth maps, however the number of subjects and amount of time each subject must spend on the experiment is prohibitive. We proposed a solution to this problem by bringing this experiment to the internet. With this crowdsourcing, we are able to test on many subjects, however additional problems arise. A controlled setting is missing in internet experiments, because each subject will necessarily have a different computer setup. We argue that we can overcome this problem by introducing a notion of relative saliency. For each subject, we only consider the relative discrimination ability of that subject. This relative notion will cancel out any affects of screen size, brightness, etc. However from these relative measurements we must obtain a global ranking of saliency. We use the mathematical theory of HodgeRank to go from pairwise relative measurements to a global notion of saliency. \n\n \n\nDuring this project, we designed and implemented this experiment and tested the viability of using HodgeRank. In a lab setting, we showed that relative saliency with HodgeRank can give an adequate saliency map under different experimental conditions. We are continuing to work on this project and hope to submit a publication with our results in the near future.\n\n \n\nIn addition to the scientific results, a large goal of the EAPSI program lies in broader cultural exchange with China. In preparation to my trip to China, I studied Mandarin language extensively. The Chinese Science and Technology Exchange Center invited me for a video interview about the EAPSI p..."
 }
}