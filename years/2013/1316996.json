{
 "awd_id": "1316996",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "NSF East Asia and Pacific Summer Institute (EAPSI) for FY 2013 in Taiwan",
 "cfda_num": "47.079",
 "org_code": "01090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Anne Emig",
 "awd_eff_date": "2013-06-01",
 "awd_exp_date": "2014-05-31",
 "tot_intn_awd_amt": 5070.0,
 "awd_amount": 5070.0,
 "awd_min_amd_letter_date": "2013-05-16",
 "awd_max_amd_letter_date": "2013-05-16",
 "awd_abstract_narration": "This action funds Chen-Ping Yu of Stony Brook University to conduct a research project in the Computer and Information Science and Engineering area during the summer of 2013 at Perception and Attention Lab of National Taiwan University in Taipei, Taiwan.  The project title is \"Modeling Human Visual Attention using Object-based Attention.\" The host scientist is Dr. Su-Ling Yeh.\r\n\r\nThis project is developing a visual attention model as measured by shift in gaze, which is based on object-based attention theory and takes object parts (proto-objects) into account in addition to the usual spatial features. Current visual attention models predict where people look next based on salient regions of a scene, such as noticeable objects or just features that are prominent somewhere in the image. This corresponds to spatially-based attention, such that attention is driven by interesting locations in the scene. However, recent work suggests that objects can serve as the attention selection basis, in a way that when a person is already attending at an object, changes that occur on the attending object is noticed faster than the same changes that occur away from the object, albeit the same spatial distances. This object-based attention has not yet been captured in predicting human visual attention, and it is the goal for this project to incorporate object-based attention processing with existing spatially-based models in order to predict gaze shift that are more consistent with human behavior. The research model predicts that the shift of eye fixation utilizes the theory of object-based attention, and it requires three major components for processing: objects, the associated object parts (proto-objects), and the saliency map. The top-down object information is being obtained by applying state-of-the-art object detectors in computer vision; proto-objects are being segmented by merging coherent pixel fragments (superpixels) that are similar in low level features; and the saliency map is being generated using multi-scale blob detector on the image, with blob strength denoting the degree of spatial saliency. Initial fixation is set at the most salient region, and whenever an object is selected as being fixated, object-based attention suggests that consequent fixations may prioritize on the associate proto-objects before moving to another spatial salient location, in contrast from existing models that may immediately release from the attending object if other spatial location is deemed more salient. The performance of the eye movement model will be validated against a human fixation dataset using 1000 images from the PASCAL VOC2008 dataset and 104 images from the SUN 2009 dataset. \r\n\r\nBroader impacts of an EAPSI fellowship include providing the Fellow a first-hand research experience outside the U.S.; an introduction to the science, science policy, and scientific infrastructure of the respective location; and an orientation to the society, culture and language.   These activities meet the NSF goal to educate for international collaborations early in the career of its scientists, engineers, and educators, thus ensuring a globally aware U.S. scientific workforce.  Furthermore, this project facilitates the learning exchange between the fields of Psychology (human vision) and Computer Science (computer vision). The model can also help and improve visual aids design for the general public, and the underrepresented groups that may require visual representations to be more intuitively perceived. This impact naturally leads to more partnerships between research, education, and the industry, which is all based on the better understanding of human visual attention.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "O/D",
 "org_dir_long_name": "Office Of The Director",
 "div_abbr": "OISE",
 "org_div_long_name": "Office of International Science and Engineering",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chen-Ping",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chen-Ping Yu",
   "pi_email_addr": "",
   "nsf_id": "000635942",
   "pi_start_date": "2013-05-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Yu                      Chen-Ping",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "Stony Brook",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "",
  "inst_zip_code": "117944400",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "National Taiwan University",
  "perf_str_addr": null,
  "perf_city_name": "Taipei",
  "perf_st_code": "",
  "perf_st_name": "RI REQUIRED",
  "perf_zip_code": "10617",
  "perf_ctry_code": "TW",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "",
  "perf_ctry_name": "Taiwan",
  "perf_ctry_flag": "0"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "731600",
   "pgm_ele_name": "EAPSI"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5924",
   "pgm_ref_txt": "TAIWAN"
  },
  {
   "pgm_ref_code": "5978",
   "pgm_ref_txt": "EAST ASIA AND PACIFIC PROGRAM"
  },
  {
   "pgm_ref_code": "7316",
   "pgm_ref_txt": "EAPSI"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 5070.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project was proposed to study the usefulness of utilizing human eye fixation data as part of a fully automatic, general purpose object detection method. Various eye fixation datasets suggest that human subjects tend to fixate on objects when instructed to freely view a scene; we have applied mixture-models to clustering human eye-fixation data, which was highly successfully in locating potential objects in images automatically.&nbsp;</p>\n<p>While the results are promising, we find that human subjects often fixate on some representative part of an object, while possibly using their peripheral vision for the rest of the objects. This phenomenon increases the difficulty of segmenting the complete object boundary using eye fixation data. Nevertheless, most objects were automatically segmented with adequate bounding box with the aid of human eye fixation.</p>\n<p>The development of this project has unified the object-based attention, as well as spatial saliency in order to achieve automatic object detection using fixation data. This process has also enhanced collaborations between Taiwan's National Taiwan University and Stony Brook University of the US. Furthermore, the project also benefited from the collaboration between the field of human vision - psychology, and the field of computer vision. It shows the importance, as well as benefits, of applying human visual information into computer vision models; in addition to statistical methods, behavioral data is a crucial factur in designing computer vision models in order to make it more accurate and robust.&nbsp;</p>\n<p>Finally, the results of this project will lead to better understanding of both object detection for computer vision, as well as how human recognizes and fixates objects. The next step for this project is to model the human peripheral vision to better capture the complete boundary of the entire objects being detected from the fixations.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2013<br>\n\t\t\t\t\tModified by: Chen-Ping&nbsp;Yu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project was proposed to study the usefulness of utilizing human eye fixation data as part of a fully automatic, general purpose object detection method. Various eye fixation datasets suggest that human subjects tend to fixate on objects when instructed to freely view a scene; we have applied mixture-models to clustering human eye-fixation data, which was highly successfully in locating potential objects in images automatically. \n\nWhile the results are promising, we find that human subjects often fixate on some representative part of an object, while possibly using their peripheral vision for the rest of the objects. This phenomenon increases the difficulty of segmenting the complete object boundary using eye fixation data. Nevertheless, most objects were automatically segmented with adequate bounding box with the aid of human eye fixation.\n\nThe development of this project has unified the object-based attention, as well as spatial saliency in order to achieve automatic object detection using fixation data. This process has also enhanced collaborations between Taiwan's National Taiwan University and Stony Brook University of the US. Furthermore, the project also benefited from the collaboration between the field of human vision - psychology, and the field of computer vision. It shows the importance, as well as benefits, of applying human visual information into computer vision models; in addition to statistical methods, behavioral data is a crucial factur in designing computer vision models in order to make it more accurate and robust. \n\nFinally, the results of this project will lead to better understanding of both object detection for computer vision, as well as how human recognizes and fixates objects. The next step for this project is to model the human peripheral vision to better capture the complete boundary of the entire objects being detected from the fixations. \n\n \n\n \n\n\t\t\t\t\tLast Modified: 11/30/2013\n\n\t\t\t\t\tSubmitted by: Chen-Ping Yu"
 }
}