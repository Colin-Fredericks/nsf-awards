{
 "awd_id": "1314547",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF: AF: Large: Collaborative Research: Parallelism without Concurrency",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2013-07-01",
 "awd_exp_date": "2018-06-30",
 "tot_intn_awd_amt": 1000000.0,
 "awd_amount": 1000000.0,
 "awd_min_amd_letter_date": "2013-06-26",
 "awd_max_amd_letter_date": "2014-09-05",
 "awd_abstract_narration": "The widespread deployment of parallel machines --- from multicores to supercomputers --- has made it critical to develop simple approaches to programming them.  Significant progress has been made in simplifying parallel programming by developing programming models to support parallelism without concurrency, that is, without the nondeterminacies in the logic of programs caused by the relative and nondeterministic timing of communicating processes.  Yet most parallel programs in practice are concurrent, and hence, nondeterministic, leading to code that can only be programmed and understood by experts.  This research project aims to understand how parallel computers can be made easier to use by the vast majority of programmers by developing software technology that enables deterministic parallel computing.\r\n\r\nThe project takes a holistic view of the problem from the key perspectives of programming linguistics, software systems, algorithmic analysis, and absolute performance.  It acknowledges the reality that parallel programming cannot be fully deterministic at every level of abstraction.  It is pursuing three key strategies for dealing with concurrency: encapsulating concurrency so that it is hidden by layered abstractions at appropriate abstraction levels, avoiding concurrency by restructuring programs to employ deterministic approaches, and managing concurrency when it is impractical to either encapsulate or avoid concurrency completely. Among the specific techniques being studied are commutative building blocks, deterministic nonassociative reducers, deterministic pipelined parallelism, deterministic interfaces, and generalized race detection for detecting invariant races.  The project is developing open-source libraries, tools, and runtime extensions integrated into a multicore-software platform, as well as a problem-based benchmark suite to compare approaches.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Charles",
   "pi_last_name": "Leiserson",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Charles E Leiserson",
   "pi_email_addr": "cel@csail.mit.edu",
   "nsf_id": "000114754",
   "pi_start_date": "2013-06-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "794300",
   "pgm_ele_name": "PROGRAMMING LANGUAGES"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "7934",
   "pgm_ref_txt": "PARAL/DISTRIBUTED ALGORITHMS"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 500000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project produced a host of parallel programming technology and advanced the techniques for coping with nondeterminism in parallel programs.&nbsp; These developments include novel parallel algorithms, parallel runtime systems, productivity tools for analyzing the correctness and performance of parallel programs, parallel compiler technology, infrastructure for software performance engineering, and a variety of new techniques for writing fast parallel software.&nbsp; As multicore processors have become ubiquitous in today's computing milieu, these developments have grown the body of highly efficient parallel-computing software and deepened our understanding of deterministic parallel programming.&nbsp; These developments have thus made significant strides towards the goal of enabling the vast majority of computer programmers, not just experts, to use multicore-computing hardware to write efficient software.</p>\n<p><br />The project produced many efficient parallel algorithms.&nbsp; We developed efficient parallel algorithms for graph coloring and for data-graph computations, a class of graph computations popularized by such programming systems as Galois, Pregel, GraphLab, PowerGraph, and GraphChi.&nbsp; We also developed a system called Laika which efficiently processes data-graph computations for graphs that represent physical simulations.&nbsp; We developed the AUTOGEN algorithm for discovering efficient cache-oblivious parallel recursive algorithms for dynamic programming problems.&nbsp; We developed a high-throughput system to tackle the \"clusterscale\" problem of brain connectomics using a single commodity multicore machine.</p>\n<p><br />The project advanced language, compiler, and runtime-system technology for parallel computing.&nbsp; We developed linguistics and scheduling support for &ldquo;on-the-fly&rdquo; pipeline parallelism.&nbsp; We investigated a variant of the work-stealing algorithm that we call the localized work-stealing algorithm.&nbsp; We developed a compiler intermediate representation (IR), called Tapir, that embeds fork-join parallelism into a mainstream compiler's conventional IR for serial code.&nbsp; We developed CilkCloud, a lightweight framework for managing cloud-computing resources that is designed to meet the needs of university classes.&nbsp; We developed Tensor Comprehensions, an expressive language for deep-learning frameworks that supports effective compilation for different hardware.&nbsp; We have begun to develop Open Cilk, a new open-source platform to support Cilk multithreaded programming, especially for researchers and teachers.</p>\n<p><br />The project investigated novel productivity tools for studying the correctness and performance of parallel programs.&nbsp; We developed tools to detect sources of nondeterministic behavior in parallel programs that use reducer hyperobjects.&nbsp; We developed a scalability profiler, called Cilkprof, that can localize scalability bottlenecks in programs.&nbsp; We studied the problem of sensitivity analysis for parallel-program scalability.&nbsp; To facilitate future tool development, we developed the CSI framework to provide comprehensive static instrumentation that a compiler can insert into a program-under-test so that dynamic-analysis tools can observe and investigate runtime behavior.<br />The project developed a variety of other novel algorithms and systems for coping with nondeterminism and parallel-program performance.&nbsp; We developed a new memory allocator, called SuperMalloc, that is more than 3 times faster than the best alternatives on the worst-case workloads.&nbsp; We introduced a remarkably simple deterministic contention-management algorithm for guaranteeing the forward progress of transactions&mdash;avoiding deadlocks, livelocks, and other anomalies.&nbsp; We investigated hardware support for scalable contended data structures, and we developed Lease/Release, a simple addition to standard directory-based MSI cache coherence protocols, allowing participants to lease memory, at the granularity of cache lines, by delaying coherence messages for a short, bounded period of time.&nbsp; We developed the Single-Time/Random (SingleR) family of policies for reissuing requests in interactive services.&nbsp; We developed an external-memory skip list that achieves write-optimized bounds.&nbsp; We investigated cache-oblivious and cache-adaptive algorithms in both theory and practice.&nbsp; For optimizing computations on sparse matrices and tensors, we developed a sampling-based algorithm called PHIL to estimate the fill of sparse matrices and tensors in any format.&nbsp; We developed a dynamic sparse graph representation called Packed Compressed Sparse Row (PCSR) to optimize computations on dynamic graphs.</p>\n<p><br />The research artifacts from this project have been published in major academic conferences and journals.&nbsp; The software artifacts have been made available as free, open-source projects on the Web.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/27/2018<br>\n\t\t\t\t\tModified by: Charles&nbsp;E&nbsp;Leiserson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project produced a host of parallel programming technology and advanced the techniques for coping with nondeterminism in parallel programs.  These developments include novel parallel algorithms, parallel runtime systems, productivity tools for analyzing the correctness and performance of parallel programs, parallel compiler technology, infrastructure for software performance engineering, and a variety of new techniques for writing fast parallel software.  As multicore processors have become ubiquitous in today's computing milieu, these developments have grown the body of highly efficient parallel-computing software and deepened our understanding of deterministic parallel programming.  These developments have thus made significant strides towards the goal of enabling the vast majority of computer programmers, not just experts, to use multicore-computing hardware to write efficient software.\n\n\nThe project produced many efficient parallel algorithms.  We developed efficient parallel algorithms for graph coloring and for data-graph computations, a class of graph computations popularized by such programming systems as Galois, Pregel, GraphLab, PowerGraph, and GraphChi.  We also developed a system called Laika which efficiently processes data-graph computations for graphs that represent physical simulations.  We developed the AUTOGEN algorithm for discovering efficient cache-oblivious parallel recursive algorithms for dynamic programming problems.  We developed a high-throughput system to tackle the \"clusterscale\" problem of brain connectomics using a single commodity multicore machine.\n\n\nThe project advanced language, compiler, and runtime-system technology for parallel computing.  We developed linguistics and scheduling support for \"on-the-fly\" pipeline parallelism.  We investigated a variant of the work-stealing algorithm that we call the localized work-stealing algorithm.  We developed a compiler intermediate representation (IR), called Tapir, that embeds fork-join parallelism into a mainstream compiler's conventional IR for serial code.  We developed CilkCloud, a lightweight framework for managing cloud-computing resources that is designed to meet the needs of university classes.  We developed Tensor Comprehensions, an expressive language for deep-learning frameworks that supports effective compilation for different hardware.  We have begun to develop Open Cilk, a new open-source platform to support Cilk multithreaded programming, especially for researchers and teachers.\n\n\nThe project investigated novel productivity tools for studying the correctness and performance of parallel programs.  We developed tools to detect sources of nondeterministic behavior in parallel programs that use reducer hyperobjects.  We developed a scalability profiler, called Cilkprof, that can localize scalability bottlenecks in programs.  We studied the problem of sensitivity analysis for parallel-program scalability.  To facilitate future tool development, we developed the CSI framework to provide comprehensive static instrumentation that a compiler can insert into a program-under-test so that dynamic-analysis tools can observe and investigate runtime behavior.\nThe project developed a variety of other novel algorithms and systems for coping with nondeterminism and parallel-program performance.  We developed a new memory allocator, called SuperMalloc, that is more than 3 times faster than the best alternatives on the worst-case workloads.  We introduced a remarkably simple deterministic contention-management algorithm for guaranteeing the forward progress of transactions&mdash;avoiding deadlocks, livelocks, and other anomalies.  We investigated hardware support for scalable contended data structures, and we developed Lease/Release, a simple addition to standard directory-based MSI cache coherence protocols, allowing participants to lease memory, at the granularity of cache lines, by delaying coherence messages for a short, bounded period of time.  We developed the Single-Time/Random (SingleR) family of policies for reissuing requests in interactive services.  We developed an external-memory skip list that achieves write-optimized bounds.  We investigated cache-oblivious and cache-adaptive algorithms in both theory and practice.  For optimizing computations on sparse matrices and tensors, we developed a sampling-based algorithm called PHIL to estimate the fill of sparse matrices and tensors in any format.  We developed a dynamic sparse graph representation called Packed Compressed Sparse Row (PCSR) to optimize computations on dynamic graphs.\n\n\nThe research artifacts from this project have been published in major academic conferences and journals.  The software artifacts have been made available as free, open-source projects on the Web.\n\n\t\t\t\t\tLast Modified: 10/27/2018\n\n\t\t\t\t\tSubmitted by: Charles E Leiserson"
 }
}