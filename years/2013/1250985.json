{
 "awd_id": "1250985",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Small: DA: Statistical Machine Learning Methods for Scalable Data Analysis",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2013-07-01",
 "awd_exp_date": "2017-06-30",
 "tot_intn_awd_amt": 738971.0,
 "awd_amount": 738971.0,
 "awd_min_amd_letter_date": "2013-04-10",
 "awd_max_amd_letter_date": "2016-07-01",
 "awd_abstract_narration": "Big Data has become ubiquitous in modern industrial and scientific applications where the size and dimensionality of data are becoming so large as to require  new statistical tools for efficient data analysis. This collaborative project involving researchers at Rutgers University and Microsoft Research focuses on the theoretical and algorithmic development of advanced computational methods for big data analytics. While the problems to be investigated are motivated by various Internet applications, the resulting solutions are expected to be broadly applicable to other domains. \r\n\r\nThe project considers three interrelated main themes in big data analytics: (a) effective sampling of big datasets to filter out unreliable data source and improve statistical analysis;  (b) dimensionality reduction techniques that can best preserve information via hashing and sparse random projection techniques; and (c) large scale optimization techniques for machine learning that can directly handle large datasize. Anticipated results of this work include new theoretical results, new data analytics algorithms, and their open source software implementations.\r\n\r\nBroader impacts of the research include broadly disseminated open source implementations of scalable data analytics algorithms, research-based training and education of graduate and undergraduate students, and academic-industrial collaborations resulting in an interplay between fundamental research in machine learning and industrial applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cun-Hui",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cun-Hui Zhang",
   "pi_email_addr": "czhang@stat.rutgers.edu",
   "nsf_id": "000185504",
   "pi_start_date": "2016-07-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Tong",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tong Zhang",
   "pi_email_addr": "tozhang@illinois.edu",
   "nsf_id": "000102616",
   "pi_start_date": "2013-04-10",
   "pi_end_date": "2016-07-01"
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "Rutgers",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 738971.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The aim of the project is to introduce, develop and study new statistical techniques for analyzing big data. Specifically, it aims to develop practical methods, efficient algorithms, and solid theory for sampling and efficient optimization algorithms and related techniques for big data analysis. The project was motivated and will be directly applicable to compressed sensing, bioinformatics, neural imaging and many more disciplines where modern information technologies prosper. &nbsp;It has focused on problems of intense current interest in statistical and machine learning research and practice due to the rapid development of information technologies and their applications to modern scientific experiments and everyday life.&nbsp;</p>\n<p>The project team has proposed and developed methodologies in second order and nonconvex problems, and achieved several theoretical understandings of these complicated methods that are important for big data analysis. Despite the long history of the classic Newton's method, second-order methods have not become as popular as first-order ones for solving optimization problems. The main reason is that each iteration of this type of methods is expensive due to the computation of Hessian matrix of the objective function or its inverse. This computation can be prohibitive for large-scale problems. Members of the project team have designed a number of efficient second-order methods for solving different class of convex optimization problems. They have investigated new stochastic optimization methods suitable for big data applications, distributed optimization methods for big data problems, sampling methods for big data optimization and complex statistical models, and nonconvex methods.&nbsp;</p>\n<p>Project results have been presented in many conferences, seminars and other venues, and have been disseminated to communities of interest by publications in top journals in statistics and machine learning, preprints on arXiv. The project has created opportunities of training and professional development through supervision of postdocs and Ph.D. students, and collaboration with young researchers. It directly impacts the development of human resources by disseminating the project results through conference presentations, seminars and special courses, and scholastic websites.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/07/2017<br>\n\t\t\t\t\tModified by: Cun-Hui&nbsp;Zhang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe aim of the project is to introduce, develop and study new statistical techniques for analyzing big data. Specifically, it aims to develop practical methods, efficient algorithms, and solid theory for sampling and efficient optimization algorithms and related techniques for big data analysis. The project was motivated and will be directly applicable to compressed sensing, bioinformatics, neural imaging and many more disciplines where modern information technologies prosper.  It has focused on problems of intense current interest in statistical and machine learning research and practice due to the rapid development of information technologies and their applications to modern scientific experiments and everyday life. \n\nThe project team has proposed and developed methodologies in second order and nonconvex problems, and achieved several theoretical understandings of these complicated methods that are important for big data analysis. Despite the long history of the classic Newton's method, second-order methods have not become as popular as first-order ones for solving optimization problems. The main reason is that each iteration of this type of methods is expensive due to the computation of Hessian matrix of the objective function or its inverse. This computation can be prohibitive for large-scale problems. Members of the project team have designed a number of efficient second-order methods for solving different class of convex optimization problems. They have investigated new stochastic optimization methods suitable for big data applications, distributed optimization methods for big data problems, sampling methods for big data optimization and complex statistical models, and nonconvex methods. \n\nProject results have been presented in many conferences, seminars and other venues, and have been disseminated to communities of interest by publications in top journals in statistics and machine learning, preprints on arXiv. The project has created opportunities of training and professional development through supervision of postdocs and Ph.D. students, and collaboration with young researchers. It directly impacts the development of human resources by disseminating the project results through conference presentations, seminars and special courses, and scholastic websites. \n\n \n\n\t\t\t\t\tLast Modified: 08/07/2017\n\n\t\t\t\t\tSubmitted by: Cun-Hui Zhang"
 }
}