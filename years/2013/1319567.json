{
 "awd_id": "1319567",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "HCC: CGV: Small: Eyeglass-Style Multi-Layer Optical See-Through Displays for Augmented Reality",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 499997.0,
 "awd_amount": 499997.0,
 "awd_min_amd_letter_date": "2013-09-02",
 "awd_max_amd_letter_date": "2013-09-02",
 "awd_abstract_narration": "For over two decades, researchers have shown the potential of augmented reality (AR) to transform computer graphics into an everyday extension of human vision that can enhance such diverse applications as medicine, manufacturing, maintenance, smart offices, and navigation.  However, there is virtually no use of augmented reality by the public or industry today.  The investigators believe that this discrepancy is due largely to the lack of suitable high performance and widely applicable augmented reality displays on which applications can be deployed.  The most capable AR displays available today, optical see-through head-mounted displays (HMDs), generally lack four key qualities that prevent their widespread use: wide field-of-view, non-encumbering, support for mutual occlusion, and preservation of most depth cues.  The investigators know of no existing or proposed displays that feature all, or even most, of these capabilities.  This project takes a radically different approach to optical see-through design that offers the potential to deliver all four missing qualities in a compact form factor that approaches ordinary glasses. The approach relies on a multi-layer display architecture that follows the principles of the emerging field of computational displays - simple optical devices whose functionality and complexity generally lies in software.  This project applies existing multi-layer optimization techniques from desktop 3D displays to optical see-through HMDs, while exploring new approaches such as perceptual error metrics, the use multiple layers for occlusion masks, and field of view zone prioritization. This knowledge will be used to build prototype optical see-through displays while handing such challenges as calibration, tracking, computational complexity, and latency. The performance of this approach will be robustly tested and evaluated in simulation, with calibrated cameras, and with human viewers.  The target device will transform augmented reality, allowing society to take advantage of the diverse set of applications that have been studied in AR.  The proposed design is a radically different approach to optical see-through displays that uses spatial light modulators and software optimization to replace conventional reflective, refractive, and diffractive optics. The ability to produce a focused image on a display placed closer than the eye can accommodate without the use of lenses will be investigated.  Sharing of display components for both image formation and occlusion masking will also be researched.  The investigators will also explore the use of multi-layer optimization to create multi-focal imagery, prioritize different areas over the viewer's field of view, and facilitate eye tracking.\r\n\r\nBroader Impacts:  Research and practice have shown the promise of augmented reality to improve such diverse areas as medicine, accessibility, worker efficiency and communications.  However, to date there is very little use of augmented reality by the public or industry.  This project will lead to a high performance augmented reality display that is badly needed to make the field practical and allow the public to reap the benefits of years of visionary augmented reality research.  The science and technology developed in this project will open the use of augmented reality to a wider class of researchers, similar to how the recent development of the commodity depth sensor has permitted new opportunities for scientific inquiry.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Henry",
   "pi_last_name": "Fuchs",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Henry Fuchs",
   "pi_email_addr": "fuchs@cs.unc.edu",
   "nsf_id": "000451367",
   "pi_start_date": "2013-09-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "201 S. Columbia St",
  "perf_city_name": "Chapel Hill",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275993175",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 499997.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we investigated the design of Augmented Reality displays that have both wide field of view and also a compact form factor, one as close as possible to ordinary eyeglasses. We investigated several designs. The first was based on multiple active layers featuring a stack of two LCDs and a backlight. Results were encouraging.&nbsp; The second design featured only a single LCD with a \"backlight\" that was a grid of tiny point light sources. This grid was achieved by laser drilling tiny divots (35 micrometer diameter, ~100micrometer deep) on the surface of an acrylic sheet. The sheet was edge-lighted with a small number LEDs. At the divots, light emerged preferentially toward the user's eye.</p>\n<p>The result was a very simple, very compact display (just the LCD, with an edge lighted acrylic sheet. The display also exhibited a field of view in excess of 100 degrees diagonal, far wider than previous eye-glass sized AR displays; displays in Lumus DK-32, Microsoft HoloLens, Daqri are all about 40 degrees diagonal.</p>\n<p>The image quality was lower than in the state of the art commercial displays, limited by the resolution of LCDs that were available in the requisite physical size (about the size of lenses in a pair of eyeglasses). With higher resolution LCDs, diffraction effects would limit the resolution.</p>\n<p>Despite these limitations, we were able to attract an industrial collaborator, NVIDIA, and to demonstrate the display widely, at an Emerging Technologies booth at ACM Siggraph 2014, the world's premier computer graphics conference.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/05/2018<br>\n\t\t\t\t\tModified by: Henry&nbsp;Fuchs</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this project, we investigated the design of Augmented Reality displays that have both wide field of view and also a compact form factor, one as close as possible to ordinary eyeglasses. We investigated several designs. The first was based on multiple active layers featuring a stack of two LCDs and a backlight. Results were encouraging.  The second design featured only a single LCD with a \"backlight\" that was a grid of tiny point light sources. This grid was achieved by laser drilling tiny divots (35 micrometer diameter, ~100micrometer deep) on the surface of an acrylic sheet. The sheet was edge-lighted with a small number LEDs. At the divots, light emerged preferentially toward the user's eye.\n\nThe result was a very simple, very compact display (just the LCD, with an edge lighted acrylic sheet. The display also exhibited a field of view in excess of 100 degrees diagonal, far wider than previous eye-glass sized AR displays; displays in Lumus DK-32, Microsoft HoloLens, Daqri are all about 40 degrees diagonal.\n\nThe image quality was lower than in the state of the art commercial displays, limited by the resolution of LCDs that were available in the requisite physical size (about the size of lenses in a pair of eyeglasses). With higher resolution LCDs, diffraction effects would limit the resolution.\n\nDespite these limitations, we were able to attract an industrial collaborator, NVIDIA, and to demonstrate the display widely, at an Emerging Technologies booth at ACM Siggraph 2014, the world's premier computer graphics conference.\n\n\t\t\t\t\tLast Modified: 06/05/2018\n\n\t\t\t\t\tSubmitted by: Henry Fuchs"
 }
}