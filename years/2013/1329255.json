{
 "awd_id": "1329255",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Acoustic Foundations of Speech Perception",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Uri Hasson",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2017-06-30",
 "tot_intn_awd_amt": 475958.0,
 "awd_amount": 475958.0,
 "awd_min_amd_letter_date": "2013-08-29",
 "awd_max_amd_letter_date": "2013-08-29",
 "awd_abstract_narration": "Our brains have evolved a highly-sophisticated auditory system for the analysis of sounds, which underlies more complicated abilities such as speech perception. We currently know very little about the organization of human auditory cortex at the interface between the auditory inputs from the peripheral sensory receptors in the ear and the higher-level language systems of the brain. Understanding the nature of the inputs to higher-level speech perception systems is critical to understanding what kind of information is ultimately used in speech perception and how this information is extracted computationally. With support from the National Science Foundation, Dr. Alyssa Brewer and colleagues Dr. Gregory Hickok and Dr. Kourosh Saberi will use functional magnetic resonance imaging (fMRI) to measure the functional organization of the human auditory cortex with a level of detail that has not previously been achieved. They will then use these measurements to examine how cortical responses to particular types of speech and speech-related stimuli relate to these lower-level cortical regions. This study will thus provide the first systematic measurements of the human speech perception system from the fundamental organization of auditory cortex to cortical speech representations.\r\n\r\n Acquired and developmental disorders of hearing, speech and language affect millions of individuals. The knowledge gained from this study will give us a better understanding of the organization and function of these systems, which will have clinical benefits for the treatment of both peripheral auditory diseases and central language disorders.  The research team will continue to share the results through \"Brain Day\" programs in the local K-8 elementary schools to bring the excitement of neuroscience research to the local communities. Furthermore, PI Brewer has developed ongoing \"Brilliant Brain\" workshops with Girls Inc., which include special presentations and summer workshops on the organization, function, and diseases of the brain.  Girls Inc. is a non-profit organization that provides research and STEM-based experiences to girls ages 6-18 across the U.S. and Canada designed to help them navigate gender, economic, and social barriers. Finally, this study incorporates training of new neuroscientists at the undergraduate, graduate, and postdoctoral levels for whom these studies will serve as a foundation of neuroscience research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alyssa",
   "pi_last_name": "Brewer",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Alyssa A Brewer",
   "pi_email_addr": "aabrewer@uci.edu",
   "nsf_id": "000523480",
   "pi_start_date": "2013-08-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gregory",
   "pi_last_name": "Hickok",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Gregory S Hickok",
   "pi_email_addr": "gshickok@uci.edu",
   "nsf_id": "000444294",
   "pi_start_date": "2013-08-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kourosh",
   "pi_last_name": "Saberi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kourosh Saberi",
   "pi_email_addr": "saberi@uci.edu",
   "nsf_id": "000453552",
   "pi_start_date": "2013-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Irvine",
  "inst_street_address": "160 ALDRICH HALL",
  "inst_street_address_2": "",
  "inst_city_name": "IRVINE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9498247295",
  "inst_zip_code": "926970001",
  "inst_country_name": "United States",
  "cong_dist_code": "47",
  "st_cong_dist_code": "CA47",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA IRVINE",
  "org_prnt_uei_num": "MJC5FCYQTPE6",
  "org_uei_num": "MJC5FCYQTPE6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Irvine",
  "perf_str_addr": "2240 SBSG",
  "perf_city_name": "Irvine",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "926975100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "47",
  "perf_st_cong_dist": "CA47",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169900",
   "pgm_ele_name": "Cognitive Neuroscience"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1699",
   "pgm_ref_txt": "COGNEURO"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "7956",
   "pgm_ref_txt": "SBE Interdisciplinary Research"
  },
  {
   "pgm_ref_code": "8213",
   "pgm_ref_txt": "IBSS"
  },
  {
   "pgm_ref_code": "8605",
   "pgm_ref_txt": "SBE 2020"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 475958.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Acquired and developmental disorders of hearing, speech and language affect millions of individuals. Excellent progress has been made in understanding the peripheral auditory system and the neural basis of language disorders, leading to translational applications. Substantially less progress has been made in understanding the organization of the system at the interface between the auditory periphery and language systems, namely, human auditory cortex, the organization of which is largely inferred from animal studies and a handful of relatively course-grained imaging studies.</p>\n<p>&nbsp;</p>\n<p>The research funded by this grant has generated a once-in-a-generation leap forward in our understanding of the cortical organization of the human auditory system. When compared to the human visual system, the organization of the human auditory system is just beginning to be understood. Sounds are inherently spectral (ranging in frequency) and temporal (ranging in time), and modulated by intensity (ranging in loudness). Until recently, the primary theory of auditory cortical organization postulated that the fundamental unit of the auditory system was frequency response, which is distributed systematically in topographic patterns across auditory cortex (tonotopy). Research funded by this grant has fundamentally altered our understanding of the auditory system, clearly indicating two fundamental topographical dimensions of auditory cortex: frequency selectivity (tonotopy) and temporal selectivity (periodotopy). This organization mirrors the most basic characteristics of sound, and also reflects the organization of the visual system, which is similarly organized around visual responses of the retinae.</p>\n<p>&nbsp;</p>\n<p>We have demonstrated that human auditory cortex contains cells that are systematically organized with neurons representing nearby dimensional values (nearby frequencies or nearby temporal envelopes) located nearby on the cortical sheet. Furthermore, these dimensions are represented orthogonally to one another, such that a population of neurons represents each unique combination of spectral and temporal values in the range of human perception. Each complete set of spectrotemporal representations is known as an auditory field map (AFM). We have now shown that each hemisphere of the human brain contains more than twenty such AFMs, each of which is specialized to detect one or more auditory features. In fact, we also demonstrated that these AFMs are grouped into cloverleaf clusters in which each AFM is very specifically oriented relative to its neighbors despite not being oriented particularly strongly with respect to anatomical landmarks.</p>\n<p>&nbsp;</p>\n<p>This knowledge is incredibly important because the entire human auditory system deals with information that first enters cortex organized as we have demonstrated. All models of auditory system organization, ranging from low-level feature detection to high-level language processing, are thus affected by the data that has resulted from funding by this grant. From the perspective of impact for a fellow auditory neuroscientist, our findings provide an efficient method that can now localize at least forty AFMs in individual human subjects with minimal scan time for the subject compared to performing a localizer for each AFM individually.&nbsp; These results have already and will continue to overturn traditional models of the human cortical auditory system, revolutionizing our understanding of auditory processing and allowing future development of specialized methods to assess dysfunction and guide medical treatment.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/23/2018<br>\n\t\t\t\t\tModified by: Kourosh&nbsp;Saberi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAcquired and developmental disorders of hearing, speech and language affect millions of individuals. Excellent progress has been made in understanding the peripheral auditory system and the neural basis of language disorders, leading to translational applications. Substantially less progress has been made in understanding the organization of the system at the interface between the auditory periphery and language systems, namely, human auditory cortex, the organization of which is largely inferred from animal studies and a handful of relatively course-grained imaging studies.\n\n \n\nThe research funded by this grant has generated a once-in-a-generation leap forward in our understanding of the cortical organization of the human auditory system. When compared to the human visual system, the organization of the human auditory system is just beginning to be understood. Sounds are inherently spectral (ranging in frequency) and temporal (ranging in time), and modulated by intensity (ranging in loudness). Until recently, the primary theory of auditory cortical organization postulated that the fundamental unit of the auditory system was frequency response, which is distributed systematically in topographic patterns across auditory cortex (tonotopy). Research funded by this grant has fundamentally altered our understanding of the auditory system, clearly indicating two fundamental topographical dimensions of auditory cortex: frequency selectivity (tonotopy) and temporal selectivity (periodotopy). This organization mirrors the most basic characteristics of sound, and also reflects the organization of the visual system, which is similarly organized around visual responses of the retinae.\n\n \n\nWe have demonstrated that human auditory cortex contains cells that are systematically organized with neurons representing nearby dimensional values (nearby frequencies or nearby temporal envelopes) located nearby on the cortical sheet. Furthermore, these dimensions are represented orthogonally to one another, such that a population of neurons represents each unique combination of spectral and temporal values in the range of human perception. Each complete set of spectrotemporal representations is known as an auditory field map (AFM). We have now shown that each hemisphere of the human brain contains more than twenty such AFMs, each of which is specialized to detect one or more auditory features. In fact, we also demonstrated that these AFMs are grouped into cloverleaf clusters in which each AFM is very specifically oriented relative to its neighbors despite not being oriented particularly strongly with respect to anatomical landmarks.\n\n \n\nThis knowledge is incredibly important because the entire human auditory system deals with information that first enters cortex organized as we have demonstrated. All models of auditory system organization, ranging from low-level feature detection to high-level language processing, are thus affected by the data that has resulted from funding by this grant. From the perspective of impact for a fellow auditory neuroscientist, our findings provide an efficient method that can now localize at least forty AFMs in individual human subjects with minimal scan time for the subject compared to performing a localizer for each AFM individually.  These results have already and will continue to overturn traditional models of the human cortical auditory system, revolutionizing our understanding of auditory processing and allowing future development of specialized methods to assess dysfunction and guide medical treatment.\n\n\t\t\t\t\tLast Modified: 07/23/2018\n\n\t\t\t\t\tSubmitted by: Kourosh Saberi"
 }
}