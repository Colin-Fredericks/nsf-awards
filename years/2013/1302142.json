{
 "awd_id": "1302142",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CGV: Medium: Collaborative Research: Developing conceptual models for navigation, marking, and inspection in the context of 3D image segmentation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2013-06-15",
 "awd_exp_date": "2018-05-31",
 "tot_intn_awd_amt": 286300.0,
 "awd_amount": 310300.0,
 "awd_min_amd_letter_date": "2013-06-12",
 "awd_max_amd_letter_date": "2016-08-06",
 "awd_abstract_narration": "3D image segmentation is an important and ubiquitous task in image-oriented scientific disciplines, particularly biomedicine, where images provide the basis for biological discovery.  While imaging techniques reveal spatial content and activities within an entire subject, ultimately biologists are interested in specific anatomical structures (e.g., organs, tissues, cells, etc.).  Delineation of the structures of interest within a given set of images is therefore a typical first-step in the data-to-knowledge pipeline, with both the efficiency and accuracy of segmentation critically affecting how the data is utilized in research and clinical practice.  Creating accurate segmentations, particularly for 3D biomedical images, is a non-trivial task that calls for cooperation between humans and computers.  While human experts, with their superior visual perception skills and vast knowledge and experience acquired from years of training, ultimately decide what constitutes an accurate segmentation, they lack the objectivity or efficiency of computational algorithms.  On the other hand, without expert guidance, segmentation algorithms easily fail in the presence of the noise and ambiguity that are inevitable in biomedical images.  In this research the PIs will investigate 3D image segmentation as a human-computer interaction paradigm to better understand the human factors that are involved in the current segmentation process, with the goal of making the process more efficient, accurate and repeatable.  The team's hypothesis is that the segmentation process could be significantly improved through a deeper understanding of how people perform low-level perception and cognition tasks in the context of 3D segmentation (e.g., visual cues, delineation of structures by marks, and local accuracy or quality criteria), and how domain experts wish to specify high-level segmentation constraints (e.g., connectivity, topology, and shape).  To test this hypothesis the PIs will analyze the segmentation process by domain experts that span a reasonable subspace of the actual segmentors and segmentation tasks in biology and clinical practice, to define a conceptual framework that captures the low-level perception and cognitive elements of segmentation as well as the higher-level information related to navigation, marking, and inspection.  Building upon and instantiating the framework, the team will work with experts to develop a prototype segmentation tool that explores novel interaction and visualization paradigms as well as their supporting algorithms.  The prototype tool will be used to both verify the conceptual framework and to create a more effective practical solution to segmentation.\r\n\r\nBroader Impacts:  By formulating and studying segmentation as a human perception and cognitive task, this work represents a major departure from existing research on either segmentation algorithms or tools.  The resulting conceptual framework will serve as a bridge between the two communities, leading both to better designs for current and future segmentation tools and the framing of new problems for segmentation algorithms.  For end users, the working prototype will support a more effective segmentation experience that is powered by the underlying conceptual framework.  Furthermore, formalizing the kinds of perceptual cues and conceptual models users have when approaching the segmentation problem will serve as a useful test case for understanding the more general question of how perception and cognition interact when they are re-mapped to solve a problem they were never designed for.  To disseminate the findings of this research, the PIs will release their working prototype as an open-source project, which can then serve as a shared communication platform between algorithm developers, tool developers, and end users.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cindy",
   "pi_last_name": "Grimm",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Cindy M Grimm",
   "pi_email_addr": "grimmc@onid.orst.edu",
   "nsf_id": "000464868",
   "pi_start_date": "2013-06-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Oregon State University",
  "inst_street_address": "1500 SW JEFFERSON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CORVALLIS",
  "inst_state_code": "OR",
  "inst_state_name": "Oregon",
  "inst_phone_num": "5417374933",
  "inst_zip_code": "973318655",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "OR04",
  "org_lgl_bus_name": "OREGON STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "MZ4DYXE1SL98"
 },
 "perf_inst": {
  "perf_inst_name": "Oregon State University",
  "perf_str_addr": "204 Rogers Hall",
  "perf_city_name": "Corvallis",
  "perf_st_code": "OR",
  "perf_st_name": "Oregon",
  "perf_zip_code": "973318569",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "OR04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 286300.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 12000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 12000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-64b4aab4-d8d8-8c1b-8c31-fd60a217d20f\"> </span></p>\n<p dir=\"ltr\"><span>3D volume segmentation is an important tool in medicine and science - it lets doctors and scientists &ldquo;see&rdquo; inside of biological structures such as cells and organs and ask questions such as &ldquo;is the tumor growing or shrinking?&rdquo;. Volume segmentation starts with taking 3D pictures of the object of interest using machines such as MRIs, CT, and ultra sounds. In order to go from a picture to something the doctor or scientist can measure (see primary image) the user works with the computer to segment the picture into structures - essentially, trace the outline of the structure. This process is, unfortunately, slow, time-intensive, and relies on the skills of the segmenter. Exactly what skills were needed, how to train someone to segment, and what the best algorithms and tools are needed to ensure quality results was unknown at the start of this project.</span></p>\n<p><span id=\"docs-internal-guid-fc785fd1-d8d9-1bdc-5add-8d11907f116f\"> </span></p>\n<p dir=\"ltr\"><span>Over the course of the project we conducted structured interviews with experts in order to understand what they were doing and why. Part of the study involved tracking where the user was looking as they traced out the boundaries of objects, along with teasing apart what steps they did when (see Field Study image). </span></p>\n<p>From these studies we were able to classify what was different from the way the expert approached the problem and how novice did. Our primary discovery was that experts were more holistic in their approach, and had a better understanding of what the overall shape they were making was and were constantly checking that what they were doing was correct.</p>\n<p>A key part of what the experts were doing was going from these cross sections (the orange drawings in primary figure) to the 3D shape and back again - and that they had a really good understanding of what the cross sections should look like depending on the shape and the plane they were drawing on. We developed both a testing and a training tool to improve someone&rsquo;s ability to do this. We tested the tool (see below) and showed that it was successful in improving this skill set.</p>\n<p>On the algorithmic side, we developed several methods for making it easier for the user to start with an existing shape and simply edit a few cross-sections to adapt that shape to a new one. This has the potential to greatly speed up the manual editing and review process, since the user only has to make a few small edits, rather than start from scratch every time.</p>\n<p>Through understanding what experts see, think and do during the process of 3D segmentation, and determining how that differs from how novices accomplish this same task, we contributed knowledge and methods to increase the efficiency, quality and repeatability of the process of 3D segmentation applicable in any field that uses 3D imaging.</p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p><span id=\"docs-internal-guid-4c97bf28-d8d9-97c9-4320-34898004e5f6\"> </span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p><span id=\"docs-internal-guid-fc785fd1-d8d9-1bdc-5add-8d11907f116f\"> </span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p><span id=\"docs-internal-guid-64b4aab4-d8d8-8c1b-8c31-fd60a217d20f\"> </span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/26/2018<br>\n\t\t\t\t\tModified by: Cindy&nbsp;M&nbsp;Grimm</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646216847_SegmentationProcess2016--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646216847_SegmentationProcess2016--rgov-800width.jpg\" title=\"Segmentation process\"><img src=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646216847_SegmentationProcess2016--rgov-66x44.jpg\" alt=\"Segmentation process\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Segmenting a developing heart by tracing the outlines of the structure (orange contour drawings) on each image plane. The contours are put together to show the overall 3D shape extracted from the imaging data (Orange lines on aqua structure, at right).</div>\n<div class=\"imageCredit\">Cindy Grimm and Ruth West</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Cindy&nbsp;M&nbsp;Grimm</div>\n<div class=\"imageTitle\">Segmentation process</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646304751_FieldStudySegmentation2015--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646304751_FieldStudySegmentation2015--rgov-800width.jpg\" title=\"Field study\"><img src=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646304751_FieldStudySegmentation2015--rgov-66x44.jpg\" alt=\"Field study\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Observing experts conducting segmentation (right). Examples of tracing contours around structures (top, light pink) and eye tracking heat map showing where experts are looking (multicolor on each of three left images).</div>\n<div class=\"imageCredit\">Cindy Grimm and Ruth West</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Cindy&nbsp;M&nbsp;Grimm</div>\n<div class=\"imageTitle\">Field study</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646388162_CrossSectionTrainingTool2017--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646388162_CrossSectionTrainingTool2017--rgov-800width.jpg\" title=\"Cross-section training tool\"><img src=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646388162_CrossSectionTrainingTool2017--rgov-66x44.jpg\" alt=\"Cross-section training tool\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Testing and training tool for cross-section and 3D cross-section understanding ability.</div>\n<div class=\"imageCredit\">Anahita Sanandanji</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Cindy&nbsp;M&nbsp;Grimm</div>\n<div class=\"imageTitle\">Cross-section training tool</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646907253_CrossSectionUpdate2016--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646907253_CrossSectionUpdate2016--rgov-800width.jpg\" title=\"Cross-section updating\"><img src=\"/por/images/Reports/POR/2018/1302142/1302142_10251440_1532646907253_CrossSectionUpdate2016--rgov-66x44.jpg\" alt=\"Cross-section updating\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Example sequence showing the incremental updates of the segmentation ascontours are added.</div>\n<div class=\"imageCredit\">Michelle Holloway</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Cindy&nbsp;M&nbsp;Grimm</div>\n<div class=\"imageTitle\">Cross-section updating</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \n3D volume segmentation is an important tool in medicine and science - it lets doctors and scientists \"see\" inside of biological structures such as cells and organs and ask questions such as \"is the tumor growing or shrinking?\". Volume segmentation starts with taking 3D pictures of the object of interest using machines such as MRIs, CT, and ultra sounds. In order to go from a picture to something the doctor or scientist can measure (see primary image) the user works with the computer to segment the picture into structures - essentially, trace the outline of the structure. This process is, unfortunately, slow, time-intensive, and relies on the skills of the segmenter. Exactly what skills were needed, how to train someone to segment, and what the best algorithms and tools are needed to ensure quality results was unknown at the start of this project.\n\n \nOver the course of the project we conducted structured interviews with experts in order to understand what they were doing and why. Part of the study involved tracking where the user was looking as they traced out the boundaries of objects, along with teasing apart what steps they did when (see Field Study image). \n\nFrom these studies we were able to classify what was different from the way the expert approached the problem and how novice did. Our primary discovery was that experts were more holistic in their approach, and had a better understanding of what the overall shape they were making was and were constantly checking that what they were doing was correct.\n\nA key part of what the experts were doing was going from these cross sections (the orange drawings in primary figure) to the 3D shape and back again - and that they had a really good understanding of what the cross sections should look like depending on the shape and the plane they were drawing on. We developed both a testing and a training tool to improve someone?s ability to do this. We tested the tool (see below) and showed that it was successful in improving this skill set.\n\nOn the algorithmic side, we developed several methods for making it easier for the user to start with an existing shape and simply edit a few cross-sections to adapt that shape to a new one. This has the potential to greatly speed up the manual editing and review process, since the user only has to make a few small edits, rather than start from scratch every time.\n\nThrough understanding what experts see, think and do during the process of 3D segmentation, and determining how that differs from how novices accomplish this same task, we contributed knowledge and methods to increase the efficiency, quality and repeatability of the process of 3D segmentation applicable in any field that uses 3D imaging.\n\n\n\n \n\n \n\n\n\n \n\n \n\n\n\n \n\n \n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 07/26/2018\n\n\t\t\t\t\tSubmitted by: Cindy M Grimm"
 }
}