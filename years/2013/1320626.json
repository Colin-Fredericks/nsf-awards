{
 "awd_id": "1320626",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Belief Evolutions in Networks of Bayesian Agents",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Cozzens",
 "awd_eff_date": "2013-07-01",
 "awd_exp_date": "2017-06-30",
 "tot_intn_awd_amt": 393059.0,
 "awd_amount": 393059.0,
 "awd_min_amd_letter_date": "2013-06-21",
 "awd_max_amd_letter_date": "2013-06-21",
 "awd_abstract_narration": "The research addresses social networks of agents, where the agents learn about the state of nature not only from private signals (i.e., signals only available to the agents receiving them), but from neighboring agents too. The agents are rational and cooperative, and in forming their beliefs about the state of nature, they process all the information that is available to them. The research aims at finding how information and misinformation can diffuse over networks of agents. The objectives are to use the new theory to design better engineering systems and to influence biological systems in ways so that beneficial outcomes are attained.\r\n\r\nThe goals of the research are to understand the processes of belief evolution about the state of nature in time and/or space in networks of agents and in a wide variety of settings. The knowledge of the agents is expressed by their beliefs about the state of nature and is quantified by posterior probability distributions. Unlike in the majority of known studies where the agents want to get point estimates about the unknown state of nature, the agents in the addressed problems strive for obtaining complete beliefs about the unknown states as measured by posterior distributions. The state of nature can be static or dynamic and the information acquired from neighbors about it can be of continuous or discrete nature. For information processing, the agents use the Bayes' rule. Endowed with Bayesian reasoning, the agents carry out optimal information processing, and thereby it is expected that they beat the performance of agents that use competing methodologies.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Petar",
   "pi_last_name": "Djuric",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Petar M Djuric",
   "pi_email_addr": "petar.djuric@stonybrook.edu",
   "nsf_id": "000110452",
   "pi_start_date": "2013-06-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117942350",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "793600",
   "pgm_ele_name": "SIGNAL PROCESSING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 393059.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The research interest in this period was on several topics, all on networks of agents, where the agents learn about the state of nature. There are two sources for learning. One is from signals only available to the agents receiving them, and the other is the neighboring agents. The information acquired from neighbors about the state of nature is of continuous or discrete types. The state of nature is static or dynamic.</p>\n<p>In much of the literature on Bayesian social learning, the sequential decision making systems are composed of agents that make &ldquo;once-in-a-life&rdquo; decisions and then broadcast them to their neighboring agents. In contrast to this work, systems that allow agents to make decisions repeatedly were studied. A problem that arises in this scenario is known as data incest. Before, it has been found that optimal Bayesian learning cannot take place if data incest exists. An approach was proposed to avoid the emergence of data incest.</p>\n<p>In work related to estimation and tracking in networks, where nodes collaborate, both, estimation of unknown parameters and of dynamic processes from noisy measurements were addressed. For the static parameters, generic solutions that are applicable to a wide class of popular models were obtained. The solutions to estimation dynamic processes are based on two different types of strategies, consensus-based and diffusion-based. All the solutions rely on incorporating the shared observations and on an effective combination of the knowledge of the agents in the network. Some of the solutions are completely analytical and some are based on Monte Carlo computations.&nbsp; All the theoretical results were verified with comprehensive simulations.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/29/2017<br>\n\t\t\t\t\tModified by: Petar&nbsp;M&nbsp;Djuric</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe research interest in this period was on several topics, all on networks of agents, where the agents learn about the state of nature. There are two sources for learning. One is from signals only available to the agents receiving them, and the other is the neighboring agents. The information acquired from neighbors about the state of nature is of continuous or discrete types. The state of nature is static or dynamic.\n\nIn much of the literature on Bayesian social learning, the sequential decision making systems are composed of agents that make \"once-in-a-life\" decisions and then broadcast them to their neighboring agents. In contrast to this work, systems that allow agents to make decisions repeatedly were studied. A problem that arises in this scenario is known as data incest. Before, it has been found that optimal Bayesian learning cannot take place if data incest exists. An approach was proposed to avoid the emergence of data incest.\n\nIn work related to estimation and tracking in networks, where nodes collaborate, both, estimation of unknown parameters and of dynamic processes from noisy measurements were addressed. For the static parameters, generic solutions that are applicable to a wide class of popular models were obtained. The solutions to estimation dynamic processes are based on two different types of strategies, consensus-based and diffusion-based. All the solutions rely on incorporating the shared observations and on an effective combination of the knowledge of the agents in the network. Some of the solutions are completely analytical and some are based on Monte Carlo computations.  All the theoretical results were verified with comprehensive simulations. \n\n \n\n\t\t\t\t\tLast Modified: 09/29/2017\n\n\t\t\t\t\tSubmitted by: Petar M Djuric"
 }
}