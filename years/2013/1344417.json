{
 "awd_id": "1344417",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Future Directions for NSF Advanced Computing Infrastructure to Support US Science in 2017-2020",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924863",
 "po_email": "edwalker@nsf.gov",
 "po_sign_block_name": "Edward Walker",
 "awd_eff_date": "2013-08-01",
 "awd_exp_date": "2018-07-31",
 "tot_intn_awd_amt": 723001.0,
 "awd_amount": 723001.0,
 "awd_min_amd_letter_date": "2013-07-19",
 "awd_max_amd_letter_date": "2017-11-24",
 "awd_abstract_narration": "This award to the National Academy of Sciences will result in the appointment of a study committee to examine anticipated priorities and associated tradeoffs for advanced computing in support of NSF-sponsored science and engineering research. Advanced computing capabilities are used to tackle a rapidly growing range of challenging science and engineering problems, many of which are compute-, communications-, and data-intensive as well. The study committee will consider: (1) The contribution of high end computing to U.S. leadership and competiveness in basic science and engineering and the role that NSF should play in sustaining this leadership; (2) Expected future national-scale computing needs: high end requirements, those arising from the full range of basic science and engineering research supported by NSF, as well as the computing infrastructure needed to support advances in modeling, simulation and data analysis; (3) Complementarities and tradeoffs that arise among investments in supporting advanced computing ecosystems; software, data, communications; (4) The range of operational models for delivering computational infrastructure, for basic science and engineering research, and the role of NSF support in these various models ; and (5) Expected technical challenges to affordably delivering the capabilities needed for world-leading scientific and engineering research.\r\n\r\nAn interim report, to be delivered within 12 months of the project start, will identify key issues and discuss potential options. It may contain preliminary findings and early recommendations. A final report, to be delivered within 24 months of the project start, will include a framework for future decision-making about NSF's advanced computing strategy and programs. The framework would address such issues as how to prioritize needs and investments and how to balance competing demands for cyberinfrastructure investments. The report will emphasize identifying issues, explicating options, and articulating tradeoffs and general recommendations. \r\n\r\nAdvanced computing capabilities are central to many areas of basic science and engineering, and are being used to tackle a rapidly growing range of challenging problems. This activity will inform future strategy and investments for delivering these capabilities. The committee reports will address such issues as how to prioritize needs and investments and how to balance competing demands for cyberinfrastructure investments. The results of the study are intended to inform decision-making about future NSF investments in advanced computing. The reports will also be a valuable resource for (1) science and engineering researchers that use or might use advanced computing capabilities (for whom the report would provide an useful overview of opportunities, challenges, and future directions) and (2) those conducting R&D on future high-performance computing (for whom the report would provide a useful view of emerging science and engineering requirements).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jon",
   "pi_last_name": "Eisenberg",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Jon K Eisenberg",
   "pi_email_addr": "jeisenbe@nas.edu",
   "nsf_id": "000064760",
   "pi_start_date": "2013-07-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "National Academy of Sciences",
  "inst_street_address": "2101 CONSTITUTION AVE NW",
  "inst_street_address_2": "",
  "inst_city_name": "WASHINGTON",
  "inst_state_code": "DC",
  "inst_state_name": "District of Columbia",
  "inst_phone_num": "2023342254",
  "inst_zip_code": "204180007",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DC00",
  "org_lgl_bus_name": "NATIONAL ACADEMY OF SCIENCES",
  "org_prnt_uei_num": "PKFJZHG2MLG9",
  "org_uei_num": "PKFJZHG2MLG9"
 },
 "perf_inst": {
  "perf_inst_name": "National Academy of Sciences",
  "perf_str_addr": "500 Fifth Street, N.W.",
  "perf_city_name": "Washington",
  "perf_st_code": "DC",
  "perf_st_name": "District of Columbia",
  "perf_zip_code": "200012721",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DC00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 723001.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>NSF asked the National Academies to provide a framework for future decision making about NSF&rsquo;s advanced computing strategy and programs.&nbsp;</p>\n<p>Large-scale simulation and analysis of massive amounts of data are revolutionizing science and engineering research. The study's recommendations, provided in a 2016 report, are aimed at achieving four &nbsp;goals: (1) position the US for continued leadership in science and engineering, (2) ensure that resources meet community needs, (3) aid the scientific community in keeping up with the revolution in computing, and (4) sustain advanced computing infrastructure.</p>\n<p><strong>Continued leadership:&nbsp;</strong>Meeting future needs will require systems that support a wide range of capabilities, including large-scale parallel systems and data-intensive systems. Approaches that combine large-scale computing and data resources in &ldquo;converged&rdquo; systems can play a role; more specialized systems may also be needed to meet some requirements. Commercial cloud computing offers certain advantages and can play a role in NSF&rsquo;s advanced computing strategy, especially for data-centric workloads and communities that share data sets.</p>\n<p><strong>Ensuring resources meet community needs:&nbsp;</strong>A more regular and structured planning process would make it possible to collect requirements, roll them up, and prioritize computing investments based on science and engineering priorities. Roadmaps would reflect the visions of the science communities supported by NSF, including both large users and those (in the &ldquo;long-tail&rdquo;) with more modest needs. Brief documents setting forth an overall strategy and approach would help inform users about future facilities, guide investment, align future procurements and services with requirements, and enable more effective internal and external partnerships. The process could be strengthened by developing a better understanding of the relationships among requirements, the costs of different approaches, and science benefits.&nbsp;</p>\n<p><strong>Keeping up with the computing revolution:&nbsp;</strong>Rapid change in computer architectures and programming models is creating challenges for the science community, which depends on and has invested significantly in science codes written for yesterday&rsquo;s systems. Better software tools, technical expertise, and more flexible service models can improve the productivity of researchers both today and in the future.</p>\n<p>By taking a leadership role in defining future advanced computing capabilities and helping researchers use them more effectively (and not investing solely in production systems), NSF can help ensure that its software and systems remain relevant to its science portfolio, that researchers are prepared to use the systems, and that investments across NSF are aligned with this future.</p>\n<p><strong>Sustaining infrastructure:&nbsp;</strong>Expertise and the physical infrastructure for computing centers are essential. In recent years, NSF adopted a strategy for acquiring computing facilities and creating centers and programs to operate and support them that relies on irregularly scheduled competition among host institutions and on cost sharing with those institutions. Mounting costs and budget pressures suggest that a strategy that relies on state, institutional, or vendor cost sharing may no longer be viable. Repeated competition can lead to proposals designed to win a competition rather than maximize scientific returns. Moreover, it is important develop and retain the talent needed to effectively manage systems, support users, and evolve software.</p>\n<p>Managing NSF's advanced computing investments more predictably and sustainably, as with other long-term infrastructure would benefit currently supported researchers; provide opportunities to apply the same expertise more broadly, such as the large-scale science projects with long-term computing needs; and create opportunities to address long-term storage, preservation, and curation challenges for data.</p>\n<p><strong>2018 follow-on workshop on opportunities for the integration of simulation and data-driven science&nbsp;</strong>explored&nbsp;current and emerging science applications that span simulation and data-driven science, their characteristics, and future approaches for their support. The committee members who participated in the workshop noted a number of recurring themes:</p>\n<ul>\n<li>Opportunities for both data-intensive and simulation approaches to science abound, especially when the two are used in combination. Data-intensive science is adding to the demand, not replacing simulation, and growing opportunities at the intersection further increase demand.</li>\n<li>Machine learning has rapidly emerged as a major driver of data-intensive science and has valuable application in simulation. Machine learning is also driving convergence at the hardware level.</li>\n<li>Realizing these expanding opportunities for science and maintaining U.S. competitiveness will require increased investment from public sources, effective leverage of commercial services, and innovative approaches to public-private partnerships.</li>\n<li>Scientific research benefits from a balanced ecosystem that includes national, institutional, and commercial cloud facilities and benefits from complementary architectures and services models they provide.</li>\n<li>Better integration of data-intensive and data-simulation approaches will depend on integration of different research cultures as well as technologies.</li>\n<li>The traditional high-performance computing and cloud computing communities bring complementary insights, tools, and techniques that are beginning to be shared.</li>\n<li>Careful attention to the costs and business models for data retention and access is needed, including how to prioritize what data should be kept and for how long. Just retaining data is more expensive than is widely understood.</li>\n<li>Workforce needs are growing as the science opportunities and technology options expand.&nbsp;</li>\n</ul><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/30/2018<br>\n\t\t\t\t\tModified by: Jon&nbsp;K&nbsp;Eisenberg</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nNSF asked the National Academies to provide a framework for future decision making about NSF?s advanced computing strategy and programs. \n\nLarge-scale simulation and analysis of massive amounts of data are revolutionizing science and engineering research. The study's recommendations, provided in a 2016 report, are aimed at achieving four  goals: (1) position the US for continued leadership in science and engineering, (2) ensure that resources meet community needs, (3) aid the scientific community in keeping up with the revolution in computing, and (4) sustain advanced computing infrastructure.\n\nContinued leadership: Meeting future needs will require systems that support a wide range of capabilities, including large-scale parallel systems and data-intensive systems. Approaches that combine large-scale computing and data resources in \"converged\" systems can play a role; more specialized systems may also be needed to meet some requirements. Commercial cloud computing offers certain advantages and can play a role in NSF?s advanced computing strategy, especially for data-centric workloads and communities that share data sets.\n\nEnsuring resources meet community needs: A more regular and structured planning process would make it possible to collect requirements, roll them up, and prioritize computing investments based on science and engineering priorities. Roadmaps would reflect the visions of the science communities supported by NSF, including both large users and those (in the \"long-tail\") with more modest needs. Brief documents setting forth an overall strategy and approach would help inform users about future facilities, guide investment, align future procurements and services with requirements, and enable more effective internal and external partnerships. The process could be strengthened by developing a better understanding of the relationships among requirements, the costs of different approaches, and science benefits. \n\nKeeping up with the computing revolution: Rapid change in computer architectures and programming models is creating challenges for the science community, which depends on and has invested significantly in science codes written for yesterday?s systems. Better software tools, technical expertise, and more flexible service models can improve the productivity of researchers both today and in the future.\n\nBy taking a leadership role in defining future advanced computing capabilities and helping researchers use them more effectively (and not investing solely in production systems), NSF can help ensure that its software and systems remain relevant to its science portfolio, that researchers are prepared to use the systems, and that investments across NSF are aligned with this future.\n\nSustaining infrastructure: Expertise and the physical infrastructure for computing centers are essential. In recent years, NSF adopted a strategy for acquiring computing facilities and creating centers and programs to operate and support them that relies on irregularly scheduled competition among host institutions and on cost sharing with those institutions. Mounting costs and budget pressures suggest that a strategy that relies on state, institutional, or vendor cost sharing may no longer be viable. Repeated competition can lead to proposals designed to win a competition rather than maximize scientific returns. Moreover, it is important develop and retain the talent needed to effectively manage systems, support users, and evolve software.\n\nManaging NSF's advanced computing investments more predictably and sustainably, as with other long-term infrastructure would benefit currently supported researchers; provide opportunities to apply the same expertise more broadly, such as the large-scale science projects with long-term computing needs; and create opportunities to address long-term storage, preservation, and curation challenges for data.\n\n2018 follow-on workshop on opportunities for the integration of simulation and data-driven science explored current and emerging science applications that span simulation and data-driven science, their characteristics, and future approaches for their support. The committee members who participated in the workshop noted a number of recurring themes:\n\nOpportunities for both data-intensive and simulation approaches to science abound, especially when the two are used in combination. Data-intensive science is adding to the demand, not replacing simulation, and growing opportunities at the intersection further increase demand.\nMachine learning has rapidly emerged as a major driver of data-intensive science and has valuable application in simulation. Machine learning is also driving convergence at the hardware level.\nRealizing these expanding opportunities for science and maintaining U.S. competitiveness will require increased investment from public sources, effective leverage of commercial services, and innovative approaches to public-private partnerships.\nScientific research benefits from a balanced ecosystem that includes national, institutional, and commercial cloud facilities and benefits from complementary architectures and services models they provide.\nBetter integration of data-intensive and data-simulation approaches will depend on integration of different research cultures as well as technologies.\nThe traditional high-performance computing and cloud computing communities bring complementary insights, tools, and techniques that are beginning to be shared.\nCareful attention to the costs and business models for data retention and access is needed, including how to prioritize what data should be kept and for how long. Just retaining data is more expensive than is widely understood.\nWorkforce needs are growing as the science opportunities and technology options expand. \n\n\n\t\t\t\t\tLast Modified: 08/30/2018\n\n\t\t\t\t\tSubmitted by: Jon K Eisenberg"
 }
}