{
 "awd_id": "1315792",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Hands Free Silent Tactile Obstacle Avoidance System for Blind Travelers",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Muralidharan Nair",
 "awd_eff_date": "2013-07-01",
 "awd_exp_date": "2014-06-30",
 "tot_intn_awd_amt": 149500.0,
 "awd_amount": 164500.0,
 "awd_min_amd_letter_date": "2013-06-17",
 "awd_max_amd_letter_date": "2013-12-09",
 "awd_abstract_narration": "This Small Business Innovation Research Phase I project proposes to design, develop, evaluate and specify an ultrasonic blind mobility assistance device that will provide an effective, affordable, lightweight and intelligent navigation assistant for vision-impaired people.  Over 46% percent of the 11.4 million visually impaired people in America experience head injury at least once a month of which 23% require medical attention while in motion.  The long cane and the guide dog or seeing-eye dog have been the most used method of providing mobility assistance for the blind for decades. Since these technologies focus on lower body protection they can actually lead the unsighted user into an upper body hazard, causing injury rather than protecting the user. A new systems innovation is needed that combines the latest available sensor technology and components with embedded intelligent functions to provide motor related assistance to those with vision disabilities. A new method designed by a blind inventor is proposed to provide hands-free and silent communication of information to these users, transmitting adequate, accurate obstacle-avoidance information for the sight disadvantaged.  \r\n\r\nThe broader impact/commercial potential of this project will be an affordable assistive device to accurately and effectively protect the unsighted from head and upper-body injury while in motion.  There are 11.4 million people with extreme vision impairment in the US and more than 160 million globally. The resulting design will use modern technology to enhance movement by allowing more freedom and confidence. The Phase I goal is to evaluate, analyze and finalize a system design of a mobility device for the blind that silently and without vibration detect and convey detailed location information about hazards and obstacles that make safe and effective travel difficult. The product is envisioned to be a pair of sunglasses that would contain sensors that would detect objects and communicate when it nears an object within a specified range.  The system design will consider pace of technology improvements and maturity of wireless, mobile internet, higher density manufacturing for more capable microcomputers and sensors; forecasts of these ever improving technologies and their product maturity to address system features will be considered as the system transitions to Phase II.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Geoffrey",
   "pi_last_name": "Lueken",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Geoffrey Lueken",
   "pi_email_addr": "gclueken@ualr.edu",
   "nsf_id": "000634872",
   "pi_start_date": "2013-06-17",
   "pi_end_date": "2013-07-10"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dan",
   "pi_last_name": "Ballard",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Dan R Ballard",
   "pi_email_addr": "dan.ballard@acronymics.com",
   "nsf_id": "000648619",
   "pi_start_date": "2013-07-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Fauxsee Innovations LLC",
  "inst_street_address": "22 REGENCY CIR",
  "inst_street_address_2": "",
  "inst_city_name": "MAGNOLIA",
  "inst_state_code": "AR",
  "inst_state_name": "Arkansas",
  "inst_phone_num": "8706963871",
  "inst_zip_code": "717534380",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AR04",
  "org_lgl_bus_name": "FAUXSEE INNOVATIONS LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "F1LKLPKE6KW5"
 },
 "perf_inst": {
  "perf_inst_name": "Fauxsee Innovations",
  "perf_str_addr": "4030 Columbia Rd. 5",
  "perf_city_name": "Magnolia",
  "perf_st_code": "AR",
  "perf_st_name": "Arkansas",
  "perf_zip_code": "717538680",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AR04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5371",
   "pgm_ref_txt": "SMALL BUSINESS PHASE I"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  },
  {
   "pgm_ref_code": "8033",
   "pgm_ref_txt": "Hardware Software Integration"
  },
  {
   "pgm_ref_code": "9139",
   "pgm_ref_txt": "INFORMATION INFRASTRUCTURE & TECH APPL"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 149500.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 15000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This report describes the research effort by Fauxsee Innovations, LLC in developing a new assistive device for helping the blind navigate obstacles. &nbsp;The device is called Roboglasses&reg;. &nbsp;Roboglasses utilizes ultrasonic sensors coupled with haptic (touch) feedback to provide the blind wearer with a view of the world as detected by the sensors. &nbsp;</p>\n<p>Ultrasonic sensors are mounted in the lens portion of glasses frames very like sunglasses. &nbsp;The ultrasonic sensors transmit and then receive ultrasonic signals. &nbsp;Processors in the sensors then compute the distance to the nearest target detected by the sensors. &nbsp;Each sensor provides a range measurement for one eye. &nbsp;Since the sensors are mounted in a horizontal plane and separated by approximately 100 mm it is possible to provide a binocular view of the sensed world and determine the azimuth to an object. &nbsp;Future versions of Roboglasses&reg; will incorporate a third sensor in the vertical plane which will be used to determine the elevation of an object (target).</p>\n<p>Information from the sensor subsystem is communicated to a central processor where the range, azimuth (and eventually) elevation data is encoded and used to drive haptic feedback actuators located in the Roboglasses&reg; stems. &nbsp;Roboglasses&reg; uses devices called Linear Resonant Actuators (LRAs) for providing the haptic feedback. &nbsp;Five LRAs are located on each stem and are used to encode the distance to a detected object by either the corresponding left or right sensor. &nbsp;</p>\n<p>Each LRA is programmable in nature. &nbsp;This means that different haptic feedback stimuli effects can be applied by the LRA. &nbsp;Over 120 effects are available and range from simple taps, bumps, buzzes to more complicated combinations of effects. &nbsp;This means that distance information can be encoded in a variety of ways. &nbsp;</p>\n<p>Roboglasses operates using a 3.2V and 5 V power. &nbsp;Future versions will require only a single 3.2 V power source (batteries). &nbsp;We are currently improving the deisgn of the Roboglasses hardware and software and making extensive use of 3D printer technology in refining the Roboglasses&reg; implementation.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/07/2014<br>\n\t\t\t\t\tModified by: Dan&nbsp;R&nbsp;Ballard</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis report describes the research effort by Fauxsee Innovations, LLC in developing a new assistive device for helping the blind navigate obstacles.  The device is called Roboglasses&reg;.  Roboglasses utilizes ultrasonic sensors coupled with haptic (touch) feedback to provide the blind wearer with a view of the world as detected by the sensors.  \n\nUltrasonic sensors are mounted in the lens portion of glasses frames very like sunglasses.  The ultrasonic sensors transmit and then receive ultrasonic signals.  Processors in the sensors then compute the distance to the nearest target detected by the sensors.  Each sensor provides a range measurement for one eye.  Since the sensors are mounted in a horizontal plane and separated by approximately 100 mm it is possible to provide a binocular view of the sensed world and determine the azimuth to an object.  Future versions of Roboglasses&reg; will incorporate a third sensor in the vertical plane which will be used to determine the elevation of an object (target).\n\nInformation from the sensor subsystem is communicated to a central processor where the range, azimuth (and eventually) elevation data is encoded and used to drive haptic feedback actuators located in the Roboglasses&reg; stems.  Roboglasses&reg; uses devices called Linear Resonant Actuators (LRAs) for providing the haptic feedback.  Five LRAs are located on each stem and are used to encode the distance to a detected object by either the corresponding left or right sensor.  \n\nEach LRA is programmable in nature.  This means that different haptic feedback stimuli effects can be applied by the LRA.  Over 120 effects are available and range from simple taps, bumps, buzzes to more complicated combinations of effects.  This means that distance information can be encoded in a variety of ways.  \n\nRoboglasses operates using a 3.2V and 5 V power.  Future versions will require only a single 3.2 V power source (batteries).  We are currently improving the deisgn of the Roboglasses hardware and software and making extensive use of 3D printer technology in refining the Roboglasses&reg; implementation.\n\n\t\t\t\t\tLast Modified: 07/07/2014\n\n\t\t\t\t\tSubmitted by: Dan R Ballard"
 }
}