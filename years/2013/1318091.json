{
 "awd_id": "1318091",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Stochastic Computing Techniques for Real-Time Image-Processing Applications",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2013-07-01",
 "awd_exp_date": "2017-06-30",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2013-06-25",
 "awd_max_amd_letter_date": "2013-06-25",
 "awd_abstract_narration": "Many beneficial applications of computers cannot now be realized because they demand excessively high performance and/or low power. An example of interest is real-time image processing to restore sight to the visually impaired. This project explores an unconventional and little-understood technology called stochastic computing (SC) which is very well-suited to such applications. Stochastic Computing processes numbers in the form of bit-streams that resemble neural signals and are interpreted as probabilities. It can implement complex arithmetic operations by small logic circuits. However, high accuracy may require long bit-streams that can be difficult to interface with conventional binary logic.  The project aims to develop a comprehensive theory of SC leading to practical methods for designing and applying stochastic circuits. It will study the foundations of SC, especially speed, accuracy and hardware-cost trade-offs, using various novel methods.  Stochastic Computing will be applied to a broad set of image-processing tasks, ranging from retinal implants for the blind, to on-the-fly feature extraction. Prototype designs will be constructed and evaluated using software simulation and hardware emulation via field-programmable gate arrays. \r\n\r\nThe project's goal is a full theoretical and practical understanding of stochastic computing in the context of emerging integrated circuit technologies and applications. Its results should interest research engineers and scientists in academe, as well as in the microelectronics, computer, and bioengineering industries. They should also be of direct practical value to designers and manufacturers in such application areas as image-processing chips, implantable medical devices, and video surveillance systems. The project's outputs will be distributed primarily via peer-reviewed journal and conference papers. A key goal is to support the training of graduate students in computer science and engineering, who will participate directly in the research as part of their M.S. and Ph.D. programs at the University of Michigan. A few undergraduates will also be invited to join the project as interns to encourage them to pursue research-related careers. A special effort will be made to involve women and minority students.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Hayes",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "John P Hayes",
   "pi_email_addr": "jhayes@eecs.umich.edu",
   "nsf_id": "000311318",
   "pi_start_date": "2013-06-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "2260 Hayward, BBB Building, 4713",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092121",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "794500",
   "pgm_ele_name": "DES AUTO FOR MICRO & NANO SYST"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Stochastic computing (SC) employs tiny digital circuits to perform complex arithmetic operations by representing numbers in a highly unconventional way. Instead of denoting a number <em>X </em>by a fixed, pattern of&nbsp; 0&rsquo;s and 1&rsquo;s, SC selects bits randomly so that <em>X&rsquo;</em>s value is the frequency or rate with which 1-bits appear. <em>X</em> thus becomes the probability of a randomly selected bit being 1, and SC is sometimes called &ldquo;computing with probabilities&rdquo;.&nbsp; The main advantages of SC are&nbsp; extremely small and low-power circuits, easily varied precision, high tolerance of errors, and compatibility with data-processing methods used by the brain. Multiplication can be accomplished by a single AND gate, whereas multiplying two conventional 8-bit binary numbers requires perhaps a hundred gates. The potential applications of SC include image processing devices such as retinal implants to restore vision to the blind. The theory and application of SC have received very little research attention in the past, and many fundamental questions have not been answered, or even been well defined. This NSF-sponsored project&rsquo;s overall goal was to develop a deep understanding of SC leading to systematic methods for the analysis, synthesis and application of stochastic designs, especially to image processing and related fields. &nbsp;The project appears to have been very successful in this regard. It has led to fundamental discoveries about SC that have attracted the attention of an international audience, as its approximately 30 publications suggest. The project supported the Ph.D. thesis work of three students at the University of Michigan, and provided research experience to several other graduate and undergraduate students at Michigan and other research institutions.</p>\n<p>Because of the randomness inherent in stochastic number representation, computation time and the accuracy of results interact in complex ways. The nature of the time-accuracy tradeoff is a central issue in SC which was investigated throughout the project. A related problem is reducing the high cost of the hardware needed for generating stochastic numbers.&nbsp; We developed new ways to measure and control the accuracy of stochastic circuits using Monte Carlo simulation theory. Novel designs were obtained for stochastic number generators that significantly improve their performance. We introduced and analyzed a property called accurate truncated progressive precision, which allows a computation to be terminated early, once a sufficient level precision has been achieved.. We clarified the role played by constant (as opposed to variable) inputs in SC, and showed that &nbsp;such constants can be an unexpected source of computational inaccuracy. We proved that this inaccuracy can be eliminated by embedding the constants in a circuit&rsquo;s memory, and we devised an optimal algorithm to eliminate unwanted constant inputs. The accuracy of SC is also negatively affected by random correlation between interacting bit-streams. We made some surprising discoveries that have resulted in major advances in understanding and managing correlation. These include a new metric for correlation called <em>SCC</em> which has been widely adopted as a standard by other SC researchers. We also showed that correlation is not always a nuisance to be eliminated, but can be exploited as a resource to improve SC. This has proven especially useful in image-processing. For example, we discovered how to compute a standard edge-detection function using a total of only 10 logic gates.&nbsp; A conventional edge detector of similar precision requires about 35 times more chip area than the stochastic design, and consumes 100 times more power. We also exploited correlation in the design of an accurate general-purpose stochastic divider, the first of its kind. For situations where correlation must be reduced or eliminated, we came up with a systematic decorrelation approach based on the careful insertion of delay elements.&nbsp; We uncovered some unexpected but fundamental links between the logical and arithmetic functions implemented by a stochastic circuit.&nbsp; Equivalence relationships among these functions point to a new direction in SC circuit synthesis. In conventional design, the starting point is a well-defined Boolean function to be realized in hardware. This is not the case in SC, however, because several different but equivalent Boolean functions of varying cost can satisfy a given design specification. We identified the basic properties of the corresponding stochastic equivalence classes (SECs), and demonstrated their importance for stochastic circuit synthesis and optimization. We developed a novel SC synthesis algorithm<em> </em>based on systematically searching SECs to find efficient stochastic designs.&nbsp; We also analyzed stochastic circuits under very general error conditions, and compared their behavior to that of conventional circuits under similar conditions. Furthermore, we showed that stochastic circuits are much less sensitive to timing errors than conventional circuits. These results indicate that SC has far better error tolerance than conventional circuits under severe fault conditions.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/17/2017<br>\n\t\t\t\t\tModified by: John&nbsp;P&nbsp;Hayes</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nStochastic computing (SC) employs tiny digital circuits to perform complex arithmetic operations by representing numbers in a highly unconventional way. Instead of denoting a number X by a fixed, pattern of  0?s and 1?s, SC selects bits randomly so that X?s value is the frequency or rate with which 1-bits appear. X thus becomes the probability of a randomly selected bit being 1, and SC is sometimes called \"computing with probabilities\".  The main advantages of SC are  extremely small and low-power circuits, easily varied precision, high tolerance of errors, and compatibility with data-processing methods used by the brain. Multiplication can be accomplished by a single AND gate, whereas multiplying two conventional 8-bit binary numbers requires perhaps a hundred gates. The potential applications of SC include image processing devices such as retinal implants to restore vision to the blind. The theory and application of SC have received very little research attention in the past, and many fundamental questions have not been answered, or even been well defined. This NSF-sponsored project?s overall goal was to develop a deep understanding of SC leading to systematic methods for the analysis, synthesis and application of stochastic designs, especially to image processing and related fields.  The project appears to have been very successful in this regard. It has led to fundamental discoveries about SC that have attracted the attention of an international audience, as its approximately 30 publications suggest. The project supported the Ph.D. thesis work of three students at the University of Michigan, and provided research experience to several other graduate and undergraduate students at Michigan and other research institutions.\n\nBecause of the randomness inherent in stochastic number representation, computation time and the accuracy of results interact in complex ways. The nature of the time-accuracy tradeoff is a central issue in SC which was investigated throughout the project. A related problem is reducing the high cost of the hardware needed for generating stochastic numbers.  We developed new ways to measure and control the accuracy of stochastic circuits using Monte Carlo simulation theory. Novel designs were obtained for stochastic number generators that significantly improve their performance. We introduced and analyzed a property called accurate truncated progressive precision, which allows a computation to be terminated early, once a sufficient level precision has been achieved.. We clarified the role played by constant (as opposed to variable) inputs in SC, and showed that  such constants can be an unexpected source of computational inaccuracy. We proved that this inaccuracy can be eliminated by embedding the constants in a circuit?s memory, and we devised an optimal algorithm to eliminate unwanted constant inputs. The accuracy of SC is also negatively affected by random correlation between interacting bit-streams. We made some surprising discoveries that have resulted in major advances in understanding and managing correlation. These include a new metric for correlation called SCC which has been widely adopted as a standard by other SC researchers. We also showed that correlation is not always a nuisance to be eliminated, but can be exploited as a resource to improve SC. This has proven especially useful in image-processing. For example, we discovered how to compute a standard edge-detection function using a total of only 10 logic gates.  A conventional edge detector of similar precision requires about 35 times more chip area than the stochastic design, and consumes 100 times more power. We also exploited correlation in the design of an accurate general-purpose stochastic divider, the first of its kind. For situations where correlation must be reduced or eliminated, we came up with a systematic decorrelation approach based on the careful insertion of delay elements.  We uncovered some unexpected but fundamental links between the logical and arithmetic functions implemented by a stochastic circuit.  Equivalence relationships among these functions point to a new direction in SC circuit synthesis. In conventional design, the starting point is a well-defined Boolean function to be realized in hardware. This is not the case in SC, however, because several different but equivalent Boolean functions of varying cost can satisfy a given design specification. We identified the basic properties of the corresponding stochastic equivalence classes (SECs), and demonstrated their importance for stochastic circuit synthesis and optimization. We developed a novel SC synthesis algorithm based on systematically searching SECs to find efficient stochastic designs.  We also analyzed stochastic circuits under very general error conditions, and compared their behavior to that of conventional circuits under similar conditions. Furthermore, we showed that stochastic circuits are much less sensitive to timing errors than conventional circuits. These results indicate that SC has far better error tolerance than conventional circuits under severe fault conditions.\n\n\t\t\t\t\tLast Modified: 09/17/2017\n\n\t\t\t\t\tSubmitted by: John P Hayes"
 }
}