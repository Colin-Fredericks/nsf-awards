{
 "awd_id": "1352924",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Enhancing Mobile Device Users' Levels of Situational Awareness through Tactile Feedback",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 96001.0,
 "awd_amount": 96001.0,
 "awd_min_amd_letter_date": "2013-09-04",
 "awd_max_amd_letter_date": "2013-09-04",
 "awd_abstract_narration": "In this project the PI will explore a novel approach to allowing individuals to monitor their wider environment for potential obstacles and threats while engaged in a task where the eyes are occupied.  Specifically, he will focus on mobile device users, who often perform visually-demanding tasks such as composing and reading text messages while ambulatory, so that they may fail to notice the presence of pedestrians, approaching vehicular traffic or other objects which they are at risk of encountering.  The PI's approach is to present tactile feedback via a head-mounted interface in order to communicate the presence of obstacles.  While situational awareness technologies have been designed to assist ambulatory users, alerts are often presented using visual or auditory feedback.  But if the user is engaged with a mobile task precious time may be taken to identify the presence of graphical indicators, whereas auditory alerts may be masked by environmental sounds to that the user misses vital cues.  The PI argues that tactile feedback offers considerable advantages when the user's other senses are blocked or restricted, and there is the additional benefit that tactile alerts can be presented discreetly without drawing attention by others.  To test these hypotheses, the PI will conduct a sequence of studies to determine whether it is possible to design tactile cues that are effective in supporting informed decisions by the user.  Project outcomes will include design of a head-mounted interface prototype using object-recognition and sensor-based technologies to track obstacles in the user's vicinity, along with innovative tactile interface design guidelines.  \r\n\r\nBroader Impacts:  This research will advance our understanding of issues relating to situational awareness among mobile device users, and it will also contribute to the body of knowledge on presenting tactile feedback to locations on the head (a field still in its infancy).  The development of a library of tactile icons to convey concepts such as the number of obstacles, their location, and their proximity to the user, will have application across diverse domains.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ravi",
   "pi_last_name": "Kuber",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Ravi A Kuber",
   "pi_email_addr": "rkuber@umbc.edu",
   "nsf_id": "000569993",
   "pi_start_date": "2013-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland Baltimore County",
  "inst_street_address": "1000 HILLTOP CIR",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4104553140",
  "inst_zip_code": "212500001",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND BALTIMORE COUNTY",
  "org_prnt_uei_num": "",
  "org_uei_num": "RNKYWXURFRL5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland Baltimore County",
  "perf_str_addr": "1000 Hilltop Circle",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212500002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 96001.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Wearable tactile technologies offer significant potential to support a broad set of users, such as pedestrians, by supplying important spatial and contextual information. However, research into tactile alerts, particularly those presented at the head (rather than the torso or hands), has focused more narrowly on considerations related to aviation or military applications. Further, inappropriate design considerations related to cues for spatial or contextual hazards, combined with the limitations of common hardware, can result in the cues which are confusing and difficult to discern.&nbsp; This project has endeavored to develop and test a head-mounted tactile prototype and multi-parameter coding scheme to support situational awareness (SA) among users engaged in common, realistic activities. The head has been selected to further understanding of interaction at this location, and because it offers potential for hands-free attention direction and integration with new augmented reality displays.</p>\n<p>Three studies have been undertaken as part of this research. &nbsp;A participatory design approach was adopted for the first study.&nbsp; Mobile device users and tactile interface designers were able to work together to produce a set of use case scenarios for tactile alerts, develop a set of tactile cues that could be presented at the head, and provide design recommendations for presentation. The second study examined the participants&rsquo; ability to discern three-parameter tactile signals presented at sites on the head. This produced a set of recommendations regarding effective use of tactile signal parameters (such as amplitude, waveform, and rhythm) for spatial or contextual alerts. The third study investigated how use of a three-parameter tactile coding scheme impacted participants&rsquo; situational awareness, across a tactile storyline based upon realistic pedestrian spatial hazards. Significant interaction was found between exertion conditions and subjective cognitive workload, and the study yielded several conclusions for developers of tactile aids, which focus on effective ways to reinforce users&rsquo; spatial and contextual awareness of their environment through the tactile channel.</p>\n<p>Information about the project, including details of publications, can be accessed at: http://www.umbc.edu/~rkuber/situationalawareness.htm</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/04/2015<br>\n\t\t\t\t\tModified by: Ravi&nbsp;A&nbsp;Kuber</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWearable tactile technologies offer significant potential to support a broad set of users, such as pedestrians, by supplying important spatial and contextual information. However, research into tactile alerts, particularly those presented at the head (rather than the torso or hands), has focused more narrowly on considerations related to aviation or military applications. Further, inappropriate design considerations related to cues for spatial or contextual hazards, combined with the limitations of common hardware, can result in the cues which are confusing and difficult to discern.  This project has endeavored to develop and test a head-mounted tactile prototype and multi-parameter coding scheme to support situational awareness (SA) among users engaged in common, realistic activities. The head has been selected to further understanding of interaction at this location, and because it offers potential for hands-free attention direction and integration with new augmented reality displays.\n\nThree studies have been undertaken as part of this research.  A participatory design approach was adopted for the first study.  Mobile device users and tactile interface designers were able to work together to produce a set of use case scenarios for tactile alerts, develop a set of tactile cues that could be presented at the head, and provide design recommendations for presentation. The second study examined the participants\u00c6 ability to discern three-parameter tactile signals presented at sites on the head. This produced a set of recommendations regarding effective use of tactile signal parameters (such as amplitude, waveform, and rhythm) for spatial or contextual alerts. The third study investigated how use of a three-parameter tactile coding scheme impacted participants\u00c6 situational awareness, across a tactile storyline based upon realistic pedestrian spatial hazards. Significant interaction was found between exertion conditions and subjective cognitive workload, and the study yielded several conclusions for developers of tactile aids, which focus on effective ways to reinforce users\u00c6 spatial and contextual awareness of their environment through the tactile channel.\n\nInformation about the project, including details of publications, can be accessed at: http://www.umbc.edu/~rkuber/situationalawareness.htm\n\n\t\t\t\t\tLast Modified: 09/04/2015\n\n\t\t\t\t\tSubmitted by: Ravi A Kuber"
 }
}