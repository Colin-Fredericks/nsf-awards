{
 "awd_id": "1253733",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Adaptively Boosting Resilience Efficiency in the Face of Frequent, Clustered, and Diverse Faults",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2013-06-01",
 "awd_exp_date": "2019-05-31",
 "tot_intn_awd_amt": 449541.0,
 "awd_amount": 481541.0,
 "awd_min_amd_letter_date": "2013-02-25",
 "awd_max_amd_letter_date": "2018-03-07",
 "awd_abstract_narration": "While technology advances allow researchers to produce chips with higher performance and lower power consumption, our ability to deliver such computational power is challenged by the increasing susceptibility of silicon devices to faults. It is expected that in future computer systems, faults will occur in a continuous manner, across all levels from hardware to application. The fault behavior is furthermore expected to be more diverse and unpredictable. Of critical concern will be not only permanent and transient faults, but also intermittent faults that occur frequently and irregularly over nanosecond to second time scales.\r\n\r\nThese predicted high fault rates and diverse fault behaviors mandate a transformation in fault resilience approaches. When faults occur in a continuous manner, both fault detection and recovery must be performed in a much finer-grained manner, and recovery becomes as critical as detection. Moreover, since fault duration varies significantly, cost-effective solutions capable of uniformly detecting all types of faults, identifying the fault type, and then adaptively recovering the execution are necessary.\r\n\r\nTo address these reliability challenges, the proposed project will incorporate fine-grained adaptivity into the system, and couple statically extracted application information with runtime optimizations to guide adaptation decisions. The proposed research includes: (1) adaptive detection and checkpointing, capable of adjusting detection and checkpointing granularity to match system reliability levels; (2) adaptive recovery, capable of performing re-execution in a way that minimizes the chance of another fault occurring; and (3) adaptive resource management, capable of monitoring application and hardware reliability levels and quickly adapting scheduling decisions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chengmo",
   "pi_last_name": "Yang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chengmo Yang",
   "pi_email_addr": "chengmo@udel.edu",
   "nsf_id": "000577737",
   "pi_start_date": "2013-02-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Delaware",
  "inst_street_address": "550 S COLLEGE AVE",
  "inst_street_address_2": "",
  "inst_city_name": "NEWARK",
  "inst_state_code": "DE",
  "inst_state_name": "Delaware",
  "inst_phone_num": "3028312136",
  "inst_zip_code": "197131324",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DE00",
  "org_lgl_bus_name": "UNIVERSITY OF DELAWARE",
  "org_prnt_uei_num": "",
  "org_uei_num": "T72NHKM259N3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Delaware",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "DE",
  "perf_st_name": "Delaware",
  "perf_zip_code": "197162553",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DE00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 240770.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 133745.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 91026.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>International Technology Roadmap of Semiconductor (ITRS) report identifies &ldquo;reliability and resilience&rdquo; as one of the grand challenges in designing future ES/CPS/IoT systems. Due to device scaling, varying environmental issues and aging effects, not only are faults expected to occur in a continuous manner, but their behavior will be more diverse and unpredictable. It is no longer adequate to simply assume a low fault rate and focus solely on optimizing fault detection while ignoring recovery overhead. Instead, it is necessary to maximize the overall efficiency of resilience by balancing fault detection and recovery overhead.</p>\n<p>In response to this challenge, this project aims to provide deep insights on the key concerns of existing systems and needs of emerging devices under the new and diverse types of faults. It offers multiple new architectural-level and system-level solutions as well as static and runtime optimization algorithms to address these needs. Our solutions incorporate fine-grained adaptivity into important functions of reliable systems including checkpointing, fault detection, fault recovery, and resource management.</p>\n<p>Focusing on checkpointing, fault detection, and fault recovery functions, we have proposed several adaptive techniques to not only boost the reliable system&rsquo;s performance and efficiency but also to minimize its overall overhead, which is a quite challenging goal due to interdependent nature of these functions. Taking the amount of computation that must be recovered upon a fault detection into account, our adaptive checkpointing and fault detection techniques fine-tune these functions such as the amount of checkpointed data, checkpointing rate, and detection frequency to match the system&rsquo;s runtime fault rate. When the fault rate is low, fault detection and checkpointing are performed in a relatively coarse-grained manner to reduce the associated overhead. When a fault is detected, the intermediate results are compared and checkpointed more frequently, allowing the computation to progress in much finer steps. The fault recovery techniques, on the other hand, minimize the system's overhead by selectively re-executing instructions and tasks or selectively recovering from some faults without imposing overhead on other system&rsquo;s functions.</p>\n<p>Each of our proposed techniques provides adaptivity via exploiting (1) statistically-extracted application-specific information such as control-flow and data-flow structures; (2) dynamically-extracted architecture-specific runtime fault information; (3) the unique characteristics of the targeted fault such as read disturbance errors in the emerging STT-MRAM non-volatile memories, or (4) the specific properties of the underlying system such as SSD&rsquo;s ability to create a trail of multiple versions of data. All of our techniques are implemented and evaluated using the cutting-edge tools and simulators such as Gem5 cycle-accurate simulator and LLVM compiler tool-chain, and are proven to be significantly effective in reducing the system's overhead.</p>\n<p>During our research, we sensed the absence of a fault injection and behavioral analysis framework to facilitate research for evaluating new reliable designs and also to enable a fair evaluation and comparison among different reliable systems. To address these needs, we developed a novel light-weight but comprehensive instruction-level fault injection/detection framework which allows for the identification of both reliable and unreliable regions of a program via the simulation of a variety of hardware faults, and can further be utilized in the tuning of reliable design techniques through the implementation of run-time fault detection and effortless experiment replay. We have utilized this framework for evaluating adaptive fault detection and checkpointing, selective instruction-replay for error recovery, and compiler-directed toleration of read-disturbance errors in STT-MRAM. Our tool can benefit other researchers in the field to evaluate their works as well.</p>\n<p>Finally, we have also tackled the adaptive resource management problem in systems with multiple cores and applications. To quickly perform runtime adaptation in a predictable manner, our work considers &ldquo;reliability level&rdquo; (RL) as an intermediate scheduling dimension and creates a &ldquo;task-to-RL-to-core&rdquo; mapping offline, allowing the &ldquo;RL-to-core&rdquo; mapping to be adapted at runtime according to fault rate variations while the &ldquo;task-to-RL&rdquo; mapping is still maintained. We have developed a core reliability model capable of tracking faults appeared in each core as well as their correlation in time. As faults appear, many intermediate reliability levels are defined, allowing the system to progressively reduce the frequency of job assignments to a core until that core becomes non-functional.</p>\n<p>Overall, this 6-year research project supported 6 graduate students (3 female) and 10 undergraduate students. It produced 10 conference papers and 2 journal papers in total.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/12/2019<br>\n\t\t\t\t\tModified by: Chengmo&nbsp;Yang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nInternational Technology Roadmap of Semiconductor (ITRS) report identifies \"reliability and resilience\" as one of the grand challenges in designing future ES/CPS/IoT systems. Due to device scaling, varying environmental issues and aging effects, not only are faults expected to occur in a continuous manner, but their behavior will be more diverse and unpredictable. It is no longer adequate to simply assume a low fault rate and focus solely on optimizing fault detection while ignoring recovery overhead. Instead, it is necessary to maximize the overall efficiency of resilience by balancing fault detection and recovery overhead.\n\nIn response to this challenge, this project aims to provide deep insights on the key concerns of existing systems and needs of emerging devices under the new and diverse types of faults. It offers multiple new architectural-level and system-level solutions as well as static and runtime optimization algorithms to address these needs. Our solutions incorporate fine-grained adaptivity into important functions of reliable systems including checkpointing, fault detection, fault recovery, and resource management.\n\nFocusing on checkpointing, fault detection, and fault recovery functions, we have proposed several adaptive techniques to not only boost the reliable system?s performance and efficiency but also to minimize its overall overhead, which is a quite challenging goal due to interdependent nature of these functions. Taking the amount of computation that must be recovered upon a fault detection into account, our adaptive checkpointing and fault detection techniques fine-tune these functions such as the amount of checkpointed data, checkpointing rate, and detection frequency to match the system?s runtime fault rate. When the fault rate is low, fault detection and checkpointing are performed in a relatively coarse-grained manner to reduce the associated overhead. When a fault is detected, the intermediate results are compared and checkpointed more frequently, allowing the computation to progress in much finer steps. The fault recovery techniques, on the other hand, minimize the system's overhead by selectively re-executing instructions and tasks or selectively recovering from some faults without imposing overhead on other system?s functions.\n\nEach of our proposed techniques provides adaptivity via exploiting (1) statistically-extracted application-specific information such as control-flow and data-flow structures; (2) dynamically-extracted architecture-specific runtime fault information; (3) the unique characteristics of the targeted fault such as read disturbance errors in the emerging STT-MRAM non-volatile memories, or (4) the specific properties of the underlying system such as SSD?s ability to create a trail of multiple versions of data. All of our techniques are implemented and evaluated using the cutting-edge tools and simulators such as Gem5 cycle-accurate simulator and LLVM compiler tool-chain, and are proven to be significantly effective in reducing the system's overhead.\n\nDuring our research, we sensed the absence of a fault injection and behavioral analysis framework to facilitate research for evaluating new reliable designs and also to enable a fair evaluation and comparison among different reliable systems. To address these needs, we developed a novel light-weight but comprehensive instruction-level fault injection/detection framework which allows for the identification of both reliable and unreliable regions of a program via the simulation of a variety of hardware faults, and can further be utilized in the tuning of reliable design techniques through the implementation of run-time fault detection and effortless experiment replay. We have utilized this framework for evaluating adaptive fault detection and checkpointing, selective instruction-replay for error recovery, and compiler-directed toleration of read-disturbance errors in STT-MRAM. Our tool can benefit other researchers in the field to evaluate their works as well.\n\nFinally, we have also tackled the adaptive resource management problem in systems with multiple cores and applications. To quickly perform runtime adaptation in a predictable manner, our work considers \"reliability level\" (RL) as an intermediate scheduling dimension and creates a \"task-to-RL-to-core\" mapping offline, allowing the \"RL-to-core\" mapping to be adapted at runtime according to fault rate variations while the \"task-to-RL\" mapping is still maintained. We have developed a core reliability model capable of tracking faults appeared in each core as well as their correlation in time. As faults appear, many intermediate reliability levels are defined, allowing the system to progressively reduce the frequency of job assignments to a core until that core becomes non-functional.\n\nOverall, this 6-year research project supported 6 graduate students (3 female) and 10 undergraduate students. It produced 10 conference papers and 2 journal papers in total.\n\n\t\t\t\t\tLast Modified: 06/12/2019\n\n\t\t\t\t\tSubmitted by: Chengmo Yang"
 }
}