{
 "awd_id": "1319810",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Collaborative Research: Statistical ranking theory without a canonical loss",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Weng-keen Wong",
 "awd_eff_date": "2013-08-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 245594.0,
 "awd_amount": 245594.0,
 "awd_min_amd_letter_date": "2013-08-08",
 "awd_max_amd_letter_date": "2013-08-08",
 "awd_abstract_narration": "The problem of ranking objects occupies a central place in key technologies such as web search and recommendation systems. These technologies have a tremendous daily impact on the lives of millions of people. Moreover, the enormous scale of data on the web makes the use of machine learning especially attractive in constructing ranking algorithms.  A huge amount of research effort has been devoted to developing efficient ranking algorithms that can deal with a variety of data sets encountered in web search and recommendation systems.\r\n\r\nThis project develops unifying mathematical theory that will provide a basis for understanding and categorizing existing algorithms and, more importantly, lead to deeper insights and new algorithms for the problem of learning to rank. The investigators also apply ranking algorithms to new domains.  For example, ranking chemical reactions based on their plausibility will help chemists discover much-needed reaction bases for technologies such as carbon dioxide reduction, and conversion of natural gas into gasoline. \r\n\r\nFundamental advances in the statistical theory of ranking will be incorporated into undergraduate and graduate courses. Data sets and software developed will be made freely available to the scientific community. The investigators will also organize a workshop with a focus on interdisciplinary participation and involvement of under-represented groups in computer science and statistics.\r\n\r\nThe primary technical challenge in developing statistical ranking theory is the absence of a universally agreed-upon loss functions for ranking. This is in contrast to classic machine learning problems such as classification and regression, where there are only a few natural possibilities for the loss function and these are well-understood theoretically. The project addresses this gap by investigating how different loss functions for ranking affect fundamental theoretical properties such as learnability, and by creating a theory of convex surrogates that is applicable when loss functions abound.  The project re-examines existing statistical literature on ranking with a computational lens.  This will enable development of flexible and efficient plug-in decision rules that model the conditional probability of labels given inputs.\r\n\r\nBy incorporating the results of this research into courses and survey articles, the PIs help train a new generation of machine learning researchers and practitioners who will view ranking as a learning problem on par with classification and regression in mathematical depth as well as practical importance.  Theoretical guidance for practitioners formulating new algorithms for ranking will improve the most common applications on the web.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ambuj",
   "pi_last_name": "Tewari",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ambuj Tewari",
   "pi_email_addr": "tewaria@umich.edu",
   "nsf_id": "000635311",
   "pi_start_date": "2013-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091271",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 245594.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Automated ranking systems are used by millions of people everyday to find webpages, news articles, consumer products, blogs, podcasts, music, videos and more. Machine learning plays a big role in the design of modern ranking systems by automatically learning good rules to rank items in response to a user generated query. This has led to the creation of an entire research area at the intersection of information retrieval and machine learning called ``learning to rank&rdquo;.</p>\n<p><br />In this project, we developed new mathematical theory to better understand the power and limitations of learning to rank algorithms. We proved formal bounds on the performance of ranking algorithms that are trained on a finite amount of humanly labeled data. These new results generated novel insights into the behavior of learning to rank algorithms and also explained why certain methods work better than others. We also extended one of the oldest learning algorithms, the perceptron, to deal with prediction problems, such as ranking, where the set of possible predictions is huge. Note that the number of possible predictions in ranking problems is huge. The number of ways to rank a given set of item grows rapidly as the size of the set increases.</p>\n<p><br />A fundamental barrier in the path towards developing learning to rank systems in the difficulty in acquiring relevance labels from humans (e.g., a human has to tell the algorithm ``this webpage is highly relevant to this particular user query&rdquo;). We created a novel theoretical framework in which a user is presented with ranked lists but the user is only required to provide relevance labels on the top few items, perhaps just the single item at the very top. Even with such very limited user feedback, we showed that learning can still occur although there are demonstrable limits to how fast a system can learn from such restricted feedback.</p>\n<p><br />Results of this project were included in a three hour tutorial on ranking delivered at the Machine Learning &ldquo;Summer&rdquo; School held at Austin, TX in January 2015. The school was attended by a large number of people both from academia as well as the industry. Results were also disseminated to the research community via invited seminars at research universities and via presentations at leading international machine learning conferences. This project also fully funded a graduate student who successfully completed his Ph.D. on learning to rank algorithms. The student&rsquo;s work received honorable mention for the best student paper award at AISTATS 2015 (18th International Conference on Artificial Intelligence and Statistics).</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/26/2016<br>\n\t\t\t\t\tModified by: Ambuj&nbsp;Tewari</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAutomated ranking systems are used by millions of people everyday to find webpages, news articles, consumer products, blogs, podcasts, music, videos and more. Machine learning plays a big role in the design of modern ranking systems by automatically learning good rules to rank items in response to a user generated query. This has led to the creation of an entire research area at the intersection of information retrieval and machine learning called ``learning to rank\".\n\n\nIn this project, we developed new mathematical theory to better understand the power and limitations of learning to rank algorithms. We proved formal bounds on the performance of ranking algorithms that are trained on a finite amount of humanly labeled data. These new results generated novel insights into the behavior of learning to rank algorithms and also explained why certain methods work better than others. We also extended one of the oldest learning algorithms, the perceptron, to deal with prediction problems, such as ranking, where the set of possible predictions is huge. Note that the number of possible predictions in ranking problems is huge. The number of ways to rank a given set of item grows rapidly as the size of the set increases.\n\n\nA fundamental barrier in the path towards developing learning to rank systems in the difficulty in acquiring relevance labels from humans (e.g., a human has to tell the algorithm ``this webpage is highly relevant to this particular user query\"). We created a novel theoretical framework in which a user is presented with ranked lists but the user is only required to provide relevance labels on the top few items, perhaps just the single item at the very top. Even with such very limited user feedback, we showed that learning can still occur although there are demonstrable limits to how fast a system can learn from such restricted feedback.\n\n\nResults of this project were included in a three hour tutorial on ranking delivered at the Machine Learning \"Summer\" School held at Austin, TX in January 2015. The school was attended by a large number of people both from academia as well as the industry. Results were also disseminated to the research community via invited seminars at research universities and via presentations at leading international machine learning conferences. This project also fully funded a graduate student who successfully completed his Ph.D. on learning to rank algorithms. The student?s work received honorable mention for the best student paper award at AISTATS 2015 (18th International Conference on Artificial Intelligence and Statistics).\n\n\t\t\t\t\tLast Modified: 08/26/2016\n\n\t\t\t\t\tSubmitted by: Ambuj Tewari"
 }
}