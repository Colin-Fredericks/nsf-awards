{
 "awd_id": "1248603",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Development of Cohort Identification Tool",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Muralidharan Nair",
 "awd_eff_date": "2013-01-01",
 "awd_exp_date": "2013-06-30",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2012-11-27",
 "awd_max_amd_letter_date": "2012-11-27",
 "awd_abstract_narration": "This Small Business Innovation Research (SBIR) Phase I project seeks to address the most significant and challenging software need in healthcare: Cohort identification. A cohort is a group of patients with a common medical condition. Cohorts underpin modern medical care, defining treatment algorithms, measuring quality improvement, supporting government initiatives, and representing the core organization for research trials. While manual techniques have been developed to identify a cohort within a healthcare organization's electronic medical record (EMR), all rely on a physician or coder identifying and marking every record for every applicable medical condition. This manual process is inaccurate and only addresses the most common conditions. The suggested novel and revolutionary approach is to use big data techniques, utilizing the detailed unstructured narrative notes recorded on every patient for every encounter in every healthcare institution.  The core technology required to extract and make unstructured data usable in healthcare is natural language processing (NLP) combined with coded representations of clinical concepts (ontologies).  This proposal brings together industry leading teams and technologies to tackle the greatest data problem in healthcare, which offers a unique opportunity to significantly influence care for decades to come.\r\n\r\nThe broader impact/commercial potential of this project includes creating the foundational infrastructure for the next generation of data-driven healthcare.  Just as Google and Yahoo required advanced information extraction and search indexing techniques to make the vast amount of internet data usable, healthcare requires similar enabling technology.  The healthcare challenge is even more complex given the multitude of natural language descriptions used by physicians and the complex logic that defines potential cohorts and algorithms.  To address these issues, healthcare requires the category of technologies used in Google and Yahoo, but specialized for the healthcare domain.  In healthcare, quality improvement requires recognizing at risk cohorts in a population. Missing these cohorts and inadequately treating them can increase mortality by an order of magnitude, as in the case of deep vein thrombosis (DVT) in acute care. For quality measures being implemented by the federal government, defining and identifying cohorts is always the first step of tracking and reporting. Current processes are manual, limited, and inaccurate. By bringing evidence derived from clinical documentation which is created in current workflow to real-time and population based treatment decisions, this intervention will form a foundation for data-driven care, supporting improved outcomes, shorter hospitalizations, and reduced direct medical costs.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Riskin",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel J Riskin",
   "pi_email_addr": "grants@verantos.com",
   "nsf_id": "000577150",
   "pi_start_date": "2012-11-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Health Fidelity, Inc.",
  "inst_street_address": "204 2nd Avenue #517",
  "inst_street_address_2": "",
  "inst_city_name": "San Mateo",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6508884956",
  "inst_zip_code": "944013963",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "CA15",
  "org_lgl_bus_name": null,
  "org_prnt_uei_num": null,
  "org_uei_num": null
 },
 "perf_inst": {
  "perf_inst_name": "Health Fidelity, Inc.",
  "perf_str_addr": "325 Sharon Park Dr. #730",
  "perf_city_name": "Menlo Park",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "940256805",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "4080",
   "pgm_ref_txt": "ADVANCED COMP RESEARCH PROGRAM"
  },
  {
   "pgm_ref_code": "5371",
   "pgm_ref_txt": "SMALL BUSINESS PHASE I"
  },
  {
   "pgm_ref_code": "8032",
   "pgm_ref_txt": "Software Services and Applications"
  },
  {
   "pgm_ref_code": "9139",
   "pgm_ref_txt": "INFORMATION INFRASTRUCTURE & TECH APPL"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><h2>Background</h2>\n<p>This Small Business Innovation Research (SBIR) project defines an innovative approach to solve a critical challenge in healthcare: measurement of clinical quality. Clinical quality metrics underlie quality improvement and are required inputs for all efforts to improve healthcare outcomes and reduce costs. Current systems to identify cohorts within electronic health records (EHR) are manually populated and, as a result, are known to be inaccurate, and to support only a handful of more than 600 nationally defined measures. With increasing government demand for quality measurement in healthcare, there is equally high demand for automated systems that can accurately identify patient cohorts, particularly those required for quality measures. An advanced approach is to use the 80% of healthcare data that exists in narrative unstructured format within the EHR. This approach has previously been limited due largely to technological limitations.</p>\n<h2>Project Approach</h2>\n<p>Automated data normalization processes were used to identify cohorts based on simple quality measures. Simple quality measures are based on single concepts, such as diabetes or hypertension. &nbsp;However, even simple quality measures can be difficult to accurately identify. For example, the term <em>hypertension</em> may appear on an EHR-based problem list for a patient. But, that concept, if resolved, may or may not be relevant within this quality cohort. To enable these types of important distinctions, feature vectors are required to algorithmically identify patients eligible for inclusion in quality measures.</p>\n<p>To apply this type of logic and translate hundreds of extracted features into a handful of quality cohorts, a standardized process was needed. The project required development of a filter, or inference layer, which identified feature vectors linked to cohorts.</p>\n<h2>Project Objectives</h2>\n<p>This Phase I program had two objectives:</p>\n<ol>\n<li>Leverage Health Fidelity&rsquo;s best-in-class REVEAL system, clinical data model, and advanced statistical modeling to develop a tool to enable patient cohort identification based on combined processed narratives and discrete data.</li>\n<li>Use the tools developed in Objective 1 to compare processed narrative and discrete data against gold standard data for 10 quality cohorts. Success criteria included: at least 10% improvement in sensitivity in correctly identifying cohorts associated with specific quality measures over discrete data alone, less than 5% decrease in specificity, and statistical significance.</li>\n</ol>\n<h2>Project Methods</h2>\n<p>For system development, this project used a large set of de-identified clinical records for training. For results analysis, this project used a separate set of 3,000 de-identified clinical records for validation. &nbsp;The validation record set contained patient records which were manually reviewed, annotated, and enhanced with 10 quality measures by a single independent clinician, who was not part of the development team. Upon sealing the results of the clinician gold standard annotation, the engineering team initiated an iterative development process using extracted features mapped to controlled vocabularies to create a statistical inference engine. The team integrated the statistical inference engine into the REVEAL tool and configured the tool to automatically accept and persist validation data from test data sets and gold standard data within a single defined data model. In order to compare the results of the test data sets to the gold standard data, the team created a data analysis tool to test system results for each individual quality measure and for the sum of measures.</p>\n<h2>Summary of Data and Conclusions</h2>\n<p>The cohort identification tool developed in this Phase I project met its success criteria. Cohort identification based on discrete claims data alone, repres...",
  "por_txt_cntn": "Background\n\nThis Small Business Innovation Research (SBIR) project defines an innovative approach to solve a critical challenge in healthcare: measurement of clinical quality. Clinical quality metrics underlie quality improvement and are required inputs for all efforts to improve healthcare outcomes and reduce costs. Current systems to identify cohorts within electronic health records (EHR) are manually populated and, as a result, are known to be inaccurate, and to support only a handful of more than 600 nationally defined measures. With increasing government demand for quality measurement in healthcare, there is equally high demand for automated systems that can accurately identify patient cohorts, particularly those required for quality measures. An advanced approach is to use the 80% of healthcare data that exists in narrative unstructured format within the EHR. This approach has previously been limited due largely to technological limitations.\nProject Approach\n\nAutomated data normalization processes were used to identify cohorts based on simple quality measures. Simple quality measures are based on single concepts, such as diabetes or hypertension.  However, even simple quality measures can be difficult to accurately identify. For example, the term hypertension may appear on an EHR-based problem list for a patient. But, that concept, if resolved, may or may not be relevant within this quality cohort. To enable these types of important distinctions, feature vectors are required to algorithmically identify patients eligible for inclusion in quality measures.\n\nTo apply this type of logic and translate hundreds of extracted features into a handful of quality cohorts, a standardized process was needed. The project required development of a filter, or inference layer, which identified feature vectors linked to cohorts.\nProject Objectives\n\nThis Phase I program had two objectives:\n\nLeverage Health Fidelity\u00c6s best-in-class REVEAL system, clinical data model, and advanced statistical modeling to develop a tool to enable patient cohort identification based on combined processed narratives and discrete data.\nUse the tools developed in Objective 1 to compare processed narrative and discrete data against gold standard data for 10 quality cohorts. Success criteria included: at least 10% improvement in sensitivity in correctly identifying cohorts associated with specific quality measures over discrete data alone, less than 5% decrease in specificity, and statistical significance.\n\nProject Methods\n\nFor system development, this project used a large set of de-identified clinical records for training. For results analysis, this project used a separate set of 3,000 de-identified clinical records for validation.  The validation record set contained patient records which were manually reviewed, annotated, and enhanced with 10 quality measures by a single independent clinician, who was not part of the development team. Upon sealing the results of the clinician gold standard annotation, the engineering team initiated an iterative development process using extracted features mapped to controlled vocabularies to create a statistical inference engine. The team integrated the statistical inference engine into the REVEAL tool and configured the tool to automatically accept and persist validation data from test data sets and gold standard data within a single defined data model. In order to compare the results of the test data sets to the gold standard data, the team created a data analysis tool to test system results for each individual quality measure and for the sum of measures.\nSummary of Data and Conclusions\n\nThe cohort identification tool developed in this Phase I project met its success criteria. Cohort identification based on discrete claims data alone, representing the most common current method of quality measurement, generated a sensitivity of 18.9% per individual patient encounter. Cohort identification based on unstructured processed data y..."
 }
}