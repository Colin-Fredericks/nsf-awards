{
 "awd_id": "1339036",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Exploring Cloud Paradigm and Practices for Science and Engineering",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924220",
 "po_email": "kthompso@nsf.gov",
 "po_sign_block_name": "Kevin Thompson",
 "awd_eff_date": "2013-06-01",
 "awd_exp_date": "2017-05-31",
 "tot_intn_awd_amt": 299984.0,
 "awd_amount": 299984.0,
 "awd_min_amd_letter_date": "2013-06-07",
 "awd_max_amd_letter_date": "2013-06-07",
 "awd_abstract_narration": "Clouds abstractions and infrastructure are rapidly becoming part of the advanced research cyber-infrastructure (ACI) providing viable platforms for scientific exploration and discovery. As a result, it is important to understand how emerging data and compute intensive application workflows can effectively utilize a hybrid ACI integrating Cloud abstractions and services, and how such a hybrid ACI can enable new paradigms and practices in science and engineering. This EAGER explores innovative science and engineering application formulations that are enabled by a hybrid federated ACI that includes Clouds and HPC resources, as well as programming and middleware support for these new application formulations. Specifically, the project focuses on three key research thrusts: (1) application formulation; (2) programming models, abstractions and systems; and (3) middleware stacks and management services, and explore two applications use cases -- (i) an oil reservoir modeling application based on an Ensemble Kalman Filter (EnKF), and (ii) molecular dynamics simulations using asynchronous replica exchange. In each of these use cases activities explore how the capabilities provided by resources and services in a federated ACI can be leveraged to optimize metrics such as time-to-science, cost-to-science and/or energy-to-science.\r\n\r\nCloud services are integral to the NSF ACI vision. Clouds are also rapidly becoming an integral part of the ACI available to science and engineering applications, and provide complementary capabilities that can have a significant impact on a range of applications. As a result, this research can have a significant impact on a diverse set of application domains by identifying new paradigms and practices that can make effective use of a hybrid ACI to accelerate science. Furthermore, the results of this research will provide resource providers information about how to best meet the needs of science and engineering applications and how current ACI can achieve broader accessibility and higher efficiencies and productivity. The development of human resources, including the training of students, researchers and software professions, as well as outreach to minorities and underrepresented group, is integral to all aspects of this effort.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Manish",
   "pi_last_name": "Parashar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Manish Parashar",
   "pi_email_addr": "manish.parashar@utah.edu",
   "nsf_id": "000148826",
   "pi_start_date": "2013-06-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ivan",
   "pi_last_name": "Rodero",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ivan Rodero",
   "pi_email_addr": "ivan.rodero@utah.edu",
   "nsf_id": "000631333",
   "pi_start_date": "2013-06-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Javier",
   "pi_last_name": "Diaz-Montes",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Javier Diaz-Montes",
   "pi_email_addr": "javidiaz@rdi2.rutgers.edu",
   "nsf_id": "000639374",
   "pi_start_date": "2013-06-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers Discovery Informatics Institute",
  "perf_str_addr": "94 Brett Road",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548058",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "768400",
   "pgm_ele_name": "CESER-Cyberinfrastructure for"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 299984.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The overarching goals of this project were to understand innovative science and engineering application formulations that are enabled by a hybrid federated ACI that includes clouds and HPC resources and to explore programming and middleware support that can enable these new application formulations.</p>\n<p>First, we explored different usage models for the integration of clouds and HPC resources, namely HPC in the Cloud, HPC plus Cloud, and HPC as a Cloud. Next, we explored how a federation can be used to tackle large-scale engineering problems and demonstrated the effectiveness of this approach by federating ten geographically distributed HPC systems for a total of 2.5 million core-hours. This scale of federation enabled scientists to create the most comprehensive data on the effect of pillars on micro fluid channel flow. We also developed an algorithm that improves upon the default Reduce phase of the scheduling policy in Hadoop by making well-informed decisions about (a) when to start the Reduce phase for a job and (b) where to schedule the Reduce task. We also used our federation approach to enable the parallel execution of a cellular segmentation algorithm across multiple HPC resources, which provided 3 to 5-fold speedups to traditional approaches in the segmentation of large brain tumor images.</p>\n<p>Further, we experimented with the use of a marketplace to enable the federation among multiple resource providers and used the framework to provide quality of service for streaming application by taking advantage of different vendors&rsquo; price points and performance. We also explored the use of Software-defined Networks (SDNs) in a federation and used it to offer data-transfer QoS. These efforts were then applied to two different scientific areas, namely content-based image retrieval for cancer research; and study of how chromatin architecture affects gene expression in DNA sequences.</p>\n<p>We also explored the use of in-transit computing and showed how in-transit resources could be used to process data along the data path, thereby reducing the computation time. The application of this approach was effective in the context of Smart Buildings, where we processed large amounts of data while optimizing both cost and energy. We also explored the application of software-defined environment concepts to infrastructure federation and created a rule-engine based software-defined federation.</p>\n<p>Finally, we expanded our software-defined federation by leveraging constraint programming and software containers. This work provides near real-time adjustments to the federation in response to changing stimuli (e.g., changes in resource properties or availabilities, or the rules or constraints regulating their use). The resulting amorphous ecosystem is transparently exposed as a service to running applications. The ability to react and adapt to changes in the underlying infrastructure while the application is running can reduce cost and/or the time-to-solution for workloads. We evaluated our approach using a synthetic workflow simulating a Gleason-grading system for prostate pathology image analysis. We also demonstrated how our work allows users to programmatically and dynamically define multiple virtual slices of the same underlying resources, and adapt each slice over time without interrupting application execution. The workflow was encapsulated using Docker containers, which was then orchestrated to run across a federation of multiple IaaS clouds.</p>\n<p>The research and development activities in this project &nbsp;(1) enabled scientists to create the most comprehensive data to date on the effect of pillars on micro fluid channel flow; (2) was one of the first efforts to enable the deployment of Docker containers across multiple clouds; and (3) enabled the parallel execution of a cellular segmentation algorithm across multiple HPC resources, which provided 3 to 5-fold speedups to traditional approaches in the segmentation of large brain tumor images.</p>\n<p>Forty (40) publications resulting from this effort have been published in major workshops, conferences, journals, and transactions. Additionally, the CometCloud open source software framework has been distributed to the community under the BSD open source license, and the framework documentation was also released under the Creative Commons Attribution 3.0 License. Other achievements include a Best Paper Award Finalist, a Best Poster Award, a winner of the 2015 Cloud Challenge Award &ndash; Category 2, and a Best Student Paper Award.</p>\n<p>This project has provided research and educational opportunities for students and researchers and has contributed to their academic work. It has also provided them the opportunity to collaborate with other researchers in academia and industry, to present their work at conferences and other meetings, to work with state of the art technologies, and to participate in software development and acquire related skills.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/14/2017<br>\n\t\t\t\t\tModified by: Manish&nbsp;Parashar</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe overarching goals of this project were to understand innovative science and engineering application formulations that are enabled by a hybrid federated ACI that includes clouds and HPC resources and to explore programming and middleware support that can enable these new application formulations.\n\nFirst, we explored different usage models for the integration of clouds and HPC resources, namely HPC in the Cloud, HPC plus Cloud, and HPC as a Cloud. Next, we explored how a federation can be used to tackle large-scale engineering problems and demonstrated the effectiveness of this approach by federating ten geographically distributed HPC systems for a total of 2.5 million core-hours. This scale of federation enabled scientists to create the most comprehensive data on the effect of pillars on micro fluid channel flow. We also developed an algorithm that improves upon the default Reduce phase of the scheduling policy in Hadoop by making well-informed decisions about (a) when to start the Reduce phase for a job and (b) where to schedule the Reduce task. We also used our federation approach to enable the parallel execution of a cellular segmentation algorithm across multiple HPC resources, which provided 3 to 5-fold speedups to traditional approaches in the segmentation of large brain tumor images.\n\nFurther, we experimented with the use of a marketplace to enable the federation among multiple resource providers and used the framework to provide quality of service for streaming application by taking advantage of different vendors? price points and performance. We also explored the use of Software-defined Networks (SDNs) in a federation and used it to offer data-transfer QoS. These efforts were then applied to two different scientific areas, namely content-based image retrieval for cancer research; and study of how chromatin architecture affects gene expression in DNA sequences.\n\nWe also explored the use of in-transit computing and showed how in-transit resources could be used to process data along the data path, thereby reducing the computation time. The application of this approach was effective in the context of Smart Buildings, where we processed large amounts of data while optimizing both cost and energy. We also explored the application of software-defined environment concepts to infrastructure federation and created a rule-engine based software-defined federation.\n\nFinally, we expanded our software-defined federation by leveraging constraint programming and software containers. This work provides near real-time adjustments to the federation in response to changing stimuli (e.g., changes in resource properties or availabilities, or the rules or constraints regulating their use). The resulting amorphous ecosystem is transparently exposed as a service to running applications. The ability to react and adapt to changes in the underlying infrastructure while the application is running can reduce cost and/or the time-to-solution for workloads. We evaluated our approach using a synthetic workflow simulating a Gleason-grading system for prostate pathology image analysis. We also demonstrated how our work allows users to programmatically and dynamically define multiple virtual slices of the same underlying resources, and adapt each slice over time without interrupting application execution. The workflow was encapsulated using Docker containers, which was then orchestrated to run across a federation of multiple IaaS clouds.\n\nThe research and development activities in this project  (1) enabled scientists to create the most comprehensive data to date on the effect of pillars on micro fluid channel flow; (2) was one of the first efforts to enable the deployment of Docker containers across multiple clouds; and (3) enabled the parallel execution of a cellular segmentation algorithm across multiple HPC resources, which provided 3 to 5-fold speedups to traditional approaches in the segmentation of large brain tumor images.\n\nForty (40) publications resulting from this effort have been published in major workshops, conferences, journals, and transactions. Additionally, the CometCloud open source software framework has been distributed to the community under the BSD open source license, and the framework documentation was also released under the Creative Commons Attribution 3.0 License. Other achievements include a Best Paper Award Finalist, a Best Poster Award, a winner of the 2015 Cloud Challenge Award &ndash; Category 2, and a Best Student Paper Award.\n\nThis project has provided research and educational opportunities for students and researchers and has contributed to their academic work. It has also provided them the opportunity to collaborate with other researchers in academia and industry, to present their work at conferences and other meetings, to work with state of the art technologies, and to participate in software development and acquire related skills.\n\n \n\n\t\t\t\t\tLast Modified: 07/14/2017\n\n\t\t\t\t\tSubmitted by: Manish Parashar"
 }
}