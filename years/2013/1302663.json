{
 "awd_id": "1302663",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: Medium: Energy-Efficient Architectures for Emerging Big-Data Workloads",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2013-07-01",
 "awd_exp_date": "2018-06-30",
 "tot_intn_awd_amt": 873286.0,
 "awd_amount": 889286.0,
 "awd_min_amd_letter_date": "2013-06-25",
 "awd_max_amd_letter_date": "2016-07-06",
 "awd_abstract_narration": "In modern server architectures, the processor socket and the memory system\r\nare implemented as separate modules.  Data exchange between these modules\r\nis expensive -- it is slow, it consumes a large amount of energy, and there\r\nare long wait times for narrow data links.  Emerging big-data workloads will\r\nrequire especially large amounts of data movement between the processor\r\nand memory.  To reduce the cost of data movement for big-data workloads,\r\nthe project attempts to design new server architectures that can leverage\r\n3D stacking technology.  The proposed approach, referred to as Near Data\r\nComputing (NDC), reduces the distance between a subset of computational\r\nunits and a subset of memory, and can yield high efficiency for workloads\r\nthat exhibit locality.  The project will also develop new big-data \r\nalgorithms and runtime systems that can exploit the properties of the\r\nnew architectures.\r\n\r\nThe project will lead to technologies that can boost performance and\r\nreduce the energy demands of big-data workloads.  Several reports have\r\ncited the importance of these workloads to national, industrial, and\r\nscientific computing infrastructures.  The project outcomes will be\r\nintegrated into University of Utah curricula and will play a significant\r\nrole in a new degree program on datacenter design and operation.  The\r\nPIs will broaden their impact by publicly distributing parts of their\r\nsoftware infrastructure and by engaging in outreach programs that\r\ninvolve minorities and K-12 students.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rajeev",
   "pi_last_name": "Balasubramonian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rajeev Balasubramonian",
   "pi_email_addr": "rajeev@cs.utah.edu",
   "nsf_id": "000136755",
   "pi_start_date": "2013-06-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Alan",
   "pi_last_name": "Davis",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Alan L Davis",
   "pi_email_addr": "ald@cs.utah.edu",
   "nsf_id": "000424298",
   "pi_start_date": "2013-06-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mary",
   "pi_last_name": "Hall",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mary Hall",
   "pi_email_addr": "mhall@cs.utah.edu",
   "nsf_id": "000367228",
   "pi_start_date": "2013-06-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Feifei",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Feifei Li",
   "pi_email_addr": "lifeifei@cs.utah.edu",
   "nsf_id": "000598994",
   "pi_start_date": "2013-06-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841128930",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 209943.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 436176.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 243167.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project's central objective was to explore hardware-software techniques to move computations closer to data, thus reducing the cost (latency, bandwidth, and energy) of data movement for big-data workloads.</p>\n<p>&nbsp;On the hardware/database front, the project explored new 3D-stacked memory devices and augmented DIMMs that are equipped with simple cores.&nbsp; MapReduce workloads were then parallelized across the many cores spread across a large memory system to extract more than an order of magnitude speedup.</p>\n<p>&nbsp;The project also explored machine learning workloads.&nbsp; An extreme form of near-data processing was explored by leveraging memristor devices.&nbsp; The project showed that memristor devices can be used not only to store machine learning parameters, but also to perform in-situ dot-product operations.&nbsp; This reduces data movement, and offers unprecedented levels of compute/storage density.&nbsp; The project explored various techniques to reduce the overhead of the required analog units.&nbsp; The eventual design outperformed state-of-the-art machine learning accelerators by 8X.</p>\n<p>&nbsp;The project also augmented in-memory graph analytics by leveraging the concept of in-memory concurrent transaction processing for big graphs. By integrating trasaction processing and in-memory computing techniques, the proposed design significantly outperformed other parallel processing models for large-scale graph analytics.</p>\n<p>To show applicability for a broader set of workloads, the project also introduced an in-memory sampling technique for large spatial and spatio-temporal data. These samples were then used for various complex data analytics tasks.</p>\n<p>In addition, the project explored compiler extensions to reduce data movement.&nbsp; GPU implementations of sparse graph algorithms, such as the Stochastic Gradient Descent algorithm used in recommendation engines, were used as target workloads.&nbsp; A custom data representation was employed to to achieve locality and wavefront parallelism.</p>\n<p>&nbsp;Overall, the project showed that near-data processing, with help from the compiler and new memory devices, can achieve an order of magnitude improvement on analytics workloads dealing with massive datasets.</p>\n<p>&nbsp;The PIs also engaged in several outreach and educational activities for students ranging from elementary schools to graduate schools.&nbsp; Workshops and magazine special issues on near-data processing were organized.&nbsp; The project has produced many graduates with key skills to drive the nation's technological workforce.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/28/2018<br>\n\t\t\t\t\tModified by: Rajeev&nbsp;Balasubramonian</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project's central objective was to explore hardware-software techniques to move computations closer to data, thus reducing the cost (latency, bandwidth, and energy) of data movement for big-data workloads.\n\n On the hardware/database front, the project explored new 3D-stacked memory devices and augmented DIMMs that are equipped with simple cores.  MapReduce workloads were then parallelized across the many cores spread across a large memory system to extract more than an order of magnitude speedup.\n\n The project also explored machine learning workloads.  An extreme form of near-data processing was explored by leveraging memristor devices.  The project showed that memristor devices can be used not only to store machine learning parameters, but also to perform in-situ dot-product operations.  This reduces data movement, and offers unprecedented levels of compute/storage density.  The project explored various techniques to reduce the overhead of the required analog units.  The eventual design outperformed state-of-the-art machine learning accelerators by 8X.\n\n The project also augmented in-memory graph analytics by leveraging the concept of in-memory concurrent transaction processing for big graphs. By integrating trasaction processing and in-memory computing techniques, the proposed design significantly outperformed other parallel processing models for large-scale graph analytics.\n\nTo show applicability for a broader set of workloads, the project also introduced an in-memory sampling technique for large spatial and spatio-temporal data. These samples were then used for various complex data analytics tasks.\n\nIn addition, the project explored compiler extensions to reduce data movement.  GPU implementations of sparse graph algorithms, such as the Stochastic Gradient Descent algorithm used in recommendation engines, were used as target workloads.  A custom data representation was employed to to achieve locality and wavefront parallelism.\n\n Overall, the project showed that near-data processing, with help from the compiler and new memory devices, can achieve an order of magnitude improvement on analytics workloads dealing with massive datasets.\n\n The PIs also engaged in several outreach and educational activities for students ranging from elementary schools to graduate schools.  Workshops and magazine special issues on near-data processing were organized.  The project has produced many graduates with key skills to drive the nation's technological workforce.\n\n\t\t\t\t\tLast Modified: 10/28/2018\n\n\t\t\t\t\tSubmitted by: Rajeev Balasubramonian"
 }
}