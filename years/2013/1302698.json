{
 "awd_id": "1302698",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Medium: Collaborative Research: Scaling Machine Learning to Massive Datasets---A Logic Based Approach",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 667000.0,
 "awd_amount": 667000.0,
 "awd_min_amd_letter_date": "2013-07-26",
 "awd_max_amd_letter_date": "2016-07-25",
 "awd_abstract_narration": "Machine learning (ML) algorithms have become ubiquitous across applications as diverse as science, engineering, business, finance, education and healthcare. However, development of ML software that can scale to massive datasets and that are also easy-to-use remains a challenge in part due to the fact that developing an ML tool currently requires the implementation of a deep software stack, from the actual runtime (i.e., how an ML algorithm is executed) to the API exposed to the users.\r\n\r\nThis  project aims to develop DeML, a system to support the authoring and execution of ML tools. Specifically, DeML would allow ML algorithms to be formulated in the form of a declarative query over the training dataset. DeML  optimizes the execution of the query over a computing platform (e.g., Amazon EC2 or SQL Azure), taking into account the characteristics of the algorithm, the data, and the available computational resources. Adoption of DeML would greatly reduce the effort required to develop scalable implementations of ML algorithms. The project is organized around three thrusts: (i) Development of a declarative query language, based on extensions of Datalog; (ii) Analysis of runtime of DeML queries; (iii) Optimization of dataflow of DeML queries based on the characteristics of data sources and the capabilities of the underlying execution platform. The resulting open source DeML prototype implementation will be made freely available to the community through the project web page at: http://deml.cs.ucla.edu.\r\n\r\nThe availability of the DeML could greatly lower the effort needed to author scalable implementations of ML algorithms for analysis of massive datasets, which in turn would increase the availability of such tools to the broader community. Experience gained by implementing and deploying ML algorithms at scale over modern cloud-computing platforms, could help inform critical design choices in the development of future cloud computing platforms for big data analytics, and hence impact a broad range of scientific, engineering, national security, healthcare and business applications of big data analytics. The project offers enhanced opportunities for research-based advanced training of graduate and undergraduate students, including members of groups that are currently under-represented in computer science, in databases, machine learning, and cloud computing.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tyson",
   "pi_last_name": "Condie",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tyson Condie",
   "pi_email_addr": "tconde@cs.ucla.edu",
   "nsf_id": "000629463",
   "pi_start_date": "2013-07-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Carlo",
   "pi_last_name": "Zaniolo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Carlo Zaniolo",
   "pi_email_addr": "zaniolo@CS.UCLA.EDU",
   "nsf_id": "000451654",
   "pi_start_date": "2013-07-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "UCLA Department of Computer Science",
  "perf_str_addr": "BOX 959515, 4531 Boelter Hall",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900951596",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 333500.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 166750.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 166750.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"paragraph_style_1\"><span><span class=\"style_2\">The project seeks to create a unified, high-productivity, declarative programming environment for the development BigData analytics that will assure&nbsp; ease-of-use, scalability and portability, much in the ways in which these properties for simple database applications were made possible by the introduction of Codd's&nbsp; Relational Model.&nbsp; To realization of this ambiguous objective&nbsp; requires&nbsp; (i) the design of a declarative language that enable the high-level specification of complex algorithms, whereby the program abstract semantics can be turned into efficient operational semantics over different platforms thanks to (ii) effective query optimization techniques that take into account&nbsp;</span></span><span><span class=\"style_2\">the characteristics of the algorithm, the data, and the available computational resources as needed to execute efficiently over diverse platforms.&nbsp; These&nbsp; must include muliti-cluster systems, multicore systems, and workshations along we new cloud-computing platforms such</span></span><span><span class=\"style_2\">&nbsp;Amazon EC2 or SQL Azure).&nbsp; In the course of this project major progress was accomplished toward realizeing these ambitions objectives using using a logic-based approach as a result of the significant technical advances summarized next.</span></span></p>\n<div>Our key technical advances stem from our work on BigDatalog, a Datalog language implementation on Apache Spark. Using our system Spark programmers can now benefit from using a declarative, recursive language to implement their distributed algorithms, while maintaining the efficiency of highly optimized programs. On our large test graph instances BigDatalog outperforms other state-of-the-art Datalog systems on the majority of our tests. Moreover, our experimental results confirmed that among Spark-based systems BigDatalog outperforms both GraphX and native Spark for recursive queries.&nbsp;</div>\n<div></div>\n<div>We addressed three key challenges for using Spark as a Datalog runtime. Speicifcally, now with BigDatalog, recursive queries are compiled and optimized for efficient evaluation on Spark, which was verified by our experimental results (Challenge 1). BigDatalog is able to identify and produce physical plans for evaluating decomposable programs. In addition, we propose a new type of job for recursive programs to allow the scheduler greater control over iterations (Challenge 2). Lastly, we propose specialized RDDs (SetRDD/AggregateSetRDD) that utilize Datalog semantics to support memory-efficient recursive evaluation (Challenge 3).</div>\n<div></div>\n<div>Future Work. In the course of this research we have identified several opportunities for exciting new directions. One first direction is to extend BigDatalog to support XYDatalog and realize the vision of to use Datalog to support complex machine learning analytics such as logistic regression over a massively parallel system. Another area is to investigate system extensions for provenance and fault tolerance enabled by monotonic Datalog constructs.</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/10/2017<br>\n\t\t\t\t\tModified by: Tyson&nbsp;Condie</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "The project seeks to create a unified, high-productivity, declarative programming environment for the development BigData analytics that will assure  ease-of-use, scalability and portability, much in the ways in which these properties for simple database applications were made possible by the introduction of Codd's  Relational Model.  To realization of this ambiguous objective  requires  (i) the design of a declarative language that enable the high-level specification of complex algorithms, whereby the program abstract semantics can be turned into efficient operational semantics over different platforms thanks to (ii) effective query optimization techniques that take into account the characteristics of the algorithm, the data, and the available computational resources as needed to execute efficiently over diverse platforms.  These  must include muliti-cluster systems, multicore systems, and workshations along we new cloud-computing platforms such Amazon EC2 or SQL Azure).  In the course of this project major progress was accomplished toward realizeing these ambitions objectives using using a logic-based approach as a result of the significant technical advances summarized next.\nOur key technical advances stem from our work on BigDatalog, a Datalog language implementation on Apache Spark. Using our system Spark programmers can now benefit from using a declarative, recursive language to implement their distributed algorithms, while maintaining the efficiency of highly optimized programs. On our large test graph instances BigDatalog outperforms other state-of-the-art Datalog systems on the majority of our tests. Moreover, our experimental results confirmed that among Spark-based systems BigDatalog outperforms both GraphX and native Spark for recursive queries. \n\nWe addressed three key challenges for using Spark as a Datalog runtime. Speicifcally, now with BigDatalog, recursive queries are compiled and optimized for efficient evaluation on Spark, which was verified by our experimental results (Challenge 1). BigDatalog is able to identify and produce physical plans for evaluating decomposable programs. In addition, we propose a new type of job for recursive programs to allow the scheduler greater control over iterations (Challenge 2). Lastly, we propose specialized RDDs (SetRDD/AggregateSetRDD) that utilize Datalog semantics to support memory-efficient recursive evaluation (Challenge 3).\n\nFuture Work. In the course of this research we have identified several opportunities for exciting new directions. One first direction is to extend BigDatalog to support XYDatalog and realize the vision of to use Datalog to support complex machine learning analytics such as logistic regression over a massively parallel system. Another area is to investigate system extensions for provenance and fault tolerance enabled by monotonic Datalog constructs.\n\n\t\t\t\t\tLast Modified: 10/10/2017\n\n\t\t\t\t\tSubmitted by: Tyson Condie"
 }
}