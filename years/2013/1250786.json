{
 "awd_id": "1250786",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Small: DA: Mining large graphs through subgraph sampling",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2013-10-01",
 "awd_exp_date": "2018-09-30",
 "tot_intn_awd_amt": 548367.0,
 "awd_amount": 560367.0,
 "awd_min_amd_letter_date": "2013-09-18",
 "awd_max_amd_letter_date": "2016-02-29",
 "awd_abstract_narration": "The size and complexity of these \"Big Data\" graphs have always posed significant challenges, limiting the scope of their analysis and thus also limiting the implications that one can draw from them. Mining data from large real-world graphs typically poses two challenges: one of computational resources and another of incomplete information.  A comprehensive analysis of these graphs has usually required access to large distributed computing platforms and sophisticated software. This project aims to address a portion of these challenges by investigating a new method, based in statistics and spectral graph theory, to infer essential properties of the full graph through extracting a representative sample of small subgraphs from the full graph. The goal is to reduce the computational burden on researchers interested in large graphs and thus broaden participation in \"Big Data\" activities.  As is now well-understood, the analysis of large graphs has many applications in a variety of fields including business, economics, public policy development, law enforcement, public health, sociology and, of course, computer science. This breadth of applicability and the proposed curriculum development activities have the potential to draw and retain a greater diversity of students into computer science and engineering and increasing the participation by under-represented groups.\r\n\r\nMany of the principal properties of a graph can be inferred from the graph spectrum (eigenvalues of its adjacency or the normalized Laplacian matrix). In particular, a rich set of interlacing results in spectral graph theory allows one to bound the eigenvalues of the full graph using the eigenvalues of its subgraphs. This project will develop new algorithms for generating subgraph samples, and then use basic estimation theory from statistics and the interlacing results from spectral graph theory to discern properties of a large graph.  The new method based on subgraph sampling (as opposed to node or edge sampling) uses  results from spectral graph theory and statistics to estimate the spectrum (eigenvalues) of the graph based on the spectrum of the sampled subgraphs. The goal is to allow a meaningful analysis of extremely large graphs without the use of anything beyond a typical desktop computer. The data collected and the algorithms developed as part of this project will be made available to the larger research community through a data repository hosted by Drexel University. The project will also make contributions to open-source software.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Harish",
   "pi_last_name": "Sethu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Harish Sethu",
   "pi_email_addr": "sethu@drexel.edu",
   "nsf_id": "000204661",
   "pi_start_date": "2013-09-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Steven",
   "pi_last_name": "Weber",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Steven P Weber",
   "pi_email_addr": "sweber@ece.drexel.edu",
   "nsf_id": "000341702",
   "pi_start_date": "2013-09-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Drexel University",
  "inst_street_address": "3141 CHESTNUT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158956342",
  "inst_zip_code": "191042875",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "DREXEL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "XF3XM9642N96"
 },
 "perf_inst": {
  "perf_inst_name": "Drexel University",
  "perf_str_addr": "3141 Chestnut Street",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191042875",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 548367.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 12000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The overarching goal of the project was to develop methods to reduce the computational burden of researchers studying large graphs and make feasible a meaningful analysis without the use of powerful computing facilities. The approach explored was based on sampling only a subset of the graph, and then using basic estimation theory from statistics and the interlacing results from spectral graph theory to discern properties of the large graph.</p>\n<p>We developed a new framework for big-graph analytics in dynamic graphs which improves upon the previously used models for tracking counts and concentrations of subgraph patterns (motifs). Our algorithm, called Edge Sample and Discard (ESD), generates an unbiased estimate of the total number of triangles, which can be continuously updated in response to both edge additions and deletions in the dynamic graph. A comparative analysis shows that our algorithm exploits the available neighborhood information of the sampled edges and achieves better accuracy and computational complexity than previously known approaches.</p>\n<p>We also pursued a method to estimate the motif statistics based on random walks in a large graph and developed the Waddling Random Walk (WRW) algorithm. It derives its name from the fact that it sways a little to the left and to the right, thus also sampling nodes not directly on the path of the random walk. The WRW algorithm achieves significantly higher accuracy (measured by the closeness of its estimate to the correct value) and higher precision (measured by the low variance in its estimations) than the current state-of-the-art algorithms for mining subgraph statistics.</p>\n<p>We also produced results in the sampling of large graphs to estimate complex properties of graphs such as eigenvalues. Accurate computation of eigenvalues of extremely large graphs is usually not feasible due to the prohibitive computational and storage costs and also because full access to many social network graphs is often restricted to most researchers. We developed a series of sampling algorithms, based on random walks, which estimate the top eigenvalues of a large graph faster and with greater accuracy on most graphs than the current state-of-the-art algorithms.</p>\n<p>We were also interested in efficiently finding nodes in a large graph with target a property, for instance a maximum degree node of a graph. To this end we developed a variant of a graph walk jump algorithm entitled Self Avoiding Walk Jump (SAWJ). We show that this algorithm efficiently finds maximum degree nodes in degree assortative graphs. Additionally we are able to approximate and upper bound on the expected number of steps required for SAWJ to find a maximum degree node using a discrete time Markov chain where the state space is the set of degrees in the graph.</p>\n<p>We also studied three variants of star sampling as means of finding node with a target property in a large graph; star sampling with replacement (SSR), star sampling without center replacement (SSC), and star sampling without star replacement (SSS). We estimated the cost of using all three star sampling variants to find a maximum degree node in Erdos Renyi (ER) graphs under both a unit and a linear cost model. Additionally, we proved that in an ER graph if the edge density is proportional to the number of nodes in the graph as the number of nodes becomes large the probability of finding the node with the target property on any sample is approximately equivalent under all three star sampling variants.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/19/2018<br>\n\t\t\t\t\tModified by: Harish&nbsp;Sethu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe overarching goal of the project was to develop methods to reduce the computational burden of researchers studying large graphs and make feasible a meaningful analysis without the use of powerful computing facilities. The approach explored was based on sampling only a subset of the graph, and then using basic estimation theory from statistics and the interlacing results from spectral graph theory to discern properties of the large graph.\n\nWe developed a new framework for big-graph analytics in dynamic graphs which improves upon the previously used models for tracking counts and concentrations of subgraph patterns (motifs). Our algorithm, called Edge Sample and Discard (ESD), generates an unbiased estimate of the total number of triangles, which can be continuously updated in response to both edge additions and deletions in the dynamic graph. A comparative analysis shows that our algorithm exploits the available neighborhood information of the sampled edges and achieves better accuracy and computational complexity than previously known approaches.\n\nWe also pursued a method to estimate the motif statistics based on random walks in a large graph and developed the Waddling Random Walk (WRW) algorithm. It derives its name from the fact that it sways a little to the left and to the right, thus also sampling nodes not directly on the path of the random walk. The WRW algorithm achieves significantly higher accuracy (measured by the closeness of its estimate to the correct value) and higher precision (measured by the low variance in its estimations) than the current state-of-the-art algorithms for mining subgraph statistics.\n\nWe also produced results in the sampling of large graphs to estimate complex properties of graphs such as eigenvalues. Accurate computation of eigenvalues of extremely large graphs is usually not feasible due to the prohibitive computational and storage costs and also because full access to many social network graphs is often restricted to most researchers. We developed a series of sampling algorithms, based on random walks, which estimate the top eigenvalues of a large graph faster and with greater accuracy on most graphs than the current state-of-the-art algorithms.\n\nWe were also interested in efficiently finding nodes in a large graph with target a property, for instance a maximum degree node of a graph. To this end we developed a variant of a graph walk jump algorithm entitled Self Avoiding Walk Jump (SAWJ). We show that this algorithm efficiently finds maximum degree nodes in degree assortative graphs. Additionally we are able to approximate and upper bound on the expected number of steps required for SAWJ to find a maximum degree node using a discrete time Markov chain where the state space is the set of degrees in the graph.\n\nWe also studied three variants of star sampling as means of finding node with a target property in a large graph; star sampling with replacement (SSR), star sampling without center replacement (SSC), and star sampling without star replacement (SSS). We estimated the cost of using all three star sampling variants to find a maximum degree node in Erdos Renyi (ER) graphs under both a unit and a linear cost model. Additionally, we proved that in an ER graph if the edge density is proportional to the number of nodes in the graph as the number of nodes becomes large the probability of finding the node with the target property on any sample is approximately equivalent under all three star sampling variants.\n\n\t\t\t\t\tLast Modified: 11/19/2018\n\n\t\t\t\t\tSubmitted by: Harish Sethu"
 }
}