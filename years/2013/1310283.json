{
 "awd_id": "1310283",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Scalable Data Coupling Abstraction for Data-Intensive Simulation Workflows",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032922247",
 "po_email": "rchadduc@nsf.gov",
 "po_sign_block_name": "Robert Chadduck",
 "awd_eff_date": "2013-05-01",
 "awd_exp_date": "2017-04-30",
 "tot_intn_awd_amt": 547283.0,
 "awd_amount": 559283.0,
 "awd_min_amd_letter_date": "2013-05-01",
 "awd_max_amd_letter_date": "2014-01-22",
 "awd_abstract_narration": "A Scalable Data Management Abstraction for Large-scale Coupled Simulation Workflows\r\n\r\nCoupled scientific simulation workflows, integrating multiple physics and scales and running at very large scales on high-end resources, have the potential for achieving unprecedented levels of accuracy and providing dramatic insights into complex phenomena. However, the coupled component of these simulation workflows need to interact and exchange significant amounts of data at runtime, and the data often has to be transformed as it flows from source to destination. As the volumes and generation rates of this data grow, the costs (latencies and energy) associated with extracting this data and transporting it for coupling, transformation and analysis have become the dominating overheads and are dictating the level of performance and productivity that can be achieved.\r\n\r\nThe goal of this project is to address these challenges and to develop conceptual solutions as well as a software framework that can enable the large-scale data-intensive simulations. Our approach is based on the premise that given the large data volumes and associated costs, data will have to be largely processed online, ?in-situ? and ?in-transit? while it is staged using resources within the computational platform, and the programming and runtime system must provide abstractions and mechanisms that facilitate such data processing. Our effort is organized around three key research thrusts: (1) Programming abstractions for in-situ/in-transit data management; (2) Design and implementation of a scalable data staging substrate; and (3) Data-centric mapping and scheduling.\r\n\r\nData and compute intensive simulations are becoming increasingly critical to a wide range of science and engineering domains, and as a result, this research has the potential to drive research and innovations in these domains. The developed framework and benchmarks also provide computer scientists with a substrate to experiment with and explore data-centric research. The development of human resources, including the training of students, researchers and software professions, as well as outreach to minorities and underrepresented group, is integral to all aspects of this effort.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Manish",
   "pi_last_name": "Parashar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Manish Parashar",
   "pi_email_addr": "manish.parashar@utah.edu",
   "nsf_id": "000148826",
   "pi_start_date": "2013-05-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ivan",
   "pi_last_name": "Rodero",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ivan Rodero",
   "pi_email_addr": "ivan.rodero@utah.edu",
   "nsf_id": "000631333",
   "pi_start_date": "2013-05-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers Discovery Informatics Institute",
  "perf_str_addr": "94 Brett Road",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548058",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  },
  {
   "pgm_ele_code": "808400",
   "pgm_ele_name": "CDS&E"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7726",
   "pgm_ref_txt": "DATANET"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 547283.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 12000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Data-intensive simulation workflows integrate data I/O and analytics pipelines, which are essential for transforming the data produced by the simulations into scientific insights. However, as the volumes and generation rates of the data grow, the costs (latencies and energy) associated with extracting this data and transporting it for coupling, transformation and analysis have become the dominating overheads, and are dictating the level of performance and productivity that can be achieved.</p>\n<p>The goal of this research activity was to address these data-related challenges and to develop conceptual solutions as well as a software framework that can enable the large-scale data-intensive simulation workflows. Our approach was based on the realization that given the large data volumes and associated costs, data will have to be largely processed online, &ldquo;in-situ&rdquo; and &ldquo;in-transit&rdquo; while it is staged using resources within the computational platform, and the programming and runtime system must provide abstractions and mechanisms that facilitate such data processing. Central to our efforts has been the formulation of a scalable abstraction that is centered on the data produced by the codes, and enables the dynamic querying and in-situ/in-transit manipulation of this data. This research effort included programming abstractions for in-situ/in-transit data management, the design and implementation of a scalable data staging substrate, and data-centric mapping and scheduling.</p>\n<p>Research activities as part of this effort have explored scalable data management abstractions and mechanisms from both performance and energy optimization perspectives. In case of the former, we researched abstractions and runtime mechanisms to support dynamic data management for application workflows on very large scale systems, application, access pattern and system aware dynamic data placement across deep memory hierarchies, and adaptive data-placement and execution for asynchronous task-based scientific workflows. In case of the latter, we characterized and modeled the performance/energy behaviors of both in-situ analytics and deep memory hierarchies for coupled scientific workflows, to gain important insights for runtime performance/energy tradeoffs. &nbsp;We also studied power and performance tradeoffs and balancing them to meet power constraints.</p>\n<p>This research has resulted in novel data staging abstractions and mechanisms that are enabling application workflows at very large scales. Furthermore, the results of this research have been deployed within the DataSpaces software, which is being used by multiple applications. The data staging capabilities resulting from this project are being used by scientific applications in multiple domains, including fusion and combustion.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/06/2017<br>\n\t\t\t\t\tModified by: Manish&nbsp;Parashar</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nData-intensive simulation workflows integrate data I/O and analytics pipelines, which are essential for transforming the data produced by the simulations into scientific insights. However, as the volumes and generation rates of the data grow, the costs (latencies and energy) associated with extracting this data and transporting it for coupling, transformation and analysis have become the dominating overheads, and are dictating the level of performance and productivity that can be achieved.\n\nThe goal of this research activity was to address these data-related challenges and to develop conceptual solutions as well as a software framework that can enable the large-scale data-intensive simulation workflows. Our approach was based on the realization that given the large data volumes and associated costs, data will have to be largely processed online, \"in-situ\" and \"in-transit\" while it is staged using resources within the computational platform, and the programming and runtime system must provide abstractions and mechanisms that facilitate such data processing. Central to our efforts has been the formulation of a scalable abstraction that is centered on the data produced by the codes, and enables the dynamic querying and in-situ/in-transit manipulation of this data. This research effort included programming abstractions for in-situ/in-transit data management, the design and implementation of a scalable data staging substrate, and data-centric mapping and scheduling.\n\nResearch activities as part of this effort have explored scalable data management abstractions and mechanisms from both performance and energy optimization perspectives. In case of the former, we researched abstractions and runtime mechanisms to support dynamic data management for application workflows on very large scale systems, application, access pattern and system aware dynamic data placement across deep memory hierarchies, and adaptive data-placement and execution for asynchronous task-based scientific workflows. In case of the latter, we characterized and modeled the performance/energy behaviors of both in-situ analytics and deep memory hierarchies for coupled scientific workflows, to gain important insights for runtime performance/energy tradeoffs.  We also studied power and performance tradeoffs and balancing them to meet power constraints.\n\nThis research has resulted in novel data staging abstractions and mechanisms that are enabling application workflows at very large scales. Furthermore, the results of this research have been deployed within the DataSpaces software, which is being used by multiple applications. The data staging capabilities resulting from this project are being used by scientific applications in multiple domains, including fusion and combustion.\n\n\t\t\t\t\tLast Modified: 07/06/2017\n\n\t\t\t\t\tSubmitted by: Manish Parashar"
 }
}