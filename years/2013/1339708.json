{
 "awd_id": "1339708",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: SI2-SSE: UT Wrangler: Understanding the Software Needs of High End Computer Users",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rajiv Ramnath",
 "awd_eff_date": "2013-10-01",
 "awd_exp_date": "2016-09-30",
 "tot_intn_awd_amt": 233046.0,
 "awd_amount": 233046.0,
 "awd_min_amd_letter_date": "2013-09-13",
 "awd_max_amd_letter_date": "2013-09-13",
 "awd_abstract_narration": "This research addresses two important questions: what software do researchers actually use on high-end computers, and how successful are they in their efforts to use it? It is a plan to improve our understanding of individual users' software needs, then leverage that understanding to help stakeholders conduct business in a more efficient, effective, and systematic way. The signature product, UTWrangler, builds on work that is already improving the user experience and enhancing support programs for thousands of users on twelve supercomputers across the United States and Europe.   For the first time, complete, accurate, detailed, and continuous ground truth information about software needs, trends, and issues at the level of the individual job are being delivered.\r\n \r\nUTWrangler will instrument, monitor, and analyze individual jobs on high-end computers to generate a picture of the compilers, libraries, and other software that users need to run their jobs successfully. It will highlight the products our researchers need and do not need, and alert users and support staff to the root causes of software configuration issues as soon as the problems occur. UTWrangler's prototypes prove its value and future impact: simplifying end users' workflows; improving support, training and documentation; saving money; and helping administrators prioritize maintenance of their large base of installed software.  UTWrangler will build on the capabilities of its prototypes, providing a robust, sustainable, second generation mechanism that will help the computational research community make the most effective use of limited computing cycles and labor hours.  And UTWrangler will mitigate the difficulties new users encounter, reporting configuration problems as soon as jobs begin, and identifying opportunities to improve documentation, education and outreach programs.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "McLay",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Robert T McLay",
   "pi_email_addr": "mclay@tacc.utexas.edu",
   "nsf_id": "000776659",
   "pi_start_date": "2013-09-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "101 E. 27th Street, Suite 5.300",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121532",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "800400",
   "pgm_ele_name": "Software Institutes"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8005",
   "pgm_ref_txt": "Scientific Software Elements"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 233046.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The goal of this project is to understand how scientists actually use supercomputers by instrumenting the software and processes on these computers. XALT provides a robust, sustainable, second generation mechanism to instrument, monitor, and analyze processes running on a supercomputer. XALT was developed as a solution to common problems shared by many supercomputer centers and vendors: the need to know exactly what software, numerical libraries, and computing functions are used both in aggregate and in fine-grain details, such that centers and vendors can adjust design, policy, and efforts to be most efficient in providing these valuable supercomputing resources.&nbsp; XALT instruments and analyzes individual jobs on high end computers to generate a complete, detailed, and continuous picture of the compilers, libraries, even function calls and other software that users need to run their jobs successfully. XALT therefore allows its stakeholders to simplify workflows; improving support, training and documentation; saving money; and helping system administrators prioritize maintenance of their large base of installed software. Initial deployments of XALT has benefited thousands users across multiple supercomputing centers.</span></p>\n<p><span><span>The research team implemented an aggressive outreach and sustainability plans, modeled on a proven approach for a successful related program, to engage users, system administrators, and the broader community of stakeholders. The plan included establishing an active and energetic user group, as well as formal and informal interactions with these stakeholders. The team held six &ldquo;Birds of a Feather&rdquo; sessions (BoFs) at multiple conferences (SC14, ISC15, XSEDE15, SC15, ISC16, XSEDE16), presented a tutorial at CUG15 conference, published 3 papers as proceeding of the HUST14, HUST15 and XSEDE16 conferences, and have a mailing list to disseminate information. The team has presented demos of the software and provided copies of virtual machines with XALT to attendees at the BoFs. A publicly accessible source code repository has been established on GitHub (</span><a href=\"https://github.com/Fahey-McLay/xalt\" target=\"_blank\">https://github.com/Fahey-McLay/xalt</a><span>) with a &nbsp;corresponding project website on SourceForge (</span><a href=\"https://sourceforge.net/projects/xalt/\" target=\"_blank\">https://sourceforge.net/projects/xalt/</a><span>). &nbsp;There is online documentation (http://xalt.readthedocs.io). Outreach has even extended to the PIs helping installation of the product at HPC centers. Lastly, data anonymization tool has been developed in order to make it possible to share XALT data while guarding users&rsquo; privacy as a by-product of this project. This opens up analytic research for software usage and user's behavior to any researcher outside of the supercomputing centers deploying XALT.</span><br /></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/23/2017<br>\n\t\t\t\t\tModified by: Robert&nbsp;T&nbsp;Mclay</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this project is to understand how scientists actually use supercomputers by instrumenting the software and processes on these computers. XALT provides a robust, sustainable, second generation mechanism to instrument, monitor, and analyze processes running on a supercomputer. XALT was developed as a solution to common problems shared by many supercomputer centers and vendors: the need to know exactly what software, numerical libraries, and computing functions are used both in aggregate and in fine-grain details, such that centers and vendors can adjust design, policy, and efforts to be most efficient in providing these valuable supercomputing resources.  XALT instruments and analyzes individual jobs on high end computers to generate a complete, detailed, and continuous picture of the compilers, libraries, even function calls and other software that users need to run their jobs successfully. XALT therefore allows its stakeholders to simplify workflows; improving support, training and documentation; saving money; and helping system administrators prioritize maintenance of their large base of installed software. Initial deployments of XALT has benefited thousands users across multiple supercomputing centers.\n\nThe research team implemented an aggressive outreach and sustainability plans, modeled on a proven approach for a successful related program, to engage users, system administrators, and the broader community of stakeholders. The plan included establishing an active and energetic user group, as well as formal and informal interactions with these stakeholders. The team held six \"Birds of a Feather\" sessions (BoFs) at multiple conferences (SC14, ISC15, XSEDE15, SC15, ISC16, XSEDE16), presented a tutorial at CUG15 conference, published 3 papers as proceeding of the HUST14, HUST15 and XSEDE16 conferences, and have a mailing list to disseminate information. The team has presented demos of the software and provided copies of virtual machines with XALT to attendees at the BoFs. A publicly accessible source code repository has been established on GitHub (https://github.com/Fahey-McLay/xalt) with a  corresponding project website on SourceForge (https://sourceforge.net/projects/xalt/).  There is online documentation (http://xalt.readthedocs.io). Outreach has even extended to the PIs helping installation of the product at HPC centers. Lastly, data anonymization tool has been developed in order to make it possible to share XALT data while guarding users? privacy as a by-product of this project. This opens up analytic research for software usage and user's behavior to any researcher outside of the supercomputing centers deploying XALT.\n\n\n\t\t\t\t\tLast Modified: 01/23/2017\n\n\t\t\t\t\tSubmitted by: Robert T Mclay"
 }
}