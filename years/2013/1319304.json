{
 "awd_id": "1319304",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Collaborative Research:Compressed databases for similarity queries: fundamental limits and algorithms",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Cozzens",
 "awd_eff_date": "2013-07-01",
 "awd_exp_date": "2017-06-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2013-06-21",
 "awd_max_amd_letter_date": "2013-06-21",
 "awd_abstract_narration": "Project abstract \r\n\r\nInformation theory has had a profound impact on the fields of data transmission and compression. In contrast, it has yielded comparably few insights into problems such as knowledge extraction from and efficient search of massive datasets. While current information-theoretic tools and techniques can be applied to these problems to some extent, the paradigms for which these tools were developed will be being carefully reexamined in this project. Models that accurately capture the fundamental challenges faced by efficient search in modern massive database systems will be developed and analyzed. The asymptotic fundamental limits, which characterize the tradeoffs between accuracy, compression rate and search efficiency, will be investigated, along with development of practical algorithms that approach the ultimate benchmarks. One concrete problem being pursued is that of compression for efficient query and search. In this setting, the goal is, given a compressed representation, to answer search queries about the data that was compressed. This is in stark contrast to traditional compression, where the data need be merely reconstructible from the compressed form. The approach taken is tailored to distributed database design, but is also relevant to compression schemes that allow search within the compressed domain. \r\n\r\nThe fundamental quantities studied play a similar role to that of the channel capacity and entropy/rate-distortion in channel and source coding, respectively. On one hand, they yield an understanding of the fundamental limits on the performance that any system for similarity queries based on compressed representations can hope to attain. On the other, the insights obtained from the theory are guiding the construction of schemes that approach these limits in practice. We will investigate how existing practical approaches (such as various hashing and clustering techniques) perform with respect to the information theoretic limits, and the extent to which approaches that have proved to be practical in source and channel coding can be used as building blocks to develop new efficient search algorithms that significantly improve on the current state of the art",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sergio",
   "pi_last_name": "Verdu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sergio Verdu",
   "pi_email_addr": "verdu@princeton.edu",
   "nsf_id": "000313701",
   "pi_start_date": "2013-06-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "4 New South Building",
  "perf_city_name": "Princeton",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442020",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "793600",
   "pgm_ele_name": "SIGNAL PROCESSING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The objective of this project is to develop and analyze models that accurately capture the fundamental challenges faced by efficient search/transmission in modern storage and communications. We have obtained both nonasymptotic and asymptotic fundamental limits, which characterize the tradeoffs between accuracy, compression rate and search efficiency, and developed practical algorithms that approach the ultimate benchmarks.<br />We have studied the fundamental limits of the minimum average length of lossless and lossy variable-length compression, allowing a nonzero error probability &epsilon;, for lossless compression. We have found nonasymptotic bounds on the minimum average length in terms of Erokhin&rsquo;s rate-distortion function and we have used those bounds to obtain a Gaussian approximation on the speed of approach to the limit, which is quite accurate for all but small blocklengths. &nbsp; Not only does a nonzero error probability reduce the asymptotically achievable rate by a factor of 1 &minus; &epsilon;, but this asymptotic limit is approached from below, i.e., larger source dispersions and shorter blocklengths are beneficial.&nbsp;<br />We have also succeeded in quantifying the fundamental limits of variable-length transmission of a general (possibly analog) source over a memoryless channel with noiseless feedback, under a distortion constraint, which may be an excess distortion, average distortion, or guaranteed distortion (d-semifaithful codes) constraint. In contrast to the Shannon asymptotic fundamental limit, a general conclusion is that allowing variable-length codes and feedback leads to a sizable improvement in the fundamental delay-distortion tradeoff. In addition, we have obtained the minimum energy required to reproduce k source samples with a given fidelity after transmission over a memoryless Gaussian channel, showing that the required minimum energy is reduced with feedback and an average (rather than maximal) power constraint.<br />Another set of outcomes of the project pertains to the &nbsp;lossy compression problem in which the compressor observes the source through a noisy channel. We have obtained new general nonasymptotic achievability, converse bounds and the dispersion analysis. While this problem is asymptotically equivalent to a noiseless lossy source coding problem with a modified distortion function, nonasymptotically there is a noticeable gap in how fast their minimum achievable coding rates approach the common rate- distortion function, as evidenced both by the refined asymptotic analysis (dispersion) and the numerical results. A salient conclusion is that the size of the gap between the dispersions of the noisy problem and the asymptotically equivalent noiseless problem depends on the stochastic variability of the channel through which the compressor observes the source.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/29/2017<br>\n\t\t\t\t\tModified by: Sergio&nbsp;Verdu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe objective of this project is to develop and analyze models that accurately capture the fundamental challenges faced by efficient search/transmission in modern storage and communications. We have obtained both nonasymptotic and asymptotic fundamental limits, which characterize the tradeoffs between accuracy, compression rate and search efficiency, and developed practical algorithms that approach the ultimate benchmarks.\nWe have studied the fundamental limits of the minimum average length of lossless and lossy variable-length compression, allowing a nonzero error probability &epsilon;, for lossless compression. We have found nonasymptotic bounds on the minimum average length in terms of Erokhin?s rate-distortion function and we have used those bounds to obtain a Gaussian approximation on the speed of approach to the limit, which is quite accurate for all but small blocklengths.   Not only does a nonzero error probability reduce the asymptotically achievable rate by a factor of 1 &minus; &epsilon;, but this asymptotic limit is approached from below, i.e., larger source dispersions and shorter blocklengths are beneficial. \nWe have also succeeded in quantifying the fundamental limits of variable-length transmission of a general (possibly analog) source over a memoryless channel with noiseless feedback, under a distortion constraint, which may be an excess distortion, average distortion, or guaranteed distortion (d-semifaithful codes) constraint. In contrast to the Shannon asymptotic fundamental limit, a general conclusion is that allowing variable-length codes and feedback leads to a sizable improvement in the fundamental delay-distortion tradeoff. In addition, we have obtained the minimum energy required to reproduce k source samples with a given fidelity after transmission over a memoryless Gaussian channel, showing that the required minimum energy is reduced with feedback and an average (rather than maximal) power constraint.\nAnother set of outcomes of the project pertains to the  lossy compression problem in which the compressor observes the source through a noisy channel. We have obtained new general nonasymptotic achievability, converse bounds and the dispersion analysis. While this problem is asymptotically equivalent to a noiseless lossy source coding problem with a modified distortion function, nonasymptotically there is a noticeable gap in how fast their minimum achievable coding rates approach the common rate- distortion function, as evidenced both by the refined asymptotic analysis (dispersion) and the numerical results. A salient conclusion is that the size of the gap between the dispersions of the noisy problem and the asymptotically equivalent noiseless problem depends on the stochastic variability of the channel through which the compressor observes the source.\n\n\t\t\t\t\tLast Modified: 09/29/2017\n\n\t\t\t\t\tSubmitted by: Sergio Verdu"
 }
}