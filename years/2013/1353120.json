{
 "awd_id": "1353120",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: 3D Event Reconstruction from Social Cameras",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 216000.0,
 "awd_min_amd_letter_date": "2013-09-02",
 "awd_max_amd_letter_date": "2014-07-17",
 "awd_abstract_narration": "This EAGER project explores the use of social cameras to reconstruct and understand social activities in the wild. Social cameras are an emerging phenomenon, producing video captures of social activity from the point of view of members of the social group itself. They are proliferating at an unprecedented rate, as smartphones, camcorders, and recently wearable cameras, become broadly adopted around the world. Users naturally direct social cameras at areas of activity they consider significant, by turning their heads towards them (with wearable cameras) or by pointing their smartphone cameras at them. The core scientific contribution of this work is the joint analysis of both the 3D motion of social cameras (that encodes group attention) and the 3D motion in the scene (that encodes social activity) towards understanding the social interactions in a scene. A number of internal models (such as maximizing rigidity or minimizing effort) for event reconstruction are being investigated to address the ill-posed inverse problems involved.\r\n\r\nThis research is establishing a new area of visual analysis by providing the requisite framework for social activity understanding in 3D rather than in 2D. The ability to analyze social videos in 3D space and time provides useful tools for almost any activity that involves social groups working together, such as citizen journalism, search-and-rescue team coordination, or collaborative assembly teams. The project is integrated with education through teaching and student training, and outreaches industry through collaborations.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yaser",
   "pi_last_name": "Sheikh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yaser Sheikh",
   "pi_email_addr": "yaser@cs.cmu.edu",
   "nsf_id": "000502497",
   "pi_start_date": "2013-09-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 200000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Intellectual Merit</strong></p>\n<p>The project outcomes included an exploration both of developing a computational understanding of social behavior from crowd captures in the wild and a more systematic investigation in a controlled laboratory setting with the Panoptic Studio.&nbsp;</p>\n<p>A major outcome of the research was in predicting gaze direction from social cameras. We build a model based on a the concept of a \"Social charge\" that effectively predicts the gaze orientation, and therefore the attentive behavior, of individuals in a group.</p>\n<p class=\"p3\"><span class=\"s1\">In addition, we explored visibility Estimation in large scale 3D reconstruction: we formulated and considered the problem of visibility estimation in large scale dynamic 3D reconstruction from social cameras. This produced the highest resolution 3D reconstruciton of trajectory streams in history.</span></p>\n<p class=\"p3\"><strong>Broad Impact</strong></p>\n<p class=\"p3\"><span class=\"s1\">We developed a state-of-the-art pose estimation system based on inference machines that can detection the anatomical landmark of people in social situations. This algorithm runs at over 14Hz when deployed on a GPU.</span></p>\n<p>Hanbyul Joo, Hyun Soo Park, Yaser Sheikh&nbsp;(2014).&nbsp;<em>MAP Visibility Estimation for Large-Scale Dynamic 3D Reconstruction</em>. IEEE Conference on Computer Vision and Pattern Recognition.&nbsp;Columbus, Ohio.<br />Varun Ramakrishna, Daniel Munoz, Martial Hebert, J. Andrew Bagnell, and Yaser Sheikh&nbsp;(2014).&nbsp;<em>Pose Machines: Articulated Pose Estimation via Inference Machines</em>. European Conference on Computer Vision.&nbsp;Zurich, Switzerland.&nbsp;<br />Hyun Soo Park, Eakta Jain, Yaser Sheikh&nbsp;(2013).&nbsp;<em>Predicting Primary Gaze Behavior using Social Saliency Fields</em>. IEEE International Conference on Computer Vision.&nbsp;Sydney, Australia.&nbsp;</p>\n<ul class=\"ul1\">\n</ul>\n<p class=\"p4\"><span class=\"s1\">Two PhD student research was supported under this grant and two visiting undergraduates were supported in the CMU Robotics Institute Summer Scholars program.</span></p>\n<p><strong>Outcomes of the award covering the life of the award</strong></p>\n<p>This project provided support to explore the foundations of event reconstruction from social cameras---cameras that capture social signals of the group using the cameras.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/10/2017<br>\n\t\t\t\t\tModified by: Yaser&nbsp;Sheikh</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1353120/1353120_10273732_1486780406931_tmp--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1353120/1353120_10273732_1486780406931_tmp--rgov-800width.jpg\" title=\"Event Reconstruction\"><img src=\"/por/images/Reports/POR/2017/1353120/1353120_10273732_1486780406931_tmp--rgov-66x44.jpg\" alt=\"Event Reconstruction\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Event Reconstruction in the Panoptic Studio</div>\n<div class=\"imageCredit\">Yaser Sheikh</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Yaser&nbsp;Sheikh</div>\n<div class=\"imageTitle\">Event Reconstruction</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nIntellectual Merit\n\nThe project outcomes included an exploration both of developing a computational understanding of social behavior from crowd captures in the wild and a more systematic investigation in a controlled laboratory setting with the Panoptic Studio. \n\nA major outcome of the research was in predicting gaze direction from social cameras. We build a model based on a the concept of a \"Social charge\" that effectively predicts the gaze orientation, and therefore the attentive behavior, of individuals in a group.\nIn addition, we explored visibility Estimation in large scale 3D reconstruction: we formulated and considered the problem of visibility estimation in large scale dynamic 3D reconstruction from social cameras. This produced the highest resolution 3D reconstruciton of trajectory streams in history.\nBroad Impact\nWe developed a state-of-the-art pose estimation system based on inference machines that can detection the anatomical landmark of people in social situations. This algorithm runs at over 14Hz when deployed on a GPU.\n\nHanbyul Joo, Hyun Soo Park, Yaser Sheikh (2014). MAP Visibility Estimation for Large-Scale Dynamic 3D Reconstruction. IEEE Conference on Computer Vision and Pattern Recognition. Columbus, Ohio.\nVarun Ramakrishna, Daniel Munoz, Martial Hebert, J. Andrew Bagnell, and Yaser Sheikh (2014). Pose Machines: Articulated Pose Estimation via Inference Machines. European Conference on Computer Vision. Zurich, Switzerland. \nHyun Soo Park, Eakta Jain, Yaser Sheikh (2013). Predicting Primary Gaze Behavior using Social Saliency Fields. IEEE International Conference on Computer Vision. Sydney, Australia. \n\n\nTwo PhD student research was supported under this grant and two visiting undergraduates were supported in the CMU Robotics Institute Summer Scholars program.\n\nOutcomes of the award covering the life of the award\n\nThis project provided support to explore the foundations of event reconstruction from social cameras---cameras that capture social signals of the group using the cameras. \n\n \n\n\t\t\t\t\tLast Modified: 02/10/2017\n\n\t\t\t\t\tSubmitted by: Yaser Sheikh"
 }
}