{
 "awd_id": "1318497",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC: Small: New Directions in Field Programmable Gate Arrays (FPGA) Security",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2013-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 432214.0,
 "awd_amount": 432214.0,
 "awd_min_amd_letter_date": "2013-09-09",
 "awd_max_amd_letter_date": "2013-09-09",
 "awd_abstract_narration": "Field-programmable gate arrays (FPGAs) represent an important computing infrastructure which must be protected from attackers. They are used in a wide variety of applications, including networking routers, satellites, military equipment, and automobiles, among others.  The storage of FPGA programming information in memory external to the device creates a natural security weakness which, to date, has primarily been addressed via bitstream encryption. Recent work has shown that bitstream encryption is not impervious to attack and, with sufficient effort, the logical function of some or all of an FPGA design can be determined from a bitstream. This work systematically investigates advanced attacks on FPGA designs and, more importantly, develops sound countermeasures against FPGA design manipulations by determined attackers. To eliminate weaknesses, FPGA security is addressed from a new angle: the use of hardware obfuscation to make the true functionality of an FPGA design nearly indecipherable even if the entire logic-level design can be determined by bitstream reverse engineering. These questions are addressed by first developing a series of search-based computer-aided design tools which can identify security primitives (e.g. crypto primitives) in FPGA design logic-level netlists. As a result of this work, a series of automated tools which allow FPGA circuit designers to obscure the functionality of their subcircuits will be developed. These tools will make malicious design modification significantly more difficult or impossible.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Russell",
   "pi_last_name": "Tessier",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Russell Tessier",
   "pi_email_addr": "tessier@ecs.umass.edu",
   "nsf_id": "000109921",
   "pi_start_date": "2013-09-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Christof",
   "pi_last_name": "Paar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christof Paar",
   "pi_email_addr": "christof.paar@rub.de",
   "nsf_id": "000324536",
   "pi_start_date": "2013-09-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "Knowles Engineering Bldg",
  "perf_city_name": "Amherst",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010039284",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 432214.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project examined increasing the security of computer chips called field programmable gate arrays (FPGAs). The chips can implement different types of circuits at different times. With one set of programming information, an FPGA could operate like a microprocessor. With another set, the device could operate like a computer interface chip. The programming information used to give an FPGA its function is called a \"bitstream\".</p>\n<p>Unfortunately, since FPGAs can potentially implement any type of circuit, it makes them vulnerable to attacks by hackers. If a bad person changes the bitstream, the chip could perform malicious activities. Most FPGA bitstreams are protected by encryption, a mathematical approach to scramble the programming information so an outside attacker can't change it.&nbsp;</p>\n<p>In this project we showed that is some cases, encryption circuits in an FPGA can be located and modified. To enhance protection, we developed ways to hide (obscure) the function of these circuits inside the FPGA to make them harder to detect. Some of these techniques involved modifying the circuits after the bitstream was loaded into the FPGA device.&nbsp;</p>\n<p>Microprocessor circuits are often implemented in FPGAs. In another part of the project we showed that it is possible to use hardware circuits to obscure the operation of software code. An external observer is unable to determine software operation simply by examining the software instructions stored in computer memory. We used mathematical techniques to show that reverse engineering the processor operation was impossible.&nbsp;</p>\n<p>Our work has been published in leading technical journals (IEEE/ACM Transactions) and in the proceedings of leading conferences. Two PhD students and three Masters students have been trained as part of the work. The students now have full-time positions in industry in the US. These broader impacts have a positive effect on society and they have increased the security of computer systems that contain FPGAs.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/08/2017<br>\n\t\t\t\t\tModified by: Russell&nbsp;Tessier</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project examined increasing the security of computer chips called field programmable gate arrays (FPGAs). The chips can implement different types of circuits at different times. With one set of programming information, an FPGA could operate like a microprocessor. With another set, the device could operate like a computer interface chip. The programming information used to give an FPGA its function is called a \"bitstream\".\n\nUnfortunately, since FPGAs can potentially implement any type of circuit, it makes them vulnerable to attacks by hackers. If a bad person changes the bitstream, the chip could perform malicious activities. Most FPGA bitstreams are protected by encryption, a mathematical approach to scramble the programming information so an outside attacker can't change it. \n\nIn this project we showed that is some cases, encryption circuits in an FPGA can be located and modified. To enhance protection, we developed ways to hide (obscure) the function of these circuits inside the FPGA to make them harder to detect. Some of these techniques involved modifying the circuits after the bitstream was loaded into the FPGA device. \n\nMicroprocessor circuits are often implemented in FPGAs. In another part of the project we showed that it is possible to use hardware circuits to obscure the operation of software code. An external observer is unable to determine software operation simply by examining the software instructions stored in computer memory. We used mathematical techniques to show that reverse engineering the processor operation was impossible. \n\nOur work has been published in leading technical journals (IEEE/ACM Transactions) and in the proceedings of leading conferences. Two PhD students and three Masters students have been trained as part of the work. The students now have full-time positions in industry in the US. These broader impacts have a positive effect on society and they have increased the security of computer systems that contain FPGAs.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 10/08/2017\n\n\t\t\t\t\tSubmitted by: Russell Tessier"
 }
}