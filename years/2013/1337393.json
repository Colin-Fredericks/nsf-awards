{
 "awd_id": "1337393",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS: DSD: A2MA - Algorithms and Architectures for Multiresolution Applications",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2013-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 749801.0,
 "awd_amount": 749801.0,
 "awd_min_amd_letter_date": "2013-09-17",
 "awd_max_amd_letter_date": "2013-09-17",
 "awd_abstract_narration": "The goal of this research project is to devise novel methodologies and\r\ndevices for problems in computational science and engineering that\r\nrequire high-intensity of arithmetic operations (also known as\r\nFloating-point Operations Per Second, or ``FLOPS'').  Among the many\r\nhurdles faced in research and development of such compute-intensive\r\ntechnologies is achieving energy-efficient utilization of the\r\navailable computing resources. Similar to the miles/gallon metric used\r\nin automotive design, one is interested in a metric that can be used\r\nin the design of new computing technologies: optimizing\r\nFLOPS/watt. This research will be on designing novel algorithms and\r\narchitectures that optimize this metric. These algorithms and\r\narchitectures will be customized to a particular class of scientific\r\ncomputing problems: tree-based finite element methods and N-body\r\nproblems.\r\n\r\nIt is possible to devise algorithms that parallelize well and are \r\nenergy efficient (i.e., produce high ``percentage-of-peak''\r\nmeasurements). Often, however, such algorithms sacrifice work\r\noptimality. It is much more difficult to design algorithms that do so\r\nwhile achieving both work optimality and energy efficiency. This\r\non-node utilization wall---a chronic problem since the early\r\nnineties---not only remains unresolved but has become more acute with\r\nthe emergence of deeper memory hierarchies and manycore and\r\nheterogeneous architectures. At the same time, there is a large\r\nuntapped potential by not only adapting algorithms to architectural\r\nchanges, but instead driving architecture design from algorithm\r\nrequirements. This research will identify the design space for\r\ntree-based algorithms (under the constraints of work-optimality and\r\nmaximum concurrency), evaluate performance of state-of-the-art codes,\r\nand explore custom algorithm/hardware platforms.  A number of broader\r\nimpacts are anticipated from this project. The target methodologies\r\nfind applications in earth sciences, engineering, cosmology, biology,\r\nand data analysis.  Along with the research activities, an educational\r\nand dissemination program will be designed to communicate the results\r\nof this work to both students and researchers, as well as a more\r\ngeneral audience of computational and application scientists.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "George",
   "pi_last_name": "Biros",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "George Biros",
   "pi_email_addr": "gbiros@gmail.com",
   "nsf_id": "000209886",
   "pi_start_date": "2013-09-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "van de Geijn",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Robert A van de Geijn",
   "pi_email_addr": "rvdg@cs.utexas.edu",
   "nsf_id": "000336892",
   "pi_start_date": "2013-09-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Lizy",
   "pi_last_name": "John",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Lizy K John",
   "pi_email_addr": "ljohn@ece.utexas.edu",
   "nsf_id": "000378662",
   "pi_start_date": "2013-09-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andreas",
   "pi_last_name": "Gerstlauer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andreas Gerstlauer",
   "pi_email_addr": "gerstl@ece.utexas.edu",
   "nsf_id": "000520598",
   "pi_start_date": "2013-09-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "101 E. 27th Street, Stop A9000",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121539",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 749801.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project we studied fast and energy-efficient algorithms and architectures for tree-based methods in science and engineering. &nbsp;We aim at the creation of new classes of integrated hardware/algorithms concepts for tree-based finite element methods(FEM) and tree-based fast N-body methods. The data access patterns for these methods can be abstracted using ``tree traversals'', a particular set of methods that use tree-based data structures. This abstraction allows us to introduce specialized, hardware-level memory access and compute primitives that overcome the on-node utilization wall, are energy efficient, can be used in a black-box fashion, and are flexible to be used by a broad range of applications. &nbsp;Our contributions are summarized below.</p>\n<p>I<strong>INTELLECTUAL MERIT:</strong></p>\n<p>We developed detailed theoretical performance models that measure throughput and capture vertical memory transfer costs in terms of both time and power overheads for tree codes. &nbsp;We have extended our analysis to multidimensional treecodes that find applications in machine learning and data analytics. We developed &nbsp;novel algorithms for N-body methods for computational physics (fast multipole methods) and data analysis (kernel methods and hierarchical matrices). These algorithnms have been implemented in open source libraries and have been scaled using distributed and shared memory parallelism, as well as GPU and special-purpose accelerators, on high-end compute clusters with thousands of nodes.</p>\n<p>We carried out thorough performance evaluations of our N-body codes. Having this baseline information and the algorithm-design space we were able to customize and co-design our codes to explore alternative algorithm/hardware scenarios. Indeed, we completed extensive optimizations for N-body kernels, in particular pairwise interactions and nearest-neighbor finding. We created synergies with the critical computational kernels (linear algebra) completed integration with the Linear Algebra Processor (LAP), a hardware accelerator for basic linear algebra primitives.</p>\n<p>For co-design of new algorithms and architectures, we worked on co-designing novel hardware mechanisms using (i) enhancements to existing general purpose heterogeneous platforms, and by (ii)designing specialized processors to accelerate the chosen applications, while also considering memory transfers and memory reshuffles. One particular need that we have identified is the ability to generalize the LAP framework to a few additional computational kernels that appear in many problems with tree-codes.</p>\n<p>Using our N-body codes as a driving example of typical HPC computation patterns, we investigated the quantitative performance and energy efficiency tradeoffs of different accelerator integration and coupling approaches.<br /><br /><strong>BROADER IMPACTS:</strong></p>\n<p>Funding from this award has resulted in 25 peer reviewed publications and 24 presentations in conferences, workshops, and other institutions.<br />In addition, this award partially funded three software packages, which are listed below.</p>\n<p>1. libaskit, a distributed memory library for N-body based kernel methods in machine learning.&nbsp;<br />http://padas.ices.utexas.edu/libaskit&nbsp;</p>\n<p>2. PVFMM, a distributed memory 3D N-body code for computational physics.<br />https://github.com/dmalhotra/pvfmm</p>\n<p>3. MARSS, an x86-architecture simulator integrated with LAP&nbsp;special-purpose accelerator for matrix-matrix multiplication.<br />https://github.com/LAProc/marss</p>\n<p><strong>BROADER IMPACTS:</strong></p>\n<p>This award partially supported two postdoctoral researchers, four graduate student (one female student), and three undergraduate students for summer internships (two female students). The first postdoctoral researcher moved to industry and the second to an academic, tenure-track faculty position. &nbsp;During the course of the award, the graduate students went to &nbsp;industrial summer internships at QUALCOMM, AMD, ARM, INTEL, and NVIDIA for technology transfer. All graduate students and postdoctoral researchers gave presentations in high-performance computing conferences.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/23/2018<br>\n\t\t\t\t\tModified by: George&nbsp;Biros</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this project we studied fast and energy-efficient algorithms and architectures for tree-based methods in science and engineering.  We aim at the creation of new classes of integrated hardware/algorithms concepts for tree-based finite element methods(FEM) and tree-based fast N-body methods. The data access patterns for these methods can be abstracted using ``tree traversals'', a particular set of methods that use tree-based data structures. This abstraction allows us to introduce specialized, hardware-level memory access and compute primitives that overcome the on-node utilization wall, are energy efficient, can be used in a black-box fashion, and are flexible to be used by a broad range of applications.  Our contributions are summarized below.\n\nIINTELLECTUAL MERIT:\n\nWe developed detailed theoretical performance models that measure throughput and capture vertical memory transfer costs in terms of both time and power overheads for tree codes.  We have extended our analysis to multidimensional treecodes that find applications in machine learning and data analytics. We developed  novel algorithms for N-body methods for computational physics (fast multipole methods) and data analysis (kernel methods and hierarchical matrices). These algorithnms have been implemented in open source libraries and have been scaled using distributed and shared memory parallelism, as well as GPU and special-purpose accelerators, on high-end compute clusters with thousands of nodes.\n\nWe carried out thorough performance evaluations of our N-body codes. Having this baseline information and the algorithm-design space we were able to customize and co-design our codes to explore alternative algorithm/hardware scenarios. Indeed, we completed extensive optimizations for N-body kernels, in particular pairwise interactions and nearest-neighbor finding. We created synergies with the critical computational kernels (linear algebra) completed integration with the Linear Algebra Processor (LAP), a hardware accelerator for basic linear algebra primitives.\n\nFor co-design of new algorithms and architectures, we worked on co-designing novel hardware mechanisms using (i) enhancements to existing general purpose heterogeneous platforms, and by (ii)designing specialized processors to accelerate the chosen applications, while also considering memory transfers and memory reshuffles. One particular need that we have identified is the ability to generalize the LAP framework to a few additional computational kernels that appear in many problems with tree-codes.\n\nUsing our N-body codes as a driving example of typical HPC computation patterns, we investigated the quantitative performance and energy efficiency tradeoffs of different accelerator integration and coupling approaches.\n\nBROADER IMPACTS:\n\nFunding from this award has resulted in 25 peer reviewed publications and 24 presentations in conferences, workshops, and other institutions.\nIn addition, this award partially funded three software packages, which are listed below.\n\n1. libaskit, a distributed memory library for N-body based kernel methods in machine learning. \nhttp://padas.ices.utexas.edu/libaskit \n\n2. PVFMM, a distributed memory 3D N-body code for computational physics.\nhttps://github.com/dmalhotra/pvfmm\n\n3. MARSS, an x86-architecture simulator integrated with LAP special-purpose accelerator for matrix-matrix multiplication.\nhttps://github.com/LAProc/marss\n\nBROADER IMPACTS:\n\nThis award partially supported two postdoctoral researchers, four graduate student (one female student), and three undergraduate students for summer internships (two female students). The first postdoctoral researcher moved to industry and the second to an academic, tenure-track faculty position.  During the course of the award, the graduate students went to  industrial summer internships at QUALCOMM, AMD, ARM, INTEL, and NVIDIA for technology transfer. All graduate students and postdoctoral researchers gave presentations in high-performance computing conferences.\n\n\t\t\t\t\tLast Modified: 01/23/2018\n\n\t\t\t\t\tSubmitted by: George Biros"
 }
}