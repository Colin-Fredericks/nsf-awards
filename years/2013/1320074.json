{
 "awd_id": "1320074",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small:  Emerging Memory Architectures for Big Memory Applications",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tao Li",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 439802.0,
 "awd_amount": 439802.0,
 "awd_min_amd_letter_date": "2013-07-29",
 "awd_max_amd_letter_date": "2013-07-29",
 "awd_abstract_narration": "Computing is changing dramatically, particularly for cloud-based service providers such as Facebook, Google, and Amazon.  On-line service applications, such as social networking and search, place unique demands on processor memory systems.  In particular, these \"big-memory\" applications have working data sizes several orders of magnitude beyond those found in the workloads typically used in computer design research.  As a result, these applications place different stresses on processor memory systems.  Simultaneously, new, non-volatile memory (NVM) technologies such as Phase Change Memory (PCM), spin-transfer torque random access memory (STT-RAM), and memristors are emerging for use as a replacement for or augmentation to traditional dynamic RAM (DRAM) main memory.  These new memory technologies promise higher capacities and fast access times along with non-volatility (data retention when the power is off).  As a result, they have the potential to bridge the gaps in current processor memory systems for both data capacity and speed requirements, leading to new usage models, such as storage class memories or combined main memory and storage implementations.  These trends together argue for new memory systems architectures, designed for the challenges of big-memory applications, leveraging new memory technologies together with traditional DRAM and emerging process techniques such as 3-D die stacking. \r\n\r\nThis research will characterize big-memory applications in light of future availability of much larger and nonvolatile memories closer to the processor.  It will study the implications of these applications on emerging memory architectures in terms of organization, hierarchies, and other structural and management questions.  In particular, this research focuses on the development of the following: 1) Memory architectures for big memory applications, leveraging emerging technologies, such as 3-D die stacking and new, byte-addressable, dense non-volatile memories; 2) Deeply speculating instruction and data prefetchers for big-memory applications;  3) Cache policies that proactively manage performance, power, and reliability in memory systems for future big memory applications utilizing NVM; 4) New memory translation microarchitectures to meet the needs of big-memory applications and storage-class main memories; and 5) Quality-of-service policies to manage memory placement based upon usage in future, hybrid, and composite memory systems composed of DRAM and new NVM technologies.  The educational impact of this research will include training graduate and undergraduate students with valuable research skills while advancing the state of the art in computer architecture and distributed systems, contributing to the technology workforce.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Paul",
   "pi_last_name": "Gratz",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Paul V Gratz",
   "pi_email_addr": "pgratz@tamu.edu",
   "nsf_id": "000537306",
   "pi_start_date": "2013-07-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Narasimha",
   "pi_last_name": "Reddy",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Narasimha A Reddy",
   "pi_email_addr": "reddy@ece.tamu.edu",
   "nsf_id": "000295859",
   "pi_start_date": "2013-07-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas Engineering Experiment Station",
  "perf_str_addr": "3259 TAMU",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778454645",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "794100",
   "pgm_ele_name": "COMPUTER ARCHITECTURE"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 439802.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Computing is changing dramatically, particularly for cloud-based service providers, such as Facebook, Google, Amazon, etc.&nbsp; These on-line service applications, such as social networking and search place unique demands on processor memory systems.&nbsp; In particular, these big memory applications have working data sizes several orders of magnitude beyond those found in the workloads typically used in computer design research.&nbsp; As a result, these applications place different stresses on processor memory systems.&nbsp; Simultaneously, new, Non-Volatile Memory technologies such as Phase Change Memory (PCM), STT-RAM and memristors, are emerging for use as a replacement for, or augmentation to traditional DRAM main memory.&nbsp; These new memory technologies promise higher capacities, fast access times along with non-volatility (i.e.&nbsp; data retention when the power is off).&nbsp; As a result, they have the potential to bridge the gaps in current processor memory systems for both data capacity and speed requirements, leading to new usage models, such as storage class memories or combined main memory and storage implementations.&nbsp; These trends together argue for new memory systems architectures, designed for the challenges of big memory applications.</p>\n<p><br />The research generously supported by this grant characterized big memory applications in light of future availability of much larger and nonvolatile memories closer to the processor.&nbsp; Based on this characterization it identified several challenges with current memory system hierarchy design in the management of these hierarchies and placement of data within them.&nbsp; In particular, this research proposed new algorithms and techniques across a wide swath of computer systems design to address these challenges: for speculating on memory usage to inform cache data prefetching (published in MICRO'14, MICRO'16), in replacement policy to reduce writebacks to future non-volatile memorys (HiPEAK'14), in multi-level cache replacement and prefetching (ASPLOS'17), in page-level management between VMs and among hybrid memory classes (MEMSYS'15, MEMSYS'17).&nbsp; The educational impact of this research included training graduate and undergraduate students with valuable research skills while advancing the state of the art in computer architecture and distributed systems, contributing to the technology workforce.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/02/2017<br>\n\t\t\t\t\tModified by: Paul&nbsp;V&nbsp;Gratz</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nComputing is changing dramatically, particularly for cloud-based service providers, such as Facebook, Google, Amazon, etc.  These on-line service applications, such as social networking and search place unique demands on processor memory systems.  In particular, these big memory applications have working data sizes several orders of magnitude beyond those found in the workloads typically used in computer design research.  As a result, these applications place different stresses on processor memory systems.  Simultaneously, new, Non-Volatile Memory technologies such as Phase Change Memory (PCM), STT-RAM and memristors, are emerging for use as a replacement for, or augmentation to traditional DRAM main memory.  These new memory technologies promise higher capacities, fast access times along with non-volatility (i.e.  data retention when the power is off).  As a result, they have the potential to bridge the gaps in current processor memory systems for both data capacity and speed requirements, leading to new usage models, such as storage class memories or combined main memory and storage implementations.  These trends together argue for new memory systems architectures, designed for the challenges of big memory applications.\n\n\nThe research generously supported by this grant characterized big memory applications in light of future availability of much larger and nonvolatile memories closer to the processor.  Based on this characterization it identified several challenges with current memory system hierarchy design in the management of these hierarchies and placement of data within them.  In particular, this research proposed new algorithms and techniques across a wide swath of computer systems design to address these challenges: for speculating on memory usage to inform cache data prefetching (published in MICRO'14, MICRO'16), in replacement policy to reduce writebacks to future non-volatile memorys (HiPEAK'14), in multi-level cache replacement and prefetching (ASPLOS'17), in page-level management between VMs and among hybrid memory classes (MEMSYS'15, MEMSYS'17).  The educational impact of this research included training graduate and undergraduate students with valuable research skills while advancing the state of the art in computer architecture and distributed systems, contributing to the technology workforce.\n\n \n\n\t\t\t\t\tLast Modified: 10/02/2017\n\n\t\t\t\t\tSubmitted by: Paul V Gratz"
 }
}