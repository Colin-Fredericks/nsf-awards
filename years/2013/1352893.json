{
 "awd_id": "1352893",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Collaborative Research: Visualizing Event Dynamics with Narrative Animation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 75317.0,
 "awd_amount": 75317.0,
 "awd_min_amd_letter_date": "2013-08-29",
 "awd_max_amd_letter_date": "2013-08-29",
 "awd_abstract_narration": "Discovering and understanding the temporal evolution of events hidden in text corpora is a complex yet critical task for knowledge discovery. Although mining event dynamics has been an important research topic leading to many successful algorithms, researchers, research and development managers, intelligence analysts and the general public are still in dire need of effective tools to explore the evolutionary trends and patterns.  This exploratory project focuses on developing and validating a novel idea called narrative animation. Narrative animation uses animated visualizations to narrate, explore, and share event dynamics conveyed in temporally evolving text collections. Film art techniques are employed to leverage the animated visualizations in information organization and change detection, with the goals of enhancing analytical power and user engagement. A prototype system called CityStories is being developed to generate narrative animations of events in cities derived from web-based text. \r\n\r\nIf this novel, risky research is successful, it is expected to yield fundamental results in narrative animation that can advance the current paradigm in information visualization and visual analytics by developing novel techniques in using animations for presenting and analyzing dynamic abstract data at a large scale.  The pilot system CityStories system is expected provide a novel network platform for education, entertainment, and data analytics. It will engage general users such as students, teachers, journalists, bloggers, and many others in web information visualization and study.  Results of this research will be disseminated through publications, the World Wide Web, and collaborations with researchers and analysts.  The project web site (http://coitweb.uncc.edu/~jyang13/narrativeanimation/narrativeanimation.htm) will include research outcomes, publications, developed software, videos, and datasets for wide dissemination to public.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jing",
   "pi_last_name": "Yang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jing Yang",
   "pi_email_addr": "Jing.Yang@uncc.edu",
   "nsf_id": "000108046",
   "pi_start_date": "2013-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Charlotte",
  "inst_street_address": "9201 UNIVERSITY CITY BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTE",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "7046871888",
  "inst_zip_code": "282230001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NC12",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHARLOTTE",
  "org_prnt_uei_num": "NEYCH3CVBTR6",
  "org_uei_num": "JB33DT84JNA5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Charlotte",
  "perf_str_addr": "9201 University City Boulevard",
  "perf_city_name": "Charlotte",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "282230001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NC12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 75317.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We extensively studied how to use film art techniques in animated visualization of temporally evolving&nbsp;datasets.&nbsp; Interaction techniques, including spot-tracking lens (zooming + automatic panning), lighting, dynamic labeling, flashback, and multiple-screen techniques, have been developed for animated visualization to promptly and effectively present event dynamics in massive, time-varying data. These techniques contribute to an under-explored yet important area in information visualization: interactive explorations in animated visualization. They advance the state of the art of visualization and interaction methods for temporally evolving datasets. This pilot study also generated novel approaches to web-based text visualization. For example, CityStories visualization system forms a tangible platform for general public to view and study massive news, which can be extended to visualize other streaming data including emails, tweets, blogs, etc. &nbsp;A wide audience is engaged in understanding and participating in the process of web-based knowledge discovery and utilization. A set of publications and presentations disseminate the achievements of the project. The significant achievements include:</p>\n<p>1. Spot-tracking lens, a zoomable user interface for animated visualization.</p>\n<p>Traditional zooming technique, which magnifies a region in the view to allow users to examine details, does not work well for animated visualization, since moving objects can easily get out of the region. In movie arts, a track shot refers to that the camera is moved sideways, parallel to a moving object, to record its movement. Inspired by the track shot, we develop the spot-tracking lens. It integrates zooming with automatic panning to follow a focal object of interest, and thus allows users to examine its movement and the dynamics of its context during the animation. A set of novel auxiliary techniques are provided to the spot-tracking lens: the reference frame to help users be oriented and sense the speed of the objects during automatic panning, the spotlight to reduce change blindness, and the automatic labeling to reveal semantics of interesting patterns in a timely manner. A fully-working prototype of the spot-tracking lens has been developed. Our preliminary user studies have revealed that the spot-tracking lens not only allows users to follow an object and examine its context, but also promotes ego-centric explorations: users follow an object in a long time period and discover many insights relevant to the object and its neighbors. Such long chains of insights are desired in visual reasoning processes.</p>\n<p>2. City storie, a dynamic visualization system to tell city stories extracted from massive city news in multiple years.</p>\n<p>The news items continuously arriving along time form a text stream, which is rendered by gradually evolving visualization aimed to help users observe and understand the dynamical topics, events and trends of urban cities. The dynamic visualization is implemented based on an incremental clustering scheme over an evolving graph consisting of the streaming news in a moving time window. The changing clusters discover thematic evolution of the city over time. They are visualized based on text summarization so that users can easily explore salient and changing focuses of the text stream which narrates the city's chronological progression. The system can be extended to other text streams to visualize stories from emails, blogs, and so on.</p>\n<p>3. Narrative StreamIT, a streaming text visualization system enhanced by a variety of film techniques.</p>\n<p>We have developed a preliminary prototype for dynamic event visualization for streaming text collections based on StreamIT, our previous work on streaming text visualization. In particular, we leverage StreamIT using the following film art techniques: framing, motif, fading, flashback, cross cut, ...",
  "por_txt_cntn": "\nWe extensively studied how to use film art techniques in animated visualization of temporally evolving datasets.  Interaction techniques, including spot-tracking lens (zooming + automatic panning), lighting, dynamic labeling, flashback, and multiple-screen techniques, have been developed for animated visualization to promptly and effectively present event dynamics in massive, time-varying data. These techniques contribute to an under-explored yet important area in information visualization: interactive explorations in animated visualization. They advance the state of the art of visualization and interaction methods for temporally evolving datasets. This pilot study also generated novel approaches to web-based text visualization. For example, CityStories visualization system forms a tangible platform for general public to view and study massive news, which can be extended to visualize other streaming data including emails, tweets, blogs, etc.  A wide audience is engaged in understanding and participating in the process of web-based knowledge discovery and utilization. A set of publications and presentations disseminate the achievements of the project. The significant achievements include:\n\n1. Spot-tracking lens, a zoomable user interface for animated visualization.\n\nTraditional zooming technique, which magnifies a region in the view to allow users to examine details, does not work well for animated visualization, since moving objects can easily get out of the region. In movie arts, a track shot refers to that the camera is moved sideways, parallel to a moving object, to record its movement. Inspired by the track shot, we develop the spot-tracking lens. It integrates zooming with automatic panning to follow a focal object of interest, and thus allows users to examine its movement and the dynamics of its context during the animation. A set of novel auxiliary techniques are provided to the spot-tracking lens: the reference frame to help users be oriented and sense the speed of the objects during automatic panning, the spotlight to reduce change blindness, and the automatic labeling to reveal semantics of interesting patterns in a timely manner. A fully-working prototype of the spot-tracking lens has been developed. Our preliminary user studies have revealed that the spot-tracking lens not only allows users to follow an object and examine its context, but also promotes ego-centric explorations: users follow an object in a long time period and discover many insights relevant to the object and its neighbors. Such long chains of insights are desired in visual reasoning processes.\n\n2. City storie, a dynamic visualization system to tell city stories extracted from massive city news in multiple years.\n\nThe news items continuously arriving along time form a text stream, which is rendered by gradually evolving visualization aimed to help users observe and understand the dynamical topics, events and trends of urban cities. The dynamic visualization is implemented based on an incremental clustering scheme over an evolving graph consisting of the streaming news in a moving time window. The changing clusters discover thematic evolution of the city over time. They are visualized based on text summarization so that users can easily explore salient and changing focuses of the text stream which narrates the city's chronological progression. The system can be extended to other text streams to visualize stories from emails, blogs, and so on.\n\n3. Narrative StreamIT, a streaming text visualization system enhanced by a variety of film techniques.\n\nWe have developed a preliminary prototype for dynamic event visualization for streaming text collections based on StreamIT, our previous work on streaming text visualization. In particular, we leverage StreamIT using the following film art techniques: framing, motif, fading, flashback, cross cut, and subtitle.\n\n4. TStreamMonitor, a streaming text visualization system.\n\nWe have developed TStreamMonitor, a ful..."
 }
}