{
 "awd_id": "1319822",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF:Small: Derandomization and Lower Bounds",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 399999.0,
 "awd_amount": 399999.0,
 "awd_min_amd_letter_date": "2013-09-05",
 "awd_max_amd_letter_date": "2013-09-05",
 "awd_abstract_narration": "Computation is omnipresent in society, and randomness plays an important role, both as a liability and as a commodity. In particular, the ability to flip fair coins seems surprisingly useful in a plethora of computational settings, and a central line of research in the theory of computing tries to determine its actual power. In that context researchers develop deterministic simulations of randomized processes that are as efficient as possible. The canonical approach entails the construction of pseudo-random generators, which are efficient deterministic procedures that stretch a short random coin flip sequence to a much longer sequence that still looks random to the process under investigation. The driving question of the project is whether this canonical approach is omnipotent or whether there exist better ways to obtain deterministic simulations.\r\n\r\nThe project focuses on the relationships between derandomization, pseudo-random generators, and lower bounds. The existence of efficient pseudo-random generators is known to be equivalent to certain types of circuit lower bounds (which remain open). There are also a number of results showing that derandomization implies circuit lower bounds of some sort, but the lower bounds are typically not strong enough so as to imply back the same derandomization. A major thrust of the project is to establish equivalences between circuit lower bounds and derandomization, implying that canonical derandomization through pseudo-random generators is omnipotent.\r\n\r\nThe PI and his coworkers have developed a framework for deriving such results, and intend to apply it to large classes of randomized processes, including efficient decision procedures and efficient verification processes known as Arthur-Merlin games. The main focus lies on the standard notion of derandomization, in which the simulation needs to be correct everywhere, but the PI will as well consider weaker notions in which the deterministic simulation is allowed to err on some inputs.\r\n\r\nApart from furthering our knowledge about the power of randomness in computation, the project aims to provide graduate training on that topic and in the broader area of computational complexity.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dieter",
   "pi_last_name": "van Melkebeek",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dieter van Melkebeek",
   "pi_email_addr": "dieter@cs.wisc.edu",
   "nsf_id": "000295926",
   "pi_start_date": "2013-09-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "1210 W Dayton St",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537061685",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "792700",
   "pgm_ele_name": "COMPLEXITY & CRYPTOGRAPHY"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7927",
   "pgm_ref_txt": "COMPLEXITY & CRYPTOGRAPHY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 399999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The <strong>intellectual merits</strong> of this project deal with the power of randomness in computation: Can randomness be eliminated without increasing the required run time by much?</p>\n<p>The question is intricately related to the existence of explicit hard computational problems. This is because whether a sequene of numbers looks random to a computing device, depends on the power of that device. On the one hand, if a sequence of numbers looks random, it should be computationally hard to predict the next number given the previous numbers in the sequence. On the other hand, given an explicit hard computational problem, one can try and use it to construct a sequence of numbers that&nbsp;has a definite pattern but nevertheless looks random to the device as the device does not have the computational power needed to discern the pattern. The process that generates such a sequence is known as a pseudorandom generator. If it exists, it allows one to efficiently derandomize the device, i.e., deterministically simulate randomized processes on the device with a small overhead in computational resources.</p>\n<p>The project establishes an equivalence between hardness and derandomization in the context of verification procedures known as Arthur-Merlin protocols. The result implies that if derandomization is possible at all in that setting, then it can be done in a canonical way that is oblivious to the procotol, namely via a pseudo-random generator based on an explicit hard computational problem. The question whether derandomization is actually possible in that setting remains open.&nbsp;</p>\n<p><strong>Broader impacts</strong> of the project include the training of five graduate students and the organization of reading groups with about fifteen participants. Another broader impact is the development of lecture notes on derandomization.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/14/2019<br>\n\t\t\t\t\tModified by: Dieter&nbsp;Van Melkebeek</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe intellectual merits of this project deal with the power of randomness in computation: Can randomness be eliminated without increasing the required run time by much?\n\nThe question is intricately related to the existence of explicit hard computational problems. This is because whether a sequene of numbers looks random to a computing device, depends on the power of that device. On the one hand, if a sequence of numbers looks random, it should be computationally hard to predict the next number given the previous numbers in the sequence. On the other hand, given an explicit hard computational problem, one can try and use it to construct a sequence of numbers that has a definite pattern but nevertheless looks random to the device as the device does not have the computational power needed to discern the pattern. The process that generates such a sequence is known as a pseudorandom generator. If it exists, it allows one to efficiently derandomize the device, i.e., deterministically simulate randomized processes on the device with a small overhead in computational resources.\n\nThe project establishes an equivalence between hardness and derandomization in the context of verification procedures known as Arthur-Merlin protocols. The result implies that if derandomization is possible at all in that setting, then it can be done in a canonical way that is oblivious to the procotol, namely via a pseudo-random generator based on an explicit hard computational problem. The question whether derandomization is actually possible in that setting remains open. \n\nBroader impacts of the project include the training of five graduate students and the organization of reading groups with about fifteen participants. Another broader impact is the development of lecture notes on derandomization.\n\n\t\t\t\t\tLast Modified: 01/14/2019\n\n\t\t\t\t\tSubmitted by: Dieter Van Melkebeek"
 }
}