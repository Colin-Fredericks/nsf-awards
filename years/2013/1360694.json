{
 "awd_id": "1360694",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER:  Bridging the Gap Between Prototyping and Production",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2013-08-01",
 "awd_exp_date": "2016-02-29",
 "tot_intn_awd_amt": 407022.0,
 "awd_amount": 407022.0,
 "awd_min_amd_letter_date": "2013-09-26",
 "awd_max_amd_letter_date": "2013-09-26",
 "awd_abstract_narration": "Modern software engineering methods improve programmer productivity by taking an incremental approach to software development. Software engineers rapidly develop prototypes and then iteratively refine the prototypes into production systems.  However, today's programming systems do not support a smooth transition from prototyping to production. On one hand, scripting languages and interactive environments support prototyping while on the other hand conventional programming languages and optimizing compilers support the development of reusable and efficient production codes. Neither support both prototyping and production, so developers use a mixture of programming systems.  This practice incurs many costs such as the impedance mismatch of inter-language data transfers and the time to translate programs between languages.\r\n\r\nThe goal of this research is to discover the scientific principles necessary for a single programming system to effectively support the incremental refinement of prototypes into production software. To accomplish this research objective, classic conflicts between flexibility and safety and between abstraction and performance need to be resolved. To achieve both flexibility and safety, the research will investigate ways to combine dynamic and static type checking, using an approach called gradual typing. To achieve both abstraction and performance, the research will develop a domain-specific compiler for linear algebra and show how show how high-level abstractions can provide greater opportunities for compiler optimization than conventional abstractions such as loops and scalar operations. The broader impacts of the project arise from improvements to programmer productivity and software quality.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeremy",
   "pi_last_name": "Siek",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Jeremy G Siek",
   "pi_email_addr": "jsiek@indiana.edu",
   "nsf_id": "000086759",
   "pi_start_date": "2013-09-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Indiana University",
  "inst_street_address": "107 S INDIANA AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BLOOMINGTON",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "3172783473",
  "inst_zip_code": "474057000",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IN09",
  "org_lgl_bus_name": "TRUSTEES OF INDIANA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "YH86RTW2YVJ4"
 },
 "perf_inst": {
  "perf_inst_name": "Indiana University",
  "perf_str_addr": "509 E 3RD ST",
  "perf_city_name": "Bloomington",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "474013654",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IN09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 2489.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 210376.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 194157.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Incremental development is an essential feature of modern software<br />engineering and greatly improves programmer productivity. Software<br />teams rapidly develop prototypes and then iteratively refine the<br />prototypes into production systems. However, today&rsquo;s programming<br />systems do not support a smooth transition from prototyping to<br />production. On one hand, dynamic languages such as MATLAB and Python<br />support prototyping while on the other hand static languages such as<br />C++ and Java support the development of reusable and efficient<br />production codes. Neither support both prototyping and production, so<br />developers use a mixture of programming systems. This practice incurs<br />many costs such as the impedance mismatches of inter-language data<br />transfers and the time to translate programs between languages.<br /><br />The goal of the project \"CAREER: Bridging the Gap Between Prototyping<br />and Production\" was to make progress towards having a single<br />programming system that would support a gradual transition from<br />prototyping to production. To accomplish the research objective, the<br />long-standing conflicts between flexibility and safety and between<br />abstraction and performance need to be resolved.&nbsp; Regarding flexibilty<br />versus safety, the project investigated the idea of gradual typing,<br />which combines both static and dynamic type checking within the same<br />language. Regarding abstraction and performance, the project<br />investigated the compilation of a high-level language for matrix<br />algebra into high-performance code. We discuss the scientific<br />accomplishments on these two lines of research in the following<br />paragraphs.&nbsp; But to summarize the outputs of the project, we published<br />18 papers including 9 at high-impact conferences and journals. We<br />graduated 2 Ph.D. students and 2 M.S. students and 3 more<br />Ph.D. students are in progress. The project also produced two software<br />artifacts that have been released to the public, a gradually typed<br />version of the Python programming language, and the Build-to-Order<br />Basic Linear Algebra Subroutines, about which we will say more below.<br /><br />The project made significant discoveries regarding both the theory and<br />practice of gradual typing. On the theory side, we discovered how to<br />integrate gradual typing with parametric polymorphism (aka. generics)<br />in a way that preserves \"parametricity\", which is import for reasoning<br />about the correctness of polymorphic procedures.&nbsp; We solved the space<br />complexity problem that arises from the use of proxies to ensure the<br />safety of statically typed code that interacts with dynamically typed<br />code. We also solved problems regarding runtime overhead in statically<br />typed code (not just in partially typed or dynamically typed<br />code). Finally, we developed formal criteria to better characterize<br />when a language design satisfies the intent of gradual typing.<br /><br />Regarding the practice of gradual typing, we designed and implemented<br />a gradually typed variant of Python, named Reticulated Python.&nbsp; We<br />encountered a number of challenges along the way and invented<br />solutions to them, including \"transient casts\", which guarantee the<br />safety of statically typed code without using proxies, thereby<br />avoiding interoperability problems that we encountered regarding plain<br />Python code and with code written in C (parts of the Python standard<br />library, and many extensions). Another significant challenge to<br />gradual typing is that the performance of partially typed code can<br />degrade significantly. To solve this problem, we have initiated two<br />projects. We are investigating whether just-in-time compilation can<br />improve performance by implementing the Racket language using the<br />RPython framework. In the second project, we are building a native<br />code ahead-of-time compiler that implements the theoretical advances<br />mentioned above.&nbsp; So far, both the just-in-time and ahead-of-time<br />compilers are showing promise and delivering good performance on<br />benchmark programs.<br /><br />The second line of research in this project was in the compilation of<br />a language for matrix algebra into high-performance parallel code.<br />The goal of our compiler was to produce the best-possible code for a<br />particular combination of matrix operations. For example, it compiles<br />the input program<br />&nbsp;&nbsp;&nbsp; y := b * A' * (A * x)<br />into low-level C code that is organized to make best use of multiple<br />processors and the multiple levels of cache memory within a computer.<br />The code transformations to accomplish this are well known: loop<br />fusion, array contraction, and data parallel loops.&nbsp; However, the the<br />techniques are not beneficial in every situation, so the challenge is<br />finding the the best combination of transformations for a given input<br />program and target computer architecture. Thus, the essense of the<br />problem is mathematical optimization and search. We evaluated a wide<br />variety of search techniques, including genetic algorithms and<br />hill-climbing, and we developed a new heuristic/greedy search<br />algorithm.&nbsp; We found that the best approach was a hybrid that started<br />with our greedy search and then finished with a genetic search.&nbsp; With<br />this approach we were able to generate code for a wide range of<br />real-world matrix computations that was just as efficient as code<br />produced by a human expert and that out-performed the best<br />general-purpose loop-optimizing compilers.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/17/2016<br>\n\t\t\t\t\tModified by: Jeremy&nbsp;G&nbsp;Siek</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIncremental development is an essential feature of modern software\nengineering and greatly improves programmer productivity. Software\nteams rapidly develop prototypes and then iteratively refine the\nprototypes into production systems. However, today?s programming\nsystems do not support a smooth transition from prototyping to\nproduction. On one hand, dynamic languages such as MATLAB and Python\nsupport prototyping while on the other hand static languages such as\nC++ and Java support the development of reusable and efficient\nproduction codes. Neither support both prototyping and production, so\ndevelopers use a mixture of programming systems. This practice incurs\nmany costs such as the impedance mismatches of inter-language data\ntransfers and the time to translate programs between languages.\n\nThe goal of the project \"CAREER: Bridging the Gap Between Prototyping\nand Production\" was to make progress towards having a single\nprogramming system that would support a gradual transition from\nprototyping to production. To accomplish the research objective, the\nlong-standing conflicts between flexibility and safety and between\nabstraction and performance need to be resolved.  Regarding flexibilty\nversus safety, the project investigated the idea of gradual typing,\nwhich combines both static and dynamic type checking within the same\nlanguage. Regarding abstraction and performance, the project\ninvestigated the compilation of a high-level language for matrix\nalgebra into high-performance code. We discuss the scientific\naccomplishments on these two lines of research in the following\nparagraphs.  But to summarize the outputs of the project, we published\n18 papers including 9 at high-impact conferences and journals. We\ngraduated 2 Ph.D. students and 2 M.S. students and 3 more\nPh.D. students are in progress. The project also produced two software\nartifacts that have been released to the public, a gradually typed\nversion of the Python programming language, and the Build-to-Order\nBasic Linear Algebra Subroutines, about which we will say more below.\n\nThe project made significant discoveries regarding both the theory and\npractice of gradual typing. On the theory side, we discovered how to\nintegrate gradual typing with parametric polymorphism (aka. generics)\nin a way that preserves \"parametricity\", which is import for reasoning\nabout the correctness of polymorphic procedures.  We solved the space\ncomplexity problem that arises from the use of proxies to ensure the\nsafety of statically typed code that interacts with dynamically typed\ncode. We also solved problems regarding runtime overhead in statically\ntyped code (not just in partially typed or dynamically typed\ncode). Finally, we developed formal criteria to better characterize\nwhen a language design satisfies the intent of gradual typing.\n\nRegarding the practice of gradual typing, we designed and implemented\na gradually typed variant of Python, named Reticulated Python.  We\nencountered a number of challenges along the way and invented\nsolutions to them, including \"transient casts\", which guarantee the\nsafety of statically typed code without using proxies, thereby\navoiding interoperability problems that we encountered regarding plain\nPython code and with code written in C (parts of the Python standard\nlibrary, and many extensions). Another significant challenge to\ngradual typing is that the performance of partially typed code can\ndegrade significantly. To solve this problem, we have initiated two\nprojects. We are investigating whether just-in-time compilation can\nimprove performance by implementing the Racket language using the\nRPython framework. In the second project, we are building a native\ncode ahead-of-time compiler that implements the theoretical advances\nmentioned above.  So far, both the just-in-time and ahead-of-time\ncompilers are showing promise and delivering good performance on\nbenchmark programs.\n\nThe second line of research in this project was in the compilation of\na language for matrix algebra into high-performance parallel code.\nThe goal of our compiler was to produce the best-possible code for a\nparticular combination of matrix operations. For example, it compiles\nthe input program\n    y := b * A' * (A * x)\ninto low-level C code that is organized to make best use of multiple\nprocessors and the multiple levels of cache memory within a computer.\nThe code transformations to accomplish this are well known: loop\nfusion, array contraction, and data parallel loops.  However, the the\ntechniques are not beneficial in every situation, so the challenge is\nfinding the the best combination of transformations for a given input\nprogram and target computer architecture. Thus, the essense of the\nproblem is mathematical optimization and search. We evaluated a wide\nvariety of search techniques, including genetic algorithms and\nhill-climbing, and we developed a new heuristic/greedy search\nalgorithm.  We found that the best approach was a hybrid that started\nwith our greedy search and then finished with a genetic search.  With\nthis approach we were able to generate code for a wide range of\nreal-world matrix computations that was just as efficient as code\nproduced by a human expert and that out-performed the best\ngeneral-purpose loop-optimizing compilers.\n\n\t\t\t\t\tLast Modified: 11/17/2016\n\n\t\t\t\t\tSubmitted by: Jeremy G Siek"
 }
}