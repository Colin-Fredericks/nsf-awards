{
 "awd_id": "1319914",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: A Generic Mid-Level Representation as Object Part Hypotheses for Scalable Object Category Recognition",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 474000.0,
 "awd_min_amd_letter_date": "2013-09-11",
 "awd_max_amd_letter_date": "2016-05-04",
 "awd_abstract_narration": "This project develops a fragment-based intermediate-level representation for images based on shape and appearance, with shape playing the primary role. The representation can be populated in a bottom-up, category-independent fashion, which at the same time can be efficiently accessible by top-level, category dependent processes. The inherent ambiguity in generating object part hypotheses is resolved by combinatorially forming alternative image fragments by standard as well as novel perceptual operations, taking into account both shape and appearance, and both region-based and boundary-based cues. The exponential growth of the number of fragments is managed under a best-first graph representation that avoids duplication, leading to a sufficient number of diagnostic recognizable object parts among a vast pool of fragments. The project also explores an embedding of these fragments in a metric similarity space via proximity graphs and a geometric index structures for efficient nearest neighbor search. The final outcome is a representation space and an index for scalable, logarithmic object category recognition. A key aspect of this work is that categories themselves are also represented in a hierarchical similarity space, and this computationally implements ideas akin to Rosch?s basic level categorization. \r\n\r\nThe broader impacts of this activity spans a vast number of applications: any application which benefits from scalable object recognition such as indexing into databases, e.g., searching in a database of trademarks, engineering drawings and computer generated graphics, content-based web search, aerial tracking and recognition of vehicles, automated animal behavior analysis, and many others.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Benjamin",
   "pi_last_name": "Kimia",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Benjamin B Kimia",
   "pi_email_addr": "Benjamin_Kimia@Brown.Edu",
   "nsf_id": "000110484",
   "pi_start_date": "2013-09-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "Office of Sponsored Projects",
  "perf_city_name": "Providence",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029129093",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 450000.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Understanding image content is useful for recognition, 3D reconstruction, and a host of visual tasks that have by now permeated much of our daily life from surveillance to face recognition and others. The processing of this information needs to proceed in stages of organization following the principle of stable subassemblies and since higher level processes make use of intermediate-level information differently. This grant has allowed us to develop such mid-level representations in several ways.</p>\n<p>First, we have developed the Topological Contour Graph (TCG) which is based on a multistage sequential decision making process to allow multiple local groupings to be retained until more context information is available. The result is a graph representing the topology of long meaningful contours that are stable under changes in view, illumination, etc.</p>\n<p>Second, we have used TCG contours to partition the image into Atomic Visual Fragments (AVF) based on their medial axis interaction, regions of the image that are more or less homogenous, a medial kind of superpixel. Using perceptual grouping operations formalized under this framework, alternative groupings are represented and retained using a containment graph. This results in Medial Visual Fragments (MVF) that are used as object part hypotheses, but in contrast to other object proposal schemes were not generated by variations in the segmentation parameters but by combinatorial grouping sequences. The process integrates contour and region attributes both in the representation and in the processing stages so that the final results are more semantically meaningful. While this process is intended as an intermediate stage of organization to the level of object parts, it can also compete with schemes that generate full object hypotheses.</p>\n<p>Third, we used a generative representative of shape in the process of tracking objects and used it for tracking animals for automated behavior analysis. Specifically, each object category, e.g., a mouse, is represented as a set of object parts much like the&nbsp;Flexible Mixture Of Parts (FMP) model but one where the shape is cohesively represented. This represents significant advantages in tracking animals in challenging situations involving self-occlusion and occlusion by other animals. Our software is already in use in an automated animal behavior analysis pipeline.</p>\n<p>Finally, image alignment and correspondence is important in a number of applications. Our contribution is to use shape content in the process of a typically appearance-based alignment so that the correspondence is more sensitive to the alignment of object outline and other curvilinear features. This results in a more semantic alignment of images for use either as interactive morphing of objects in one image to another, to automated processing like semantic image segmentation, scene parsing, video depth estimation, and image enhancement.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/13/2018<br>\n\t\t\t\t\tModified by: Benjamin&nbsp;B&nbsp;Kimia</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nUnderstanding image content is useful for recognition, 3D reconstruction, and a host of visual tasks that have by now permeated much of our daily life from surveillance to face recognition and others. The processing of this information needs to proceed in stages of organization following the principle of stable subassemblies and since higher level processes make use of intermediate-level information differently. This grant has allowed us to develop such mid-level representations in several ways.\n\nFirst, we have developed the Topological Contour Graph (TCG) which is based on a multistage sequential decision making process to allow multiple local groupings to be retained until more context information is available. The result is a graph representing the topology of long meaningful contours that are stable under changes in view, illumination, etc.\n\nSecond, we have used TCG contours to partition the image into Atomic Visual Fragments (AVF) based on their medial axis interaction, regions of the image that are more or less homogenous, a medial kind of superpixel. Using perceptual grouping operations formalized under this framework, alternative groupings are represented and retained using a containment graph. This results in Medial Visual Fragments (MVF) that are used as object part hypotheses, but in contrast to other object proposal schemes were not generated by variations in the segmentation parameters but by combinatorial grouping sequences. The process integrates contour and region attributes both in the representation and in the processing stages so that the final results are more semantically meaningful. While this process is intended as an intermediate stage of organization to the level of object parts, it can also compete with schemes that generate full object hypotheses.\n\nThird, we used a generative representative of shape in the process of tracking objects and used it for tracking animals for automated behavior analysis. Specifically, each object category, e.g., a mouse, is represented as a set of object parts much like the Flexible Mixture Of Parts (FMP) model but one where the shape is cohesively represented. This represents significant advantages in tracking animals in challenging situations involving self-occlusion and occlusion by other animals. Our software is already in use in an automated animal behavior analysis pipeline.\n\nFinally, image alignment and correspondence is important in a number of applications. Our contribution is to use shape content in the process of a typically appearance-based alignment so that the correspondence is more sensitive to the alignment of object outline and other curvilinear features. This results in a more semantic alignment of images for use either as interactive morphing of objects in one image to another, to automated processing like semantic image segmentation, scene parsing, video depth estimation, and image enhancement.\n\n \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 11/13/2018\n\n\t\t\t\t\tSubmitted by: Benjamin B Kimia"
 }
}