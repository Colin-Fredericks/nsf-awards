{
 "awd_id": "1248638",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  A Cloud-Based Service for Audio Access to News and Blogs",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Glenn H. Larsen",
 "awd_eff_date": "2013-01-01",
 "awd_exp_date": "2013-06-30",
 "tot_intn_awd_amt": 149999.0,
 "awd_amount": 149999.0,
 "awd_min_amd_letter_date": "2012-12-11",
 "awd_max_amd_letter_date": "2012-12-11",
 "awd_abstract_narration": "The innovation improves access and discovery of online written content when content is automatically converted to an audio format such as mp3. In general, synthesized audio from random written text often delivers a poor listening experience. The technical effort is motivated by the absence of applications that provide a user preferred news articles and blogs with high quality synthesized audio that is phonetically correct for the visually impaired person or the multitasking visually busy person such as a car driver. This work uses techniques such as textual processing motivated by text understanding and content analysis by domain knowledge and machine learning.  Machine learning techniques are used to improve speech synthesis and to incorporate auto-discovery of user preferences into listenable news. Since content scanning by listening is a slower process than visually scanning for relevant responses, this technical work will improve this auditory search process by combining user input with information retrieval for a smoother user experience. The resulting technology infrastructure is expected to provide an array of compelling commercial products with far-reaching implications.\r\n\r\nThe broader/commercial impact of this technical work comes from the cloud-based infrastructure that can process online written text into high-quality audio.  This cloud software has advantages of unlimited storage and computing capacity, and uses this to support content retrieval, machine learning, text preprocessing, content discovery, natural language processing, and interaction with commercial Text-to-Speech servers. The first version of this technology will focus on news and blogs, a sufficiently large corpus of information that provides a challenge while also providing considerable commercial interest.  The cloud infrastructure can support a range of client-side applications that work on smart-phones, tablets, and desktops. These applications will have access to high quality synthesized audio useable in an \"eyes-busy\" situation including the low-vision community.  The apps will provide customizable access to user-preferred content via intelligent information retrieval. While there is commercial potential in such client applications, the greater value is from licensing the server technology.  The societal impact of such a product is tremendous since neither the blind community nor the general public have such easy listening access to the large corpus of online content that is curated with user preferences and with an application control mechanism that is entirely via voice and finger gestures.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Radhika",
   "pi_last_name": "Thekkath",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Radhika Thekkath",
   "pi_email_addr": "rthekkath@agivox.com",
   "nsf_id": "000622064",
   "pi_start_date": "2012-12-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "AgiVox, Inc.",
  "inst_street_address": "440 N. Wolfe Road",
  "inst_street_address_2": "",
  "inst_city_name": "Sunnyvale",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6509960224",
  "inst_zip_code": "940853869",
  "inst_country_name": "United States",
  "cong_dist_code": "17",
  "st_cong_dist_code": "CA17",
  "org_lgl_bus_name": null,
  "org_prnt_uei_num": null,
  "org_uei_num": null
 },
 "perf_inst": {
  "perf_inst_name": "AgiVox, Inc.",
  "perf_str_addr": "830 Stewart Dr, Suite 272",
  "perf_city_name": "Sunnyvale",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "940854513",
  "perf_ctry_code": "US",
  "perf_cong_dist": "17",
  "perf_st_cong_dist": "CA17",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5371",
   "pgm_ref_txt": "SMALL BUSINESS PHASE I"
  },
  {
   "pgm_ref_code": "8032",
   "pgm_ref_txt": "Software Services and Applications"
  },
  {
   "pgm_ref_code": "8039",
   "pgm_ref_txt": "Information, Communication & Computing"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 149999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The two main goals of the research were: (1) improve synthesized speech quality of free-flow text, and (2) incorporate auto-discovery of user preferences into listenable news. This research has made significant progress with both goals. The research has uncovered a major issue in synthesis and found a solution that can be applied to improve synthesized speech. The work done in document text analysis has led to automatic discovery of the topic of a corpus of content. The great results obtained from this machine learning work enables the implementation of a user search and user preference system into the client application.</p>\n<p>Based on a user study, it was discovered that a significant issue in synthesized speech was mispronunciations. Even more than a lack of emotion in typical synthesized speech, mispronunciations would completely throw off the user&rsquo;s understanding of the sentence, thus requiring more concentration, repeat listening, or looking at the screen to read the actual text of the article. And reading was only possible for non-blind users assuming they were in a situation where this was possible without causing an endangerment. For mispronunciations not caused by heteronyms, a pronunciation dictionary of plain text and phoneme substitutions worked very well. For heteronyms, mispronunciations could be corrected using a mixed technique that used the semantic context as well as the positional context of the word within a sentence.</p>\n<p>For the corpus of data in our system that comprised of RSS feeds, it was required to build a classification system and topic hierarchy for the heteronym disambiguation work. It was also required that to categorize the content sources for the purposes of user search and browsing and determining user preferences.&nbsp; It was a requirement that the research work utilize an automatic algorithm for statistical modeling of document collections. This led to the Latent Dirichlet Allocation (LDA) simplistic topic model. The idea behind this algorithm is that documents exhibit multiple topics and these topics exist in the form of word co-occurrence in documents, where ultimately a topic is determined to be a set of words that exist within a document with a certain proportion. Using LDA on a large corpus of RSS feeds the experimental research has shown that automatic discovery of topic content can be obtained and used for user preference and content discovery.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/11/2013<br>\n\t\t\t\t\tModified by: Radhika&nbsp;Thekkath</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe two main goals of the research were: (1) improve synthesized speech quality of free-flow text, and (2) incorporate auto-discovery of user preferences into listenable news. This research has made significant progress with both goals. The research has uncovered a major issue in synthesis and found a solution that can be applied to improve synthesized speech. The work done in document text analysis has led to automatic discovery of the topic of a corpus of content. The great results obtained from this machine learning work enables the implementation of a user search and user preference system into the client application.\n\nBased on a user study, it was discovered that a significant issue in synthesized speech was mispronunciations. Even more than a lack of emotion in typical synthesized speech, mispronunciations would completely throw off the user\u00c6s understanding of the sentence, thus requiring more concentration, repeat listening, or looking at the screen to read the actual text of the article. And reading was only possible for non-blind users assuming they were in a situation where this was possible without causing an endangerment. For mispronunciations not caused by heteronyms, a pronunciation dictionary of plain text and phoneme substitutions worked very well. For heteronyms, mispronunciations could be corrected using a mixed technique that used the semantic context as well as the positional context of the word within a sentence.\n\nFor the corpus of data in our system that comprised of RSS feeds, it was required to build a classification system and topic hierarchy for the heteronym disambiguation work. It was also required that to categorize the content sources for the purposes of user search and browsing and determining user preferences.  It was a requirement that the research work utilize an automatic algorithm for statistical modeling of document collections. This led to the Latent Dirichlet Allocation (LDA) simplistic topic model. The idea behind this algorithm is that documents exhibit multiple topics and these topics exist in the form of word co-occurrence in documents, where ultimately a topic is determined to be a set of words that exist within a document with a certain proportion. Using LDA on a large corpus of RSS feeds the experimental research has shown that automatic discovery of topic content can be obtained and used for user preference and content discovery.\n\n \n\n\t\t\t\t\tLast Modified: 07/11/2013\n\n\t\t\t\t\tSubmitted by: Radhika Thekkath"
 }
}