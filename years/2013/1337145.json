{
 "awd_id": "1337145",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS: CLCCA (XPS: DSD) Future Extreme Scale Frameworks using DSL and ERTS",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 700000.0,
 "awd_amount": 700000.0,
 "awd_min_amd_letter_date": "2013-09-11",
 "awd_max_amd_letter_date": "2013-09-11",
 "awd_abstract_narration": "This project will lay the foundations for solving large multi-scale multi-physics engineering problems using new computational frameworks on the next decade's exascale computers. These frameworks will anticipate trends in proposed future computer hardware by being adaptive, asynchronous, fault-tolerant, and energy-aware and will address the possible billion-way parallelism of exascale systems by both generating efficient specific code through a domain specific language (DSL) and by efficiently scheduling that code through an Exascale Run Time System, ERTS.\r\n\r\nThe project's prototype computational framework will use Directed Acyclic Graphs (DAGs) to generate code in the DSL that is specialized for multicore nodes and/or accelerators and it will also use DAGS at the runtime system level in the ERTS. At a nodal multicore or accelerator level the DSL will be a declarative, high-level, type-safe domain-specific language for multi-scale, multi-physics simulations that will improve productivity by automating the writing of optimized code that is executed by the ERTS. In order to ensure that these activities produce relevant solutions for important engineering applications with high impact such as, for example, the design of new batteries and fuel cells or clean coal boilers, the project will employ a multi-disciplinary approach that couples computer science advances to the solution of such meaningful engineering problems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Martin",
   "pi_last_name": "Berzins",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Martin Berzins",
   "pi_email_addr": "mb@cs.utah.edu",
   "nsf_id": "000175130",
   "pi_start_date": "2013-09-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Might",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew Might",
   "pi_email_addr": "might@cs.utah.edu",
   "nsf_id": "000068857",
   "pi_start_date": "2013-09-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Sutherland",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "James C Sutherland",
   "pi_email_addr": "james.sutherland@utah.edu",
   "nsf_id": "000425319",
   "pi_start_date": "2013-09-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841129023",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 700000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><!-- p { margin-bottom: 0.1in; direction: ltr; color: rgb(0, 0, 10); line-height: 120%; text-align: left; }p.western { font-family: \"Liberation Serif\",serif; font-size: 12pt; }p.cjk { font-family: \"Tahoma\"; font-size: 12pt; }p.ctl { font-family: \"Lohit Devanagari\"; font-size: 12pt; }a:link { color: rgb(5, 99, 193); } -->\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">This research has addressed three aspects of the challenges that arise from the need to solve complex science and engineering problems on parallel computer architectures. These aspects reflect the expertise of the three investigators concerning the use of&nbsp; software that makes it possible for scientists to solve problems at a much higher and more abstract level on larger and more complex parallel computers.</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">The high-level specification of such applications  is done through the use of domain specific languages (DSLs) that allow problem  specification in a way that is close to the applications area, both being areas of expertise of Dr. James Sutherland. The design of DSL&rsquo;s  raises fundamental computer language questions  which were addressed by Dr. Matt Might. Once a problem has been specified through a DSL it is necessary to execute the DSL tasks in an efficient and fail-safe manner using a runtime system on  parallel computers. The design of these runtime systems is the research area of Dr. Martin Berzins.</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">Dr. Might&rsquo;s group used template meta-programming which allows the C++ language to generate code at compile time. They looked at the theoretical and practical limits of template meta-meta-programming for C++ and found that C++ template meta-programming resembles a first-class term-rewriting system and that means that these programs can be much more better expressed in terms of higher-order term-rewriting systems and  this makes it easier to encode the core logic necessary to do template-meta-programming and DSL design and implementation.</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">This research used Honeycomb, which extends lexical scoping and nesting in C++ template meta-programming for Nebo/Fulmar which is the main  C++ template meta-programming DSL&nbsp; of the project. The research&nbsp; showed that Honeycomb could generate stencil physics code and also undertook fundamental research on the complexity of parsing techniques used for DSLs. This research also provided a much better and stronger idea of how to construct good domain specific languages for stencil operations using C++ template meta-programming.</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">These results in turn influenced  the development of PoKiTT: a library for Portable Kinetics, Thermodynamics and Transport calculations. PoKiTT replaces much of the functionality provided by Cantera (a library at MIT) but with kernels that provide better performance in serial and add multicore and GPU kernels for reacting flow calculations. Speedups on 16 cores were approximately 10x and 40x for GPU over single core The dense linear algebra kernels provide speedups on a K20 GPU of 8-15x for linear solves and 15-30x for eigenvalue decomposition relative to single core performance execution for reacting flow calculations.</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">In the area of runtime systems the decomposition of software into a programming model that generates a task-graph for execution by a runtime system makes portability and performance possible, but is challenging in key areas such as support for data structures, tasks on heterogeneous architectures, performance portability, power management and designing for resilience. In heterogeneous machines, accelerator tasks pose significant challenges over their CPU task counterparts particularly when tasks need communicated values and compute within a few milliseconds.  Current and emerging heterogeneous architectures necessitate addressing these challenges within Uintah. The principal result was to identify and address inefficiencies that arise when mapping tasks onto the GPU, to implement new schemes to reduce   runtime system overhead, to introduce new features that allow for more tasks to leverage on-node accelerators, and to show nodal performance results from these improvements.</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">&nbsp;</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">Finally in the area of making such task-based calculations more resilient the research used coarse replication of fine-mesh patches on a different compute node. This adds only about 12.5% overhead for three dimensional mesh blocks.  However, in order&nbsp; to avoid introducing an unacceptable degree of error it is necessary for the interpolation process to recreate the fine mesh to preserve physical solution properties such as positivity of chemical concentrations. Such interpolants were not available and so had to be discovered and implemented together with the use of existing fault tolerant tools for message passing. As a result ithere is now&nbsp; a prototype approach for dealing with resilience issues at exascale. Finally the project&nbsp; successfully demonstrated these approaches on two very recent and very different computers, the new NSF Stampede 2 computer at TACC in Austin and the current fastest machine in the world the Sunway Tiahulight at Wuxi China.</p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\"><a name=\"_GoBack\"></a></p>\n<p class=\"western\" style=\"margin-bottom: 0in; line-height: 100%;\">Of equal importance to these technical results is the training and development outcome of this project wiith regard to those who worked on it. The research that undergraduate and graduate students have undertaken has helped prepare them for&nbsp; their future careers. In particular 4 MS students undertook research before graduating to go and work for industry and 7 students undertook research that was part of their Ph.D.s or led to them doing a Ph.D. As a result of this activity one undergraduate thesis resulted  and seven journal or conference papers were published with two more submitted or to be submitted.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/03/2017<br>\n\t\t\t\t\tModified by: Martin&nbsp;Berzins</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis research has addressed three aspects of the challenges that arise from the need to solve complex science and engineering problems on parallel computer architectures. These aspects reflect the expertise of the three investigators concerning the use of  software that makes it possible for scientists to solve problems at a much higher and more abstract level on larger and more complex parallel computers.\n \nThe high-level specification of such applications  is done through the use of domain specific languages (DSLs) that allow problem  specification in a way that is close to the applications area, both being areas of expertise of Dr. James Sutherland. The design of DSL?s  raises fundamental computer language questions  which were addressed by Dr. Matt Might. Once a problem has been specified through a DSL it is necessary to execute the DSL tasks in an efficient and fail-safe manner using a runtime system on  parallel computers. The design of these runtime systems is the research area of Dr. Martin Berzins.\n \nDr. Might?s group used template meta-programming which allows the C++ language to generate code at compile time. They looked at the theoretical and practical limits of template meta-meta-programming for C++ and found that C++ template meta-programming resembles a first-class term-rewriting system and that means that these programs can be much more better expressed in terms of higher-order term-rewriting systems and  this makes it easier to encode the core logic necessary to do template-meta-programming and DSL design and implementation.\nThis research used Honeycomb, which extends lexical scoping and nesting in C++ template meta-programming for Nebo/Fulmar which is the main  C++ template meta-programming DSL  of the project. The research  showed that Honeycomb could generate stencil physics code and also undertook fundamental research on the complexity of parsing techniques used for DSLs. This research also provided a much better and stronger idea of how to construct good domain specific languages for stencil operations using C++ template meta-programming.\n \nThese results in turn influenced  the development of PoKiTT: a library for Portable Kinetics, Thermodynamics and Transport calculations. PoKiTT replaces much of the functionality provided by Cantera (a library at MIT) but with kernels that provide better performance in serial and add multicore and GPU kernels for reacting flow calculations. Speedups on 16 cores were approximately 10x and 40x for GPU over single core The dense linear algebra kernels provide speedups on a K20 GPU of 8-15x for linear solves and 15-30x for eigenvalue decomposition relative to single core performance execution for reacting flow calculations.\n \nIn the area of runtime systems the decomposition of software into a programming model that generates a task-graph for execution by a runtime system makes portability and performance possible, but is challenging in key areas such as support for data structures, tasks on heterogeneous architectures, performance portability, power management and designing for resilience. In heterogeneous machines, accelerator tasks pose significant challenges over their CPU task counterparts particularly when tasks need communicated values and compute within a few milliseconds.  Current and emerging heterogeneous architectures necessitate addressing these challenges within Uintah. The principal result was to identify and address inefficiencies that arise when mapping tasks onto the GPU, to implement new schemes to reduce   runtime system overhead, to introduce new features that allow for more tasks to leverage on-node accelerators, and to show nodal performance results from these improvements.\n \nFinally in the area of making such task-based calculations more resilient the research used coarse replication of fine-mesh patches on a different compute node. This adds only about 12.5% overhead for three dimensional mesh blocks.  However, in order  to avoid introducing an unacceptable degree of error it is necessary for the interpolation process to recreate the fine mesh to preserve physical solution properties such as positivity of chemical concentrations. Such interpolants were not available and so had to be discovered and implemented together with the use of existing fault tolerant tools for message passing. As a result ithere is now  a prototype approach for dealing with resilience issues at exascale. Finally the project  successfully demonstrated these approaches on two very recent and very different computers, the new NSF Stampede 2 computer at TACC in Austin and the current fastest machine in the world the Sunway Tiahulight at Wuxi China.\n\nOf equal importance to these technical results is the training and development outcome of this project wiith regard to those who worked on it. The research that undergraduate and graduate students have undertaken has helped prepare them for  their future careers. In particular 4 MS students undertook research before graduating to go and work for industry and 7 students undertook research that was part of their Ph.D.s or led to them doing a Ph.D. As a result of this activity one undergraduate thesis resulted  and seven journal or conference papers were published with two more submitted or to be submitted.\n\n\t\t\t\t\tLast Modified: 11/03/2017\n\n\t\t\t\t\tSubmitted by: Martin Berzins"
 }
}