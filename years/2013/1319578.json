{
 "awd_id": "1319578",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Small: Integrated Digital Event Archiving and Library (IDEAL)",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2013-08-14",
 "awd_max_amd_letter_date": "2016-05-26",
 "awd_abstract_narration": "The Integrated Digital Event Archive and Library (IDEAL) system addresses the need for combining the best of digital library and archive technologies in support of stakeholders who are remembering and/or studying important events. It extends the work at Virginia Tech on the Crisis, Tragedy, and Recovery network (see http://www.ctrnet.net) to handle government and community events, in addition to a range of significant natural or manmade disasters. It addresses needs of those interested in emergency preparedness/response, digital government, and the social sciences. It proves the effectiveness of the 5S (Societies, Scenarios, Spaces, Structures, Streams) approach to intelligent information systems by crawling and archiving events of broad interest. It leverages and extends the capabilities of the Internet Archive to develop spontaneous event collections that can be permanently archived as well as searched and accessed, and of the LucidWorks Big Data software that supports scalable indexing, analyzing, and accessing of very large collections. Through a new model-based approach to intelligent focused crawling, it improves the quality (e.g., accuracy, coverage, and elimination of noise) of collections of webpages so as to ensure comprehensiveness, balance, and low bias, as is needed for scholarly study of historically important events by social scientists. It incorporates a range of visualization capabilities in support of key stakeholder communities, including archivists, librarians, researchers, scholars, and the general public. IDEAL connects the processing of tweets and webpages, combining informal and formal media, to automatically detect important events, as well as to support building collections on chosen general or specific topics. It supports integration of multiple types and at multiple levels, including key models about the event it is crawling (event models), the sources of information about the event (source models), the mechanisms used for disseminating information about the event (publishing venue models), and the entities related to the event (society /organization models). Integrated services include topic identification, categorization (building upon special ontologies being devised), sentiment analysis, and visualization of data, information, and context.\r\n\r\nThe IDEAL website (http://www.eventsarchive.org) supports searching, browsing, analyzing, and visualizing of event collections (of both tweets and webpages), as well as access to project software, methods, findings, publications, and other results. Usage is encouraged of the integrated system along with a growing number of collections, as well as of particular tools such as for focused crawling, which should aid curators to avoid non-relevant content while including a broader range of sources, improving significantly upon current crawling and archiving methods. Important data and information on events of interest are saved rather than lost, helping preserve our history and culture, in support of public interest, education, policy making, historical analyses, and comparative studies. Students studying sociology, human-computer interaction, digital libraries, information retrieval, computational linguistics, multimedia, and hypertext are gaining experience and contributing in scholarly studies, algorithms, software, interfaces, and big data handling.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Edward",
   "pi_last_name": "Fox",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Edward A Fox",
   "pi_email_addr": "fox@vt.edu",
   "nsf_id": "000151687",
   "pi_start_date": "2013-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Donald",
   "pi_last_name": "Shoemaker",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Donald J Shoemaker",
   "pi_email_addr": "shoemake@vt.edu",
   "nsf_id": "000354531",
   "pi_start_date": "2013-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andrea",
   "pi_last_name": "Kavanaugh",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Andrea L Kavanaugh",
   "pi_email_addr": "kavan@vt.edu",
   "nsf_id": "000211795",
   "pi_start_date": "2013-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Steven",
   "pi_last_name": "Sheetz",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Steven D Sheetz",
   "pi_email_addr": "sheetz@vt.edu",
   "nsf_id": "000215791",
   "pi_start_date": "2013-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Kristine",
   "pi_last_name": "Hanna",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kristine Hanna",
   "pi_email_addr": "kristine@archive.org",
   "nsf_id": "000611634",
   "pi_start_date": "2013-08-14",
   "pi_end_date": "2016-05-26"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jefferson",
   "pi_last_name": "Bailey",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Jefferson J Bailey",
   "pi_email_addr": "jefferson@archive.org",
   "nsf_id": "000705884",
   "pi_start_date": "2016-05-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Polytechnic Institute and State University",
  "inst_street_address": "300 TURNER ST NW",
  "inst_street_address_2": "STE 4200",
  "inst_city_name": "BLACKSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "5402315281",
  "inst_zip_code": "240603359",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "VA09",
  "org_lgl_bus_name": "VIRGINIA POLYTECHNIC INSTITUTE & STATE UNIVERSITY",
  "org_prnt_uei_num": "X6KEFGLHSJX7",
  "org_uei_num": "QDE5UHE5XD16"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Polytechnic Institute and State University",
  "perf_str_addr": "",
  "perf_city_name": "Blacksburg",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "240603580",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "VA09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 334622.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 165378.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Integrated Digital Event Archiving and Library (IDEAL) project, with more than 27 collaborators and 7 collaborating institutions, developed tweet and webpage collections, datasets, services, software, systems, and methods. In addition to many publications (e.g., 2 books, 4 dissertations - leading to faculty positions at Louisiana State University and Radford University as well as universities in Egypt and Jordan, 3 theses, and 31 other works), there were 49 student reports across 12 offerings in 5 different courses. Advances have been made in big data handling, computational linguistics, digital libraries, information retrieval, information visualization, machine learning, and Web archiving. More than 22 computers are connected, mostly in a Hadoop cluster. This network was constructed to support collection, processing, and access to almost 2 billion tweets across over 1300 collections, along with millions of webpages, covering hundreds of important events. The Internet Archive has expanded its collections and technology support, as well as outreach activities. It hosts, preserves, and provides public access with attribution to web collections created by the project team through its public Wayback Machine interface and Archive-It service. The latter may be browsed by descriptive metadata and searched through Archive-It&rsquo;s newly deployed full-text Elasticsearch engine. New or updated Internet Archive and Archive-It API documentation and workshops provide project stakeholders with several means to query the data from and about these collections, and to derive datasets for further textual and visual analyses. Three workshops on Web Archiving and Digital Libraries were coordinated, further disseminating project results. Collaborations and/or presentations have involved multiple countries including Canada, Egypt, Jordan, Mexico, Philippines, Qatar, Saudi Arabia, and Tunisia.<br /><br />Collection building and analysis (of both tweets and webpages) has improved through advances in classification, big data workflows, focused crawling (to identify webpages focused on an event of interest), inferring the location of tweets from their text when GPS data is unavailable, topic analysis, and natural language processing (including Arabic).<br /><br />Insights gained have been shared regarding juvenile delinquency, school shootings, and the use of information during conflicts, crises, elections, and uprisings. Collections are available to support other research and exploration regarding important events since 2007 such as the above, as well as attacks, bombings, celebrations, climate change, collapses, community activities, crashes, disease outbreaks, earthquakes, eclipses, environmental disruptions, erosion, explosions, fires, floods, hurricanes, innovations, judicial decisions, pollution, power outages, protests, revolutions, shootings, sports, storms, summits, tornadoes, transportation failures, tsunamis, typhoons, and veteran activities.<br /><br />In addition to the insights and collections associated with the library and archive, the IDEAL project has developed novel methodology and workflows, tailored to addressing the challenging problem of working with events, as is highlighted in the six images provided. The TweetURLsWorkflow image (primary, image number 1) shows the broad flow of data: collecting tweets, using the URLs present therein as seeds to our event focused crawler, and leading in part to our Web collection. The EventFocusedCrawler image (number 4) illustrates part of that flow, i.e., how seeds lead to an event model that guides the selection and focused crawling for webpages. The remaining four images describe some of the methods developed to analyze and accordingly add value (and metadata) to the collected content. The Xpantrac Components image (number 6) explains our new approach to find topics in webpages; it generalizes beyond the webpage content through searching, combining and analyzing results, and summarizing/extracting topics. Regarding our processing of tweets, the FlowTweetFramework image (number 3) describes software built to streamline a variety of tweet analysis and transformation workflows. The LearningOptimizer image (number 2) illustrates how iterative processing with minimal human effort can yield high quality classification of tweets into collections for particular real world events. The LIW Prediction image (number 5) explains the methodology for associating locations with tweets based on location indicative words; this is essential since few tweets have a specific location stored with their metadata. All of these images come from IDEAL project dissertations and theses, supported in part by this grant from NSF.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/14/2017<br>\n\t\t\t\t\tModified by: Edward&nbsp;A&nbsp;Fox</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509411258644_TweetURLsWorkflow--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509411258644_TweetURLsWorkflow--rgov-800width.jpg\" title=\"TweetURLsWorkflow\"><img src=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509411258644_TweetURLsWorkflow--rgov-66x44.jpg\" alt=\"TweetURLsWorkflow\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Workflow for extracting, expanding, and selecting URLs from tweets. Fig. 28 from doctoral dissertation: Intelligent Event Focused Crawling (supported by this grant)</div>\n<div class=\"imageCredit\">Mohamed Magdy Gharib Farag</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Edward&nbsp;A&nbsp;Fox</div>\n<div class=\"imageTitle\">TweetURLsWorkflow</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509409167622_LearningOptimizerMethodology--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509409167622_LearningOptimizerMethodology--rgov-800width.jpg\" title=\"Learning Optimizer\"><img src=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509409167622_LearningOptimizerMethodology--rgov-66x44.jpg\" alt=\"Learning Optimizer\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Sequence diagram for the Learning Optimizer methodology. Figure 13 of Saurabh Chakravarty's MS thesis: A Large Collection Learning Optimizer Framework (supported in part by this grant)</div>\n<div class=\"imageCredit\">Saurabh Chakravarty</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Edward&nbsp;A&nbsp;Fox</div>\n<div class=\"imageTitle\">Learning Optimizer</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509410341742_DataFlowTweetFramework--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509410341742_DataFlowTweetFramework--rgov-800width.jpg\" title=\"FlowTweetFramework\"><img src=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509410341742_DataFlowTweetFramework--rgov-66x44.jpg\" alt=\"FlowTweetFramework\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The flow of data through the framework, from raw data on disk to pre-processed data to results of analytics tools. Fig. 3.1 of MS thesis: A Framework for Hadoop Based Digital Libraries of Tweets (supported in part by this grant)</div>\n<div class=\"imageCredit\">Matthew Bock</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Edward&nbsp;A&nbsp;Fox</div>\n<div class=\"imageTitle\">FlowTweetFramework</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509411809861_EFCflow--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509411809861_EFCflow--rgov-800width.jpg\" title=\"EventFocusedCrawler\"><img src=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509411809861_EFCflow--rgov-66x44.jpg\" alt=\"EventFocusedCrawler\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Event Focused Crawler. Slide 32 from final defense of doctoral dissertation: Intelligent Event Focused Crawling (supported by this grant)</div>\n<div class=\"imageCredit\">Mohamed Magdy Gharib Farag</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Edward&nbsp;A&nbsp;Fox</div>\n<div class=\"imageTitle\">EventFocusedCrawler</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509412441192_LIWprediction--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509412441192_LIWprediction--rgov-800width.jpg\" title=\"LIW Prediction\"><img src=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509412441192_LIWprediction--rgov-66x44.jpg\" alt=\"LIW Prediction\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An overview data flow diagram. Fig. 4 from doctoral dissertation: Geo-Locating Tweets with Latent Location Information (supported by this grant)</div>\n<div class=\"imageCredit\">Sunshin Lee</div>\n<div class=\"imageSubmitted\">Edward&nbsp;A&nbsp;Fox</div>\n<div class=\"imageTitle\">LIW Prediction</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509408392215_Xpantrac_components_no_caption--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509408392215_Xpantrac_components_no_caption--rgov-800width.jpg\" title=\"Xpantrac Components\"><img src=\"/por/images/Reports/POR/2017/1319578/1319578_10267300_1509408392215_Xpantrac_components_no_caption--rgov-66x44.jpg\" alt=\"Xpantrac Components\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Components of Xpantrac grouped into two parts: Expansion and Extraction. Figure 5 in Seungwon Yang's doctoral dissertation: Automatic Identification of Topic Tags from Texts Based on Expansion-Extraction Approach (supported by this grant)</div>\n<div class=\"imageCredit\">Seungwon Yang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Edward&nbsp;A&nbsp;Fox</div>\n<div class=\"imageTitle\">Xpantrac Components</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe Integrated Digital Event Archiving and Library (IDEAL) project, with more than 27 collaborators and 7 collaborating institutions, developed tweet and webpage collections, datasets, services, software, systems, and methods. In addition to many publications (e.g., 2 books, 4 dissertations - leading to faculty positions at Louisiana State University and Radford University as well as universities in Egypt and Jordan, 3 theses, and 31 other works), there were 49 student reports across 12 offerings in 5 different courses. Advances have been made in big data handling, computational linguistics, digital libraries, information retrieval, information visualization, machine learning, and Web archiving. More than 22 computers are connected, mostly in a Hadoop cluster. This network was constructed to support collection, processing, and access to almost 2 billion tweets across over 1300 collections, along with millions of webpages, covering hundreds of important events. The Internet Archive has expanded its collections and technology support, as well as outreach activities. It hosts, preserves, and provides public access with attribution to web collections created by the project team through its public Wayback Machine interface and Archive-It service. The latter may be browsed by descriptive metadata and searched through Archive-It?s newly deployed full-text Elasticsearch engine. New or updated Internet Archive and Archive-It API documentation and workshops provide project stakeholders with several means to query the data from and about these collections, and to derive datasets for further textual and visual analyses. Three workshops on Web Archiving and Digital Libraries were coordinated, further disseminating project results. Collaborations and/or presentations have involved multiple countries including Canada, Egypt, Jordan, Mexico, Philippines, Qatar, Saudi Arabia, and Tunisia.\n\nCollection building and analysis (of both tweets and webpages) has improved through advances in classification, big data workflows, focused crawling (to identify webpages focused on an event of interest), inferring the location of tweets from their text when GPS data is unavailable, topic analysis, and natural language processing (including Arabic).\n\nInsights gained have been shared regarding juvenile delinquency, school shootings, and the use of information during conflicts, crises, elections, and uprisings. Collections are available to support other research and exploration regarding important events since 2007 such as the above, as well as attacks, bombings, celebrations, climate change, collapses, community activities, crashes, disease outbreaks, earthquakes, eclipses, environmental disruptions, erosion, explosions, fires, floods, hurricanes, innovations, judicial decisions, pollution, power outages, protests, revolutions, shootings, sports, storms, summits, tornadoes, transportation failures, tsunamis, typhoons, and veteran activities.\n\nIn addition to the insights and collections associated with the library and archive, the IDEAL project has developed novel methodology and workflows, tailored to addressing the challenging problem of working with events, as is highlighted in the six images provided. The TweetURLsWorkflow image (primary, image number 1) shows the broad flow of data: collecting tweets, using the URLs present therein as seeds to our event focused crawler, and leading in part to our Web collection. The EventFocusedCrawler image (number 4) illustrates part of that flow, i.e., how seeds lead to an event model that guides the selection and focused crawling for webpages. The remaining four images describe some of the methods developed to analyze and accordingly add value (and metadata) to the collected content. The Xpantrac Components image (number 6) explains our new approach to find topics in webpages; it generalizes beyond the webpage content through searching, combining and analyzing results, and summarizing/extracting topics. Regarding our processing of tweets, the FlowTweetFramework image (number 3) describes software built to streamline a variety of tweet analysis and transformation workflows. The LearningOptimizer image (number 2) illustrates how iterative processing with minimal human effort can yield high quality classification of tweets into collections for particular real world events. The LIW Prediction image (number 5) explains the methodology for associating locations with tweets based on location indicative words; this is essential since few tweets have a specific location stored with their metadata. All of these images come from IDEAL project dissertations and theses, supported in part by this grant from NSF.\n\n\t\t\t\t\tLast Modified: 11/14/2017\n\n\t\t\t\t\tSubmitted by: Edward A Fox"
 }
}