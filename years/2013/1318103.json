{
 "awd_id": "1318103",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Memory Consistency -- Hardware, Compiler, and Programming Support",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 539999.0,
 "awd_min_amd_letter_date": "2013-08-26",
 "awd_max_amd_letter_date": "2015-07-23",
 "awd_abstract_narration": "The advent of multicore machines has enabled delivery of high performance via parallelism for a wide range of applications. While such machines have become ubiquitous, they pose significant challenges for software developers. One challenge is dealing with the relaxed memory consistency models supported by commercial multicore machines. Simultaneously delivering high performance and ensuring program correctness requires careful introduction of fence instructions in the code. Excessive use of fence instructions leads to poor performance while their omission of can lead to incorrect program behavior.\r\n\r\nThis research will investigate means for constraining the scope of a fence instruction to minimize its impact on performance while preserving desired program behavior. In existing systems the hardware is unaware of the scope and hence fence implementations enforce a strict ordering of memory accesses across a fence that leads to unnecessary stalls. Alternative means for inferring the scope information will be developed for constraining the memory orderings enforced by the hardware. In particular, development of hardware, compiler, and programming support will be carried out. The software and hardware techniques developed in this research will be made available so other researchers are able to experiment with them. The subject of research is relevant to commercial processor manufacturers. The students involved in this research will receive valuable training in the design and programming of multicore systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rajiv",
   "pi_last_name": "Gupta",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rajiv Gupta",
   "pi_email_addr": "gupta@cs.ucr.edu",
   "nsf_id": "000077772",
   "pi_start_date": "2013-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Riverside",
  "inst_street_address": "200 UNIVERSTY OFC BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "RIVERSIDE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9518275535",
  "inst_zip_code": "925210001",
  "inst_country_name": "United States",
  "cong_dist_code": "39",
  "st_cong_dist_code": "CA39",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA AT RIVERSIDE",
  "org_prnt_uei_num": "",
  "org_uei_num": "MR5QC5FCAVH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Riverside",
  "perf_str_addr": "",
  "perf_city_name": "Riverside",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "925210001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "39",
  "perf_st_cong_dist": "CA39",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "794100",
   "pgm_ele_name": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ele_code": "794300",
   "pgm_ele_name": "PROGRAMMING LANGUAGES"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 450000.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 89999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Intellectual Merit:</strong></p>\n<p>The implementation of memory consistency models used by modern parallel systems (multicores, clusters, and GPGPUs) has an enormous impact on programmer productivity and application performance. The choice of model and its implementation have traditionally been viewed as a trade-off between productivity and performance. This project made several important contributions that simultaneously deliver both productivity and performance. The key outcomes of this project are as follows:<br /><br />1. <em>Efficiently supporting sequential and relaxed consistency on multicores</em>: In context of multicores we developed new hardware implementations of sequential consistency whose performance is close to that achieved by relaxed consistency models. We also developed new forms of fence semantics that can enable the ordering of memory operations to be relaxed without violating sequential consistency including address-aware fences and fence scoping.<br /><br />2. <em>Relaxed consistency based asynchronous algorithms on clusters</em>: In context of clusters we developed new asynchronous algorithms for graph analytics tasks that exploit semantics of computations to safely relax consistency. The benefits derived include achieving better tolerance to communication latency for performance (ASPIRE), rapid and low cost recovery to machine failures (CoRAL), and rapid computation updates in reponse to changes to the graph structure in context of streaming graphs (KickStarter).<br /><br />3. <em>Asynchronous algorithms for GPGPUs</em>: Finally this project also developed parallel asynchronous algorothms for graph analytics and key-value stores that are suitable for single and multiple GPGPU configurations (CuSha, Vertex Refinement). These algorithms not only improve the SIMD efficiency on a single GPGPU, they also highly balance load across multiple GPGPUs and optimize communication between multiple GPGPUs.</p>\n<p><strong>Broader Impacts:</strong></p>\n<p>The results of this research have been widely disseminated by publication in high quality venues including ASPLOS (3 papers), HPDC (3 papers), USENIX ATC, OOPSLA, ICS (2 papers), SC (2 papers), LCPC, IJPP, ACM TACO and others. A number of PhD students participated in this project and have successfully completed their dissertations and are employed in academia as well as industry. Keval Vora (Simon Fraser Univ.) and Sai Charan Koduru (Microsoft) performed work related to clusters, Farzad Khorasani's (Georgia Tech) research dealt with GPGPUs, and work related to multicores was performed by Changhui Lin (Samsung), Amlan Kusum (Oracle), and Vineet Singh (Intel).</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/02/2017<br>\n\t\t\t\t\tModified by: Rajiv&nbsp;Gupta</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIntellectual Merit:\n\nThe implementation of memory consistency models used by modern parallel systems (multicores, clusters, and GPGPUs) has an enormous impact on programmer productivity and application performance. The choice of model and its implementation have traditionally been viewed as a trade-off between productivity and performance. This project made several important contributions that simultaneously deliver both productivity and performance. The key outcomes of this project are as follows:\n\n1. Efficiently supporting sequential and relaxed consistency on multicores: In context of multicores we developed new hardware implementations of sequential consistency whose performance is close to that achieved by relaxed consistency models. We also developed new forms of fence semantics that can enable the ordering of memory operations to be relaxed without violating sequential consistency including address-aware fences and fence scoping.\n\n2. Relaxed consistency based asynchronous algorithms on clusters: In context of clusters we developed new asynchronous algorithms for graph analytics tasks that exploit semantics of computations to safely relax consistency. The benefits derived include achieving better tolerance to communication latency for performance (ASPIRE), rapid and low cost recovery to machine failures (CoRAL), and rapid computation updates in reponse to changes to the graph structure in context of streaming graphs (KickStarter).\n\n3. Asynchronous algorithms for GPGPUs: Finally this project also developed parallel asynchronous algorothms for graph analytics and key-value stores that are suitable for single and multiple GPGPU configurations (CuSha, Vertex Refinement). These algorithms not only improve the SIMD efficiency on a single GPGPU, they also highly balance load across multiple GPGPUs and optimize communication between multiple GPGPUs.\n\nBroader Impacts:\n\nThe results of this research have been widely disseminated by publication in high quality venues including ASPLOS (3 papers), HPDC (3 papers), USENIX ATC, OOPSLA, ICS (2 papers), SC (2 papers), LCPC, IJPP, ACM TACO and others. A number of PhD students participated in this project and have successfully completed their dissertations and are employed in academia as well as industry. Keval Vora (Simon Fraser Univ.) and Sai Charan Koduru (Microsoft) performed work related to clusters, Farzad Khorasani's (Georgia Tech) research dealt with GPGPUs, and work related to multicores was performed by Changhui Lin (Samsung), Amlan Kusum (Oracle), and Vineet Singh (Intel).\n\n\t\t\t\t\tLast Modified: 09/02/2017\n\n\t\t\t\t\tSubmitted by: Rajiv Gupta"
 }
}