{
 "awd_id": "1302668",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: RI: Processing Opinion Sharing Dialogue in Social Media",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 1038556.0,
 "awd_amount": 1070556.0,
 "awd_min_amd_letter_date": "2013-09-05",
 "awd_max_amd_letter_date": "2016-06-28",
 "awd_abstract_narration": "When people make decisions or form beliefs, they often discuss them with others, seeking out others' opinions and sharing their own. Recently such conversations are occurring online, providing a public source of information of interest to companies, the military, the government, public policy bodies, and educators. Moreover these dialogs occur at scale, allowing researchers in natural language processing access to large-scale dialog datasets for the first time. However, automatically processing such dialogs is challenging, because current tools are targeted to traditional language resources such as newspaper articles. This project develops innovative algorithms for automatically processing and identifying important phenomena in such dialogs including: (a) stance - participants' views on a topic; (b) subjective dialog acts - including sarcasm and humor; and (c) central propositions - core ideas in the dialog, by combining methods of crowd-sourced annotation, bootstrapping and machine learning, and cognitive science. A critical project output is a new  corpus, including  annotations and dialogic summaries. \r\n\r\nLonger term impacts include public policy, providing government and the military with methods to discover what \"the man on the street\" is saying about current topics. Educators can re-use the corpora and tools to expose children to compelling arguments about important issues. Greater understanding of opinion sharing dialog enables new cognitive experiments and theory: automatically identifying compelling arguments allows political science and social psychology researchers to examine learning and opinion formation. The project trains undergraduate and graduate students in interdisciplinary research combining social media, human computer interaction, computational linguistics and natural language processing.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Marilyn",
   "pi_last_name": "Walker",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Marilyn A Walker",
   "pi_email_addr": "mawalker@ucsc.edu",
   "nsf_id": "000515313",
   "pi_start_date": "2013-09-05",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jean",
   "pi_last_name": "Fox Tree",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Jean E Fox Tree",
   "pi_email_addr": "foxtree@ucsc.edu",
   "nsf_id": "000106307",
   "pi_start_date": "2013-09-05",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Pranav",
   "pi_last_name": "Anand",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pranav Anand",
   "pi_email_addr": "panand@ucsc.edu",
   "nsf_id": "000561648",
   "pi_start_date": "2013-09-05",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Steve",
   "pi_last_name": "Whittaker",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Steve Whittaker",
   "pi_email_addr": "swhittak@ucsc.edu",
   "nsf_id": "000580847",
   "pi_start_date": "2013-09-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Cruz",
  "inst_street_address": "1156 HIGH ST",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA CRUZ",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8314595278",
  "inst_zip_code": "950641077",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "CA19",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA SANTA CRUZ",
  "org_prnt_uei_num": "",
  "org_uei_num": "VXUFPE4MCZH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Cruz",
  "perf_str_addr": "1156 High St.",
  "perf_city_name": "Santa Cruz",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "950641077",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "CA19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 357996.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 688560.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Where 200 years ago someone looking to convince others would get on their literal soapbox in the town square or where someone 100 years ago would write letters to the editor, today we increasingly go online to discuss and to argue important political and cultural concerns with friends and strangers alike. These substantive discussions, now happening daily between hundreds of thousands of people, constitute an untapped wealth of knowledge, both practically and scientifically. From a practical standpoint, being able to automatically digest and summarize these discussions would be enormously helpful for more reliably tracking public opinion and, perhaps more importantly, for understanding people's reasoning behind their opinions. However, the automatic digesting necessary for these applications is challenging, since these kinds of discussions involve kinds of conversational interaction that remain particularly challenging for machine understanding, including sarcasm and insults. In addition, because these discussions are argumentative, they frequently invoke common \"pro\" and \"con\" arguments for particular positions (a kind of specialized, constantly-evolving, issue-dependent background knowledge), but do so in the context of the particular discussion at hand, making it very difficult for machines to appreciate which abstract arguments are being referenced.</p>\n<p><br />The purpose of this research was to build new datasets and computational tools to help deal with these challenging phenomena, leveraging the inter-disciplinary expertise of computer scientists, psychologists, and humanists.</p>\n<p><br />On the data end, the research resulted in 9 publicly downloadable datasets covering topics including sarcasm in internet comments, rhetorical questions in Twitter, expressions of personal goals, and personality's effect on persuasiveness. In terms of tools, we built algorithms to automatically determine several dimensions of conversational arguments, including the emotion, sarcasm level, and effectiveness of an argument. We also developed algorithms for determining how arguments fit into both a particular conversation (e.g., to what extent a reply agrees or disagrees with what it is replying to) as well as the more general positions that people typically adopt for the argumentative topic (e.g., the sub-issue or \"facet\" that an argument is about, what side or \"stance\" an argument is on), and used those to construct methods for characterizing the stances of participants within and across multiple conversations as well as methods for finding similar arguments across conversations. To explore the real-world value of our tools, we used all of the tools described above to build a prototype chatbot that can engage in a debate with a human. Finally, we conducted psycholinguistic experiments to validate our data-driven findings about how normal conversational markers are recruited as markers of sarcasm online.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/21/2019<br>\n\t\t\t\t\tModified by: Pranav&nbsp;Anand</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhere 200 years ago someone looking to convince others would get on their literal soapbox in the town square or where someone 100 years ago would write letters to the editor, today we increasingly go online to discuss and to argue important political and cultural concerns with friends and strangers alike. These substantive discussions, now happening daily between hundreds of thousands of people, constitute an untapped wealth of knowledge, both practically and scientifically. From a practical standpoint, being able to automatically digest and summarize these discussions would be enormously helpful for more reliably tracking public opinion and, perhaps more importantly, for understanding people's reasoning behind their opinions. However, the automatic digesting necessary for these applications is challenging, since these kinds of discussions involve kinds of conversational interaction that remain particularly challenging for machine understanding, including sarcasm and insults. In addition, because these discussions are argumentative, they frequently invoke common \"pro\" and \"con\" arguments for particular positions (a kind of specialized, constantly-evolving, issue-dependent background knowledge), but do so in the context of the particular discussion at hand, making it very difficult for machines to appreciate which abstract arguments are being referenced.\n\n\nThe purpose of this research was to build new datasets and computational tools to help deal with these challenging phenomena, leveraging the inter-disciplinary expertise of computer scientists, psychologists, and humanists.\n\n\nOn the data end, the research resulted in 9 publicly downloadable datasets covering topics including sarcasm in internet comments, rhetorical questions in Twitter, expressions of personal goals, and personality's effect on persuasiveness. In terms of tools, we built algorithms to automatically determine several dimensions of conversational arguments, including the emotion, sarcasm level, and effectiveness of an argument. We also developed algorithms for determining how arguments fit into both a particular conversation (e.g., to what extent a reply agrees or disagrees with what it is replying to) as well as the more general positions that people typically adopt for the argumentative topic (e.g., the sub-issue or \"facet\" that an argument is about, what side or \"stance\" an argument is on), and used those to construct methods for characterizing the stances of participants within and across multiple conversations as well as methods for finding similar arguments across conversations. To explore the real-world value of our tools, we used all of the tools described above to build a prototype chatbot that can engage in a debate with a human. Finally, we conducted psycholinguistic experiments to validate our data-driven findings about how normal conversational markers are recruited as markers of sarcasm online.\n\n \n\n\t\t\t\t\tLast Modified: 02/21/2019\n\n\t\t\t\t\tSubmitted by: Pranav Anand"
 }
}