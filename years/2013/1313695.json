{
 "awd_id": "1313695",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Using Rule Space and Poset-based Adaptive Testing Methodologies to Identify Ability Patterns in Early Mathematics and Create a Comprehensive Mathematics Ability Test",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Karen King",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2018-02-28",
 "tot_intn_awd_amt": 1887501.0,
 "awd_amount": 2148857.0,
 "awd_min_amd_letter_date": "2013-01-16",
 "awd_max_amd_letter_date": "2017-02-07",
 "awd_abstract_narration": "A new assessment for children ages 3-7 is being developed to provide teachers with diagnostic information on a child's development of mathematics facility on ten domains such as counting, sequencing, adding/subtracting, and measurement. The Comprehensive Research-based Mathematics Assessment (CREMA) is being developed using innovative psychometric models to reveal information about children on specific attributes for each of the 10 domains. The CREMA will produce information based on carefully developed learning trajectories in a relative short period of time by using computer adaptive testing. The project is guided by two goals: 1) to produce a cognitively diagnostic adaptive assessment that will yield more useful and detailed information about students' knowledge of mathematics than previously possible, and 2) subject the developmental progressions to close cognitive diagnosis using cutting-edge psychometric approaches. An item pool of about 350 items is being developed that can be used to identify the level of understanding children ages 3-7 have on the 10 domains that have been identified as foundational to further learning in mathematics. A research team headed by Dr. Douglas Clements at the University of Buffalo is conducting the development work while being assisted by Dr. Curtis Tatsuoka, a statistician at Case Western Reserve University.\r\n\r\nThe CREMA is being developed using leading-edge psychometric models based on Q-Matrix theory, rule-state models, and posets. The initial item pool includes items from the REMA, a previously developed instrument based on unidemensional IRT models. New items are being piloted with at least 200 students from a group of a total of 800 students evenly distributed among pre-K to grade 2. The successful items then are used to create the new CREMA. The new assessment is being field tested with 300 children, pre-K to grade 2. A random sample of 50 students (at least 10 from each grade) is being video taped as they work the items. Specific criteria of convergence are being used for feedback on how specific items are performing to meet the required specifications. An external evaluator is auditing the process and is doing spot checks of item codings and other analyses performed.\r\n\r\nThe main product will be the CREMA that will be made widely available. This instrument using computer adaptive testing will provide teachers with ready information on young children's understanding of critical mathematical ideas. The new psychometric models that will be used and developed to process multiple attributes from individual items will make large strives to move forward the field of mathematics assessment of young children. A publisher has expressed interest to make the assessment widely available that increases the likelihood the assessment will have large impact on early childhood mathematics learning.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Douglas",
   "pi_last_name": "Clements",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Douglas H Clements",
   "pi_email_addr": "Douglas.Clements@du.edu",
   "nsf_id": "000148020",
   "pi_start_date": "2013-01-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Denver",
  "inst_street_address": "2199 S UNIVERSITY BLVD RM 222",
  "inst_street_address_2": "",
  "inst_city_name": "DENVER",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "3038712000",
  "inst_zip_code": "802104711",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "CO01",
  "org_lgl_bus_name": "UNIVERSITY OF DENVER",
  "org_prnt_uei_num": "WCUGNQQ8DZU1",
  "org_uei_num": "WCUGNQQ8DZU1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Denver",
  "perf_str_addr": "",
  "perf_city_name": "Denver",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "802104711",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "CO01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "764500",
   "pgm_ele_name": "Discovery Research K-12"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0410",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001011DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0413",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001314DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0415",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001516DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 1283882.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 603619.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 261356.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Teachers&rsquo; abilities to make decisions about how to tailor mathematics instruction depends in part on the quality of their assessments. In particular, teachers are in need of assessments with two characteristics: (1) assessments that are&nbsp;<em>efficient</em>in yielding data and (2) assessments that provide&nbsp;<em>thorough</em>information on students&rsquo; mathematical understanding.&nbsp;</p>\n<p>Previously, we have developed the Research-based Early Mathematics Assessment (REMA) as a means of assessing students&rsquo; mathematical competence along a series of mathematical learning progressions that cover essential mathematical goals&nbsp;(Clements &amp; Sarama, 2007; Sarama &amp; Clements, 2009). While the REMA addresses the second characteristic described above, it also covers a wide breadth of mathematical domains, and therefore can be time-consuming to administer.&nbsp;</p>\n<p>&nbsp;Consequently, in this project, we developed the Comprehensive Research-based Early Mathematics Ability Test (CREMAT). CREMAT extends previous REMA work by putting REMA-based items in a&nbsp;<em>computer-adaptive assessment.&nbsp;</em>CREMAT continually monitors students&rsquo; mathematical understanding and dynamically provides items tailored to their understanding, in order to comprehensively assess how students are progressing within that mathematical domain. CREMAT aimed to provide information about specific concepts and skills that constitute the cognitive elements of problem-solving involved in various tasks; yield information about each child&rsquo;s strengths and weaknesses for concepts and skills in each of multiple domains of mathematics; and maintain a reasonable administration time.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Our first task was to identify concepts, skills, or procedures, known generally as&nbsp;<em>attributes</em>, that play important roles in performance on individual test items. This is done through cognitive analysis of each item, specifically identifying what is required to perform well. With a specified link between items and attributes, as denoted by what is known as a Q-matrix (K.K. Tatsuoka, 2009), it becomes possible to assess learners&rsquo; strengths and weaknesses on the identified attributes from observed item responses.&nbsp;&nbsp;&nbsp;</p>\n<p>&nbsp;</p>\n<p>Using REMA items as a foundation along with learning trajectory theories (Sarama &amp; Clements 2007) we then identified several discrete mathematics domains and partitioned REMA items accordingly into &ldquo;sub-tests&rdquo; (e.g., measurement versus arithmetic). We pilot tested paper-and-pencil versions of these items with elementary school children to determine (1) how well the items discriminated skill levels and (2) if the items were comprehensible to children. Based on the analyses of responses, we discarded some items, added others, and modified existing items. We went through multiple rounds of testing. As a result of this process, we added our final set of items into the computer adaptive tests, which we again field tested to examine test functionality as well as to gather psychometric data.&nbsp;</p>\n<p>To date, we have field-tested and psychometrically evaluated three of the computer-adaptive&nbsp;&nbsp;subtests: 1<sup>st</sup>Grade Measurement, 2<sup>nd</sup>Grade Measurement-Area, and 2<sup>nd</sup>Grade Measurement-Length. Results reveal that all three sub-tests are adequate to excellent in decisively and quickly classifying students&rsquo; mastery levels. As additional subtests are added to the CREMAT platform, they will be field-tested and evaluated, so that CREMAT can be shared with educators. &nbsp;\\</p>\n<p>Multiple outcomes proceed from this work. First, the design process through which we arrived at the final CREMAT instrument could serve as a basis for future development of other computer adaptive assessments. Second, we have produced three tests (accessible via www.cremat.org), assessing first and second graders&rsquo; understanding of measurement, that can be widely used by teachers to efficiently and assess their students&rsquo; mathematical competencies within the measurement domain. Finally, we continue to develop tests within other mathematical domains (e.g. arithmetic, counting, geometry) that can also be disseminated in the future to assist teachers.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/18/2018<br>\n\t\t\t\t\tModified by: Douglas&nbsp;H&nbsp;Clements</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nTeachers? abilities to make decisions about how to tailor mathematics instruction depends in part on the quality of their assessments. In particular, teachers are in need of assessments with two characteristics: (1) assessments that are efficientin yielding data and (2) assessments that provide thoroughinformation on students? mathematical understanding. \n\nPreviously, we have developed the Research-based Early Mathematics Assessment (REMA) as a means of assessing students? mathematical competence along a series of mathematical learning progressions that cover essential mathematical goals (Clements &amp; Sarama, 2007; Sarama &amp; Clements, 2009). While the REMA addresses the second characteristic described above, it also covers a wide breadth of mathematical domains, and therefore can be time-consuming to administer. \n\n Consequently, in this project, we developed the Comprehensive Research-based Early Mathematics Ability Test (CREMAT). CREMAT extends previous REMA work by putting REMA-based items in a computer-adaptive assessment. CREMAT continually monitors students? mathematical understanding and dynamically provides items tailored to their understanding, in order to comprehensively assess how students are progressing within that mathematical domain. CREMAT aimed to provide information about specific concepts and skills that constitute the cognitive elements of problem-solving involved in various tasks; yield information about each child?s strengths and weaknesses for concepts and skills in each of multiple domains of mathematics; and maintain a reasonable administration time. \n\n \n\nOur first task was to identify concepts, skills, or procedures, known generally as attributes, that play important roles in performance on individual test items. This is done through cognitive analysis of each item, specifically identifying what is required to perform well. With a specified link between items and attributes, as denoted by what is known as a Q-matrix (K.K. Tatsuoka, 2009), it becomes possible to assess learners? strengths and weaknesses on the identified attributes from observed item responses.   \n\n \n\nUsing REMA items as a foundation along with learning trajectory theories (Sarama &amp; Clements 2007) we then identified several discrete mathematics domains and partitioned REMA items accordingly into \"sub-tests\" (e.g., measurement versus arithmetic). We pilot tested paper-and-pencil versions of these items with elementary school children to determine (1) how well the items discriminated skill levels and (2) if the items were comprehensible to children. Based on the analyses of responses, we discarded some items, added others, and modified existing items. We went through multiple rounds of testing. As a result of this process, we added our final set of items into the computer adaptive tests, which we again field tested to examine test functionality as well as to gather psychometric data. \n\nTo date, we have field-tested and psychometrically evaluated three of the computer-adaptive  subtests: 1stGrade Measurement, 2ndGrade Measurement-Area, and 2ndGrade Measurement-Length. Results reveal that all three sub-tests are adequate to excellent in decisively and quickly classifying students? mastery levels. As additional subtests are added to the CREMAT platform, they will be field-tested and evaluated, so that CREMAT can be shared with educators.  \\\n\nMultiple outcomes proceed from this work. First, the design process through which we arrived at the final CREMAT instrument could serve as a basis for future development of other computer adaptive assessments. Second, we have produced three tests (accessible via www.cremat.org), assessing first and second graders? understanding of measurement, that can be widely used by teachers to efficiently and assess their students? mathematical competencies within the measurement domain. Finally, we continue to develop tests within other mathematical domains (e.g. arithmetic, counting, geometry) that can also be disseminated in the future to assist teachers. \n\n\t\t\t\t\tLast Modified: 05/18/2018\n\n\t\t\t\t\tSubmitted by: Douglas H Clements"
 }
}