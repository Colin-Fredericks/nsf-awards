{
 "awd_id": "1337375",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS:DSD:Synthesizing Domain Specific Systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tao Li",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 260000.0,
 "awd_amount": 260000.0,
 "awd_min_amd_letter_date": "2013-09-10",
 "awd_max_amd_letter_date": "2013-09-10",
 "awd_abstract_narration": "Information\u00a0technology is now a major catalyst for innovation across all aspects of human\u00a0endeavor. Hence, it is vital to maintain the exponential performance growth of\u00a0computing devices that has been the key enabler for information technology\u00a0advances for more than four decades. In the past, semiconductor technology\u00a0provided us with\u00a0increasing transistor densities and decreasing power supplies,\u00a0allowing us to improve performance without increasing energy consumption.\u00a0However, the lack of power supply\u00a0scaling in current and future technologies\u00a0has made all computing systems energy limited. Improving energy efficiency is a\u00a0defining challenge and the prerequisite to increasing\u00a0the capabilities of all\u00a0computing systems, from smartphones to warehouse-scale data-centers.\r\n\u00a0\r\nThe goal of this project is to\u00a0enable cost-effective customized computing by bridging the gap between\u00a0high-level application development and the design of\u00a0specialized hardware for\u00a0energy efficient computing. Specialization is the prevailing approach for\u00a0energy efficient computing, as customized units can eliminate the energy\u00a0overheads of general-purpose cores. However, the complexity of designing\u00a0and managing\u00a0customized hardware is currently limiting the benefits from specialization to\u00a0high-volume, slowly evolving applications. We will create domain specific synthesis tools\u00a0that, given an application written in an easy-to-use, domain-specific\u00a0programming language, will generate domain or\u00a0application specific hardware:\u00a0compute units and memory systems.\u00a0The core of our approach to domain specific\u00a0synthesis is a combination of domain specific languages to capture high-level\u00a0application information, domain-specific\u00a0optimization, parallelism and locality\u00a0optimization, and hardware generation from parallelism and locality patterns.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Oyekunle",
   "pi_last_name": "Olukotun",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Oyekunle A Olukotun",
   "pi_email_addr": "kunle@stanford.edu",
   "nsf_id": "000320046",
   "pi_start_date": "2013-09-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Christoforos",
   "pi_last_name": "Kozyrakis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christoforos Kozyrakis",
   "pi_email_addr": "kozyraki@stanford.edu",
   "nsf_id": "000486618",
   "pi_start_date": "2013-09-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "353 Serra Mall",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943059025",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 260000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Intellectual Merit</strong></p>\n<p>In recent years, due to the slowing of Moore's Law and power constraints, the computing landscape has seen an increasing shift towards specialized accelerators. Field programmable gate arrays (FPGAs) are particularly promising as they offer significant performance and power improvements compared to CPUs for a wide class of applications and are far more flexible than fixed-function ASICs. However, FPGAs are difficult to program. Traditional programming models for reconfigurable logic use low-level hardware description languages like Verilog and VHDL, which have none of the productivity features of modern software development languages but produce very efficient designs, and low-level software languages like C and OpenCL coupled with high-level synthesis (HLS) tools that typically produce designs that are far less efficient.</p>\n<p>Under this project we have developed high-level software environments for generating high-performance FPGA designs. Functional languages with parallel patterns are a good fit for hardware generation because they both provide high-level abstractions for programmers with little experience in hardware design and avoid many of the problems faced when generating hardware from imperative languages like C++. We have &nbsp;identified two key optimizations that are important for translating parallel patterns into efficient hardware: tiling and metapipelining (hierarchical pipelining). We have developed a general representation of tiled parallel patterns, and rules for automatically tiling patterns and generating metapipelines. We have demonstrated &nbsp;that these optimizations result in speedups up to 40 times on a set of benchmarks from the data analytics domain.</p>\n<p>&nbsp;</p>\n<p><strong>Broader Impacts</strong></p>\n<p>This project has provided for the training and professional development of three graduate students. One of these students is an underrepresented minority.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/11/2015<br>\n\t\t\t\t\tModified by: Oyekunle&nbsp;A&nbsp;Olukotun</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIntellectual Merit\n\nIn recent years, due to the slowing of Moore's Law and power constraints, the computing landscape has seen an increasing shift towards specialized accelerators. Field programmable gate arrays (FPGAs) are particularly promising as they offer significant performance and power improvements compared to CPUs for a wide class of applications and are far more flexible than fixed-function ASICs. However, FPGAs are difficult to program. Traditional programming models for reconfigurable logic use low-level hardware description languages like Verilog and VHDL, which have none of the productivity features of modern software development languages but produce very efficient designs, and low-level software languages like C and OpenCL coupled with high-level synthesis (HLS) tools that typically produce designs that are far less efficient.\n\nUnder this project we have developed high-level software environments for generating high-performance FPGA designs. Functional languages with parallel patterns are a good fit for hardware generation because they both provide high-level abstractions for programmers with little experience in hardware design and avoid many of the problems faced when generating hardware from imperative languages like C++. We have  identified two key optimizations that are important for translating parallel patterns into efficient hardware: tiling and metapipelining (hierarchical pipelining). We have developed a general representation of tiled parallel patterns, and rules for automatically tiling patterns and generating metapipelines. We have demonstrated  that these optimizations result in speedups up to 40 times on a set of benchmarks from the data analytics domain.\n\n \n\nBroader Impacts\n\nThis project has provided for the training and professional development of three graduate students. One of these students is an underrepresented minority.\n\n \n\n \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/11/2015\n\n\t\t\t\t\tSubmitted by: Oyekunle A Olukotun"
 }
}