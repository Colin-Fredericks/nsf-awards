{
 "awd_id": "1311446",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "US-French Collaboration: Auditory computations for interpreting and producing communication signals.",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2013-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 718805.0,
 "awd_amount": 718805.0,
 "awd_min_amd_letter_date": "2013-09-13",
 "awd_max_amd_letter_date": "2015-08-20",
 "awd_abstract_narration": "Human speech and animal communication require both the extraction of meaning from sound and the processing of one's own voice to guide the production of these vocalizations. These processes require non-trivial computations that have challenged linguists and engineers but that are performed effortlessly by our brains. To understand what are the neural computations performed to decode the behavioral meaning and vocal gestures of communication signals, this study will examine how the auditory cortex of a songbird processes the complete vocal repertoire of its own species.  \r\n\r\nThe Theunissen Lab acquired a unique database of all the vocalizations emitted by adult and juvenile, and both male and female zebra finches.  This database contains the complete repertoire with multiple exemplars of each vocalization type for many individuals. Because the behavioral context of each communication sound was carefully recorded, these sounds are classified in meaning categories. This database will thus enable the detailed investigation of how the auditory system extract meaning from vocalizations, while controlling for variability of production within vocalization type as well as between individuals.\r\n\r\nThe approach of this project consists in obtaining neural responses to these communication sounds using advanced neurophysiological recording techniques, and then investigating the neural computations by finding the statistics models that best predict these responses. Multi-electrode arrays will be used to record the simultaneous neural activity of large sets of single neurons in the primary and secondary auditory areas. The response of these neurons will then be fitted using statistical models that incorporate increasing levels of abstraction: from elementary sound features, to vocal gestures and semantic labels.  The representation in terms of vocal gestures will be obtained from a reduced physical model of the avian vocal organ.  This analysis will not only point out the brain regions that are involved in semantic processing but also the nature of the hierarchical computations that lead to these higher-level representations.  The research will also investigate the link between perception and production by directly assessing the role of a motor-based representation of sounds in high-level auditory areas.  \r\n\r\nBy combining ethological, neurophysiological and computational studies of acoustic communication in a songbird, the project will establish an appropriate animal model system to elucidate how the auditory cortex extracts and categorizes sound features in order to link sound to meaning. Given the similarities in the anatomy and physiology of the auditory system across vertebrates and the common signal processing problems shared in all vocal communications, this study can also contribute significantly to the neurophysiological understanding of neural mechanisms underlying speech perception. \r\n\r\nThis award is being co-funded by NSF's Office of the Director, International Science and Engineering.  A companion project is being funded by the French National Research Agency (ANR).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Frederic",
   "pi_last_name": "Theunissen",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Frederic E Theunissen",
   "pi_email_addr": "theunissen@berkeley.edu",
   "nsf_id": "000463441",
   "pi_start_date": "2013-09-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "3425 Tolman Hall",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947201650",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "729800",
   "pgm_ele_name": "International Research Collab"
  },
  {
   "pgm_ele_code": "732700",
   "pgm_ele_name": "CRCNS-Computation Neuroscience"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5918",
   "pgm_ref_txt": "FRANCE"
  },
  {
   "pgm_ref_code": "5980",
   "pgm_ref_txt": "WESTERN EUROPE PROGRAM"
  },
  {
   "pgm_ref_code": "7298",
   "pgm_ref_txt": "COLLABORATIVE RESEARCH"
  },
  {
   "pgm_ref_code": "7327",
   "pgm_ref_txt": "CRCNS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 336158.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 306697.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 75950.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Communication sounds carry information about the vocalizer&rsquo;s intent (the meaning of the vocalization), the vocalizer&rsquo;s id and emotional status and his or her location.&nbsp; The goal of our research is to understand how the brain extracts such information from the sound pressure waveform impinging at the ear of the listener.&nbsp; To do so, we have studied the communication capacities of a social songbird, the zebra finch.&nbsp; Our research involves acoustical analyses of their communication sounds, behavioral experiments to assess the bird&rsquo;s auditory discrimination abilities, neurophysiological experiments to record brain activity when birds are actively communicating and computational analyses to decipher how network of neurons extract meaning from sounds.</p>\n<p>&nbsp;</p>\n<p>We found the acoustical code that is used by songbirds to produce call types with different meanings: just as in humans, songbirds actively modulate not only their vocal organ but also their upper vocal tract to shape the sound into meaningful utterances.&nbsp; We also found that songbirds individualize their vocal output so that the listener can recognize calls produced by familiar individuals irrespective of the call type that is produced.</p>\n<p>&nbsp;</p>\n<p>In our neurophysiological research, we have found auditory neurons in secondary avian auditory cortical areas that are selective sensitive for specific call types, such as aggressive calls only or alternatively contact calls only.&nbsp; We have then examined the computations that could lead to this selectivity.&nbsp; These computations involve not only the detection of specific acoustical features but also operations on responses to these features that can be understood as combinations of logical OR and AND operations.</p>\n<p>&nbsp;</p>\n<p>Our research also provided training to undergraduate and graduate students in signal processing techniques that are used both in neurosciences and in engineering applications such as those needed in automatic speech recognition or in the design of the next generation of hearing aids.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/25/2018<br>\n\t\t\t\t\tModified by: Frederic&nbsp;E&nbsp;Theunissen</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1311446/1311446_10280050_1516922178666_ZebraFinch--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1311446/1311446_10280050_1516922178666_ZebraFinch--rgov-800width.jpg\" title=\"Responses from an Avian Cortical Auditory Neuron to Communication Sounds.\"><img src=\"/por/images/Reports/POR/2018/1311446/1311446_10280050_1516922178666_ZebraFinch--rgov-66x44.jpg\" alt=\"Responses from an Avian Cortical Auditory Neuron to Communication Sounds.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The top row shows the spectrogram of three vocalizations, the middle section the neural spike rasters obtained for 10 presentations of that same sound, and the bottom row the average neural response in number of spikes per ms. This neuron is selective for Distance Contact calls.</div>\n<div class=\"imageCredit\">Julie Elie</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Frederic&nbsp;E&nbsp;Theunissen</div>\n<div class=\"imageTitle\">Responses from an Avian Cortical Auditory Neuron to Communication Sounds.</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nCommunication sounds carry information about the vocalizer?s intent (the meaning of the vocalization), the vocalizer?s id and emotional status and his or her location.  The goal of our research is to understand how the brain extracts such information from the sound pressure waveform impinging at the ear of the listener.  To do so, we have studied the communication capacities of a social songbird, the zebra finch.  Our research involves acoustical analyses of their communication sounds, behavioral experiments to assess the bird?s auditory discrimination abilities, neurophysiological experiments to record brain activity when birds are actively communicating and computational analyses to decipher how network of neurons extract meaning from sounds.\n\n \n\nWe found the acoustical code that is used by songbirds to produce call types with different meanings: just as in humans, songbirds actively modulate not only their vocal organ but also their upper vocal tract to shape the sound into meaningful utterances.  We also found that songbirds individualize their vocal output so that the listener can recognize calls produced by familiar individuals irrespective of the call type that is produced.\n\n \n\nIn our neurophysiological research, we have found auditory neurons in secondary avian auditory cortical areas that are selective sensitive for specific call types, such as aggressive calls only or alternatively contact calls only.  We have then examined the computations that could lead to this selectivity.  These computations involve not only the detection of specific acoustical features but also operations on responses to these features that can be understood as combinations of logical OR and AND operations.\n\n \n\nOur research also provided training to undergraduate and graduate students in signal processing techniques that are used both in neurosciences and in engineering applications such as those needed in automatic speech recognition or in the design of the next generation of hearing aids.\n\n \n\n\t\t\t\t\tLast Modified: 01/25/2018\n\n\t\t\t\t\tSubmitted by: Frederic E Theunissen"
 }
}