{
 "awd_id": "1359814",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Efficient Atomic Decompositions of Massive Data Sets",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2013-08-01",
 "awd_exp_date": "2018-05-31",
 "tot_intn_awd_amt": 356249.0,
 "awd_amount": 356249.0,
 "awd_min_amd_letter_date": "2013-09-13",
 "awd_max_amd_letter_date": "2016-07-26",
 "awd_abstract_narration": "Scientists and Engineers often struggle to deduce the state or structure of a system from partial, noisy measurements.  The corresponding problems are ill-posed because there are fewer measurements available than the number of parameters they would like to estimate. In practice, however, many interesting signals or models contain considerably fewer degrees than the apparent number of parameters: a small number of genes may constitute the signature of a disease, very few parameters may specify the correlation structure of a time series, or a sparse collection of geometric constraints may determine a molecular configuration. Discovering, leveraging, or recognizing such low-dimensional structure plays an important role in posing inverse problems well.\r\n \r\nThis project pursues a unified approach to transform notions of simplicity and latent low-dimensionality into convex penalty functions. The investigators focus on a theoretically sound suite of data analysis algorithms designed to decompose complex signals into sums of a small number of simple atoms.  The work first catalogs the objects and structures that can be recovered from a small number of measurements using atomic decomposition algorithms, in order to show that many structures of significant scientific and technological interest need only be probed a few times to extract complete and accurate knowledge. Second, the project explores a range of practically useful implementations of atomic decomposition algorithms for data recovery, enabling efficient solutions of large-scale problems with guaranteed success. Finally, practical implementation in a diverse set of applications, including web-scale data analysis, high-throughput biology, and experimental physics, continually motivate and refine this mathematical research program.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Benjamin",
   "pi_last_name": "Recht",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Benjamin H Recht",
   "pi_email_addr": "brecht@berkeley.edu",
   "nsf_id": "000569581",
   "pi_start_date": "2013-09-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947045940",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 84061.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 185052.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 87136.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project made large-scale data analysis less sensitive to missing data and noise by exploiting domain-specific knowledge and prior information about structure. The PI and his research group showed that when a signal or system of interest is representable as a combination of a few simple building blocks, it can be rapidly identified with minimal sensing by solving a convex optimization problem. For example, RADAR signals can be decomposed into a sum of elementary propagating waves, metabolic dynamics can be analyzed as sums of multi-index data arrays, and aggregate rankings of sports teams can be written as sums of a few permutations.&nbsp; For each application, this project demonstrated how to define the most appropriate set of atomic building blocks and how to estimate the most parsimonious that agrees with a small set of measurements.</p>\n<p>This project provided a coherent, comprehensive catalog of objects and structures that can be recovered from a small number of measurements using convex optimization.&nbsp; This effort showed that many structures of significant scientific and technological interest need only be probed a few times to extract complete and accurate knowledge.&nbsp; The theoretical foundations were complemented by software embodiments and new algorithms for large-scale data recovery. These algorithms exploit geometric structure provided by the prior assumptions about the basic atoms. The algorithmic and mathematical techniques were validated in several joint projects with collaborators in biomarker discovery, neutrino physics, reflection seismology, and exercise testing. Each of these investigations provided detailed evaluations of the advantages and drawbacks of the atomic decomposition framework in comparison to existing approaches.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/15/2019<br>\n\t\t\t\t\tModified by: Benjamin&nbsp;H&nbsp;Recht</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project made large-scale data analysis less sensitive to missing data and noise by exploiting domain-specific knowledge and prior information about structure. The PI and his research group showed that when a signal or system of interest is representable as a combination of a few simple building blocks, it can be rapidly identified with minimal sensing by solving a convex optimization problem. For example, RADAR signals can be decomposed into a sum of elementary propagating waves, metabolic dynamics can be analyzed as sums of multi-index data arrays, and aggregate rankings of sports teams can be written as sums of a few permutations.  For each application, this project demonstrated how to define the most appropriate set of atomic building blocks and how to estimate the most parsimonious that agrees with a small set of measurements.\n\nThis project provided a coherent, comprehensive catalog of objects and structures that can be recovered from a small number of measurements using convex optimization.  This effort showed that many structures of significant scientific and technological interest need only be probed a few times to extract complete and accurate knowledge.  The theoretical foundations were complemented by software embodiments and new algorithms for large-scale data recovery. These algorithms exploit geometric structure provided by the prior assumptions about the basic atoms. The algorithmic and mathematical techniques were validated in several joint projects with collaborators in biomarker discovery, neutrino physics, reflection seismology, and exercise testing. Each of these investigations provided detailed evaluations of the advantages and drawbacks of the atomic decomposition framework in comparison to existing approaches.\n\n\t\t\t\t\tLast Modified: 04/15/2019\n\n\t\t\t\t\tSubmitted by: Benjamin H Recht"
 }
}