{
 "awd_id": "1320791",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Small: Managing Spatial Data in a Distributed Environment",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 508000.0,
 "awd_min_amd_letter_date": "2013-09-06",
 "awd_max_amd_letter_date": "2015-07-10",
 "awd_abstract_narration": "Advances in distributed computing enable the pooling of resources located across the Internet to provide a scalable, and robust solution for many computational needs. Distributed key-value store systems like Google's BigTable and Amazon's Dynamo allow the indexing and retrieval of a large amount of data in parallel, while distributed computing frameworks like MapReduce and Pregel provide a fault-tolerant way to process a large amount of data using distributed computing resources. These distributed computing techniques are applied to the spatial database domain. Specifically, issues involved in storing and retrieving spatial data in a distributed environment, as well as, processing spatial queries in parallel using a distributed computing framework are investigated. All of these methods rely on variants of hashing in order to obtain near constant time behavior in distributing the data and it is preferable that they are as close as possible to being distance-preserving.  Specifically, spatial objects in proximity should have similar hash values.  In particular, it is desirable to be able to estimate how far apart two objects are (within a given error bound) by just considering their hash values.  Such hash functions enable performing an approximate range query using simple hash table lookup operations.  Other issues involve the parallel processing of spatial queries.  Some easy examples are the distance join query which finds pairs (p,q) of objects (from two different sets) where the distance between p and q is less than a given threshold, or computing the shortest paths from each node to every other node in a road network.  More difficult are the spatial problems which can not be easily decomposed into multiple tasks running in parallel, e.g., the distance semi-join query, and network Voronoi diagram construction. This requires developing a generic method to traverse a graph or a tree in parallel to solve these query problems.  Ideally, the method should require little or no communication between parallel tasks which will be accomplished by allowing the parallel tasks to produce redundant results which can then be pruned.\r\n\r\nThe developed tools will help improve the robustness and scalability for spatial data management. The parallel query processing results can be useful for query problems which requires traversing a tree or a graph which are often spatially embedded.  Having a method to traverse a graph or a tree in parallel that requires little or no communication enables processing of many types of spatial queries using distributed computing resources where currently communication can be very costly.  Specifically, it can be expected that the tools will enable spatial applications such as online mapping, computer aided design, online gaming and scientific simulations to handle terabytes of spatial data while it is impossible or inefficient to do with the current technologies.  This is of utility to all organizations that process spatial data and attempts will be made to use it in some government agencies.  In addition, the project provides educational and research opportunities for graduate and undergraduates. The project web site (http://www.cs.umd.edu/~hjs/distributed-spatial.html) will be used to disseminate results.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hanan",
   "pi_last_name": "Samet",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hanan Samet",
   "pi_email_addr": "hjs@umd.edu",
   "nsf_id": "000445634",
   "pi_start_date": "2013-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425141",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 331011.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 168989.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Spatial analytical queries that compute millions of network distances<br />are commonplace in logistics, route planning, and spatial business<br />intelligence.&nbsp; Existing solutions usually use the geodesic distance<br />(Euclidean distance) instead of the network distance, which makes<br />their results inaccurate as it underestimates the true distance.<br />For instance, a delivery company that delivers 10,000 packages would<br />compute a distance matrix that captures the distance between every<br />pair of destination locations to plan the routes.&nbsp; Computing such a<br />distance matrix requires one hundred million network distance queries.<br />Note that Google Distance Matrix offers an API to compute the distance<br />matrix but limits the service, even to their paying customers, to 25<br />by 25 matrices (i.e., 625 distance computations).&nbsp; What is needed is a<br />framework to perform tens of millions of distance computations on road<br />networks quickly so that we can cater to the requirements of delivery<br />companies such as Amazon Fresh, Google Express, Uber Rush etc., that<br />seek to respond quickly to the dynamic supply-demand arising in their<br />business.<br /><br />The majority of existing shortest distance methods on road networks<br />focus mainly on decreasing the latency time for a single shortest path<br />query.&nbsp; However, reviewing spatial analytical queries in the business<br />environment reveals that what is really needed is an increase in<br />throughput which is the total time needed to compute millions of<br />pair-wise network distances.&nbsp; Thus we are interested in the average<br />number of distance computations per second.<br /><br />We developed a distributed framework called SPDO (pronounced<br />\"speedo\" standing for \"Spark and Distance Oracles\" using Apache Spark<br />that is optimized for high-throughput network distance computations.<br />This work extends our prior award-winning (one of the best papers in<br />the 2009 ICDE Conference) research on the epsilon-Distance Oracle<br />which precomputes and stores the shortest distances between all pairs of<br />vertices in a road network.&nbsp; The resulting representation takes uses<br />O(n/epsilon^2) space, where n is the number of vertices in the road<br />network and epsilon is an approximation error bound on the result.<br />In our previous work we showed how to map the instance oracle<br />representation to an RDBMS system and how to use it to solve complex<br />analytical queries on a road network.&nbsp; We showed how to map distance<br />oracles to a distributed key-value store (i.e., hash abstraction)<br />which we choose to be Spark.&nbsp; Combining Spark and distance oracles is<br />a good match.&nbsp; In essence, Spark provides a highly scalable<br />fault-tolerant distributed framework with the ability to cache large<br />datasets in memory using RDD, while distance oracles provide a compact<br />representation of network distances that requires very little<br />computation at run-time.&nbsp; Furthermore, Spark is a popular open-source<br />distributed framework for general purposes, which is more than a<br />key-value store.&nbsp; We can easily develop functions in Spark combining<br />distance oracles and other techniques that are not efficient in a<br />key-value store. In particular, we use the IndexedRDD library on Spark<br />which is a memory resident, key-value store.&nbsp; The high-throughput of<br />our proposed framework is achieved due to the ability to spread query<br />processing across multi-machines in a Spark cluster as well as the<br />in-memory representation of distance oracles.</p>\n<p>The main contributions of our work are:&nbsp; 1) a high-throughput<br />architecture using distance oracles and Spark for a large set of<br />spatial analytical queries; 2) three variants of distributed key-value<br />algorithms for our architecture; 3) an analysis of the time and space<br />complexity of our methods, and 4) a detailed comparison with<br />state-of-the-art methods for realistic datasets and applications.<br />It is important to note that SPDO needs just a few lines of code in<br />order to be incorporated into an existing Spark project that needs to<br />compute large number of network distances.&nbsp; Our experiments showed<br />that SPDO is able to compute more than 200K distance computations/sec<br />per machine for the entire USA road network which contains<br />approximately 24 million vertices.&nbsp; In contrast, CH, one of the<br />fastest state of the art latency methods, can perform at most on<br />the order of 1K distance computations/sec per machine, which is at<br />least two orders of magnitude slower than what is achievable using our<br />approach.&nbsp; A paper describing this research appears in the Proceedings<br />of the 2016 IEEE International Conference on Data Engineering in<br />Helsinki, Finland.<br /><br />Some other outcomes of our research were:<br /><br />1.&nbsp; Commercial air traffic is undergoing unprecedented growth.<br />Currently airspace capacity and efficiency is approached<br />deterministically.&nbsp; We have been taking external operational<br />circumstances into account.&nbsp; We believe that a major factor in<br />increased airspace efficiency and capacity is the accurate prediction<br />of Estimated Time of Arrival (ETA) and have devised a novel<br />ETA Prediction System for commercial flights.<br /><br />2.&nbsp; The news business is rapidly changing as more and more newspapers<br />have online editions and its hard to wean readers from a model where<br />the news is free to one requiring payment.&nbsp; The decreasing revenues<br />mean that the number of reporters is being reduced which has an effect<br />in less reporting on local events.&nbsp; On the other hand, people are<br />tweeting about local events.&nbsp; We have devised ways of detecting such<br />tweets out of the large number that are being sent.<br /><br />3.&nbsp; We created a blog RoadsInDB.com which shows how to incorporate our<br />work on computing road notwork distance into a database and pose<br />spatial analytical queries.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/05/2018<br>\n\t\t\t\t\tModified by: Hanan&nbsp;Samet</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSpatial analytical queries that compute millions of network distances\nare commonplace in logistics, route planning, and spatial business\nintelligence.  Existing solutions usually use the geodesic distance\n(Euclidean distance) instead of the network distance, which makes\ntheir results inaccurate as it underestimates the true distance.\nFor instance, a delivery company that delivers 10,000 packages would\ncompute a distance matrix that captures the distance between every\npair of destination locations to plan the routes.  Computing such a\ndistance matrix requires one hundred million network distance queries.\nNote that Google Distance Matrix offers an API to compute the distance\nmatrix but limits the service, even to their paying customers, to 25\nby 25 matrices (i.e., 625 distance computations).  What is needed is a\nframework to perform tens of millions of distance computations on road\nnetworks quickly so that we can cater to the requirements of delivery\ncompanies such as Amazon Fresh, Google Express, Uber Rush etc., that\nseek to respond quickly to the dynamic supply-demand arising in their\nbusiness.\n\nThe majority of existing shortest distance methods on road networks\nfocus mainly on decreasing the latency time for a single shortest path\nquery.  However, reviewing spatial analytical queries in the business\nenvironment reveals that what is really needed is an increase in\nthroughput which is the total time needed to compute millions of\npair-wise network distances.  Thus we are interested in the average\nnumber of distance computations per second.\n\nWe developed a distributed framework called SPDO (pronounced\n\"speedo\" standing for \"Spark and Distance Oracles\" using Apache Spark\nthat is optimized for high-throughput network distance computations.\nThis work extends our prior award-winning (one of the best papers in\nthe 2009 ICDE Conference) research on the epsilon-Distance Oracle\nwhich precomputes and stores the shortest distances between all pairs of\nvertices in a road network.  The resulting representation takes uses\nO(n/epsilon^2) space, where n is the number of vertices in the road\nnetwork and epsilon is an approximation error bound on the result.\nIn our previous work we showed how to map the instance oracle\nrepresentation to an RDBMS system and how to use it to solve complex\nanalytical queries on a road network.  We showed how to map distance\noracles to a distributed key-value store (i.e., hash abstraction)\nwhich we choose to be Spark.  Combining Spark and distance oracles is\na good match.  In essence, Spark provides a highly scalable\nfault-tolerant distributed framework with the ability to cache large\ndatasets in memory using RDD, while distance oracles provide a compact\nrepresentation of network distances that requires very little\ncomputation at run-time.  Furthermore, Spark is a popular open-source\ndistributed framework for general purposes, which is more than a\nkey-value store.  We can easily develop functions in Spark combining\ndistance oracles and other techniques that are not efficient in a\nkey-value store. In particular, we use the IndexedRDD library on Spark\nwhich is a memory resident, key-value store.  The high-throughput of\nour proposed framework is achieved due to the ability to spread query\nprocessing across multi-machines in a Spark cluster as well as the\nin-memory representation of distance oracles.\n\nThe main contributions of our work are:  1) a high-throughput\narchitecture using distance oracles and Spark for a large set of\nspatial analytical queries; 2) three variants of distributed key-value\nalgorithms for our architecture; 3) an analysis of the time and space\ncomplexity of our methods, and 4) a detailed comparison with\nstate-of-the-art methods for realistic datasets and applications.\nIt is important to note that SPDO needs just a few lines of code in\norder to be incorporated into an existing Spark project that needs to\ncompute large number of network distances.  Our experiments showed\nthat SPDO is able to compute more than 200K distance computations/sec\nper machine for the entire USA road network which contains\napproximately 24 million vertices.  In contrast, CH, one of the\nfastest state of the art latency methods, can perform at most on\nthe order of 1K distance computations/sec per machine, which is at\nleast two orders of magnitude slower than what is achievable using our\napproach.  A paper describing this research appears in the Proceedings\nof the 2016 IEEE International Conference on Data Engineering in\nHelsinki, Finland.\n\nSome other outcomes of our research were:\n\n1.  Commercial air traffic is undergoing unprecedented growth.\nCurrently airspace capacity and efficiency is approached\ndeterministically.  We have been taking external operational\ncircumstances into account.  We believe that a major factor in\nincreased airspace efficiency and capacity is the accurate prediction\nof Estimated Time of Arrival (ETA) and have devised a novel\nETA Prediction System for commercial flights.\n\n2.  The news business is rapidly changing as more and more newspapers\nhave online editions and its hard to wean readers from a model where\nthe news is free to one requiring payment.  The decreasing revenues\nmean that the number of reporters is being reduced which has an effect\nin less reporting on local events.  On the other hand, people are\ntweeting about local events.  We have devised ways of detecting such\ntweets out of the large number that are being sent.\n\n3.  We created a blog RoadsInDB.com which shows how to incorporate our\nwork on computing road notwork distance into a database and pose\nspatial analytical queries.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/05/2018\n\n\t\t\t\t\tSubmitted by: Hanan Samet"
 }
}