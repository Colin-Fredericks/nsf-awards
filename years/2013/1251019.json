{
 "awd_id": "1251019",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Small: DCM: DA: Building a Mergeable and Interactive Distributed Data Layer for Big Data Summarization Systems",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 685380.0,
 "awd_amount": 701386.0,
 "awd_min_amd_letter_date": "2013-09-09",
 "awd_max_amd_letter_date": "2014-04-02",
 "awd_abstract_narration": "Big data today is stored in a distributed fashion across many different machines or data sources. This poses new algorithmic and system challenges to performing efficient analysis on the full data set.  To address these difficulties, the PIs are building the MIDDLE (Mergeable and Interactive Distributed Data LayEr) Summarization System and deploying it on large real-world datasets. The MIDDLE system builds and maintains a special class of summaries that can be efficiently constructed and updated while still allowing fine-grained analysis on the heavy tail. Mergeable summaries can represent any data set with a guaranteed tradeoff between size and accuracy, and any two such summaries can be merged to create a new summary with the same size-accuracy tradeoff.\r\n\r\nInteractive summaries can be quickly adapted to a specified query range of data while maintaining the same size-accuracy tradeoffs relative to the data in that range. This allows accurate efficient analysis to zero-in on small subsets of big data.\r\nThe MIDDLE system enables different big data users to develop a wide spectrum of efficient and scalable data analytic tasks through the use of data summaries. The MIDDLE system is being evaluated and refined with the aid of domain experts. Since the prospect of data-summary-based analytics becoming a part of standard techniques in processing big data is tantalizing, this research generates broader impacts on the nation's government agencies, research institutes, education system, and high-tech industries. Our broad impacts also extend to academia and community outreach, through the design and development big data curriculum and education, and the involvement of general public in understanding and using big data through concise summaries.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Feifei",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Feifei Li",
   "pi_email_addr": "lifeifei@cs.utah.edu",
   "nsf_id": "000598994",
   "pi_start_date": "2013-09-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jeff",
   "pi_last_name": "Phillips",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jeff M Phillips",
   "pi_email_addr": "jeffp@cs.utah.edu",
   "nsf_id": "000610188",
   "pi_start_date": "2013-09-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "School of Computing, University of Utah",
  "perf_str_addr": "50 S. Central Campus Drive",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841129249",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "807400",
   "pgm_ele_name": "EarthCube"
  },
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 685380.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 16006.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Big data today is stored in a distributed fashion across many different machines or data sources. This poses new algorithmic and system challenges to performing efficient analysis on the full data set. This porject focused on designing and implementing a class of summaries that can be efficiently constructed and updated while still allowing fine-grained analysis on the heavy tail. </span></p>\n<p>In particular, two types of data summaries were explored and produced in this project: mergeable summaries can represent any data set with a guaranteed tradeoff between size and accuracy, and any two such summaries can be merged to create a new summary with the same size-accuracy tradeoff;&nbsp;Interactive summaries can be quickly adapted to a specified query range of data while maintaining the same size-accuracy tradeoffs relative to the data in that range. This allows accurate efficient analysis to zero-in on small subsets of big data.</p>\n<p>More specifically, this project developed much of the analysis, extensions, and code for the Frequent Directions matrix summary.&nbsp; This is a data-dependent summary of matrix data, that arises from a variety of complex data analysis settings, from recommendation systems to image analysis to tracking of website interactions.&nbsp; This sketch mimics the properties of the well-known principal component analysis (PCA) technique, except that it can be maintained in a stream of data without requiring storing the entire data set, or spending much time to update.&nbsp; It is also mergeable, in that two sketches from different data sources can be combined into a single one without any loss in accuracy.&nbsp; Moreover, this sketch is significantly more accurate than randomized data-oblivious sketches, which use random sampling or random hashing techniques.&nbsp; Specifically, this project has developed tight analysis bounds for this sketch, practical variants which roughly match popular heuristic without error guarantees, sparse data settings where most matrix entrees are zeros, and to kernelized version of PCA. This project also explored other types of data summaries for other complex data types and operations, such as data summaries for supporting similarity search operations on large data.&nbsp;</p>\n<p>This project produced a long list of publications at high impact venues. A complete list of publications is to be found at the following&nbsp;project website:&nbsp;http://datagroup.cs.utah.edu/project_detail.php?projectID=40. The results of this project have also been integrated into the curriculum of the data track and the big data certificate program at the School of Computing, University of Utah; many materials are publicly available online&nbsp;via the UoU&nbsp;Data channel on YouTube:&nbsp;https://www.youtube.com/channel/UCDUS80bdunpmvWVPyFRPqFQ</p>\n<p>A number of open source libraries were also released, that contain the implementation of the various data summaries designed and produced by the research of this project. The links to these open source libraries can be found in annual reports associated with the&nbsp;project.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/25/2017<br>\n\t\t\t\t\tModified by: Feifei&nbsp;Li</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nBig data today is stored in a distributed fashion across many different machines or data sources. This poses new algorithmic and system challenges to performing efficient analysis on the full data set. This porject focused on designing and implementing a class of summaries that can be efficiently constructed and updated while still allowing fine-grained analysis on the heavy tail. \n\nIn particular, two types of data summaries were explored and produced in this project: mergeable summaries can represent any data set with a guaranteed tradeoff between size and accuracy, and any two such summaries can be merged to create a new summary with the same size-accuracy tradeoff; Interactive summaries can be quickly adapted to a specified query range of data while maintaining the same size-accuracy tradeoffs relative to the data in that range. This allows accurate efficient analysis to zero-in on small subsets of big data.\n\nMore specifically, this project developed much of the analysis, extensions, and code for the Frequent Directions matrix summary.  This is a data-dependent summary of matrix data, that arises from a variety of complex data analysis settings, from recommendation systems to image analysis to tracking of website interactions.  This sketch mimics the properties of the well-known principal component analysis (PCA) technique, except that it can be maintained in a stream of data without requiring storing the entire data set, or spending much time to update.  It is also mergeable, in that two sketches from different data sources can be combined into a single one without any loss in accuracy.  Moreover, this sketch is significantly more accurate than randomized data-oblivious sketches, which use random sampling or random hashing techniques.  Specifically, this project has developed tight analysis bounds for this sketch, practical variants which roughly match popular heuristic without error guarantees, sparse data settings where most matrix entrees are zeros, and to kernelized version of PCA. This project also explored other types of data summaries for other complex data types and operations, such as data summaries for supporting similarity search operations on large data. \n\nThis project produced a long list of publications at high impact venues. A complete list of publications is to be found at the following project website: http://datagroup.cs.utah.edu/project_detail.php?projectID=40. The results of this project have also been integrated into the curriculum of the data track and the big data certificate program at the School of Computing, University of Utah; many materials are publicly available online via the UoU Data channel on YouTube: https://www.youtube.com/channel/UCDUS80bdunpmvWVPyFRPqFQ\n\nA number of open source libraries were also released, that contain the implementation of the various data summaries designed and produced by the research of this project. The links to these open source libraries can be found in annual reports associated with the project.\n\n\t\t\t\t\tLast Modified: 11/25/2017\n\n\t\t\t\t\tSubmitted by: Feifei Li"
 }
}