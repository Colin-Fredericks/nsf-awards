{
 "awd_id": "1337531",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MRI: Acquisition of a Motion Capture System to Facilitate Multidisciplinary Research Efforts and Enhance Undergraduate Research Training",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Joanne Culbertson",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 114039.0,
 "awd_amount": 114039.0,
 "awd_min_amd_letter_date": "2013-07-28",
 "awd_max_amd_letter_date": "2013-07-28",
 "awd_abstract_narration": "This Major Research Instrumentation (MRI) grant supports the acquisition of a motion capture system for the accurate spatial tracking of small markers that researchers attach to humans, robots, or other moving objects.  The instrumentation's high-accuracy and fast capture rate allows dynamic models to be applied to human movements and allows precise tracking of small, fast motions, such as with the fingers.  With this tracking capability, researchers can make biomechanical and neuromechanical inferences about human interactions with objects during real-world tasks and workplace jobs.\r\n\r\nThe instrument will be used by junior faculty in three departments and will expand existing research capacity in the overlapping areas of ergonomics and human factors, haptics, robotics, and computer science.  The instrumentation will also enhance research leading to the development and evaluation of autonomous robotic vehicle localization, targeting, and navigation systems and marker-less motion capture devices by providing a validated, standard benchmarking tool.  Finally, the instrumentation will be used to evaluate effects of equipment design on climbing behavior and human responses to vertical balance perturbations. This research will help to inform design guidelines and best use practices for emerging computing technologies and workplace equipment to increase user productivity, comfort, and safety. The instrumentation will also increase research opportunities for undergraduate students, support new laboratory classroom exercises and enrich STEM recruiting and outreach efforts.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Justin",
   "pi_last_name": "Young",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Justin Young",
   "pi_email_addr": "jyoung@kettering.edu",
   "nsf_id": "000637614",
   "pi_start_date": "2013-07-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Terri",
   "pi_last_name": "Lynch-Caris",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Terri Lynch-Caris",
   "pi_email_addr": "tlynch@kettering.edu",
   "nsf_id": "000324424",
   "pi_start_date": "2013-07-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mehrdad",
   "pi_last_name": "Zadeh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mehrdad Zadeh",
   "pi_email_addr": "mzadeh@kettering.edu",
   "nsf_id": "000545749",
   "pi_start_date": "2013-07-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Girma",
   "pi_last_name": "Tewolde",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Girma Tewolde",
   "pi_email_addr": "gtewolde@kettering.edu",
   "nsf_id": "000547962",
   "pi_start_date": "2013-07-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Giuseppe",
   "pi_last_name": "Turini",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Giuseppe Turini",
   "pi_email_addr": "gturini@kettering.edu",
   "nsf_id": "000643034",
   "pi_start_date": "2013-07-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Kettering University",
  "inst_street_address": "1700 University Ave",
  "inst_street_address_2": "",
  "inst_city_name": "Flint",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "8107629677",
  "inst_zip_code": "485046214",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "MI08",
  "org_lgl_bus_name": "KETTERING UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "C8K8EGHC6CW9"
 },
 "perf_inst": {
  "perf_inst_name": "Kettering University",
  "perf_str_addr": "1700 University Ave",
  "perf_city_name": "Flint",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "485046214",
  "perf_ctry_code": "US",
  "perf_cong_dist": "08",
  "perf_st_cong_dist": "MI08",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "118900",
   "pgm_ele_name": "Major Research Instrumentation"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 114039.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Kettering University&rsquo;s acquisition of a high-accuracy, three-dimensional motion capture system has enabled several collaborative research projects in the overlapping areas of ergonomics and human factors, haptics, robotics, and computer science.&nbsp; The acquisition has been vital to several different research efforts thus far.&nbsp; For example, the instrument has been used to:</p>\n<ul>\n<li>Implement touchless gestural computing control interfaces where users can control typical computing functions by moving their arms and fingers without the need for touching other input devices.&nbsp; This research evaluates how best to design these controls, their software optimizations, and supporting office furniture paradigms in order to overcome ergonomic and usability issues for future computing environments.</li>\n<li>Develop haptic guidance algorithms for medical students learning how to perform laparoscopic surgery. This project aims to use haptic feedback to help novice trainees move their upper limbs and surgical instruments as an expert surgeon would do, thus reducing training time and improving performance.</li>\n<li>Validate quality and accuracy of autonomous mobile robot indoor localization algorithms.&nbsp; </li>\n</ul>\n<p>These research projects have supported 15 undergraduate and master&rsquo;s students and resulted in over 12 conference presentations and 3 Master&rsquo;s theses thus far.&nbsp; The instrument will continue to support these research avenues, in addition to bolstering future projects in the areas of virtual/augmented reality interaction and design of climbing structures and handholds to prevent falls from ladders and in bathrooms.</p>\n<p>In addition to research, the motion tracking system has significantly enhanced Kettering Univeristy's undergraduate learning and outreach programs to neighboring communities.&nbsp; Learning modules utilizing the instrument have been developed and integrated into 7 different university courses spanning Computer Science, Industrial &amp; Manufacturing Engineering, and Electrical and Computer Engineering majors.&nbsp; Furthermore, each year 30+ female high school students participate in a 2-week residential STEM camp at Kettering University called the Lives Improved Through Engineering (LITE) Program.&nbsp; In multiple sessions, these young women use the motion tracking system to collect and analyze upper body movements in order to determine the best tools and techniques for simulated assembly line workers.&nbsp; By having this state-of-the-art instrumentation available for young minds to touch and experience, we hope to show that engineering and technology research is accessible and encourage more female students to pursue STEM degrees.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2015<br>\n\t\t\t\t\tModified by: Justin&nbsp;Young</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2015/1337531/1337531_10261978_1448894759906_IMG_9800--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2015/1337531/1337531_10261978_1448894759906_IMG_9800--rgov-800width.jpg\" title=\"Touchless Gestural Computer Interfaces\"><img src=\"/por/images/Reports/POR/2015/1337531/1337531_10261978_1448894759906_IMG_9800--rgov-66x44.jpg\" alt=\"Touchless Gestural Computer Interfaces\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A study participant navigates a shopping website using touchless gestural controls and a prototype office chair armrest.  T...",
  "por_txt_cntn": "\nKettering University\u00c6s acquisition of a high-accuracy, three-dimensional motion capture system has enabled several collaborative research projects in the overlapping areas of ergonomics and human factors, haptics, robotics, and computer science.  The acquisition has been vital to several different research efforts thus far.  For example, the instrument has been used to:\n\nImplement touchless gestural computing control interfaces where users can control typical computing functions by moving their arms and fingers without the need for touching other input devices.  This research evaluates how best to design these controls, their software optimizations, and supporting office furniture paradigms in order to overcome ergonomic and usability issues for future computing environments.\nDevelop haptic guidance algorithms for medical students learning how to perform laparoscopic surgery. This project aims to use haptic feedback to help novice trainees move their upper limbs and surgical instruments as an expert surgeon would do, thus reducing training time and improving performance.\nValidate quality and accuracy of autonomous mobile robot indoor localization algorithms.  \n\n\nThese research projects have supported 15 undergraduate and master\u00c6s students and resulted in over 12 conference presentations and 3 Master\u00c6s theses thus far.  The instrument will continue to support these research avenues, in addition to bolstering future projects in the areas of virtual/augmented reality interaction and design of climbing structures and handholds to prevent falls from ladders and in bathrooms.\n\nIn addition to research, the motion tracking system has significantly enhanced Kettering Univeristy's undergraduate learning and outreach programs to neighboring communities.  Learning modules utilizing the instrument have been developed and integrated into 7 different university courses spanning Computer Science, Industrial &amp; Manufacturing Engineering, and Electrical and Computer Engineering majors.  Furthermore, each year 30+ female high school students participate in a 2-week residential STEM camp at Kettering University called the Lives Improved Through Engineering (LITE) Program.  In multiple sessions, these young women use the motion tracking system to collect and analyze upper body movements in order to determine the best tools and techniques for simulated assembly line workers.  By having this state-of-the-art instrumentation available for young minds to touch and experience, we hope to show that engineering and technology research is accessible and encourage more female students to pursue STEM degrees.\n\n\t\t\t\t\tLast Modified: 11/30/2015\n\n\t\t\t\t\tSubmitted by: Justin Young"
 }
}