{
 "awd_id": "1309665",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research:   Renyi Divergence-based Robust Inference in Regression, Time Series and Association Studies.",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2013-07-15",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 75999.0,
 "awd_amount": 75999.0,
 "awd_min_amd_letter_date": "2013-07-24",
 "awd_max_amd_letter_date": "2013-07-24",
 "awd_abstract_narration": "This collaborative research project focuses on developing a novel approach to dimension reduction in regression, time series, and multivariate association studies based on a family of R\u00e9nyi divergences, with a central theme of providing estimators that are inherently robust to data contamination, sustaining only a minimal loss in efficiency. This family not only characterizes the conditional independence underlying the concept of sufficient dimension reduction in regression and time series, but also characterizes independence between canonical variates in multivariate association studies. The novelty of the approach lies in exploiting a tuning parameter of the family, which balances the efficiency and the degree of robustness of the estimators. In each of the three areas, this project focuses on investigating a host of issues such as: (i) the computation of estimates, (ii) the detection of the true dimension, (iii) the selection of an optimal tuning parameter, and (iv) a formal justification of the method via theory. Furthermore, the project focuses on carrying out an in-depth study of robustness via influence functions and sample/empirical influence functions. Finally, the project focuses on finding an optimal R\u00e9nyi divergence measure that is both robust and efficient, without the need for prior outlier detection or removal. \r\n\r\nRapid advances in technology have led to an information overload in most sciences. A typical characteristic of many contemporary datasets is that they are relatively high-dimensional in nature. This has prompted a shift in the applied sciences toward a different relationship-study genre arising in regression, time series and multivariate association, popularly known as dimension reduction, whose goal is to reduce the dimensionality of the variables as a first phase in the data analysis. However, the presence of outliers in high-dimensional datasets adversely affects the performance of existing dimension reduction methodologies, resulting in conclusions that are not completely reliable. Given that outliers are commonly encountered in high-dimensional datasets and that their presence is hard to detect, there is an urgent need to identify dimension reduction methods that possess some degree of automatic robustness, or non-sensitivity, to outliers. The proposed project provides robust dimension reduction methods, which would contribute significantly to the analysis of high-dimensional data arising in fields such as the social sciences, machine learning, sports, economics, environmental studies, morphometrics and cancer studies, among others. In fact, this project will not only provide novel tools for scientists in various disciplines to obtain reliable conclusions on high-dimensional data analysis, but also significantly advance the statistical theory, thereby paving a new research path in dimension reduction.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tharuvai",
   "pi_last_name": "Sriram",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Tharuvai N Sriram",
   "pi_email_addr": "tn@stat.uga.edu",
   "nsf_id": "000319524",
   "pi_start_date": "2013-07-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Georgia Research Foundation Inc",
  "inst_street_address": "310 E CAMPUS RD RM 409",
  "inst_street_address_2": "",
  "inst_city_name": "ATHENS",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "7065425939",
  "inst_zip_code": "306021589",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "GA10",
  "org_lgl_bus_name": "UNIVERSITY OF GEORGIA RESEARCH FOUNDATION, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "NMJHD63STRC5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Georgia",
  "perf_str_addr": "200 D.W. Brooks Drive",
  "perf_city_name": "Athens",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "306025016",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "GA10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 75999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Some of the most broadly used methods for statistical analysis are in the areas of regression, time series and multivariate association. Given that the response may depend on a number of predictors and the dimension of such predictors are increasing in many real datasets, it is necessary to identify a few linear combinations of the explanatory variables, which will predict the response as accurately and efficiently as all the predictors, leading to a significant reduction in the dimension of the predictors. This is commonly termed &ldquo;Dimension Reduction.&rdquo;</p>\n<p>Inherent in many datasets are outliers or extreme values, which can have a significant impact on the analysis, as many statistical methods are sensitive to such observations. Even if it is possible to detect highly influential values, the fact that these observations may genuinely be part of the dataset makes it essential to consider inherently robust methodologies. Our developed methods in the areas of regression, time series and multivariate association based on <em>R&eacute;nyi</em> and <em>Density Power Divergence</em>, enable the construction of estimators that are inherently robust to data contamination, meaning that a preliminary analysis to detect and remove outliers from a dataset is unnecessary. Importantly, our methods are able to identify both linear and nonlinear relationships that exist between random vectors.</p>\n<p>In simulation, our methods were able to accurately recover regression relationships for a variety of linear and nonlinear models, where the errors followed contaminated normal distributions with varying proportions of contamination. Importantly, the chosen simulation studies included both single and multiple index models, and the relationships between the response and the explanatory variables were linear and/or nonlinear. An example of one of the complicated nonlinear relationships studied is given in the plot below. Included was the study of the developed theoretical influence values through the sample influence functions (SIF). These influence functions measure the impact of observations on the regression analysis and used to develop methods to determine both the number of coefficient vectors needed to recover the significant relationships and the level of the most efficient tuning parameter. In general, the plot of the ordered SIF values at a level of the tuning parameter that results in the maximum area under the curve identifies the parameterization of the index least affected by extreme observations. An overlaid plot of these values for each number of estimated coefficient vectors aids in visually identifying the true number of significant relationships. Methods based on comparing the variability of these values are also used to determine the necessary number of coefficient vectors. The <em>R&eacute;nyi</em> and <em>Density Power Divergence</em> methodologies were used to analyze a hitter baseball salary dataset, which was initially presented as a data analysis exposition sponsored by the <em>American Statistical Association</em>, and recovered two significantly nonlinear relationships between baseball salaries and sixteen predominately performance based predictors in the presence of extreme observations known to exist from previous analyses. Plots of the recovered relationships are given in the second plots below for the <em>R&eacute;nyi </em>based method. In the last plot, the first 250 of the 866 ordered SIF values show the potentially most influential values in the analysis.</p>\n<p>In multivariate association studies, recently developed dimension reduction methods have focused on reducing sets of random vectors into equivalently sized dimensions. However, requiring paired dimensional subspaces can be limiting in certain settings. As an alternative to requiring a paired dimension reduction, in the recent article of Iaci, Yin and Zhu (2016) we developed a new concept, termed the Dual Central Subspaces (DCS), to produce a method for simultaneously reducing the dimensions of two sets of random vectors. The recovery of this subspace provides a new method for multivariate sufficient dimension reduction (SDR) that does not require the reduced dimensions to be paired as in standard multivariate association methodologies. Importantly, the introduction of this new methodology was necessary to provide the basis for studying the robust estimation of the DCS using both the <em>R&eacute;nyi</em> and <em>Density Power Divergences</em>. In fact, both methods can be paramterized through the tuning parameter to yield the same information based index used in the development of this new concept. &nbsp;</p>\n<h4>Related to the study of time series the recent article of Park and Sriram (2015) considered conditionally heteroskedastic time series and developed a sufficient dimension reduction (SDR) procedure that reduces the dimension in the conditional variance without assuming a specific model. Heteroskedastic time series are often encountered in the field of financial time series, where extreme values are highly likely. This work not only extends the SDR approach to include heteroskedastic time series, but also incorporates <em>the Density Power Divergence</em> to produce estimators that are automatically robust against extreme observations. Here, we developed the necessary theoretical underpinnings to validate the use of our SDR approach. This approach provides a viable, and possibly superior, alternative to the well-known ARCH/GARCH models currently used in finance.</h4><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/18/2018<br>\n\t\t\t\t\tModified by: Tharuvai&nbsp;N&nbsp;Sriram</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1309665/1309665_10260910_1526680572312_r_variate_plots_hitter_renreg_09--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1309665/1309665_10260910_1526680572312_r_variate_plots_hitter_renreg_09--rgov-800width.jpg\" title=\"Hitter's Salary Plots\"><img src=\"/por/images/Reports/POR/2018/1309665/1309665_10260910_1526680572312_r_variate_plots_hitter_renreg_09--rgov-66x44.jpg\" alt=\"Hitter's Salary Plots\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Plots 1</div>\n<div class=\"imageCredit\">Iaci & Sriram</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tharuvai&nbsp;N&nbsp;Sriram</div>\n<div class=\"imageTitle\">Hitter's Salary Plots</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1309665/1309665_10260910_1526680812494_sif_renreg_hitter_plots--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1309665/1309665_10260910_1526680812494_sif_renreg_hitter_plots--rgov-800width.jpg\" title=\"Sample Influence Function\"><img src=\"/por/images/Reports/POR/2018/1309665/1309665_10260910_1526680812494_sif_renreg_hitter_plots--rgov-66x44.jpg\" alt=\"Sample Influence Function\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Influence Function Plots</div>\n<div class=\"imageCredit\">Iaci & Sriram</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tharuvai&nbsp;N&nbsp;Sriram</div>\n<div class=\"imageTitle\">Sample Influence Function</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1309665/1309665_10260910_1526680889550_sim_4_1_data_plot_ex_n_200_95--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1309665/1309665_10260910_1526680889550_sim_4_1_data_plot_ex_n_200_95--rgov-800width.jpg\" title=\"SImulation plots\"><img src=\"/por/images/Reports/POR/2018/1309665/1309665_10260910_1526680889550_sim_4_1_data_plot_ex_n_200_95--rgov-66x44.jpg\" alt=\"SImulation plots\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Plots from Simulations</div>\n<div class=\"imageCredit\">Iaci & Sriram</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tharuvai&nbsp;N&nbsp;Sriram</div>\n<div class=\"imageTitle\">SImulation plots</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nSome of the most broadly used methods for statistical analysis are in the areas of regression, time series and multivariate association. Given that the response may depend on a number of predictors and the dimension of such predictors are increasing in many real datasets, it is necessary to identify a few linear combinations of the explanatory variables, which will predict the response as accurately and efficiently as all the predictors, leading to a significant reduction in the dimension of the predictors. This is commonly termed \"Dimension Reduction.\"\n\nInherent in many datasets are outliers or extreme values, which can have a significant impact on the analysis, as many statistical methods are sensitive to such observations. Even if it is possible to detect highly influential values, the fact that these observations may genuinely be part of the dataset makes it essential to consider inherently robust methodologies. Our developed methods in the areas of regression, time series and multivariate association based on R&eacute;nyi and Density Power Divergence, enable the construction of estimators that are inherently robust to data contamination, meaning that a preliminary analysis to detect and remove outliers from a dataset is unnecessary. Importantly, our methods are able to identify both linear and nonlinear relationships that exist between random vectors.\n\nIn simulation, our methods were able to accurately recover regression relationships for a variety of linear and nonlinear models, where the errors followed contaminated normal distributions with varying proportions of contamination. Importantly, the chosen simulation studies included both single and multiple index models, and the relationships between the response and the explanatory variables were linear and/or nonlinear. An example of one of the complicated nonlinear relationships studied is given in the plot below. Included was the study of the developed theoretical influence values through the sample influence functions (SIF). These influence functions measure the impact of observations on the regression analysis and used to develop methods to determine both the number of coefficient vectors needed to recover the significant relationships and the level of the most efficient tuning parameter. In general, the plot of the ordered SIF values at a level of the tuning parameter that results in the maximum area under the curve identifies the parameterization of the index least affected by extreme observations. An overlaid plot of these values for each number of estimated coefficient vectors aids in visually identifying the true number of significant relationships. Methods based on comparing the variability of these values are also used to determine the necessary number of coefficient vectors. The R&eacute;nyi and Density Power Divergence methodologies were used to analyze a hitter baseball salary dataset, which was initially presented as a data analysis exposition sponsored by the American Statistical Association, and recovered two significantly nonlinear relationships between baseball salaries and sixteen predominately performance based predictors in the presence of extreme observations known to exist from previous analyses. Plots of the recovered relationships are given in the second plots below for the R&eacute;nyi based method. In the last plot, the first 250 of the 866 ordered SIF values show the potentially most influential values in the analysis.\n\nIn multivariate association studies, recently developed dimension reduction methods have focused on reducing sets of random vectors into equivalently sized dimensions. However, requiring paired dimensional subspaces can be limiting in certain settings. As an alternative to requiring a paired dimension reduction, in the recent article of Iaci, Yin and Zhu (2016) we developed a new concept, termed the Dual Central Subspaces (DCS), to produce a method for simultaneously reducing the dimensions of two sets of random vectors. The recovery of this subspace provides a new method for multivariate sufficient dimension reduction (SDR) that does not require the reduced dimensions to be paired as in standard multivariate association methodologies. Importantly, the introduction of this new methodology was necessary to provide the basis for studying the robust estimation of the DCS using both the R&eacute;nyi and Density Power Divergences. In fact, both methods can be paramterized through the tuning parameter to yield the same information based index used in the development of this new concept.  \nRelated to the study of time series the recent article of Park and Sriram (2015) considered conditionally heteroskedastic time series and developed a sufficient dimension reduction (SDR) procedure that reduces the dimension in the conditional variance without assuming a specific model. Heteroskedastic time series are often encountered in the field of financial time series, where extreme values are highly likely. This work not only extends the SDR approach to include heteroskedastic time series, but also incorporates the Density Power Divergence to produce estimators that are automatically robust against extreme observations. Here, we developed the necessary theoretical underpinnings to validate the use of our SDR approach. This approach provides a viable, and possibly superior, alternative to the well-known ARCH/GARCH models currently used in finance.\n\n\t\t\t\t\tLast Modified: 05/18/2018\n\n\t\t\t\t\tSubmitted by: Tharuvai N Sriram"
 }
}