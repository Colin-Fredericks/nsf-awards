{
 "awd_id": "1343544",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "INSPIRE Track 1:  Action, Vision and Language, and their Brain Mechanisms in Evolutionary Relationship",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2019-12-31",
 "tot_intn_awd_amt": 800000.0,
 "awd_amount": 800000.0,
 "awd_min_amd_letter_date": "2013-09-10",
 "awd_max_amd_letter_date": "2018-10-22",
 "awd_abstract_narration": "This INSPIRE award is partially funded by the Perception, Action, and Cognition Program in the Division of Behavioral and Cognitive Sciences in the Directorate for Social, Behavioral, and Economic Sciences and the Robust Intelligence Program in the Division of Information and Intelligent Systems in the Directorate of Computer and Information Science and Engineering.\r\n\r\nThis research will address and bridge two grand challenges: (1) To understand how action, perception, and social interaction were supported by the brain of the last common ancestor of macaque and human, complementing modeling elsewhere on great apes, and (2) To build on evolutionary insights to better understand how different parts of the human brain work together when we use language.   Key entry points will be signed and spoken languages and the use of hand gestures (e.g., novel hand gestures by apes) to convey meaning. Going further, a particular focus will be on systems that link the brain's capacities to generate as well as recognize actions, and their interactions with other brain systems. \r\n\r\nAn international group of scientists in linguistics, primatology, neuroanatomy, neurophysiology, and  neurocomputational modeling of motor, cognitive and language processes will pool data on the anatomy, physiology, behavior and communication of the various primate species. To support this extended collaboration, the researchers will build a novel online collaborative environment (\"Collaboratory Workspaces\") to test, make predictions, and challenge both the modeling and experimentation. This infrastructure may catalyze a new style of collaboration between modelers, experimentalists, and clinicians. \r\n\r\nThe research also has the potential to support modeling of the damage that results in the clinical disorders of apraxia and aphasia. Integration of models of vision, action and language is also important for creating robots that can flexibly and usefully interact with individual people and for \"neuromorphic architecture,\" in which a building's sensors and action systems adaptively adjust to the human inhabitants.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Arbib",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Michael A Arbib",
   "pi_email_addr": "arbib@usc.edu",
   "nsf_id": "000100552",
   "pi_start_date": "2013-09-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3720 S. Flower St.",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900070701",
  "perf_ctry_code": "US",
  "perf_cong_dist": "34",
  "perf_st_cong_dist": "CA34",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  },
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "807800",
   "pgm_ele_name": "INSPIRE"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8653",
   "pgm_ref_txt": "INSPIRE Track-1 Creative"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 667000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 133000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In the years leading up to the work covered by this grant, PI Michael Arbib worked with neuropsychologists and neuroscientists to probe the ways in which the brain coordinates eye and hand. Specifically, Arbib?s group developed computational models to integrate findings on human behavior and brain imaging in both normal and brain-damaged subjects, and neuron activity recorded in alert, behaving macaque monkeys. Giacomo Rizzolatti?s group in Parma discovered mirror neurons in the macaque brain, neurons active both when the monkey observes a specific class of actions and when &nbsp;it observes someone else performing other actions. Arbib?s group developed the first computational model of mirror neurons and showed their activity depended on interaction with brain systems ?beyond the mirror? and their properties were established through learning. Our brain imaging established a similar ?mirror system for hand movements? in the human brain, and that it overlapped Broca?s area, an area long implicated in human speech production. This led us to publish highly influential papers suggesting that this showed that hand movements and gesture were essential in the evolution of language, with mirror neurons supporting evolution of the ability not only to produce words (spoken or signed) but also to recognize them when produced by others.</p>\n<p>All this laid the basis for the research conducted under the INSPIRE funding:</p>\n<p>&nbsp;a) We developed computational models of the neural networks involved in further properties of mirror systems. In particular, we showed their relevance to the individual?s skill learning, complementing their role in social interaction.</p>\n<p>b) We established the methodology of ?dyadic brain modeling,? where we model a result of the interactions. In particular, we showed how two apes could create and use novel gestures through a process of ?ontogenetic ritualization? whereby a string of behavior used to get a conspecific to behave in a desired way becomes reduced to a single communicative gesture with the same effect.</p>\n<p>c) We also modeled sequential behavior in monkeys and apes as part of developing a new field of ?comparative computational neuroprimatology? informed by comparative data on brain, behavior and/or social interaction in monkeys, apes and humans. To support this effort, we built an international consortium to test, provide feedback, and apply these ideas under the banner of the ABLE Project, with ABLE standing for Action, Brain, Language and Evolution.</p>\n<p>d) We extended our Brain Operation Database (BODB), developed under earlier NSF funding, to support interactions between experimentalists (e.g., in neuroscience, primatology and linguistics) and computational modelers (computational neuroscience, AI, robotics). Additional work yielded a prototype for a database for primatological behavior and gesture (GBDB: Gesture and Behavior Database).</p>\n<p>e) Evolution of the Language-ready Brain: We used the computational comparative neuroprimatology of monkey, ape and human to develop hypotheses about brain and behavior in LCA-m (the last common ancestor of macaque and human; c. 25 Mya) and LCA-c (the last common ancestor of chimpanzee and human; c. 5-7 Mya), and in the biological and cultural evolution LCA-m -&gt; LCA-c -&gt; <em>Homo sapiens. </em>We developed the thesis that complex imitation and pantomime played a crucial role, and that early humans had protolanguage but not language. We explored how cultural evolution may have supported the emergence of language. To complement the work based on modeling the brains of monkeys and apes to gain hypotheses on LCA-m and LCA-c and their evolutionary relationship, we also developed a neurolinguistic model, using the description of visual scenes to link studies of human brain-language correlates to the established study of brain mechanisms of visual perception. The resultant models of production and comprehension offered new insights into the phenomenon of agrammatism, where specific brain lesions may impair the use of grammar in producing and understanding sentences.</p>\n<p>f) A relatively new research area complements the above work ? exploring the linkage between neuroscience and study of the built environment: For example, we are exploring the implications of our account of the evolution of the language-ready brain for an account of brain mechanisms that support sketching in 2D and 3D and their implications for architectural design. Another study updates our earlier modeling of visual perception and the role of hippocampus in spatial navigation and in episodic memory (wayfinding in time) to offer a new account of how systems integrated with the hippocampus may integrate memory and imagination. We then use this account to analyze case studies of architectural design, such as J?rn Utzon?s Sydney Opera House and Frank Gehry?s Bilbao Guggenheim Museum. The current phase of this work (ongoing after INSPIRE funding) will culminate with publication of the book <em>When Brains Meet Buildings: A Conversation between Neuroscience and Architecture </em>by Oxford University Press in 2021.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/29/2020<br>\n\t\t\t\t\tModified by: Michael&nbsp;A&nbsp;Arbib</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1343544/1343544_10277755_1583013641895_Figure2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1343544/1343544_10277755_1583013641895_Figure2--rgov-800width.jpg\" title=\"Dyadic Brain Modeling 1\"><img src=\"/por/images/Reports/POR/2020/1343544/1343544_10277755_1583013641895_Figure2--rgov-66x44.jpg\" alt=\"Dyadic Brain Modeling 1\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Conceptual framework for modeling brain changes due to learning as 2 apes interact</div>\n<div class=\"imageCredit\">Arbib, Ganesh & Gasser 2014</div>\n<div class=\"imageSubmitted\">Michael&nbsp;A&nbsp;Arbib</div>\n<div class=\"imageTitle\">Dyadic Brain Modeling 1</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1343544/1343544_10277755_1583014462058_20151018_150455--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1343544/1343544_10277755_1583014462058_20151018_150455--rgov-800width.jpg\" title=\"When Brains Meet Buildings\"><img src=\"/por/images/Reports/POR/2020/1343544/1343544_10277755_1583014462058_20151018_150455--rgov-66x44.jpg\" alt=\"When Brains Meet Buildings\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An unusual sculpture in Berlin in 2015 that whimisically but non-scientifically illustrates the theme \"When Brains Meet Buildings.\"</div>\n<div class=\"imageCredit\">Michael A. Arbib</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Michael&nbsp;A&nbsp;Arbib</div>\n<div class=\"imageTitle\">When Brains Meet Buildings</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nIn the years leading up to the work covered by this grant, PI Michael Arbib worked with neuropsychologists and neuroscientists to probe the ways in which the brain coordinates eye and hand. Specifically, Arbib?s group developed computational models to integrate findings on human behavior and brain imaging in both normal and brain-damaged subjects, and neuron activity recorded in alert, behaving macaque monkeys. Giacomo Rizzolatti?s group in Parma discovered mirror neurons in the macaque brain, neurons active both when the monkey observes a specific class of actions and when  it observes someone else performing other actions. Arbib?s group developed the first computational model of mirror neurons and showed their activity depended on interaction with brain systems ?beyond the mirror? and their properties were established through learning. Our brain imaging established a similar ?mirror system for hand movements? in the human brain, and that it overlapped Broca?s area, an area long implicated in human speech production. This led us to publish highly influential papers suggesting that this showed that hand movements and gesture were essential in the evolution of language, with mirror neurons supporting evolution of the ability not only to produce words (spoken or signed) but also to recognize them when produced by others.\n\nAll this laid the basis for the research conducted under the INSPIRE funding:\n\n a) We developed computational models of the neural networks involved in further properties of mirror systems. In particular, we showed their relevance to the individual?s skill learning, complementing their role in social interaction.\n\nb) We established the methodology of ?dyadic brain modeling,? where we model a result of the interactions. In particular, we showed how two apes could create and use novel gestures through a process of ?ontogenetic ritualization? whereby a string of behavior used to get a conspecific to behave in a desired way becomes reduced to a single communicative gesture with the same effect.\n\nc) We also modeled sequential behavior in monkeys and apes as part of developing a new field of ?comparative computational neuroprimatology? informed by comparative data on brain, behavior and/or social interaction in monkeys, apes and humans. To support this effort, we built an international consortium to test, provide feedback, and apply these ideas under the banner of the ABLE Project, with ABLE standing for Action, Brain, Language and Evolution.\n\nd) We extended our Brain Operation Database (BODB), developed under earlier NSF funding, to support interactions between experimentalists (e.g., in neuroscience, primatology and linguistics) and computational modelers (computational neuroscience, AI, robotics). Additional work yielded a prototype for a database for primatological behavior and gesture (GBDB: Gesture and Behavior Database).\n\ne) Evolution of the Language-ready Brain: We used the computational comparative neuroprimatology of monkey, ape and human to develop hypotheses about brain and behavior in LCA-m (the last common ancestor of macaque and human; c. 25 Mya) and LCA-c (the last common ancestor of chimpanzee and human; c. 5-7 Mya), and in the biological and cultural evolution LCA-m -&gt; LCA-c -&gt; Homo sapiens. We developed the thesis that complex imitation and pantomime played a crucial role, and that early humans had protolanguage but not language. We explored how cultural evolution may have supported the emergence of language. To complement the work based on modeling the brains of monkeys and apes to gain hypotheses on LCA-m and LCA-c and their evolutionary relationship, we also developed a neurolinguistic model, using the description of visual scenes to link studies of human brain-language correlates to the established study of brain mechanisms of visual perception. The resultant models of production and comprehension offered new insights into the phenomenon of agrammatism, where specific brain lesions may impair the use of grammar in producing and understanding sentences.\n\nf) A relatively new research area complements the above work ? exploring the linkage between neuroscience and study of the built environment: For example, we are exploring the implications of our account of the evolution of the language-ready brain for an account of brain mechanisms that support sketching in 2D and 3D and their implications for architectural design. Another study updates our earlier modeling of visual perception and the role of hippocampus in spatial navigation and in episodic memory (wayfinding in time) to offer a new account of how systems integrated with the hippocampus may integrate memory and imagination. We then use this account to analyze case studies of architectural design, such as J?rn Utzon?s Sydney Opera House and Frank Gehry?s Bilbao Guggenheim Museum. The current phase of this work (ongoing after INSPIRE funding) will culminate with publication of the book When Brains Meet Buildings: A Conversation between Neuroscience and Architecture by Oxford University Press in 2021.\n\n\t\t\t\t\tLast Modified: 02/29/2020\n\n\t\t\t\t\tSubmitted by: Michael A Arbib"
 }
}