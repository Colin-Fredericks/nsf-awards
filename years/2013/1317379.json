{
 "awd_id": "1317379",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: Small: Modeling, Quantification, and Optimization of Prosthesis-User Interface",
 "cfda_num": "47.041",
 "org_code": "07020000",
 "po_phone": "7032922895",
 "po_email": "cpayne@nsf.gov",
 "po_sign_block_name": "Christina Payne",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 999900.0,
 "awd_amount": 999900.0,
 "awd_min_amd_letter_date": "2013-08-27",
 "awd_max_amd_letter_date": "2014-01-22",
 "awd_abstract_narration": "PI: Sensinger, J. W.; Hargrove, L.; and Kording, K. P.\r\nProposal Number: 1317379\r\n\r\nProblem Description: Better robotic prostheses can dramatically improve the quality of life for the more than 40,000 Americans with an upper limb amputation, many of whom reject existing devices because they have trouble controlling them in the same intuitive, subconscious way that they controlled their intact arms. Prosthesis control is difficult because amputees experience great uncertainty both with respect to whether their device will respond appropriately to their control signals and whether sensory feedback cues accurately reflect the actual movement. Researchers have focused on improving isolated aspects of control, for example by improving filters or mimicking able-bodied sensory cues through haptic devices, but these approaches have minimally reduced the uncertainty of prosthesis control. Human interaction with a prosthesis is a multifaceted, time-varying problem that is difficult to solve. What is missing from robotic prosthesis research are principled methods for optimizing control strategies and sensory cues which take into account behavioral choices people are known to make in the face of high uncertainty.\r\n\r\nIntellectual Merit: The proposed research is innovative because it poses the co-robot problem in a broader context that incorporates the highly sophisticated behavioral decisions that humans make in optimizing their control strategy and sensory cues. This principled approach is able to integrate multiple effects in ways that were not possible using previous approaches. For example, the proposed approach naturally incorporates the fact that people prefer to use less exerted effort to accomplish a task, but tolerate more effort during portions of movement that require greater precision (e.g. final portion of a trajectory). On the other hand, the approach does not favor high-certainty haptic cues if those cues provide redundant information to existing sensory cues such as vision, or if the haptic information does not reduce the uncertainty of controllable system dynamics. Due to the large sources of control-signal noise present in amputees, the proposed work will lead to improved techniques within the fields of computational motor control and optimal control. This research builds on the team?s extensive experience in the design and control of upper-limb prostheses and in developing the field of computational motor control. Achievement of the proposed aims will contribute to the field of robotic control and to such diverse fields as human-robot interaction, perception, manipulation, and exoskeletons.\r\n\r\nBroader Impacts: True biomimetic prostheses, exoskeletons, and humanoid robot control will not be possible until there is a firm understanding of how humans integrate with these co-robots in the face of interacting sources of uncertainty. This computational motor project will provide transformative insight into how humans control movement in the presence of large uncertainty and thus fill a critical gap in the knowledge base of this field. The framework developed in this research will be of great interest to the motor-control research community and may be useful in the restoration of other movement disorders such as spinal cord injury and stroke. The lead institution of this proposal, the Rehabilitation Institute of Chicago (RIC), is consistently ranked the top rehabilitation hospital in the country. The close proximity of research and clinical excellence within RIC ensures that the benefits resulting from this work will be quickly disseminated to prosthesis users. The research team will also seek to reach a broader audience?the laboratories at the RIC are regularly visited by students from local high schools and universities, and the RIC also contributes to outreach activities within inner-city Chicago. These outreach programs promote an awareness of rehabilitation research and an enthusiasm for pursuing a career in engineering. Additionally, the team will develop a K-12 educational module based on the template of the successful Summer School in Computational Sensory-Motor Neuroscience developed at Northwestern University and Queen?s University, which will provide a combination of theory and student-driven experimentation using games that will address many of the Illinois Learning Standards in science, math, and English language arts.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CBET",
 "org_div_long_name": "Division of Chemical, Bioengineering, Environmental, and Transport Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Jonathon",
   "pi_last_name": "Sensinger",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Jonathon W Sensinger",
   "pi_email_addr": "j-sensinger@northwestern.edu",
   "nsf_id": "000611183",
   "pi_start_date": "2013-08-27",
   "pi_end_date": "2014-01-22"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Levi",
   "pi_last_name": "Hargrove",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Levi Hargrove",
   "pi_email_addr": "lhargrove@sralab.org",
   "nsf_id": "000611184",
   "pi_start_date": "2014-01-22",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Konrad",
   "pi_last_name": "Kording",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Konrad Kording",
   "pi_email_addr": "koerding@gmail.com",
   "nsf_id": "000096260",
   "pi_start_date": "2013-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Levi",
   "pi_last_name": "Hargrove",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Levi Hargrove",
   "pi_email_addr": "lhargrove@sralab.org",
   "nsf_id": "000611184",
   "pi_start_date": "2013-08-27",
   "pi_end_date": "2014-01-22"
  }
 ],
 "inst": {
  "inst_name": "Rehabilitation Institute of Chicago",
  "inst_street_address": "355 E ERIE ST",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3122385195",
  "inst_zip_code": "606113167",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "IL07",
  "org_lgl_bus_name": "REHABILITATION INSTITUTE OF CHICAGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "XAJWT43U55A3"
 },
 "perf_inst": {
  "perf_inst_name": "Rehabilitation Institute of Chicago",
  "perf_str_addr": "345 E. Superior Street",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606112654",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "IL05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 999900.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The way that we can move our bodies is nothing short of incredible. Coordinated movements like opening jars and using utensils can be done without really thinking about it. However, for the 40,00 Americans with an upper-limb amputation, completing these same tasks with a robotic prosthesis can be significantly more challenging. Controlling a prosthesis involves a great deal of uncertainty, both in the commands a user sends the prosthesis and subsequently how the prosthesis will respond, and in the clarity of the feedback to the user helping them understand what the prosthesis is actually doing. These uncertainties, in both outgoing control and incoming sensory signals, contribute to people rejecting robotic prostheses because they can&rsquo;t control them in the same intuitive and subconscious way they would control their intact limb.</p>\n<p>Developing solutions to these problems requires a thorough understanding of how these high uncertainties affect behavioral choices people make while controlling a prosthesis. To this end, we investigated different aspects of prosthesis control and feedback using a computational motor control approach, mathematically modeling how people behave during different scenarios to better understand how control uncertainty affects prosthesis control and how best to reduce feedback uncertainty.</p>\n<p>One critical aspect of computational motor control is the ability to make corrections. That is, how well does someone adapt their control to account for variance and errors in motor tasks? Adaptation behavior in able-bodied individuals has been extensively studied, but adaptation of people with upper-limb amputations had been largely overlooked. In our study, we demonstrated that a standard prosthesis control interface&mdash;which moves a robotic limb faster based on the user&rsquo;s muscle contraction effort, or EMG&mdash;does not result in different adaptation behavior than controlling a prosthesis using the position or torque of a limb. However, this EMG control did feature larger errors in general.&nbsp; Furthermore, we showed that artificially increasing the variability of a torque controller to match the variability of an EMG controller did not resolve this increase in error. This suggests that the outgoing control signals from the user to the prosthesis are not the main culprit behind poor prosthesis control, but instead that the feedback from the prosthesis back to the user is insufficient. To reliably improve prosthesis control, we may need to provide additional sensory feedback.</p>\n<p>When we move our intact limbs, receptors in our muscles and joints provide a sense of proprioception&mdash;the knowledge of where the limb is and how it&rsquo;s moving. This proprioception is missing from standard robotic prostheses, thus the only avenue for a user to know what their limb is doing is to visually monitor it as it moves. This results in a distinct gaze behavior, as prosthesis users must focus on their limb and divert attention from the surrounding environment or objects of interest. However, substituting an artificial sense of feedback (e.g. encoding the position of the prosthesis using audio cues or vibrating motors) may not improve control if implemented poorly. We applied a computational motor control approach to this issue by considering how artificial feedback would combine with vision to yield a single estimate of the movement of the limb. Because vision is very precise when it comes to estimating the position of objects, providing artificial feedback with much lower precision (i.e. higher uncertainty) results in the feedback being largely ignored in favor of vision. Thus, we investigated how well artificial feedback encoding the speed of a prosthetic arm fuses with visual estimates of arm speed. Our study demonstrates that vision is especially poor at determining joint speeds within a moving reference frame&mdash;for example, a robotic elbow moving while the shoulder moves. Furthermore, our work shows that audio feedback encoding the speed of the prosthetic limb improves a user&rsquo;s estimate of the limb speed. This suggests that providing this audio feedback may help prosthesis users control their devices more accurately and precisely.</p>\n<p>Taken together, these studies provide a unique insight into human motor control while using a prosthesis, a task complicated by large uncertainties in control and feedback. This understanding will help guide future prosthesis control and feedback systems with the ultimate goal of making daily tasks such as opening jars and using utensils easier for prosthesis users. These insights pertain not only to the field of robotic prostheses, but broadly contributes to the field of robotic control including human-machine interactions and exoskeletons. Finally, the framework we have developed to address these problems could be applied to other movement disorders including spinal cord injury and stroke.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2018<br>\n\t\t\t\t\tModified by: Levi&nbsp;Hargrove</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe way that we can move our bodies is nothing short of incredible. Coordinated movements like opening jars and using utensils can be done without really thinking about it. However, for the 40,00 Americans with an upper-limb amputation, completing these same tasks with a robotic prosthesis can be significantly more challenging. Controlling a prosthesis involves a great deal of uncertainty, both in the commands a user sends the prosthesis and subsequently how the prosthesis will respond, and in the clarity of the feedback to the user helping them understand what the prosthesis is actually doing. These uncertainties, in both outgoing control and incoming sensory signals, contribute to people rejecting robotic prostheses because they can?t control them in the same intuitive and subconscious way they would control their intact limb.\n\nDeveloping solutions to these problems requires a thorough understanding of how these high uncertainties affect behavioral choices people make while controlling a prosthesis. To this end, we investigated different aspects of prosthesis control and feedback using a computational motor control approach, mathematically modeling how people behave during different scenarios to better understand how control uncertainty affects prosthesis control and how best to reduce feedback uncertainty.\n\nOne critical aspect of computational motor control is the ability to make corrections. That is, how well does someone adapt their control to account for variance and errors in motor tasks? Adaptation behavior in able-bodied individuals has been extensively studied, but adaptation of people with upper-limb amputations had been largely overlooked. In our study, we demonstrated that a standard prosthesis control interface&mdash;which moves a robotic limb faster based on the user?s muscle contraction effort, or EMG&mdash;does not result in different adaptation behavior than controlling a prosthesis using the position or torque of a limb. However, this EMG control did feature larger errors in general.  Furthermore, we showed that artificially increasing the variability of a torque controller to match the variability of an EMG controller did not resolve this increase in error. This suggests that the outgoing control signals from the user to the prosthesis are not the main culprit behind poor prosthesis control, but instead that the feedback from the prosthesis back to the user is insufficient. To reliably improve prosthesis control, we may need to provide additional sensory feedback.\n\nWhen we move our intact limbs, receptors in our muscles and joints provide a sense of proprioception&mdash;the knowledge of where the limb is and how it?s moving. This proprioception is missing from standard robotic prostheses, thus the only avenue for a user to know what their limb is doing is to visually monitor it as it moves. This results in a distinct gaze behavior, as prosthesis users must focus on their limb and divert attention from the surrounding environment or objects of interest. However, substituting an artificial sense of feedback (e.g. encoding the position of the prosthesis using audio cues or vibrating motors) may not improve control if implemented poorly. We applied a computational motor control approach to this issue by considering how artificial feedback would combine with vision to yield a single estimate of the movement of the limb. Because vision is very precise when it comes to estimating the position of objects, providing artificial feedback with much lower precision (i.e. higher uncertainty) results in the feedback being largely ignored in favor of vision. Thus, we investigated how well artificial feedback encoding the speed of a prosthetic arm fuses with visual estimates of arm speed. Our study demonstrates that vision is especially poor at determining joint speeds within a moving reference frame&mdash;for example, a robotic elbow moving while the shoulder moves. Furthermore, our work shows that audio feedback encoding the speed of the prosthetic limb improves a user?s estimate of the limb speed. This suggests that providing this audio feedback may help prosthesis users control their devices more accurately and precisely.\n\nTaken together, these studies provide a unique insight into human motor control while using a prosthesis, a task complicated by large uncertainties in control and feedback. This understanding will help guide future prosthesis control and feedback systems with the ultimate goal of making daily tasks such as opening jars and using utensils easier for prosthesis users. These insights pertain not only to the field of robotic prostheses, but broadly contributes to the field of robotic control including human-machine interactions and exoskeletons. Finally, the framework we have developed to address these problems could be applied to other movement disorders including spinal cord injury and stroke.\n\n \n\n\t\t\t\t\tLast Modified: 11/29/2018\n\n\t\t\t\t\tSubmitted by: Levi Hargrove"
 }
}