{
 "awd_id": "1318955",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC TTP: Small: Mitigating Insider Attacks in Provenance Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2013-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 496066.0,
 "awd_amount": 496066.0,
 "awd_min_amd_letter_date": "2013-09-09",
 "awd_max_amd_letter_date": "2013-09-09",
 "awd_abstract_narration": "The digital provenance of a digital object gives a history of its life cycle including its creation, update, and access. It thus provides meta-level information about the sequence of events that lead up to the current version of the object, as well as its chain of custody. Such provenance information can be used for a variety of purposes, such as identifying the origins of a document, assessing the quality or reliability of data, and detecting undesirable actions such as forgery or unauthorized alteration of data. However, all of these practical uses of provenance information presuppose that the provenance system is secure, i.e. that provenance data is collected, processed, and stored in a manner that ensures its confidentiality and integrity. Without such guarantees, users can get an incorrect impression of document authenticity, potentially with significant real-world consequences.\r\n\r\nThis project investigates the design of secure provenance collection systems where the collected meta-data can be relied upon even in light of realistic insider attack models. Security, however, is not sufficient; a practical system must also be efficient even when large amounts of fine-grained provenance data needs to be stored and processed. The project is aimed at addressing both issues through the following three objectives. (1) Techniques for continuously updatable software tamperproofing to ensure the integrity of the system itself. (2) Techniques for robust, continuous marking, collusion-free, text fingerprinting to mitigate document leakage. (3) Techniques for anonymous storage on untrusted storage servers to allow for efficient storage and access of fine-grained provenance data.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christian",
   "pi_last_name": "Collberg",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Christian S Collberg",
   "pi_email_addr": "collberg@cs.arizona.edu",
   "nsf_id": "000485481",
   "pi_start_date": "2013-09-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Saumya",
   "pi_last_name": "Debray",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Saumya K Debray",
   "pi_email_addr": "debray@cs.arizona.edu",
   "nsf_id": "000120753",
   "pi_start_date": "2013-09-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sudha",
   "pi_last_name": "Ram",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sudha Ram",
   "pi_email_addr": "ram@eller.arizona.edu",
   "nsf_id": "000297451",
   "pi_start_date": "2013-09-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Arizona",
  "inst_street_address": "845 N PARK AVE RM 538",
  "inst_street_address_2": "",
  "inst_city_name": "TUCSON",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "5206266000",
  "inst_zip_code": "85721",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "AZ07",
  "org_lgl_bus_name": "UNIVERSITY OF ARIZONA",
  "org_prnt_uei_num": "",
  "org_uei_num": "ED44Y3W6P7B9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Arizona",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "857210077",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "AZ07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 496066.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-946d382c-c34b-a999-3e4d-d400c963461e\">\n<p dir=\"ltr\"><span>In this project we investigated the design of a system that employs fine-grained provenance capture, text watermarking, and software protection techniques to protect office documents against leakage, spoofing, and unauthorized modification. Our attack model assumed a powerful insider who edits documents on their local machine, who at times is disconnected from the network, and who is in complete control over hardware, operating system, and application binaries. Such a scenario is often termed the </span><span>Man-At-The-End</span><span> (MATE) scenario. </span></p>\n<br />\n<p dir=\"ltr\"><span>Concretely, the project designed and built a secure provenance system for digital documents (available for download from http://collberg.github.io/provenance/downloads.html), specifically text documents for the OpenOffice office suite. The project addressed an important aspect of secure provenance, namely how to securely trace the chain of custody of a document that leaks outside the system. To protect documents from such leakage attacks the project developed algorithms for robust, continuous marking, collusion-free, text fingerprinting.</span></p>\n<br />\n<p dir=\"ltr\"><span>In addition, the project found that advancements in software protection techniques (techniques to protect against a MATE attack) are necessary to build and evaluate secure provenance systems. Specifically, the research focused on building the software protection defense techniques necessary to support secure provenance systems, techniques for evaluating such defenses, benchmarks to be used in evaluations, and techniques for attacking protected systems. </span></p>\n<br />\n<p dir=\"ltr\"><span>Much of this work addressed </span><span>symbolic analysis</span><span>, since symbolic/concolic analysis is an important component of many reverse engineering (i.e. attack) techniques. As such, it is used both by adversaries wanting to understand or manipulate a program under their control and by computer security expert wanting to analyze malware samples. Our work shed new light on both sides of this coin: we designed reverse engineering algorithms based on symbolic analysis that are generic, i.e. not targeted at undoing a particular obfuscating transformation, and we designed new obfuscation algorithms that make symbolic analysis less effective. These insights will be important in the future cat-and-mouse game between software protection attackers and defenders.</span></p>\n<br />\n<p dir=\"ltr\"><span>With respect to software protection </span><span>defense</span><span> techniques, the project designed new obfuscation transformations that change program behavior in subtle yet acceptable ways, and we showed that they can render symbolic-execution based deobfuscation analysis ineffective in practice. The project also developed a generic dynamic obfuscation algorithm as part of our Tigress code obfuscation tool (available for download from tigress.cs.arizona.edu). </span></p>\n<p dir=\"ltr\"><span><span> </span></span><span> </span><span><span> </span></span><span> </span><span><span> </span></span><span><span> </span></span></p>\n<p dir=\"ltr\"><span>With respect to software protection </span><span>evaluation</span><span> techniques, the project proposed a method for evaluating the artificiality of protected code. The goal is to measure the stealth of the protected code, i.e. the degree to which protected code can be distinguished from unprotected code. The results show that static obfuscating transformations have little effect on artificiality. However, dynamic obfuscating transformations, or a technique that inserts junk code fragments into the program, tend to increase the artificiality. Based on these results, we developed a defense method which aims to improve the stealth of obfuscated code. The project also addressed the problem of characterizing the resilience of code obfuscation transformations against automated symbolic execution attacks. The results show that many existing obfuscation transformations, such as virtualization, stand little chance of withstanding symbolic execution based deobfuscation. Finally, the project developed a general framework for choosing the most relevant software features to estimate the effort of automated attacks. We showed that features such as the number of community structures in the graph-representation of symbolic path-constraints are far more relevant for predicting deobfuscation time than other features generally used to measure the potency of control-flow obfuscation (e.g. cyclomatic complexity). </span></p>\n<p dir=\"ltr\"><span><span> </span></span></p>\n<p dir=\"ltr\"><span>With respect to software protection </span><span>attack</span><span> techniques, the project investigated a number of generic attacks against software protections. Specifically, the research developed a generic technique for deobfuscation based on semantics-based simplification of runtime execution traces. The approach is based on the view that a program defines a transformation from input values to output values, and that deobfuscation can be considered as the process of identifying and simplifying this transformation. &nbsp;The project also showed how symbolic execution of obfuscated code can be made more precise by an application of architecture-aware bit-precise taint analysis. Finally, the project developed an approach for identifying self-checksumming anti-tampering defenses.</span></p>\n<br /><br /></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/04/2018<br>\n\t\t\t\t\tModified by: Christian&nbsp;S&nbsp;Collberg</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nIn this project we investigated the design of a system that employs fine-grained provenance capture, text watermarking, and software protection techniques to protect office documents against leakage, spoofing, and unauthorized modification. Our attack model assumed a powerful insider who edits documents on their local machine, who at times is disconnected from the network, and who is in complete control over hardware, operating system, and application binaries. Such a scenario is often termed the Man-At-The-End (MATE) scenario. \n\n\nConcretely, the project designed and built a secure provenance system for digital documents (available for download from http://collberg.github.io/provenance/downloads.html), specifically text documents for the OpenOffice office suite. The project addressed an important aspect of secure provenance, namely how to securely trace the chain of custody of a document that leaks outside the system. To protect documents from such leakage attacks the project developed algorithms for robust, continuous marking, collusion-free, text fingerprinting.\n\n\nIn addition, the project found that advancements in software protection techniques (techniques to protect against a MATE attack) are necessary to build and evaluate secure provenance systems. Specifically, the research focused on building the software protection defense techniques necessary to support secure provenance systems, techniques for evaluating such defenses, benchmarks to be used in evaluations, and techniques for attacking protected systems. \n\n\nMuch of this work addressed symbolic analysis, since symbolic/concolic analysis is an important component of many reverse engineering (i.e. attack) techniques. As such, it is used both by adversaries wanting to understand or manipulate a program under their control and by computer security expert wanting to analyze malware samples. Our work shed new light on both sides of this coin: we designed reverse engineering algorithms based on symbolic analysis that are generic, i.e. not targeted at undoing a particular obfuscating transformation, and we designed new obfuscation algorithms that make symbolic analysis less effective. These insights will be important in the future cat-and-mouse game between software protection attackers and defenders.\n\n\nWith respect to software protection defense techniques, the project designed new obfuscation transformations that change program behavior in subtle yet acceptable ways, and we showed that they can render symbolic-execution based deobfuscation analysis ineffective in practice. The project also developed a generic dynamic obfuscation algorithm as part of our Tigress code obfuscation tool (available for download from tigress.cs.arizona.edu). \n      \nWith respect to software protection evaluation techniques, the project proposed a method for evaluating the artificiality of protected code. The goal is to measure the stealth of the protected code, i.e. the degree to which protected code can be distinguished from unprotected code. The results show that static obfuscating transformations have little effect on artificiality. However, dynamic obfuscating transformations, or a technique that inserts junk code fragments into the program, tend to increase the artificiality. Based on these results, we developed a defense method which aims to improve the stealth of obfuscated code. The project also addressed the problem of characterizing the resilience of code obfuscation transformations against automated symbolic execution attacks. The results show that many existing obfuscation transformations, such as virtualization, stand little chance of withstanding symbolic execution based deobfuscation. Finally, the project developed a general framework for choosing the most relevant software features to estimate the effort of automated attacks. We showed that features such as the number of community structures in the graph-representation of symbolic path-constraints are far more relevant for predicting deobfuscation time than other features generally used to measure the potency of control-flow obfuscation (e.g. cyclomatic complexity). \n \nWith respect to software protection attack techniques, the project investigated a number of generic attacks against software protections. Specifically, the research developed a generic technique for deobfuscation based on semantics-based simplification of runtime execution traces. The approach is based on the view that a program defines a transformation from input values to output values, and that deobfuscation can be considered as the process of identifying and simplifying this transformation.  The project also showed how symbolic execution of obfuscated code can be made more precise by an application of architecture-aware bit-precise taint analysis. Finally, the project developed an approach for identifying self-checksumming anti-tampering defenses.\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 01/04/2018\n\n\t\t\t\t\tSubmitted by: Christian S Collberg"
 }
}