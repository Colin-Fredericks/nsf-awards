{
 "awd_id": "1317560",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Visual Cortex on Silicon",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2013-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 4823456.0,
 "awd_amount": 4913456.0,
 "awd_min_amd_letter_date": "2013-09-17",
 "awd_max_amd_letter_date": "2020-06-03",
 "awd_abstract_narration": "The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.\r\n\r\nWhile several machine vision systems today can each successfully perform one or a few human tasks - such as detecting human faces in point-and-shoot cameras - they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions.  In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.\r\n\r\nMachine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "VIJAYKRISHNAN",
   "pi_last_name": "NARAYANAN",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "VIJAYKRISHNAN NARAYANAN",
   "pi_email_addr": "vijay@cse.psu.edu",
   "nsf_id": "000484513",
   "pi_start_date": "2013-09-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Carroll",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "John M Carroll",
   "pi_email_addr": "jcarroll@ist.psu.edu",
   "nsf_id": "000205369",
   "pi_start_date": "2013-09-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Chitaranjan",
   "pi_last_name": "Das",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chitaranjan Das",
   "pi_email_addr": "cxd12@psu.edu",
   "nsf_id": "000358842",
   "pi_start_date": "2013-09-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mary Beth",
   "pi_last_name": "Rosson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mary Beth Rosson",
   "pi_email_addr": "mrosson@psu.edu",
   "nsf_id": "000421157",
   "pi_start_date": "2013-09-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "C. Lee",
   "pi_last_name": "Giles",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "C. Lee Giles",
   "pi_email_addr": "giles@ist.psu.edu",
   "nsf_id": "000346235",
   "pi_start_date": "2013-09-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "110 Technology Center Building",
  "perf_city_name": "University Park",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168027000",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "PA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "772300",
   "pgm_ele_name": "Expeditions in Computing"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7723",
   "pgm_ref_txt": "EXPERIMENTAL EXPEDITIONS"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 1932787.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 990046.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 1958623.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 32000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Visual Cortex on Silicon project focused on designing intelligent machine vision systems that assist persons with visual impairment. The project involved researchers from multiple institutions and disciplines towards advancements in better understanding of vision systems in the human brain, developing efficient vision algorithms and theory and the design of new paradigms in computing hardware. The project contributed to design of human-computer interfaces that allowed persons with visual impairments to leverage these smart vision systems in their day-to-day tasks.</p>\n<p>Intellectual Merit: The project started with goal of enhancing the energy efficiency of computer vision systems comparable to those of the human visual cortex. Towards this goal, the project made advances in both the algorithm and hardware system design, enabling orders of magnitude gain in energy efficiency compared to prior systems. As an example, a new human-in-the-loop object detection algorithm was developed that involves asking a person with visual impairment wearing the smart camera to move to enhance accuracy of object detection. This approach significantly reduces effort to achieve comparable accuracy without this holistic human-machine design. Another innovation helped leverage the spatial co-occurrence of objects in a scene to reduce the effort for detecting a group of objects. In addition, the algorithms were also made more robust to challenging real world scenarios. Text detection and extraction algorithms were developed to enable the extraction of arbitrary oriented text in cluttered real-world scenarios.</p>\n<p>At the hardware level, the use of coupled-oscillator based systems emerged as a novel energy-efficient computing architecture for solving video analytics task leveraging the underlying physical behavior of the devices. The project also saw the among the first large scale chip designs using resistive cross-point arrays for machine learning. It also resulted in advances in domain-specific accelerators and FPGA based accelerators deployed in prototype assistive systems. These advances have influenced the creation of other new projects. The project also made important contributions to the design of human-computer interfaces for efficient interaction with persons with visual impairment. These advances included design of haptic gloves, combined audio-vibration instruction modalities and wearable camera prototypes.</p>\n<p>&nbsp;</p>\n<p>Broader Impacts: The project resulted in publications at premier venues across multiple disciplines. &nbsp;Through interaction with industry and government partners, our technology was transferred to other programs. The program trained a diverse group of graduate and undergraduate students. Many of these students are now working on AI related products in leading companies around the world and some have started careers in academia. The students in the program have won important recognition including the second position in the IEEE Computer Society Global Student Competition and winning the Nittany AI Challenge. &nbsp;The students and faculty in the project have won external awards and recognition for their contributions. They have also been featured in articles in the media. The project also included several outreach activities such as a summer camp for middle school girls, demonstrations at public fairs and museums, workshops for K-12 students, and summer internships for high school teachers and students. The program also resulted in integration of the research into curriculum as lab projects and course modules. The project is grateful to the persons of visual impairment who helped&nbsp; in the design and&nbsp; evaluation of the prototypes.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/26/2022<br>\n\t\t\t\t\tModified by: Vijaykrishnan&nbsp;Narayanan</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643211908302_expedition2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643211908302_expedition2--rgov-800width.jpg\" title=\"Wearable camera for grocery shopping assistance\"><img src=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643211908302_expedition2--rgov-66x44.jpg\" alt=\"Wearable camera for grocery shopping assistance\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Kevin Irick showing project prototype for grocery shopping assistance at the The Coalition for National Science Funding Annual Exhibit</div>\n<div class=\"imageCredit\">Vijaykrishnan Narayanan</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Vijaykrishnan&nbsp;Narayanan</div>\n<div class=\"imageTitle\">Wearable camera for grocery shopping assistance</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643212116810_expedition3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643212116810_expedition3--rgov-800width.jpg\" title=\"AIGuide helping picking an object in the pantry\"><img src=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643212116810_expedition3--rgov-66x44.jpg\" alt=\"AIGuide helping picking an object in the pantry\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">AIGuide is a smart phone-based application that embodies the algorithmic and user-interface advances from the project to assist persons with visual impairment pick objects.</div>\n<div class=\"imageCredit\">Chonghan Lee</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Vijaykrishnan&nbsp;Narayanan</div>\n<div class=\"imageTitle\">AIGuide helping picking an object in the pantry</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643212226503_expedition4-group-2016--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643212226503_expedition4-group-2016--rgov-800width.jpg\" title=\"Project team\"><img src=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643212226503_expedition4-group-2016--rgov-66x44.jpg\" alt=\"Project team\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A diverse group of students and partners participated in this project. The picture shows the 2016 summer group.</div>\n<div class=\"imageCredit\">Vijaykrishnan Narayanan</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Vijaykrishnan&nbsp;Narayanan</div>\n<div class=\"imageTitle\">Project team</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643211719038_PVIworkshop--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643211719038_PVIworkshop--rgov-800width.jpg\" title=\"Demonstrating visual assistance prototypes to visually impaired attendees at the National Federation of the Blind of Pennsylvania Convention\"><img src=\"/por/images/Reports/POR/2022/1317560/1317560_10281074_1643211719038_PVIworkshop--rgov-66x44.jpg\" alt=\"Demonstrating visual assistance prototypes to visually impaired attendees at the National Federation of the Blind of Pennsylvania Convention\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Graduate Student, Peter Zientara, demonstrating visual assistance prototypes developed in the project to persons with visual impairment at the National Federation of the Blind of Pennsylvania Convention</div>\n<div class=\"imageCredit\">Vijaykrishnan Narayanan</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Vijaykrishnan&nbsp;Narayanan</div>\n<div class=\"imageTitle\">Demonstrating visual assistance prototypes to visually impaired attendees at the National Federation of the Blind of Pennsylvania Convention</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe Visual Cortex on Silicon project focused on designing intelligent machine vision systems that assist persons with visual impairment. The project involved researchers from multiple institutions and disciplines towards advancements in better understanding of vision systems in the human brain, developing efficient vision algorithms and theory and the design of new paradigms in computing hardware. The project contributed to design of human-computer interfaces that allowed persons with visual impairments to leverage these smart vision systems in their day-to-day tasks.\n\nIntellectual Merit: The project started with goal of enhancing the energy efficiency of computer vision systems comparable to those of the human visual cortex. Towards this goal, the project made advances in both the algorithm and hardware system design, enabling orders of magnitude gain in energy efficiency compared to prior systems. As an example, a new human-in-the-loop object detection algorithm was developed that involves asking a person with visual impairment wearing the smart camera to move to enhance accuracy of object detection. This approach significantly reduces effort to achieve comparable accuracy without this holistic human-machine design. Another innovation helped leverage the spatial co-occurrence of objects in a scene to reduce the effort for detecting a group of objects. In addition, the algorithms were also made more robust to challenging real world scenarios. Text detection and extraction algorithms were developed to enable the extraction of arbitrary oriented text in cluttered real-world scenarios.\n\nAt the hardware level, the use of coupled-oscillator based systems emerged as a novel energy-efficient computing architecture for solving video analytics task leveraging the underlying physical behavior of the devices. The project also saw the among the first large scale chip designs using resistive cross-point arrays for machine learning. It also resulted in advances in domain-specific accelerators and FPGA based accelerators deployed in prototype assistive systems. These advances have influenced the creation of other new projects. The project also made important contributions to the design of human-computer interfaces for efficient interaction with persons with visual impairment. These advances included design of haptic gloves, combined audio-vibration instruction modalities and wearable camera prototypes.\n\n \n\nBroader Impacts: The project resulted in publications at premier venues across multiple disciplines.  Through interaction with industry and government partners, our technology was transferred to other programs. The program trained a diverse group of graduate and undergraduate students. Many of these students are now working on AI related products in leading companies around the world and some have started careers in academia. The students in the program have won important recognition including the second position in the IEEE Computer Society Global Student Competition and winning the Nittany AI Challenge.  The students and faculty in the project have won external awards and recognition for their contributions. They have also been featured in articles in the media. The project also included several outreach activities such as a summer camp for middle school girls, demonstrations at public fairs and museums, workshops for K-12 students, and summer internships for high school teachers and students. The program also resulted in integration of the research into curriculum as lab projects and course modules. The project is grateful to the persons of visual impairment who helped  in the design and  evaluation of the prototypes. \n\n \n\n\t\t\t\t\tLast Modified: 01/26/2022\n\n\t\t\t\t\tSubmitted by: Vijaykrishnan Narayanan"
 }
}