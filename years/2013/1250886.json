{
 "awd_id": "1250886",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Small: DCM: Data Management for Analytics Applications on Modern Architecture",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2013-06-01",
 "awd_exp_date": "2018-05-31",
 "tot_intn_awd_amt": 680916.0,
 "awd_amount": 680916.0,
 "awd_min_amd_letter_date": "2013-06-11",
 "awd_max_amd_letter_date": "2013-06-11",
 "awd_abstract_narration": "We are now in the midst of the big data revolution where enterprise services are increasingly being driven by operational and business models that are powered by data analysis. A key part in making big data successful is ensuring that basic data processing primitives can execute efficiently on large and every increasing volumes of data. However, data processing kernels today largely employ techniques that have been designed about three decades ago, and are now out of touch with modern hardware that has made a fundamental technological shift. First, driven by power consumption characteristics, modern processors now have multiple processing units (called cores) fabricated in a single chip. In contrast, processors just a few years ago were single core. Second, traditionally the storage media for data has been the magnetic hard disk. Now, data has started to move nearly permanently to higher levels of the memory hierarchy, and more specifically to main memory. The goal of this project is to rethink key aspects of data processing techniques for the modern many-core and main memory hardware environment. The research approach is to design, implement and evaluate various methods for data kernels that can be used to store and process data efficiently. In other words, the key focus is on producing data kernels that \"run at the speed of modern hardware.\" Thus, this project aims to have a broad impact on the big data ecosystem by developing faster, cheaper and more energy-efficient data kernels.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jignesh",
   "pi_last_name": "Patel",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jignesh M Patel",
   "pi_email_addr": "jignesh@cmu.edu",
   "nsf_id": "000336296",
   "pi_start_date": "2013-06-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "21 North Park Street",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537151218",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 680916.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The move towards data-driven decision making in enterprises coupled with the growth in data volumes requires taking a fresh look at key mechanims that power data analytics platform. This fresh look is especially critical as the hardware used in modern servers uses compute and storage methods that have architecturally very different propoerties than those from a decade ago, which implies that traditional methods for data processing do not effectively exploit the full potential of modern hardware. The overall goal of this project was to design, implement and evaluate more efficient, and thus cost-effective, ways to carry out data analytics than existing methods.</p>\n<p>Various data organization algoritms were developed as part of this project, contributing to the key components of the intellectual merit contributions of this project. Other intellectual contributions include the development of various algorithms for common data processing tasks such as searching though large datasets and combining informatoin from two or more differnent datasets. Methods were also developed to speed up machine learning programs by using static analysis methods. Overall the intellectual merits have lead to the creation of more efficient ways to carry out complex data analytics tasks.</p>\n<p>The broader impacts of this work consists of taking ideas from this research and developing into an actual platform that has been open-sourced. Work under this project has been published in top-tier confereneces, and this project has contributed to the training of five Ph.D. students.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/04/2018<br>\n\t\t\t\t\tModified by: Jignesh&nbsp;M&nbsp;Patel</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe move towards data-driven decision making in enterprises coupled with the growth in data volumes requires taking a fresh look at key mechanims that power data analytics platform. This fresh look is especially critical as the hardware used in modern servers uses compute and storage methods that have architecturally very different propoerties than those from a decade ago, which implies that traditional methods for data processing do not effectively exploit the full potential of modern hardware. The overall goal of this project was to design, implement and evaluate more efficient, and thus cost-effective, ways to carry out data analytics than existing methods.\n\nVarious data organization algoritms were developed as part of this project, contributing to the key components of the intellectual merit contributions of this project. Other intellectual contributions include the development of various algorithms for common data processing tasks such as searching though large datasets and combining informatoin from two or more differnent datasets. Methods were also developed to speed up machine learning programs by using static analysis methods. Overall the intellectual merits have lead to the creation of more efficient ways to carry out complex data analytics tasks.\n\nThe broader impacts of this work consists of taking ideas from this research and developing into an actual platform that has been open-sourced. Work under this project has been published in top-tier confereneces, and this project has contributed to the training of five Ph.D. students. \n\n\t\t\t\t\tLast Modified: 07/04/2018\n\n\t\t\t\t\tSubmitted by: Jignesh M Patel"
 }
}