{
 "awd_id": "1321168",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CGV: Small: A Patch-based Framework for Capturing a World in Motion",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2013-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 499719.0,
 "awd_amount": 499719.0,
 "awd_min_amd_letter_date": "2013-08-21",
 "awd_max_amd_letter_date": "2015-07-16",
 "awd_abstract_narration": "Although the real world is dynamic, many techniques used to image/capture it are fundamentally sequential in nature.  For example, capturing a high-dynamic range (HDR) image of a scene (which contains a wide range of illumination) without special hardware involves taking a set of sequential images at different exposures, each one measuring a small range of illumination.  However, this approach has problems when reconstructing the HDR image of dynamic scenes with moving subjects, since the individual frames are not registered correctly.  Problems like this appear in many research areas, from medical imaging to computer vision.\r\n\r\nIn this project, the PI and his team are developing a common framework that addresses artifacts from motion for a variety of different applications.  Their key insight is that patch-based optimization can be used to handle motion inconsistencies without explicitly solving the challenging problem of accurate motion estimation.  This produces results that are reconstructed from different inputs in a consistent manner without motion artifacts.  The PI is exploring how this framework can be applied to several important research areas, from high-quality imaging to computer vision applications such as the reconstruction of dynamic scenes.\r\n  \r\nImproved capture of dynamic scenes has the potential to transform the way certain imaging procedures (such as medical imaging) are done.  Scientific results of this work are disseminated through technical publications at top venues in the graphics/vision communities, and the PI plans to release the algorithms developed online.  Finally, this project involves high school and under-represented students into the research effort.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Pradeep",
   "pi_last_name": "Sen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pradeep Sen",
   "pi_email_addr": "psen@ece.ucsb.edu",
   "nsf_id": "000291374",
   "pi_start_date": "2013-08-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Barbara",
  "inst_street_address": "3227 CHEADLE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA BARBARA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8058934188",
  "inst_zip_code": "931060001",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SANTA BARBARA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G9QBQDH39DF4"
 },
 "perf_inst": {
  "perf_inst_name": "University of California, Santa Barbara",
  "perf_str_addr": "5117 Harold Frank Hall",
  "perf_city_name": "Santa Barbara",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "931069560",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 166378.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 163936.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 169405.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This sponsored project set out to study how patch-based synthesis algorithms could be applied to a whole host of problems in both computational imaging and rendering. During the course of the grant, we achieved several important research accomplishments:</p>\n<p>In computational imaging, we developed a robust algorithm for high-dynamic range (HDR) image reconstruction from stack-based images. Since standard digital cameras have a very limited dynamic range (ability to measure simultaneously the entire range from the brightest to the darkest part of a scene), one common approach that was proposed back in the 1990's is to take a stack of photographs at different exposure levels which can then be combined digitally to produce a final, well-exposed photograph.</p>\n<p>However, this approach has problems when there is motion in the scene or the camera is hand-held, which is something that happens a lot in consumer photography. To address this important problem, two previous kinds of methods had been proposed. First there were rejection-based methods, which assume that most of the image is static and use algorithms to identify the pixels that contain motion artifacts.&nbsp; In those regions only one image (or a subset of images that are deemed to be static) is used. The second kind of approaches are alignment methods which try to align the images before merging them together. However, both approaches have fundamental problems that result in artifacts for scenes with even slight motion.</p>\n<p>As part of this sponsored project, we have developed a third approach based on patch-based synthesis. Using an optimization that solves what we call the HDR synthesis equation, we are able to produce high-quality results without the artifacts that plague existing methods. This approach has been independently rated the best HDR reconstruction algorithm proposed by far, and has inspired a lot of follow-on work that builds upon that. We also implemented a version of the algorithm that works with video to produce results that look like they were cinematically lit.</p>\n<p>We also developed a new imaging paradigm called \"computational zoom,\" where the user takes a stack of images moving towards the scene and then can use our framework to manipulate the perspective of different portions of the image. This results in a new kind of multi-perspective image that can tell a different \"story\" than the individual images in the stack.&nbsp; We also developed a framework for transferring motion onto a static image to make it look like it is moving (e.g., rippling water in a lake), as well as explored training a machine learning algorithm to recognize differences in images similar to a human.</p>\n<p>On the rendering side, we developed the first learning-based system for Monte Carlo denoising. Monte Carlo (MC) algorithms are some of the most powerful algorithms for rendering today, since they can compute photorealistic images from a description of a 3D scene by simulating the flow of light through the scene. The main drawback of MC algorithms is that when only a few light paths are simulated you get objectionable noise in the result. Although there have been over 30 years of studying this problem of MC noise, no good practical solutions have been developed that allow fast results to be computed.</p>\n<p>In earlier work sponsored by a previous CAREER grant, we explored the idea of MC denoising algorithms, which apply a post-process algorithm to the final rendering to clean up the noise.&nbsp; We were able to build the first system that demonstrated that high-quality MC denoising was indeed possible and which helped usher in the modern era of Monte Carlo denoising algorithms. In this grant, we continued exploring this problem by proposing the first machine -learning based system for MC denoising. Our initial idea was to train a system end-to-end to take in noisy inputs and produce clean results, but since we did not have many scenes to train with we simplified the system to only output the parameters for hard-coded filter that would remove the noise. The resulting algorithm produced images that were of higher quality than existing state-of-the-art MC denoising algorithms.</p>\n<p>This original paper had a significant impact in rendering, and many companies began to implement learning-based MC denoising in their rendering pipelines.&nbsp; For example, we began to work with Disney/Pixar on a new, more sophisticated learning-based system that could train on hundreds or thousands of scenes Pixar had available. The resulting system produced high quality results that could be used in production environment and a paper on the system was recently published at SIGGRAPH the top venue in computer graphics.</p>\n<p>In terms of broader impact, the research has impacted related areas such as computer vision and image processing.&nbsp; In addition, the work sponsored by this grant has led to widespread adoption of Monte Carlo denoising algorithms, which is making it easier to create artistic works such as animated films.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/28/2017<br>\n\t\t\t\t\tModified by: Pradeep&nbsp;Sen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis sponsored project set out to study how patch-based synthesis algorithms could be applied to a whole host of problems in both computational imaging and rendering. During the course of the grant, we achieved several important research accomplishments:\n\nIn computational imaging, we developed a robust algorithm for high-dynamic range (HDR) image reconstruction from stack-based images. Since standard digital cameras have a very limited dynamic range (ability to measure simultaneously the entire range from the brightest to the darkest part of a scene), one common approach that was proposed back in the 1990's is to take a stack of photographs at different exposure levels which can then be combined digitally to produce a final, well-exposed photograph.\n\nHowever, this approach has problems when there is motion in the scene or the camera is hand-held, which is something that happens a lot in consumer photography. To address this important problem, two previous kinds of methods had been proposed. First there were rejection-based methods, which assume that most of the image is static and use algorithms to identify the pixels that contain motion artifacts.  In those regions only one image (or a subset of images that are deemed to be static) is used. The second kind of approaches are alignment methods which try to align the images before merging them together. However, both approaches have fundamental problems that result in artifacts for scenes with even slight motion.\n\nAs part of this sponsored project, we have developed a third approach based on patch-based synthesis. Using an optimization that solves what we call the HDR synthesis equation, we are able to produce high-quality results without the artifacts that plague existing methods. This approach has been independently rated the best HDR reconstruction algorithm proposed by far, and has inspired a lot of follow-on work that builds upon that. We also implemented a version of the algorithm that works with video to produce results that look like they were cinematically lit.\n\nWe also developed a new imaging paradigm called \"computational zoom,\" where the user takes a stack of images moving towards the scene and then can use our framework to manipulate the perspective of different portions of the image. This results in a new kind of multi-perspective image that can tell a different \"story\" than the individual images in the stack.  We also developed a framework for transferring motion onto a static image to make it look like it is moving (e.g., rippling water in a lake), as well as explored training a machine learning algorithm to recognize differences in images similar to a human.\n\nOn the rendering side, we developed the first learning-based system for Monte Carlo denoising. Monte Carlo (MC) algorithms are some of the most powerful algorithms for rendering today, since they can compute photorealistic images from a description of a 3D scene by simulating the flow of light through the scene. The main drawback of MC algorithms is that when only a few light paths are simulated you get objectionable noise in the result. Although there have been over 30 years of studying this problem of MC noise, no good practical solutions have been developed that allow fast results to be computed.\n\nIn earlier work sponsored by a previous CAREER grant, we explored the idea of MC denoising algorithms, which apply a post-process algorithm to the final rendering to clean up the noise.  We were able to build the first system that demonstrated that high-quality MC denoising was indeed possible and which helped usher in the modern era of Monte Carlo denoising algorithms. In this grant, we continued exploring this problem by proposing the first machine -learning based system for MC denoising. Our initial idea was to train a system end-to-end to take in noisy inputs and produce clean results, but since we did not have many scenes to train with we simplified the system to only output the parameters for hard-coded filter that would remove the noise. The resulting algorithm produced images that were of higher quality than existing state-of-the-art MC denoising algorithms.\n\nThis original paper had a significant impact in rendering, and many companies began to implement learning-based MC denoising in their rendering pipelines.  For example, we began to work with Disney/Pixar on a new, more sophisticated learning-based system that could train on hundreds or thousands of scenes Pixar had available. The resulting system produced high quality results that could be used in production environment and a paper on the system was recently published at SIGGRAPH the top venue in computer graphics.\n\nIn terms of broader impact, the research has impacted related areas such as computer vision and image processing.  In addition, the work sponsored by this grant has led to widespread adoption of Monte Carlo denoising algorithms, which is making it easier to create artistic works such as animated films.\n\n\t\t\t\t\tLast Modified: 12/28/2017\n\n\t\t\t\t\tSubmitted by: Pradeep Sen"
 }
}