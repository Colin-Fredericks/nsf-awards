{
 "awd_id": "1305365",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CI-ADDO-NEW: Collaborative Research: The Speech Recognition Virtual Kitchen",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 542371.0,
 "awd_amount": 542371.0,
 "awd_min_amd_letter_date": "2013-06-04",
 "awd_max_amd_letter_date": "2013-06-04",
 "awd_abstract_narration": "The Speech Recognition Virtual Kitchen \r\n\r\nPerforming successful research on end-to-end speech processing problems requires the integration of many individual tools (e.g. for data cleaning, acoustic model training, language modeling, data analysis, real-time audio, decoding, parsing, synthesis, etc.). It is difficult for new researchers to get started in the field, simply because a typical lab environment consists of a hodgepodge of tools suited to a particular computing set-ups. This environment is hard to recreate, because few people are experts in the theory and practice of all these fields, and can debug and replicate experiments from scratch. \r\n\r\nThis research infrastructure project creates a \"kitchen\" environment based on Virtual Machines (VMs) to promote community sharing of research techniques, and provides solid reference systems as a tool for education, research, and evaluation. We liken VMs to a \"kitchen\" because they provide an environment into which one can install \"appliances\" (e.g., toolkits), \"recipes\" (scripts for creating state-of-the art systems using these tools), and \"ingredients\" (spoken language data). The kitchen even holds \"reference dishes\" in the form of complete experiments with baseline runs, log-files, etc., together with all that is needed to recreate and modify them. \r\n\r\nThe project is developing a community and repository by (a) building pilot VMs, (b) engaging the community in using and continuing to develop them on its own, and (c) evaluating the impact of providing VMs for education and research. We envision researchers as well as students downloading a VM, reproducing the baseline experiment, implementing changes, posting their results in the community, discussing with other users who have worked on the same VM, merging improvements back into the VM, which get re-distributed, and finally publishing easily reproducible results. Work with curriculum and project development will support the creation of engaging activities to specifically encourage students at undergraduate and graduate levels.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Florian",
   "pi_last_name": "Metze",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Florian Metze",
   "pi_email_addr": "fmetze@cs.cmu.edu",
   "nsf_id": "000518948",
   "pi_start_date": "2013-06-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 542371.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-4291fbeb-dea4-3a9d-bdfd-c2dde53ac58c\"> </span></p>\n<p dir=\"ltr\"><span>This community research infrastructure project supports the challenges faced by the automatic speech recognition community. &nbsp;Performing successful research on end-to-end speech processing problems requires the integration of many individual tools (e.g., for data cleaning, acoustic model training, language modeling, data analysis, real-time audio, decoding, parsing, synthesis, etc.). It is difficult for new researchers to get started in the field, simply because a typical lab environment consists of a hodgepodge of tools suited to a particular computing set-up. This environment is hard to recreate, because few people are experts in the theory and practice of all these fields, and few can debug and replicate experiments from scratch. </span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>Intellectual merit:</span></p>\n<p dir=\"ltr\"><span>The outcome of this project was a community research infrastructure, the &ldquo;Speech Recognition Virtual Kitchen,&rdquo; &nbsp;which promotes community sharing of research techniques (also known as recipes), and provides solid reference systems via virtual machines (VMs) as a tool for education, research, and evaluation. &nbsp;The kitchen holds \"reference dishes\" in the form of complete experiments with baseline runs, models, log-files, etc., together with all that is needed to recreate and modify them.  Researchers and students can download a VM, reproduce a baseline experiment, implement changes, and share their results and modifications with the community. </span></p>\n<p dir=\"ltr\"><span>The current infrastructure hosts a number of ready-to-go software resources for building speech recognition systems and other speech and language resources. &nbsp;The infrastructure can be accessed through the website portals </span><a href=\"http://speechkitchen.org\"><span>http://speechkitchen.org</span></a><span> and </span><a href=\"http://srvk.github.io\"><span>http://srvk.github.io</span></a><span>. &nbsp;&nbsp;As of early 2018, there has been significant usage on Github, where usage statistics include 483 &ldquo;stars&rdquo; or project follows by users and 301 forks indicating code that has been downloaded and saved as user copies that allow for edits to virtual machine code. &nbsp;The most popular virtual machine has been the Eesen speech recognition system, which provides an end-to-end speech recognition framework. Curriculum and project development has also supported the creation of learning activities to specifically encourage students at undergraduate and graduate levels. &nbsp;&nbsp;Educational virtual machine resources are published on the site; these materials are in use at several universities and are freely available.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>Broader impact:</span></p>\n<p><span>The project as a whole has several broader impacts: the infrastructure is usable (and is also starting to be used) by fields other than speech recognition that are data intensive (synthesis, dialog systems, NLP, computer vision, data mining, (mental) health care). &nbsp;Examples of the infrastructure&rsquo;s reach beyond the speech recognition community include development of a speech synthesis virtual machine for teaching computational linguistics, and a virtual machine for transcription of real-world audio.  The Speech Kitchen team engaged the speech recognition community through a special session at Interspeech 2016 titled &ldquo;Understanding Speech Processing using Shared Resources for Research and Education.&rdquo; (</span><a href=\"http://speechkitchen.org/interspeech-2016-special-session/\"><span>http://speechkitchen.org/interspeech-2016-special-session/</span></a><span>). &nbsp;This session was dedicated to describing reproducible, reusable resources for speech recognition research and education. In an example of impact that goes beyond the initial community, a collaboration with the &ldquo;Analysis of Children&rsquo;s Language Experiences Around the World&rdquo; team within the &ldquo;Digging into Data&rdquo; program (</span><a href=\"https://sites.google.com/view/aclewdid/home\"><span>https://sites.google.com/view/aclewdid/home</span></a><span>) resulted in a VM that can diarize daylong audio recordings of children, which is now being used by a number of sites, and is receiving enhancements based on community input (e.g., addressee detection, syllable counting, language universal phone recognition). &nbsp;The infrastructure, and the virtual machines provided on the site, can be used as a jumping off point for many different kinds of research that require speech recognition.</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/19/2018<br>\n\t\t\t\t\tModified by: Florian&nbsp;Metze</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1305365/1305365_10249954_1524154004040_Screenshot--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1305365/1305365_10249954_1524154004040_Screenshot--rgov-800width.jpg\" title=\"Speech Recognition Virtual Kitchen\"><img src=\"/por/images/Reports/POR/2018/1305365/1305365_10249954_1524154004040_Screenshot--rgov-66x44.jpg\" alt=\"Speech Recognition Virtual Kitchen\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The landing page of the speech recognition virtual kitchen web site.</div>\n<div class=\"imageCredit\">n/a</div>\n<div class=\"imageSubmitted\">Florian&nbsp;Metze</div>\n<div class=\"imageTitle\">Speech Recognition Virtual Kitchen</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nThis community research infrastructure project supports the challenges faced by the automatic speech recognition community.  Performing successful research on end-to-end speech processing problems requires the integration of many individual tools (e.g., for data cleaning, acoustic model training, language modeling, data analysis, real-time audio, decoding, parsing, synthesis, etc.). It is difficult for new researchers to get started in the field, simply because a typical lab environment consists of a hodgepodge of tools suited to a particular computing set-up. This environment is hard to recreate, because few people are experts in the theory and practice of all these fields, and few can debug and replicate experiments from scratch. \n\n \nIntellectual merit:\nThe outcome of this project was a community research infrastructure, the \"Speech Recognition Virtual Kitchen,\"  which promotes community sharing of research techniques (also known as recipes), and provides solid reference systems via virtual machines (VMs) as a tool for education, research, and evaluation.  The kitchen holds \"reference dishes\" in the form of complete experiments with baseline runs, models, log-files, etc., together with all that is needed to recreate and modify them.  Researchers and students can download a VM, reproduce a baseline experiment, implement changes, and share their results and modifications with the community. \nThe current infrastructure hosts a number of ready-to-go software resources for building speech recognition systems and other speech and language resources.  The infrastructure can be accessed through the website portals http://speechkitchen.org and http://srvk.github.io.   As of early 2018, there has been significant usage on Github, where usage statistics include 483 \"stars\" or project follows by users and 301 forks indicating code that has been downloaded and saved as user copies that allow for edits to virtual machine code.  The most popular virtual machine has been the Eesen speech recognition system, which provides an end-to-end speech recognition framework. Curriculum and project development has also supported the creation of learning activities to specifically encourage students at undergraduate and graduate levels.   Educational virtual machine resources are published on the site; these materials are in use at several universities and are freely available.\n\n \nBroader impact:\n\nThe project as a whole has several broader impacts: the infrastructure is usable (and is also starting to be used) by fields other than speech recognition that are data intensive (synthesis, dialog systems, NLP, computer vision, data mining, (mental) health care).  Examples of the infrastructure?s reach beyond the speech recognition community include development of a speech synthesis virtual machine for teaching computational linguistics, and a virtual machine for transcription of real-world audio.  The Speech Kitchen team engaged the speech recognition community through a special session at Interspeech 2016 titled \"Understanding Speech Processing using Shared Resources for Research and Education.\" (http://speechkitchen.org/interspeech-2016-special-session/).  This session was dedicated to describing reproducible, reusable resources for speech recognition research and education. In an example of impact that goes beyond the initial community, a collaboration with the \"Analysis of Children?s Language Experiences Around the World\" team within the \"Digging into Data\" program (https://sites.google.com/view/aclewdid/home) resulted in a VM that can diarize daylong audio recordings of children, which is now being used by a number of sites, and is receiving enhancements based on community input (e.g., addressee detection, syllable counting, language universal phone recognition).  The infrastructure, and the virtual machines provided on the site, can be used as a jumping off point for many different kinds of research that require speech recognition.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 04/19/2018\n\n\t\t\t\t\tSubmitted by: Florian Metze"
 }
}