{
 "awd_id": "1314560",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC: Medium: Collaborative: HIMALAYAS: Hierarchical Machine Learning Stack for Fine-Grained Analysis of Malware Domain Groups",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2013-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 252545.0,
 "awd_amount": 252545.0,
 "awd_min_amd_letter_date": "2013-08-30",
 "awd_max_amd_letter_date": "2013-08-30",
 "awd_abstract_narration": "The domain name system (DNS) protocol plays a significant role in operation of the Internet by enabling the bi-directional association of domain names with IP addresses.  It is also increasingly abused by malware, particularly botnets, by use of:  (1) automated domain generation algorithms for rendezvous with a command-and-control (C&C) server, (2) DNS fast flux as a way to hide the location of malicious servers, and (3) DNS as a carrier channel for C&C communications.\r\nThis project explores the development of a scalable, hierarchical machine-learning stack, called HIMALAYAS, which specializes in algorithms for automatically mining DNS data for malware activity. In particular, we are interested in isolating both ordered and unordered sets of malware domain groups whose access patterns are temporally and logically correlated.  \r\n\r\nHIMALAYAS performs a task of increasing complexity at each level ? starting from scalable clustering and feature selection at lower levels, to more advanced malware domain subsequence identification algorithms at higher levels. It has multiple benefits, including speed, accuracy, interpretability, and ability to use domain knowledge, which makes it very well suited for malware analysis and related tasks. The analysis by HIMALAYAS should accelerate the identification and takedown of malware domains on the Internet and improve services such as Google SafeSearch. \r\n\r\nThe machine-learning stack developed as part of the HIMALAYAS project has broader application to many important data mining problems, e.g., in financial data analysis, and mining user patterns from web access logs.  The project provides opportunities for students to participate in the development and transition of the technology.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Arindam",
   "pi_last_name": "Banerjee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Arindam Banerjee",
   "pi_email_addr": "arindamb@illinois.edu",
   "nsf_id": "000491325",
   "pi_start_date": "2013-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "University of Minnesota-Twin Cities",
  "perf_str_addr": "200 Union Street SE",
  "perf_city_name": "Minneapolis",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "554550169",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MN05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 252545.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Internet&rsquo;s Domain Name Service (DNS) offers a valuable vantage point for tracking malicious software campaigns that propagate daily across the world. We made progress on leveraging recent advances in large-scale machine learning algorithms to develop novel analytics that can uncover previously unknown malicious domains in massive streams of DNS resolution traffic. Our focus was on developing a new machine learning methods capable of uncovering &ldquo;malware domain groups&rdquo; over massive streams of DNS queries.</p>\n<p>From the machine learning perspective, several challenges needed to be addressed. First, since the machine learning methods are to be applied to massive streams of DNS queries, i.e., on the order of hundreds of millions of queries (or gigabytes of data) per hour, the algorithms need to be extremely scalable. Since such learning happens based on optimization, the initial focus of our work was on developing scalable parallel and/or stochastic algorithms for optimization. The algorithms developed were illustrated to have desirable scalability, and outperformed commercial optimization packages by a large margin, e.g., linear programming with 200 million variables takes our algorithm ~5 minutes using a GPU with 5Gb memory, whereas the state-of-the-art commercial packages tend to give up at 100 million variables even with 100Gb memory. The optimization algorithms developed have found wide ranging applications in scalable machine learning, including recent advances in deep reinforcement learning.</p>\n<p>While hidden Markov models (HMMs) have been widely studied for modeling discrete sequences, e.g., DNS queries from a user, HMMs fail to model the state persistence common in human activity, i.e., staying on one context (state) for a brief stretch before switching contexts and starting another activity. To handle state persistence, we studied hidden semi-Markov Models (HSMMs) and developed the first provably correct (spectral) algorithm for inference in HSMMs. For continuous multivariate time series, while vector auto-regressive (VAR) models and variants have been widely studied, it can be difficult to correctly estimate the historical dependencies of such models using finite amount of data. We developed a general geometric framework for analyzing such estimation problems assuming that the parameters to be estimated have structure, e.g., sparse, low rank, etc. Further, we also gave a precise characterization of the sample complexity of parameter estimation for VAR models assuming structured parameters.</p>\n<p>One of the central challenges of using massive streams of DNS queries to identify malware domains is that the query stream observed is in fact an interlacing of multiple query streams from individual users. While several users have query streams associated with normal domains, some will have streams associated with malicious domains, and it is difficult to identify the malicious domains and domain groups without first un-entangling or un-interlacing the query streams. The problem is challenging from a machine learning perspective because of the number of users, the unsupervised nature of the problem with no ground truth, variations in user query stream length, potential long range dependencies, latent interlacing information, among others. We have developed a synthetic generator for such data to evaluate methods, and also developed a set of approaches for handling the un-interlacing problem including approaches based on a (mixture of) HSMMs which can handle state persistence and approaches based on recurrent networks which has a more flexible representation of latent states and can handle long term temporal dependencies. The approaches have shown promising performance on the un-interlacing problem.&nbsp; &nbsp; &nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/01/2018<br>\n\t\t\t\t\tModified by: Arindam&nbsp;Banerjee</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe Internet?s Domain Name Service (DNS) offers a valuable vantage point for tracking malicious software campaigns that propagate daily across the world. We made progress on leveraging recent advances in large-scale machine learning algorithms to develop novel analytics that can uncover previously unknown malicious domains in massive streams of DNS resolution traffic. Our focus was on developing a new machine learning methods capable of uncovering \"malware domain groups\" over massive streams of DNS queries.\n\nFrom the machine learning perspective, several challenges needed to be addressed. First, since the machine learning methods are to be applied to massive streams of DNS queries, i.e., on the order of hundreds of millions of queries (or gigabytes of data) per hour, the algorithms need to be extremely scalable. Since such learning happens based on optimization, the initial focus of our work was on developing scalable parallel and/or stochastic algorithms for optimization. The algorithms developed were illustrated to have desirable scalability, and outperformed commercial optimization packages by a large margin, e.g., linear programming with 200 million variables takes our algorithm ~5 minutes using a GPU with 5Gb memory, whereas the state-of-the-art commercial packages tend to give up at 100 million variables even with 100Gb memory. The optimization algorithms developed have found wide ranging applications in scalable machine learning, including recent advances in deep reinforcement learning.\n\nWhile hidden Markov models (HMMs) have been widely studied for modeling discrete sequences, e.g., DNS queries from a user, HMMs fail to model the state persistence common in human activity, i.e., staying on one context (state) for a brief stretch before switching contexts and starting another activity. To handle state persistence, we studied hidden semi-Markov Models (HSMMs) and developed the first provably correct (spectral) algorithm for inference in HSMMs. For continuous multivariate time series, while vector auto-regressive (VAR) models and variants have been widely studied, it can be difficult to correctly estimate the historical dependencies of such models using finite amount of data. We developed a general geometric framework for analyzing such estimation problems assuming that the parameters to be estimated have structure, e.g., sparse, low rank, etc. Further, we also gave a precise characterization of the sample complexity of parameter estimation for VAR models assuming structured parameters.\n\nOne of the central challenges of using massive streams of DNS queries to identify malware domains is that the query stream observed is in fact an interlacing of multiple query streams from individual users. While several users have query streams associated with normal domains, some will have streams associated with malicious domains, and it is difficult to identify the malicious domains and domain groups without first un-entangling or un-interlacing the query streams. The problem is challenging from a machine learning perspective because of the number of users, the unsupervised nature of the problem with no ground truth, variations in user query stream length, potential long range dependencies, latent interlacing information, among others. We have developed a synthetic generator for such data to evaluate methods, and also developed a set of approaches for handling the un-interlacing problem including approaches based on a (mixture of) HSMMs which can handle state persistence and approaches based on recurrent networks which has a more flexible representation of latent states and can handle long term temporal dependencies. The approaches have shown promising performance on the un-interlacing problem.     \n\n\t\t\t\t\tLast Modified: 01/01/2018\n\n\t\t\t\t\tSubmitted by: Arindam Banerjee"
 }
}