{
 "awd_id": "1328816",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: Large: Collaborative Research: Fast and Accurate Infrastructure Modeling and Inspection with Low-Flying Robots",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 311250.0,
 "awd_amount": 328050.0,
 "awd_min_amd_letter_date": "2013-09-04",
 "awd_max_amd_letter_date": "2016-06-15",
 "awd_abstract_narration": "The goal of this project is to transform the efficiency, fidelity, and safety of current critical infrastructure inspection methods by combining human judgment with machine intelligence through the development of an autonomous robotic inspection assistant. The proposed work utilizes small aerial robots, coupled with three-dimensional imaging and the state-of-the-art in planning, modeling, and analysis to develop safe and efficient, high-precision assessment of structures. The key themes of the proposed work are: (1) rapid infrastructure modeling and analysis of large complex structures via a small autonomous aerial robot with 3D mapping capabilities; (2) immersive inspection and structural assessment to combine shape and appearance into an integrated representation amenable to structural health evaluation by an inspector; and (3) adaptive aerial vehicle motion plans that seek to learn from the experience of human inspectors and facilitate as autonomous inspection assistants. The proposed work is exploring the role of humans in the entire cycle from deployment of flying robots to registering data to the assessment.  This project brings together members of participating communities and is developing curriculum to engage undergraduate and graduate students from robotics and civil engineering in the proposed research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jerome",
   "pi_last_name": "Hajjar",
   "pi_mid_init": "F",
   "pi_sufx_name": "",
   "pi_full_name": "Jerome F Hajjar",
   "pi_email_addr": "jf.hajjar@northeastern.edu",
   "nsf_id": "000100756",
   "pi_start_date": "2013-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Avenue",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 311250.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 4800.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 4000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span lang=\"EN\">The goal of the ARIA project was to transform the efficiency, fidelity, and safety of current critical infrastructure inspection methods by combining human judgment with machine intelligence through the development of an autonomous robotic inspection assistant. A small aerial robot (micro air vehicle, or MAV), coupled with three-dimensional imaging and the state-of-the-art in planning, modeling, and analysis, provides safe and efficient, high-precision assessment of structures.<span>&nbsp; </span></span></p>\n<p><span lang=\"EN\">The project was comprised of three key objectives: (1) Rapid infrastructure modeling and analysis of large complex structures via a small autonomous aerial robot with 3D mapping capabilities;<span>&nbsp; </span>(2) Immersive inspection and structural assessment to combine shape and appearance into an integrated representation amenable to structural health evaluation by an inspector; and (3) Adaptive aerial vehicle motion plans that seek to learn from the experience of human inspectors and facilitate as autonomous inspection assistants. The first theme is further sub-divided into several components: robust state estimation, mapping, knowledge-based semantic modeling, visual analysis and inspection, and structural modeling and assessment.</span></p>\n<p><span lang=\"EN\">In the project we are able to demonstrate significant progress in furthering the robot autonomy, GPS-denied state estimation, semantic 3D segmentation, structural analysis, and assesment of structures. Additionally, we engaged with stake holders to educate on the art of possible and gather feedback on requirements. The following types of approaches were developed:</span></p>\n<p><span lang=\"EN\">- robust plane segmentation algorithms</span></p>\n<p><span lang=\"EN\">- visual damage inspection methods</span></p>\n<p><span lang=\"EN\">- 3D point cloud to structure segmentation methods</span></p>\n<p><span lang=\"EN\">- automatic finite-element meshing methods</span></p>\n<p><span lang=\"EN\">- immersive inspection visualization and interaction approaches</span></p>\n<p><span lang=\"EN\">- automatic coverage planning algorithms</span></p>\n<p><span lang=\"EN\">- localization and mapping algorithms that do not require GPS</span></p>\n<p><span lang=\"EN\">- disturbance-aware motion planning</span></p>\n<p><span lang=\"EN\">The methods were integrated and tested on a custom robot equipped with a spinning LiDAR scanner and cameras in several experiments on bridges. The largest bridge scanned was the Delaware Memorial bridge. Live demonstrations were performed with several stakeholders and the results of our research were shared annually with an advisory board and during regular open house events.</span></p>\n<p><span lang=\"EN\">The GPS-denied mapping was commercialized into a separate spin-off company (Kaarta Inc.). Several of the algorithms developed in this project have the potential to have a larger impact on the civil and construction industry by making comprehensive 3D modelling accessible in a large set of environments. We have been in conversations with multiple partners on commercializing the products generated in the project. The algorithms developed have advanced the state of the art in terms of flying robots, semantic segmentation, structural modeling, and inspection.</span></p>\n<p><strong>&nbsp;</strong><em>&nbsp;</em></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/11/2018<br>\n\t\t\t\t\tModified by: Jerome&nbsp;F&nbsp;Hajjar</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of the ARIA project was to transform the efficiency, fidelity, and safety of current critical infrastructure inspection methods by combining human judgment with machine intelligence through the development of an autonomous robotic inspection assistant. A small aerial robot (micro air vehicle, or MAV), coupled with three-dimensional imaging and the state-of-the-art in planning, modeling, and analysis, provides safe and efficient, high-precision assessment of structures.  \n\nThe project was comprised of three key objectives: (1) Rapid infrastructure modeling and analysis of large complex structures via a small autonomous aerial robot with 3D mapping capabilities;  (2) Immersive inspection and structural assessment to combine shape and appearance into an integrated representation amenable to structural health evaluation by an inspector; and (3) Adaptive aerial vehicle motion plans that seek to learn from the experience of human inspectors and facilitate as autonomous inspection assistants. The first theme is further sub-divided into several components: robust state estimation, mapping, knowledge-based semantic modeling, visual analysis and inspection, and structural modeling and assessment.\n\nIn the project we are able to demonstrate significant progress in furthering the robot autonomy, GPS-denied state estimation, semantic 3D segmentation, structural analysis, and assesment of structures. Additionally, we engaged with stake holders to educate on the art of possible and gather feedback on requirements. The following types of approaches were developed:\n\n- robust plane segmentation algorithms\n\n- visual damage inspection methods\n\n- 3D point cloud to structure segmentation methods\n\n- automatic finite-element meshing methods\n\n- immersive inspection visualization and interaction approaches\n\n- automatic coverage planning algorithms\n\n- localization and mapping algorithms that do not require GPS\n\n- disturbance-aware motion planning\n\nThe methods were integrated and tested on a custom robot equipped with a spinning LiDAR scanner and cameras in several experiments on bridges. The largest bridge scanned was the Delaware Memorial bridge. Live demonstrations were performed with several stakeholders and the results of our research were shared annually with an advisory board and during regular open house events.\n\nThe GPS-denied mapping was commercialized into a separate spin-off company (Kaarta Inc.). Several of the algorithms developed in this project have the potential to have a larger impact on the civil and construction industry by making comprehensive 3D modelling accessible in a large set of environments. We have been in conversations with multiple partners on commercializing the products generated in the project. The algorithms developed have advanced the state of the art in terms of flying robots, semantic segmentation, structural modeling, and inspection.\n\n  \n\n \n\n\t\t\t\t\tLast Modified: 07/11/2018\n\n\t\t\t\t\tSubmitted by: Jerome F Hajjar"
 }
}