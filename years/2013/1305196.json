{
 "awd_id": "1305196",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "II-EN: Acquisition of Sensors and Displays for Research on Motion Synthesis and Rehabilitation",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Harriet Taylor",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 302869.0,
 "awd_amount": 302869.0,
 "awd_min_amd_letter_date": "2013-08-26",
 "awd_max_amd_letter_date": "2013-08-26",
 "awd_abstract_narration": "Real-time motion-capture and interactive 3D computer-generated environments are rapidly emerging as an integrated and powerful human-computer interaction context with the ability to revolutionize applications in many areas. Recent advances in sensor and display technologies can now be seen in both low-cost consumer-oriented and in high-end industrial-oriented human-centered computer systems. This proposal aims to support and enhance research and educational activities in new research and application areas by strengthening and expanding the available research infrastructure at the University of California - Merced, specifically by enhancing an existing visualization and motion capture facility with the acquisition of (a) a high-end data glove, (b) an occlusion-free motion capture suit, and (c) portable interactive displays integrated with Kinect sensors.  The proposed equipment enhancement will allow the development of new research projects on the following topics: (a) gesture synthesis models with coordinated hand-arm motions, (b) remote virtual collaborative sessions for upper body motion rehabilitation assessment and remote therapy delivery, (c) automated progress monitoring of hand motor rehabilitation in respect to given motion protocols, and (d) human-like full-body motion planning in tight spaces for training applications. The projects will target interactive training and therapy applications that can benefit from new human-computer interfaces that are situated in virtual environments.\r\n\r\nIntellectual Merit\r\n\r\nAn interdisciplinary team from computer science and cognitive science will explore novel human-centered computing research with a focus on the channels of communication that are used in parallel during physical training and therapy. The proposed portable and occlusion-free high-end motion sensing equipment will allow the development of human-like motion models for synthesis of gestures as well as full-body task-oriented motions. These models will enable, during immersive remote interactions, the discovery of new interaction paradigms, which will involve autonomously synthesized human-like motions and human motions that will be captured and streamed back to the system.  A gesture analysis tool will be developed to provide algorithmic infrastructure to automatically analyze and extract the components of the gestures.  The infrastructure will permit rehabilitation and therapy to be evaluated in actual practice.  The scientific and practical research projects will advance the effectiveness of virtual humans in diverse educational, training, and therapeutic applications, and will help make such 3D computer-generated environments more accessible to the common user.\r\n\r\nBroader Impact\r\n\r\nThe infrastructure will support research projects that relate to motion rehabilitation, which has the potential to benefit the many Americans who are in need of physical therapy such as for ailments in the back, neck, and shoulders.  The research will advance an understanding of a principled approach for using virtual humans for a broad range of practical training and therapy applications.  The instrumentation and research will provide unique learning opportunities for graduate and undergraduate students. The research outcomes will be disseminated broadly in cognitive science, computer science, and rehabilitation therapy publications.  The infrastructure and research will be demonstrated to local high school and community college students to motivate interest in science and engineering.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Marcelo",
   "pi_last_name": "Kallmann",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Marcelo Kallmann",
   "pi_email_addr": "mkallmann@ucmerced.edu",
   "nsf_id": "000489904",
   "pi_start_date": "2013-08-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Teenie",
   "pi_last_name": "Matlock",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Teenie Matlock",
   "pi_email_addr": "tmatlock@ucmerced.edu",
   "nsf_id": "000443831",
   "pi_start_date": "2013-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California - Merced",
  "inst_street_address": "5200 N LAKE RD",
  "inst_street_address_2": "",
  "inst_city_name": "MERCED",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2092012039",
  "inst_zip_code": "953435001",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "CA13",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, MERCED",
  "org_prnt_uei_num": "",
  "org_uei_num": "FFM7VPAG8P92"
 },
 "perf_inst": {
  "perf_inst_name": "University of California - Merced",
  "perf_str_addr": "5200 North Lake Road",
  "perf_city_name": "Merced",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "953435001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "CA13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 302869.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This award has enabled the acquisition and integration of new research equipment to support projects in the areas of interactive systems for physical rehabilitation, interaction with autonomous virtual trainers, gesture synthesis models, and full-body character animation. These topics contribute to the development of computer-animated virtual trainers for interactive human-centric applications. The new research equipment included a full-body motion capture suit, data gloves, head-mounted displays, and large movable interactive displays integrated with motion capture sensors. The new equipment has enhanced a virtual reality laboratory at UC Merced dedicated to human interaction in virtual environments and the supported activities have produced several results reported in scientific publications.</p>\n<p>The produced work &ldquo;The Effects of Avatars, Stereo Vision and Display Size on Reaching and Motion Reproduction&rdquo; reports new findings related to how different system configurations influence motion performances. The results show that the use of 3D avatars improve the quality of produced motions and the resemblance of replicated motions; however, direct interaction in user-perspective mode leads to tasks executed in less time and to targets more accurately reached. Display size was not found to significantly impact performances. These and additional tradeoffs are important for the effective design of avatar-based training systems.</p>\n<p>The produced work &ldquo;3D Printing and Immersive Visualization for Improved Perception and Interaction with Ancient Artifacts&rdquo; investigated the effectiveness of different presentation modes when displaying ancient artifacts to people. The results show that object manipulation is a critical component in learning about the objects, and immersive applications allowing interactions with 3D virtual reconstructions of artifacts improve engagement and learning in comparison to static displays of the real objects.</p>\n<p>The produced work &ldquo;VR-Assisted Physical Rehabilitation: Adapting to the Needs of Therapists and Patients&rdquo; reports new techniques for parameterizing upper-body exercises delivered by animated characters in an interactive system, such that deliveries adapt to user performances according to specifications set by therapists. The presented techniques address autonomous delivery of exercises which adapt to individual preferences, thus improving adoption and enabling monitored exercises at home.</p>\n<p>The produced work &ldquo;Coordinating Full-Body Interactions with the Environment&rdquo; reports a new methodology for achieving virtual trainers capable of autonomously performing complex full-body actions involving manipulation and locomotion. The proposed model is based on learning local spatial relationships from motion-captured performances of example actions, and then on transforming the learned information to new situations and environments. The work contributes to achieving autonomous virtual characters that can demonstrate tasks to be executed in virtual training systems with minimal input from the task designer.</p>\n<p>Overall this award supported projects which generated 4 peer-reviewed journal publications, 6 peer-reviewed publications in conference proceedings, and 5 peer-reviewed conference talks and poster presentations. This award contributed to the work of 5 Ph. D. students and several undergraduate students who were exposed to the projects as assistants, during lab visits, and in course projects. This project was carried out at UC Merced, a Hispanic-serving institution with a large proportion of under-represented minority undergraduate students.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/13/2017<br>\n\t\t\t\t\tModified by: Marcelo&nbsp;Kallmann</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis award has enabled the acquisition and integration of new research equipment to support projects in the areas of interactive systems for physical rehabilitation, interaction with autonomous virtual trainers, gesture synthesis models, and full-body character animation. These topics contribute to the development of computer-animated virtual trainers for interactive human-centric applications. The new research equipment included a full-body motion capture suit, data gloves, head-mounted displays, and large movable interactive displays integrated with motion capture sensors. The new equipment has enhanced a virtual reality laboratory at UC Merced dedicated to human interaction in virtual environments and the supported activities have produced several results reported in scientific publications.\n\nThe produced work \"The Effects of Avatars, Stereo Vision and Display Size on Reaching and Motion Reproduction\" reports new findings related to how different system configurations influence motion performances. The results show that the use of 3D avatars improve the quality of produced motions and the resemblance of replicated motions; however, direct interaction in user-perspective mode leads to tasks executed in less time and to targets more accurately reached. Display size was not found to significantly impact performances. These and additional tradeoffs are important for the effective design of avatar-based training systems.\n\nThe produced work \"3D Printing and Immersive Visualization for Improved Perception and Interaction with Ancient Artifacts\" investigated the effectiveness of different presentation modes when displaying ancient artifacts to people. The results show that object manipulation is a critical component in learning about the objects, and immersive applications allowing interactions with 3D virtual reconstructions of artifacts improve engagement and learning in comparison to static displays of the real objects.\n\nThe produced work \"VR-Assisted Physical Rehabilitation: Adapting to the Needs of Therapists and Patients\" reports new techniques for parameterizing upper-body exercises delivered by animated characters in an interactive system, such that deliveries adapt to user performances according to specifications set by therapists. The presented techniques address autonomous delivery of exercises which adapt to individual preferences, thus improving adoption and enabling monitored exercises at home.\n\nThe produced work \"Coordinating Full-Body Interactions with the Environment\" reports a new methodology for achieving virtual trainers capable of autonomously performing complex full-body actions involving manipulation and locomotion. The proposed model is based on learning local spatial relationships from motion-captured performances of example actions, and then on transforming the learned information to new situations and environments. The work contributes to achieving autonomous virtual characters that can demonstrate tasks to be executed in virtual training systems with minimal input from the task designer.\n\nOverall this award supported projects which generated 4 peer-reviewed journal publications, 6 peer-reviewed publications in conference proceedings, and 5 peer-reviewed conference talks and poster presentations. This award contributed to the work of 5 Ph. D. students and several undergraduate students who were exposed to the projects as assistants, during lab visits, and in course projects. This project was carried out at UC Merced, a Hispanic-serving institution with a large proportion of under-represented minority undergraduate students.\n\n \n\n\t\t\t\t\tLast Modified: 10/13/2017\n\n\t\t\t\t\tSubmitted by: Marcelo Kallmann"
 }
}