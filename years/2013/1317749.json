{
 "awd_id": "1317749",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: Small: Robotic Scouts: Augmenting Human Perception for Underground Rescue",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "jeffrey trinkle",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 600000.0,
 "awd_amount": 608000.0,
 "awd_min_amd_letter_date": "2013-09-09",
 "awd_max_amd_letter_date": "2014-05-09",
 "awd_abstract_narration": "Robots are potential tools for life saving in underground rescue operations like mine disasters. Human rescuers are thwarted by roof falls, explosion dangers, quality of air, visibility through smoke and dust, mental stress and physical endurance. The inability of human rescuers to cover sufficient distance in a short time often has fatal consequences for accident victims. Robots which autonomously scout ahead of human rescuers and summarize environmental information can greatly enhance situational awareness, enabling teams to push forward without delay. This proposal envisions immersive, robotically-created 3D models, fused from many sensor sources and created through smoke, dust, mud, flood and fire. These expansive models provide rescuers with visual clarity that are uncorrupted by environmental condition. Illumination artifacts, sensor noise and errors are removed by fusion and intelligent view planning of radical new modalities including LIDAR, RADAR, multispectral imaging and actively-illuminated RGB sensing. \r\n\r\nWhile the world has often been captivated by high-visibility mine accidents, robots are tangible tools with visible results that have the opportunity to become the centerpiece of any rescue effort. The disrupting effect of the first trapped miner found and human life saved by a rescue robot would inspire countless people to appreciate the evolving role of science and technology in our lives. Prior underground robotics work by this team have generated considerable press and initiated acceptance of robotic technology in even the most change-adverse industries. The investigators will continue to push for robots through media appearances, lab and mine tours for school children and live demonstrations at science museums. This project will support education at all levels, which includes supporting postdoctoral and graduate research in robotics at CMU, employing undergraduate REU interns, and developing curriculum for the Mobile Robot Design course at CMU. Contributions from this research will impact automation in industries ranging from underground production to civic inspection, and defense.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Whittaker",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "William L Whittaker",
   "pi_email_addr": "red@ri.cmu.edu",
   "nsf_id": "000222720",
   "pi_start_date": "2013-09-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Srinivasa",
   "pi_last_name": "Narasimhan",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Srinivasa G Narasimhan",
   "pi_email_addr": "srinivas@cs.cmu.edu",
   "nsf_id": "000149438",
   "pi_start_date": "2013-09-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 600000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Smoke and dust occur with explosions, fire and roof collapse associated with most of the worst mine accidents.&nbsp;The worst mine disaster of this century occurred in Soma, Turkey on May 13, 2014. This disaster produced heavy smoke that impeded rescue making it difficult for human rescuers to see, navigate, and breathe. More than 300 people died and 80 more were injured. Lighting is a paradox since lighting is required to see anything in a dark mine, but it also obscures the scene. &nbsp;Imagine a more common scenario of driving in foggy conditions where high beams make the visibility worse.</p>\n<p>The research goal of this project was to develop robotic technologies to help in rescue missions. Robotics relies heavily on visual cameras and LIDAR to navigate in the world. Existing methods with these technologies allow successful mapping and navigation of mines in clear conditions. However, the smoke and dust that are present in mine disasters obscure both LIDAR and vision, making traditional methods fail. Episcan3D, a 3D sensor developed in this research precludes scatter by intelligently illuminating and capturing the scene. Similarly, thermal imaging sees through smoke. &nbsp;However, since underground thermal gradients are small, the features are faint and indistinct. &nbsp;This research developed dense and direct SLAM that succeeds where these faint features fail. &nbsp;It lacks the detail of clear sensing, but is sufficient for robot navigation. Finally, multimodal navigation fuses visual, range, Episcan3D and thermal data to reliably navigate and model smoke-filled mines.</p>\n<p>In summary, this research innovated sensing and modeling for unprecedented navigation through dust and smoke. This is useful for miners, firefighters, and other first responders in difficult rescue missions.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/01/2016<br>\n\t\t\t\t\tModified by: William&nbsp;L&nbsp;Whittaker</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2016/1317749/1317749_10277217_1480550808148_cover_photo_rev4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1317749/1317749_10277217_1480550808148_cover_photo_rev4--rgov-800width.jpg\" title=\"Robotics for Mine Rescue\"><img src=\"/por/images/Reports/POR/2016/1317749/1317749_10277217_1480550808148_cover_photo_rev4--rgov-66x44.jpg\" alt=\"Robotics for Mine Rescue\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Robots working with humans can autonomously scout ahead and provide vital rescue information when it is not yet safe for humans. This research innovated sensing and modelling for robot navigation through dust and smoke that occurs in mine disasters.</div>\n<div class=\"imageCredit\">Joe Bartels</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">William&nbsp;L&nbsp;Whittaker</div>\n<div class=\"imageTitle\">Robotics for Mine Rescue</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nSmoke and dust occur with explosions, fire and roof collapse associated with most of the worst mine accidents. The worst mine disaster of this century occurred in Soma, Turkey on May 13, 2014. This disaster produced heavy smoke that impeded rescue making it difficult for human rescuers to see, navigate, and breathe. More than 300 people died and 80 more were injured. Lighting is a paradox since lighting is required to see anything in a dark mine, but it also obscures the scene.  Imagine a more common scenario of driving in foggy conditions where high beams make the visibility worse.\n\nThe research goal of this project was to develop robotic technologies to help in rescue missions. Robotics relies heavily on visual cameras and LIDAR to navigate in the world. Existing methods with these technologies allow successful mapping and navigation of mines in clear conditions. However, the smoke and dust that are present in mine disasters obscure both LIDAR and vision, making traditional methods fail. Episcan3D, a 3D sensor developed in this research precludes scatter by intelligently illuminating and capturing the scene. Similarly, thermal imaging sees through smoke.  However, since underground thermal gradients are small, the features are faint and indistinct.  This research developed dense and direct SLAM that succeeds where these faint features fail.  It lacks the detail of clear sensing, but is sufficient for robot navigation. Finally, multimodal navigation fuses visual, range, Episcan3D and thermal data to reliably navigate and model smoke-filled mines.\n\nIn summary, this research innovated sensing and modeling for unprecedented navigation through dust and smoke. This is useful for miners, firefighters, and other first responders in difficult rescue missions.\n\n\t\t\t\t\tLast Modified: 12/01/2016\n\n\t\t\t\t\tSubmitted by: William L Whittaker"
 }
}