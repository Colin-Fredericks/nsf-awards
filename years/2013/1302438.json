{
 "awd_id": "1302438",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CIF: Medium:Collaborative Research: Nonasymptotic Analysis of Feature-Rich Decision Problems with Applications to Computer Vision",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2013-07-01",
 "awd_exp_date": "2018-06-30",
 "tot_intn_awd_amt": 669212.0,
 "awd_amount": 669212.0,
 "awd_min_amd_letter_date": "2013-06-07",
 "awd_max_amd_letter_date": "2015-06-03",
 "awd_abstract_narration": "This project deals with theory and efficient algorithms for statistical decision problems that are radically different from those that have been studied to date in two key aspects: First, the decision-maker may choose among a large class of observation channels (features) of varying complexity and quality; and second, the total cost of computational resources that can be used prior to arriving at a decision is limited. Computer vision is a paradigmatic source of such feature-rich decision problems, requiring the use of multiple heterogeneous feature types, integration of diverse sources of contextual information, and possibly even human interaction.\r\n\r\nThis project entails the development of a rigorous mathematical framework for feature-rich decision problems in accordance with three specific aims: (1) structural characterization of features as stochastic belief-refining filters; (2) universal cost-sensitive criteria for numerical comparison of features in terms of expected information gains; and (3) optimal value-of-information criteria for sequential feature selection that take into account both feature extraction costs and terminal decision losses. As corollaries, this research investigates connections to asymptotic information-theoretic characterizations of optimal feature selection rules and decisions. The fourth specific aim of the project is the development of practical algorithms for two challenging computer vision problems: active visual search and fine-grained categorization. This component of the project leverages theoretical aims (1) and (2) to develop practical cost- and loss-sensitive feature compression techniques. Theoretical aim (3) targets algorithms that function as autonomous decision-making agents. Faced with an inference task on an image, they apply cost-sensitive non-myopic value- of-information criteria to decide at each time step whether to extract a new feature from the image or to stop and declare an answer.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maxim",
   "pi_last_name": "Raginsky",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maxim Raginsky",
   "pi_email_addr": "maxim@illinois.edu",
   "nsf_id": "000551233",
   "pi_start_date": "2013-06-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Svetlana",
   "pi_last_name": "Lazebnik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Svetlana Lazebnik",
   "pi_email_addr": "slazebni@illinois.edu",
   "nsf_id": "000298493",
   "pi_start_date": "2013-06-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618207473",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  },
  {
   "pgm_ele_code": "793600",
   "pgm_ele_name": "SIGNAL PROCESSING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 334805.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 334407.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"tinyMCEContent\">\n<p>This project focused on theory and  efficient algorithms for statistical decision problems where the  decision-maker may choose among a large class of features of varying complexity, quality,&nbsp; and cost. Computer  vision is a paradigmatic source of such feature-rich decision problems,  requiring&nbsp;the use of multiple heterogeneous feature types, integration  of diverse sources of contextual information, and possibly even human  interaction.</p>\n<p>The following objectives were accomplished:</p>\n<ol>\n<li>A theoretical framework was developed for describing and analyzing the fundamental limits of feature maps (i.e., signal representations) with structured encoders and decoders. The analysis covered linear representations, such as PCA, vector quantization, and dictionary learning, as well as nonlinear representations, such as convolutional neural nets. Generalization bounds were derived for learning such representations from data.<br /><br /></li>\n<li>The problem of domain adaptation arises when the training data are sampled from  one distribution, but the resulting predictor is evaluated (or tested)  on a closely related but different distribution. A theoretical framework was developed based on the theory of optimal transport. It provides theoretical and practical  guidance for designing optimal features to ensure that the effect of domain  drift can be reliably captured via the Wasserstein distance between the  corresponding probability models.<br /><br /></li>\n<li>A theoretical framework and algorithms were developed for graph-based active object detection. Active object detection refers to the problem of determining the existence and location of objects in an image by actively selecting which regions of the image to explore. The algorithm was based on representing overlaps between local features as a graph and then extracting a spanning tree that would direct the search by optimzing conditional mutual information. In experimental evaluation, the use of the algorithm led to significant reduction of the number of region features that were queried.<br /><br /></li>\n<li>State-of-the-art object detection systems rely on an accurate set of region proposals. Several recent methods use a neural network architecture to hypothesize promising object locations. While these approaches are computationally efficient, they rely on fixed image regions as anchors for predictions. An alternative search strategy was developed that adaptively directs computational resources to sub-regions likely to contain objects. This approach was shown to be comparable in terms of accuracy to a state-of-the-art Faster R-CNN method while using two orders of magnitude fewer anchors on average. The code was made available to the public.<br /><br /></li>\n<li>Algorithms were developed for automated answering of visual  questions from the Visual Madlibs dataset (available publicly at http://tamaraberg.com/visualmadlibs/). Instead of generic commonly used features trained on the ImageNet  dataset (http://www.image-net.org/), this approach employs a combination of networks trained for  specialized tasks such as scene recognition, person activity  classification, and attribute prediction. <br /><br /></li>\n<li>Recurrent Neural Network  (RNN) models were developed for making predictions in structured &lsquo;image situations&rsquo; &ndash; actions and  noun entities fulfilling semantic roles related to the action. In  contrast to prior work relying on Conditional Random Fields (CRFs), this approach relied on a specialized action prediction network followed  by an RNN for noun prediction. This system obtained state-of-the-art  accuracy on the challenging recent imSitu dataset (http://imsitu.org/), beating CRF-based  models, including ones trained with additional data. Further, it showed that specialized features learned from situation prediction can be  transferred to the task of image captioning to more accurately describe  human-object interactions. </li>\n</ol></div><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/30/2018<br>\n\t\t\t\t\tModified by: Maxim&nbsp;Raginsky</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThis project focused on theory and  efficient algorithms for statistical decision problems where the  decision-maker may choose among a large class of features of varying complexity, quality,  and cost. Computer  vision is a paradigmatic source of such feature-rich decision problems,  requiring the use of multiple heterogeneous feature types, integration  of diverse sources of contextual information, and possibly even human  interaction.\n\nThe following objectives were accomplished:\n\nA theoretical framework was developed for describing and analyzing the fundamental limits of feature maps (i.e., signal representations) with structured encoders and decoders. The analysis covered linear representations, such as PCA, vector quantization, and dictionary learning, as well as nonlinear representations, such as convolutional neural nets. Generalization bounds were derived for learning such representations from data.\n\n\nThe problem of domain adaptation arises when the training data are sampled from  one distribution, but the resulting predictor is evaluated (or tested)  on a closely related but different distribution. A theoretical framework was developed based on the theory of optimal transport. It provides theoretical and practical  guidance for designing optimal features to ensure that the effect of domain  drift can be reliably captured via the Wasserstein distance between the  corresponding probability models.\n\n\nA theoretical framework and algorithms were developed for graph-based active object detection. Active object detection refers to the problem of determining the existence and location of objects in an image by actively selecting which regions of the image to explore. The algorithm was based on representing overlaps between local features as a graph and then extracting a spanning tree that would direct the search by optimzing conditional mutual information. In experimental evaluation, the use of the algorithm led to significant reduction of the number of region features that were queried.\n\n\nState-of-the-art object detection systems rely on an accurate set of region proposals. Several recent methods use a neural network architecture to hypothesize promising object locations. While these approaches are computationally efficient, they rely on fixed image regions as anchors for predictions. An alternative search strategy was developed that adaptively directs computational resources to sub-regions likely to contain objects. This approach was shown to be comparable in terms of accuracy to a state-of-the-art Faster R-CNN method while using two orders of magnitude fewer anchors on average. The code was made available to the public.\n\n\nAlgorithms were developed for automated answering of visual  questions from the Visual Madlibs dataset (available publicly at http://tamaraberg.com/visualmadlibs/). Instead of generic commonly used features trained on the ImageNet  dataset (http://www.image-net.org/), this approach employs a combination of networks trained for  specialized tasks such as scene recognition, person activity  classification, and attribute prediction. \n\n\nRecurrent Neural Network  (RNN) models were developed for making predictions in structured ?image situations? &ndash; actions and  noun entities fulfilling semantic roles related to the action. In  contrast to prior work relying on Conditional Random Fields (CRFs), this approach relied on a specialized action prediction network followed  by an RNN for noun prediction. This system obtained state-of-the-art  accuracy on the challenging recent imSitu dataset (http://imsitu.org/), beating CRF-based  models, including ones trained with additional data. Further, it showed that specialized features learned from situation prediction can be  transferred to the task of image captioning to more accurately describe  human-object interactions. \n\n\n\t\t\t\t\tLast Modified: 08/30/2018\n\n\t\t\t\t\tSubmitted by: Maxim Raginsky"
 }
}