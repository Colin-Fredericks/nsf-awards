{
 "awd_id": "1318126",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Developing a Normative Framework for Cyber Warfare",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Frederick Kronz",
 "awd_eff_date": "2013-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 184774.0,
 "awd_amount": 184774.0,
 "awd_min_amd_letter_date": "2013-09-20",
 "awd_max_amd_letter_date": "2015-07-09",
 "awd_abstract_narration": "Project Overview \r\n \r\nThe PIs propose to develop a normative framework for policies of cyber warfare. They plan to conduct an investigation into cyber warfare practices and to evaluate the extent to which current cyber warfare conforms to basic war ethics principles underlying the Hague and Geneva conventions including discrimination, attribution, proportionality, and deception. For these purposes, they are partnering with the Consortium for Emerging Technologies, Military Operations, and National Security (CETMONS).\r\n \r\nIntellectual Merit \r\n \r\nThe US is clearly worried about cyber attacks; other nations could inflict serious damage to military capabilities, as well as strike physical targets and infrastructure, with more anonymity and without placing their soldiers at risk. In response to these prospects, the US is developing a thoughtful plan to operate with greater safety and security in cyberspace. However, cyber warfare also poses great challenges to just war theory, the basis for international laws of armed conflict. This project fills an important need by investigating tensions with the basic principles of war, helping to determine the permissibility and policies of cyber warfare. It will provide a concise set of normative principles that could also serve to safeguard cyberspace, which is increasingly essential to modern life. \r\n \r\nBroader Impact \r\n \r\nThe results of this project will include a comprehensive report on cyber warfare ethics, a university-level ethics course, and an edited volume that would serve as a text for such a course. This report will identify specific options for a coherent cyber war ethics in clear language useful for policymakers. The PIs plan to solicit input and disseminate their research through public workshops, one at the beginning and another at the end of the project, as well as conference and classroom talks throughout.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Patrick",
   "pi_last_name": "Lin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Patrick Lin",
   "pi_email_addr": "palin@calpoly.edu",
   "nsf_id": "000499030",
   "pi_start_date": "2013-09-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "California Polytechnic State University Foundation",
  "inst_street_address": "1 GRAND AVE BLDG 15",
  "inst_street_address_2": "",
  "inst_city_name": "SAN LUIS OBISPO",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8057562982",
  "inst_zip_code": "934079000",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "CAL POLY CORPORATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "MC4RJJM9XLT5"
 },
 "perf_inst": {
  "perf_inst_name": "California Polytechnic State University",
  "perf_str_addr": "One Grand Avenue",
  "perf_city_name": "San Luis Obispo",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "934070001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760300",
   "pgm_ele_name": "STS-Sci, Tech & Society"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "7915",
   "pgm_ref_txt": "Ethics & Values of SET"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 52075.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 53635.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 79064.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Today, we have the capability to strike in cyberspace, but should we?&nbsp; Even if we have good reason to mount an attack, how should we proceed?&nbsp; These are legal but also ethical questions.&nbsp; Because the laws of armed conflict (LOAC) had not been written with cyberspace in mind, we face a governance and ethics gap.&nbsp; New proposals for &ldquo;cyber norms&rdquo; and to clarify LOAC are emerging to fill that gap, however, such as the NATO-sponsored &ldquo;Tallinn Manual&rdquo; (both first- and second-generation versions).</p>\n<p>While the Tallinn Manual is a major first step toward clarity in international law, it only applies existing law to cyber conflicts and does not delve into more murky realm of ethics, including policy recommendations beyond what is legally required or prohibited.&nbsp; As US State Dept. advisor Harold Koh had put it, &ldquo;Not all of the issues [about cyberwar] are susceptible to clear legal answers derived from existing precedents&mdash;in many cases, quite the contrary.&rdquo;&nbsp; That&rsquo;s to say, reasoning by analogy takes us only so far, and we need to dig deeper into &ldquo;first principles&rdquo; in ethics as a way to guide us forward when law has run out of road.&nbsp;</p>\n<p>To that end, this project undertook a systematic study of ethical and other foundational questions, such as: When does a cyberattack count as an &ldquo;armed attack&rdquo; or &ldquo;use of force&rdquo; in LOAC? &nbsp;When might a cyberattack rise to the level of <em>casus belli</em> or a justified cause for counterstrikes? &nbsp;If a state response is too risky, e.g., could escalate international tensions and create a conventional conflict, would it be ethical or legal for private companies to &ldquo;hack back&rdquo;?&nbsp; Is an industry engineer who materially helps to create a cyberweapon considered a &ldquo;noncombatant directly participating in hostilities&rdquo; and therefore no longer legally immune to being targeted and killed?</p>\n<p>There are novel features of cyberoperations that may be difficult to reconcile with existing LOAC.&nbsp; Cyberattacks seem different than conventional attacks in that individual incidents might not rise to the level of <em>casus belli</em>, yet they can aggregate into massive harms (&ldquo;death by a thousand cuts&rdquo;); should that change the moral calculus of counterstriking?&nbsp; Some cyberops may be indiscriminate, e.g., phishing scams in hopes to penetrate a particular organization; does the prohibition on targeting noncombatants still apply since cyber effects are nonlethal?&nbsp; Does the prohibition on perfidy or treacherous deception still apply here, e.g., is dressing up in enemy uniform analogous to dressing an email up (spoofing) as coming from an enemy&rsquo;s own command?</p>\n<p>We also explored missing connections between cyberoperations and artificial intelligence, e.g., autonomous cyberoffense or cyberdefense.&nbsp; Inasmuch as &ldquo;meaningful human control&rdquo; (MHC) is a key objection made against lethal autonomous weapons systems (&ldquo;killer robots&rdquo;), it&rsquo;s strange that there&rsquo;s little discussion of MHC in the context of cyber.&nbsp; So, cyberwar norms can also learn from robot ethics, as well as cognate fields such as Internet of Things ethics.</p>\n<p>In tackling these questions, we&rsquo;ve engaged scholars and practitioners worldwide in several expert meetings we organized at various locations that include: International Committee of the Red Cross, Geneva (2014); US Naval Postgraduate School, Monterey (2015); United Nations, NYC (2015); United Nations, Geneva (2015); US Naval Academy, Annapolis (2016); University of Iceland, Reykjavik (2017); and smaller meetings at Cal Poly, San Luis Obispo.&nbsp; We&rsquo;ve also founded the Australasia-Pacific chapter of the International Society for Military Ethics (APAC-ISME).&nbsp; These also served to disseminate our research, learn about new research, and cross-pollinate expertise, since cyberwar ethics is very much an interdisciplinary and global area.</p>\n<p>Our outcomes or products include two journal papers, seven book chapters, a policy paper, an edited book (Oxford University Press, 2016), a monograph (Springer, 2016), and a university-level course on ethics and emerging military technologies, especially cyberwar.&nbsp; We also wanted to raise awareness and engage a broader audience, including policymakers and practitioners, which we achieved through more than 10 by-lined media articles (such as in <em>The Atlantic, Slate, Wall Street Journal, Bulletin of the Atomic Scientists</em>, others) and media interviews.&nbsp;</p>\n<p>We also delivered invited lectures, testimony, and public talks at such venues as Stanford University, United Nations, Google, Apple, MIT, RSA Conference, European Intelligence and Security Informatics Conference, and others.&nbsp; We brought our research to bear in expert meetings at World Economic Forum, Aspen Institute/IBM, NSF/Department of Homeland Security, ISME, and more.</p>\n<p>There&rsquo;s now growing recognition that cyberconflicts will present unique challenges to society.&nbsp; The laws of armed conflict exist for good reason: they limit the horrors of war, protecting both civilians and combatants.&nbsp; So, clarifying LOAC is important to keep cyberwarfare within the bounds of law and ethics; and when law is unclear or missing entirely, ethics can be a North Star to illuminate the darkness.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/27/2017<br>\n\t\t\t\t\tModified by: Patrick&nbsp;Lin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nToday, we have the capability to strike in cyberspace, but should we?  Even if we have good reason to mount an attack, how should we proceed?  These are legal but also ethical questions.  Because the laws of armed conflict (LOAC) had not been written with cyberspace in mind, we face a governance and ethics gap.  New proposals for \"cyber norms\" and to clarify LOAC are emerging to fill that gap, however, such as the NATO-sponsored \"Tallinn Manual\" (both first- and second-generation versions).\n\nWhile the Tallinn Manual is a major first step toward clarity in international law, it only applies existing law to cyber conflicts and does not delve into more murky realm of ethics, including policy recommendations beyond what is legally required or prohibited.  As US State Dept. advisor Harold Koh had put it, \"Not all of the issues [about cyberwar] are susceptible to clear legal answers derived from existing precedents&mdash;in many cases, quite the contrary.\"  That?s to say, reasoning by analogy takes us only so far, and we need to dig deeper into \"first principles\" in ethics as a way to guide us forward when law has run out of road. \n\nTo that end, this project undertook a systematic study of ethical and other foundational questions, such as: When does a cyberattack count as an \"armed attack\" or \"use of force\" in LOAC?  When might a cyberattack rise to the level of casus belli or a justified cause for counterstrikes?  If a state response is too risky, e.g., could escalate international tensions and create a conventional conflict, would it be ethical or legal for private companies to \"hack back\"?  Is an industry engineer who materially helps to create a cyberweapon considered a \"noncombatant directly participating in hostilities\" and therefore no longer legally immune to being targeted and killed?\n\nThere are novel features of cyberoperations that may be difficult to reconcile with existing LOAC.  Cyberattacks seem different than conventional attacks in that individual incidents might not rise to the level of casus belli, yet they can aggregate into massive harms (\"death by a thousand cuts\"); should that change the moral calculus of counterstriking?  Some cyberops may be indiscriminate, e.g., phishing scams in hopes to penetrate a particular organization; does the prohibition on targeting noncombatants still apply since cyber effects are nonlethal?  Does the prohibition on perfidy or treacherous deception still apply here, e.g., is dressing up in enemy uniform analogous to dressing an email up (spoofing) as coming from an enemy?s own command?\n\nWe also explored missing connections between cyberoperations and artificial intelligence, e.g., autonomous cyberoffense or cyberdefense.  Inasmuch as \"meaningful human control\" (MHC) is a key objection made against lethal autonomous weapons systems (\"killer robots\"), it?s strange that there?s little discussion of MHC in the context of cyber.  So, cyberwar norms can also learn from robot ethics, as well as cognate fields such as Internet of Things ethics.\n\nIn tackling these questions, we?ve engaged scholars and practitioners worldwide in several expert meetings we organized at various locations that include: International Committee of the Red Cross, Geneva (2014); US Naval Postgraduate School, Monterey (2015); United Nations, NYC (2015); United Nations, Geneva (2015); US Naval Academy, Annapolis (2016); University of Iceland, Reykjavik (2017); and smaller meetings at Cal Poly, San Luis Obispo.  We?ve also founded the Australasia-Pacific chapter of the International Society for Military Ethics (APAC-ISME).  These also served to disseminate our research, learn about new research, and cross-pollinate expertise, since cyberwar ethics is very much an interdisciplinary and global area.\n\nOur outcomes or products include two journal papers, seven book chapters, a policy paper, an edited book (Oxford University Press, 2016), a monograph (Springer, 2016), and a university-level course on ethics and emerging military technologies, especially cyberwar.  We also wanted to raise awareness and engage a broader audience, including policymakers and practitioners, which we achieved through more than 10 by-lined media articles (such as in The Atlantic, Slate, Wall Street Journal, Bulletin of the Atomic Scientists, others) and media interviews. \n\nWe also delivered invited lectures, testimony, and public talks at such venues as Stanford University, United Nations, Google, Apple, MIT, RSA Conference, European Intelligence and Security Informatics Conference, and others.  We brought our research to bear in expert meetings at World Economic Forum, Aspen Institute/IBM, NSF/Department of Homeland Security, ISME, and more.\n\nThere?s now growing recognition that cyberconflicts will present unique challenges to society.  The laws of armed conflict exist for good reason: they limit the horrors of war, protecting both civilians and combatants.  So, clarifying LOAC is important to keep cyberwarfare within the bounds of law and ethics; and when law is unclear or missing entirely, ethics can be a North Star to illuminate the darkness.\n\n\t\t\t\t\tLast Modified: 09/27/2017\n\n\t\t\t\t\tSubmitted by: Patrick Lin"
 }
}