{
 "awd_id": "1321174",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF:Small:Collaborative Research: Compressed databases for similarity queries: fundamental limits and algorithms",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Cozzens",
 "awd_eff_date": "2013-07-01",
 "awd_exp_date": "2016-06-30",
 "tot_intn_awd_amt": 249999.0,
 "awd_amount": 249999.0,
 "awd_min_amd_letter_date": "2013-06-21",
 "awd_max_amd_letter_date": "2013-06-21",
 "awd_abstract_narration": "Information theory has had a profound impact on the fields of data transmission and compression. In contrast, it has yielded comparably few insights into problems such as knowledge extraction from and efficient search of massive datasets. While current information-theoretic tools and techniques can be applied to these problems to some extent, the paradigms for which these tools were developed will be being carefully reexamined in this project. Models that accurately capture the fundamental challenges faced by efficient search in modern massive database systems will be developed and analyzed. The asymptotic fundamental limits, which characterize the tradeoffs between accuracy, compression rate and search efficiency, will be investigated, along with development of practical algorithms that approach the ultimate benchmarks. One concrete problem being pursued is that of compression for efficient query and search. In this setting, the goal is, given a compressed representation, to answer search queries about the data that was compressed. This is in stark contrast to traditional compression, where the data need be merely reconstructible from the compressed form. The approach taken is tailored to distributed database design, but is also relevant to compression schemes that allow search within the compressed domain. \r\n\r\nThe fundamental quantities studied play a similar role to that of the channel capacity and entropy/rate-distortion in channel and source coding, respectively. On one hand, they yield an understanding of the fundamental limits on the performance that any system for similarity queries based on compressed representations can hope to attain. On the other, the insights obtained from the theory are guiding the construction of schemes that approach these limits in practice. We will investigate how existing practical approaches (such as various hashing and clustering techniques) perform with respect to the information theoretic limits, and the extent to which approaches that have proved to be practical in source and channel coding can be used as building blocks to develop new efficient search algorithms that significantly improve on the current state of the art.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tsachy",
   "pi_last_name": "Weissman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tsachy Weissman",
   "pi_email_addr": "tsachy@stanford.edu",
   "nsf_id": "000488863",
   "pi_start_date": "2013-06-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943054100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "793600",
   "pgm_ele_name": "SIGNAL PROCESSING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 249999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">The project was dedicated to the development and analysis of models that capture the fundamental challenges faced by efficient search in modern massive database systems. We have characterized the asymptotic fundamental limits on achievable tradeoffs between accuracy, compression rate and search efficiency. We've also developed practical algorithms that approach the ultimate benchmarks.</p>\n<p class=\"p1\">One concrete problem that was extensively studied in this project is that of compression for efficient query and search. In this setting, the goal is, given a compressed representation, to answer search queries about the data that were compressed. This is in stark contrast to traditional compression, where the data need be merely reconstructible (with or without distortion) from the compressed representation. Our approach and models, which were motivated by discussions with practitioners about real problems encountered in biological data integration and in forensics, are tailored to distributed genomic database design, but no less relevant to&nbsp;other compression scenarios involving search within the compressed domain. We have exploited insight obtained from our theoretical findings for implementing and experimenting with practical schemes. Some of our resulting implementations are already in use for the compression and analysis of data pertaining to a large scale genomic sequencing project at the Stanford medical school. &nbsp; &nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/02/2016<br>\n\t\t\t\t\tModified by: Itschak(Tsachy&nbsp;Weissman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "The project was dedicated to the development and analysis of models that capture the fundamental challenges faced by efficient search in modern massive database systems. We have characterized the asymptotic fundamental limits on achievable tradeoffs between accuracy, compression rate and search efficiency. We've also developed practical algorithms that approach the ultimate benchmarks.\nOne concrete problem that was extensively studied in this project is that of compression for efficient query and search. In this setting, the goal is, given a compressed representation, to answer search queries about the data that were compressed. This is in stark contrast to traditional compression, where the data need be merely reconstructible (with or without distortion) from the compressed representation. Our approach and models, which were motivated by discussions with practitioners about real problems encountered in biological data integration and in forensics, are tailored to distributed genomic database design, but no less relevant to other compression scenarios involving search within the compressed domain. We have exploited insight obtained from our theoretical findings for implementing and experimenting with practical schemes. Some of our resulting implementations are already in use for the compression and analysis of data pertaining to a large scale genomic sequencing project at the Stanford medical school.    \n\n\t\t\t\t\tLast Modified: 09/02/2016\n\n\t\t\t\t\tSubmitted by: Itschak(Tsachy Weissman"
 }
}