{
 "awd_id": "1319378",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: TwitterHealth: Learning Fine-Grained Models of Health Influences and Interactions From Social Media",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 481939.0,
 "awd_amount": 497939.0,
 "awd_min_amd_letter_date": "2013-08-26",
 "awd_max_amd_letter_date": "2015-05-14",
 "awd_abstract_narration": "Current techniques for answering questions about the influence of behaviorial and environmental factors on public health are based on surveys, which are costly and subject to response bias, or simulations, which rely on possibly incorrect or simplistic assumptions.  The TwitterHealth project is developing techniques to extract reliable public health information from social media.  In essence, the online population becauses a vast organic sensor network.  Statistical natural language processing techniques are employed to classify tweets (or other social media postings) as self-reports of disease or particular behaviors of interest.  GPS information included in postings made from cell phones allow a variety of behavioral information to be inferred about each user, such as the venues visited and the other individuals from the data set who are encountered.\r\n\r\nMajor technical challenges for using social media in this manner are the highly noisy nature of the information channel, scaling to a large number of different health conditions, and the need to discover causal influences as well as correlations between behavioral and environmental factors and health.  The challenge of noise is approached by learning dynamic relational models of health states, which generalize classical epidemiological models but support individual as well as aggregate predictions.  The scaling challenge is dealt with by knowledge transfer techniques, which reduce data and computational requirements by transfering information between models for different health conditions.  Specific knowledge transfer techniques are cascaded training of a target classifier starting with a given classifier for a related but different disease, and the use of ensembles of general and specific classifiers.  The challenge of inferring casuality is addressed by temporal-lag methods, which identify changes in behaviorial or environmental conditions that consistently precede changes in health.  For example, the inference that a venue is a cause (vector) of disease spread is accomplished by tracing backward in time the GPS trails of users who post social media reports of illness.  TwitterHealth employs two approaches for validating its results: first, comparing the aggregate predictions of the model against CDC statistics; second, comparing individuals' behavior in reporting or not reporting disease symptoms in status updates against the behavior predicted by the models.  The project also includes planning for clinic based evaluations, in which subjects identified by their social media postings would provide swabs that would be tested for disease agents.\r\n\r\nThe TwitterHealth approach to collecting and analyzing health information has the potential to improve public health, by making detailed data about health, behavior, social structure, and geographic influences available in real time and at almost no cost.  While it will not completely replace traditional methods of gathering health information, it provides an important complementary information channel, which emphases speed, reach, and scale.  The project includes outreach expert medical professionals in order to plan future clinical validation.  The outreach interaction provides a forum for exchange of computer science and medical expertise between researchers and students in the two fields. Information about the project is available online at http://www.cs.rochester.edu/u/kautz/twitterhealth.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Henry",
   "pi_last_name": "Kautz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Henry Kautz",
   "pi_email_addr": "henry.kautz@virginia.edu",
   "nsf_id": "000240955",
   "pi_start_date": "2013-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146270140",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  },
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 481939.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The TwitterHealth project has created general methods for deriving public health information from social media data, and developed applications that use such information to improve public health.&nbsp; We first developed natural language processing techniques that can be used to find tweets that are self-reports of disease symptoms.&nbsp; Finding such tweets, which are as few as 1 out 30,000, is a challenging \"needle in a haystack\" problem.&nbsp; We showed how a combination of crowdsourcing and machine learning can solve this problem for any given diseases.&nbsp; We first used this approach to measure and predict changes in the rate of influenza in cities around the world.&nbsp; We went on to use the approach to build a system that could determine when and where people were sending tweets about drinking, and demographics characteristics of the drinkers; such data is useful for measuring the effectiveness of campaigns against teenage drinking.&nbsp; Finally, we built a system that could find tweets that were reports of foodborne illness.&nbsp; We worked with the public health department for the city of Las Vegas in order to build a system that helps restaurant inspectors prioritize inspections.&nbsp; The system works by finding tweets about foodborne illness, and then linking back to restaurants where the tweeter was the day before.&nbsp; A double-blind trial showed that the system was effective in increasing the number of food safety violations that were caught by inspectors.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/12/2017<br>\n\t\t\t\t\tModified by: Henry&nbsp;Kautz</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe TwitterHealth project has created general methods for deriving public health information from social media data, and developed applications that use such information to improve public health.  We first developed natural language processing techniques that can be used to find tweets that are self-reports of disease symptoms.  Finding such tweets, which are as few as 1 out 30,000, is a challenging \"needle in a haystack\" problem.  We showed how a combination of crowdsourcing and machine learning can solve this problem for any given diseases.  We first used this approach to measure and predict changes in the rate of influenza in cities around the world.  We went on to use the approach to build a system that could determine when and where people were sending tweets about drinking, and demographics characteristics of the drinkers; such data is useful for measuring the effectiveness of campaigns against teenage drinking.  Finally, we built a system that could find tweets that were reports of foodborne illness.  We worked with the public health department for the city of Las Vegas in order to build a system that helps restaurant inspectors prioritize inspections.  The system works by finding tweets about foodborne illness, and then linking back to restaurants where the tweeter was the day before.  A double-blind trial showed that the system was effective in increasing the number of food safety violations that were caught by inspectors.\n\n\t\t\t\t\tLast Modified: 11/12/2017\n\n\t\t\t\t\tSubmitted by: Henry Kautz"
 }
}