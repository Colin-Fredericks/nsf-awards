{
 "awd_id": "1317214",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: Small: Collaborative Research: Don't Read my Face: Tackling the Challenges of Facial Masking in Parkinson's Disease Rehabilitation through Co-Robot Mediators",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "David Miller",
 "awd_eff_date": "2013-09-15",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 579987.0,
 "awd_amount": 587987.0,
 "awd_min_amd_letter_date": "2013-09-02",
 "awd_max_amd_letter_date": "2015-05-14",
 "awd_abstract_narration": "The overarching scientific goal of this project is two-fold: (1) to develop a robotic architecture endowed with moral emotional control mechanisms, abstract moral reasoning, and a theory of mind that allow corobots to be sensitive to human affective and ethical demands, and (2) to develop a specific instance of the architecture for a co-robot mediator between people with \"facial masking\" due to Parkinson's disease (PD) that reduces their ability to signal emotion, pain, personality and intentions to their family caregivers, and health care providers who often misinterpret the lack of emotional expressions as disinterest and an inability to adhere to treatment regimen, resulting in stigmatization. To tackle these problems, the project brings together two roboticists with extensive prior experience in robot ethics and modeling emotions as well as implementing them in integrated autonomous robotic systems. The robotics expertise is combined with that of an expert in early PD rehabilitation and daily social life. The project will build on extensive software, hardware and data set resources, including complex robotic control architectures with ethical control mechanisms, personality and emotion models, and affect and natural language capabilities.\r\n\r\nThe general expected outcome of the project is an architecture for co-robots that can be adapted to a great variety of health care scenarios in an effort to enrich and dignify already stressed and stigmatized relationships between humans. The project also includes novel educational efforts such as a course in occupational therapy robotics as well as significant K?12 outreach through the Tufts Centers for STEM Diversity and for Engineering Education and Outreach, as well as various important community and public activities such as presentations on health care robotics to focus and patient groups.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ronald",
   "pi_last_name": "Arkin",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Ronald C Arkin",
   "pi_email_addr": "arkin@cc.gatech.edu",
   "nsf_id": "000185791",
   "pi_start_date": "2013-09-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Ave",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 579987.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>This project contributed knowledge about how the mere presence of human-like robots influences human-human interactions.</strong></p>\n<p>When two people are interacting, the mere presence of another person can change their behavior; they become more conservative and restrict the information they share with one another. Human-human relationships need positive and open interactions to develop and overcome conflict. We ran a study examining how a bystander robot influences the disclosure of private information during an interview in which one individual asks personal questions of another individual. The intimacy of the disclosures was not influenced by the presence of the robot, even when that robot responded by smiling and frowning in response to disclosures. People may be able to interact with one another more naturally and be more open with a robot present than a third person present. This quality makes a robot well suited to support two-person relationships in which intimate information will be discussed, like patient-caregiver relationships.<strong>&nbsp;</strong></p>\n<p><strong>&nbsp;</strong></p>\n<p><strong>The project developed a rule-based robot to protect the dignity of relationship members who are involved in interactions with clear boundary violations. This included using a study to gather feedback from potential users about how such a robot should behave.</strong></p>\n<p>In certain types of human-human relationships, like patient-caregiver relationships, there are clearly defined types of communication and/or behavior that are never appropriate during their interactions. For example, a caregiver should never be screaming at or swearing at a patient, and the patient should remain with caregiver until the end of their session together. As part of this grant, researchers created a robot that identified some of these clearly defined rules of inappropriate relationship behavior. The robot responded to these instances by saying something to calm the caregiver and/or the patient. Researchers filmed examples of the robot intervening in a dramatized patient-caregiver relationship and asked participants over the age of sixty what they thought of the robot acting in this way. The participants believed that the robot intervening to support safety in the relationship was incredibly important, but they did not like it when the robot was commanding of the patient or the caregiver. These insights inform the development of robots that intervene to support relationships and uphold the dignity of both relationship members. Robots should not command people to act in certain ways and should focus on intervening in situations that are critical to both individuals? safety and wellbeing.&nbsp;</p>\n<p><strong>&nbsp;</strong></p>\n<p><strong>As part of the grant, researchers developed and tested a model to identify strain in relationships with power differences, like patient-caregiver relationships.&nbsp;</strong></p>\n<p>If a robot is going to support healthy communication in human-human relationships, it needs to first be able to identify when there is strain in these relationships. Researchers conducted an extensive literature review of relationship-focused human mediation and conflict theory to decide upon instances when a robot may be able to identify strain in and support the functioning of human-human relationships. They presented a novel computational model for a robot to identify problematic relationship states, and they proposed behaviors for the robot to enact to help to ameliorate these states. They ran a study in which they collected and labeled videos that had exemplary instances of relationship strain. These videos informed the creation of algorithms that help robotic systems identify some of these problematic states. This work revealed the nuance of problematic relationship states. Typical markers of relationship strain such as raised voice or gaze aversion are not necessarily present in situations with relationship strain, and they may be present in healthy relationships. The implementation of the algorithms also revealed technical difficulties that can challenge the identification of these states. Researchers provided insights into how future systems could change to better capture the nuance of these states. For example, it will be important for future systems to incorporate additional features to understand when relationships are strained, such as incorporating language processing. These insights will help to design systems to support better communication in hierarchical relationships, which previous research has shown often will handle conflict in unhealthy ways.&nbsp;</p>\n<p><strong>&nbsp;</strong></p>\n<p><strong>Researchers created and tested a robot that tried to understand and support human-human relationships with power differences involved in conflict.&nbsp;</strong></p>\n<p>The analysis into this intervening robot is ongoing. There are clear differences in how people responded to the robot's interventions. The interventions attempted to support openness and orient the parties to each other. There are those who ignore the robot's interventions or were clearly perturbed by interventions. There were others who were responsive to the interventions and appeared to open up. The analysis of how individuals responded to these interventions will provide insights into how a robot is able to promote interactions in hierarchical relationships where both members are open and engaged with one another. These types of interactions promote healthier relationships that are able to overcome conflict and evolve to the benefit of both relationship members.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/04/2019<br>\n\t\t\t\t\tModified by: Ronald&nbsp;C&nbsp;Arkin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project contributed knowledge about how the mere presence of human-like robots influences human-human interactions.\n\nWhen two people are interacting, the mere presence of another person can change their behavior; they become more conservative and restrict the information they share with one another. Human-human relationships need positive and open interactions to develop and overcome conflict. We ran a study examining how a bystander robot influences the disclosure of private information during an interview in which one individual asks personal questions of another individual. The intimacy of the disclosures was not influenced by the presence of the robot, even when that robot responded by smiling and frowning in response to disclosures. People may be able to interact with one another more naturally and be more open with a robot present than a third person present. This quality makes a robot well suited to support two-person relationships in which intimate information will be discussed, like patient-caregiver relationships. \n\n \n\nThe project developed a rule-based robot to protect the dignity of relationship members who are involved in interactions with clear boundary violations. This included using a study to gather feedback from potential users about how such a robot should behave.\n\nIn certain types of human-human relationships, like patient-caregiver relationships, there are clearly defined types of communication and/or behavior that are never appropriate during their interactions. For example, a caregiver should never be screaming at or swearing at a patient, and the patient should remain with caregiver until the end of their session together. As part of this grant, researchers created a robot that identified some of these clearly defined rules of inappropriate relationship behavior. The robot responded to these instances by saying something to calm the caregiver and/or the patient. Researchers filmed examples of the robot intervening in a dramatized patient-caregiver relationship and asked participants over the age of sixty what they thought of the robot acting in this way. The participants believed that the robot intervening to support safety in the relationship was incredibly important, but they did not like it when the robot was commanding of the patient or the caregiver. These insights inform the development of robots that intervene to support relationships and uphold the dignity of both relationship members. Robots should not command people to act in certain ways and should focus on intervening in situations that are critical to both individuals? safety and wellbeing. \n\n \n\nAs part of the grant, researchers developed and tested a model to identify strain in relationships with power differences, like patient-caregiver relationships. \n\nIf a robot is going to support healthy communication in human-human relationships, it needs to first be able to identify when there is strain in these relationships. Researchers conducted an extensive literature review of relationship-focused human mediation and conflict theory to decide upon instances when a robot may be able to identify strain in and support the functioning of human-human relationships. They presented a novel computational model for a robot to identify problematic relationship states, and they proposed behaviors for the robot to enact to help to ameliorate these states. They ran a study in which they collected and labeled videos that had exemplary instances of relationship strain. These videos informed the creation of algorithms that help robotic systems identify some of these problematic states. This work revealed the nuance of problematic relationship states. Typical markers of relationship strain such as raised voice or gaze aversion are not necessarily present in situations with relationship strain, and they may be present in healthy relationships. The implementation of the algorithms also revealed technical difficulties that can challenge the identification of these states. Researchers provided insights into how future systems could change to better capture the nuance of these states. For example, it will be important for future systems to incorporate additional features to understand when relationships are strained, such as incorporating language processing. These insights will help to design systems to support better communication in hierarchical relationships, which previous research has shown often will handle conflict in unhealthy ways. \n\n \n\nResearchers created and tested a robot that tried to understand and support human-human relationships with power differences involved in conflict. \n\nThe analysis into this intervening robot is ongoing. There are clear differences in how people responded to the robot's interventions. The interventions attempted to support openness and orient the parties to each other. There are those who ignore the robot's interventions or were clearly perturbed by interventions. There were others who were responsive to the interventions and appeared to open up. The analysis of how individuals responded to these interventions will provide insights into how a robot is able to promote interactions in hierarchical relationships where both members are open and engaged with one another. These types of interactions promote healthier relationships that are able to overcome conflict and evolve to the benefit of both relationship members.\n\n \n\n\t\t\t\t\tLast Modified: 09/04/2019\n\n\t\t\t\t\tSubmitted by: Ronald C Arkin"
 }
}