{
 "awd_id": "1251217",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Small: DA: Semantic Modeling of Cities from Scanned Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2013-08-01",
 "awd_exp_date": "2017-07-31",
 "tot_intn_awd_amt": 600000.0,
 "awd_amount": 600000.0,
 "awd_min_amd_letter_date": "2013-07-19",
 "awd_max_amd_letter_date": "2013-07-19",
 "awd_abstract_narration": "Detailed three-dimensional models of urban environments provide critical information for many applications, including emergency response preparation, security analysis, urban planning, and augmented-reality maps.  For example, if 3D models of complete cities were publicly available with detailed labels for all semantic objects (e.g., buildings, fire hydrants, fire escapes, doors, windows, trees, etc.), then fire fighters, police forces, and other emergency response teams could use them to make plans for rescue operations, taking into account possible access points, lines of sight, and risks to the neighborhood.  Or, if the 3D model contained labeled representations of stop lights, traffic signs, parking spaces, store locations, mailboxes, and ATMs, then augmented reality displays could help people navigate their daily lives.\r\n\r\nThe research goal of this project is to develop algorithms to build detailed, labeled 3D models from currently available data.  Several companies (e.g., Google, Nokia, Microsoft, etc.) are currently collecting photographic imagery and LIDAR data with scanners mounted on cars driving up and down streets of cities throughout the world.  This data contains a vast amount of information about our world, but in a very primitive form: pixels and points. The PI is developing algorithms to analyze this raw data to build semantically labeled 3D models: 1) new methods for discovering correspondence relationships between heterogeneous data types, focusing on LIDAR, images, and 3D polygonal models found in online repositories, 2) new ways to infer surface geometry, segmentations, and labels simultaneously based on a model learned from examples, 3) new interactive systems to allow users to visualize and guide the algorithms as they operate by incorporating user input into incrementally updated solutions, and 4) data management algorithms for multiresolution storage, compression, and retrieval of massive scanned 3D data sets.\r\n\r\nThe broader goals of the project include educational programs, industrial collaboration, free distribution of software and data sets, and outreach activities.  Besides the published research results, the  PI will disseminate 3D models of major cities that can be used directly in applications developed by other people.  He will also distribute code, benchmark data sets, and statistical models that could benefit researchers in a variety of disciplines.  This proposed  work is integrated with educational programs, including interdisciplinary workshops and courses at the graduate, undergraduate, and professional levels, and diversity enhancement programs that promote opportunities for disadvantaged groups",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thomas",
   "pi_last_name": "Funkhouser",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas A Funkhouser",
   "pi_email_addr": "funk@cs.princeton.edu",
   "nsf_id": "000092134",
   "pi_start_date": "2013-07-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "4 New South Building",
  "perf_city_name": "Princeton",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442020",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 600000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The long-term goal of the project is to recover semantically labeled3D models of building and cities from data captured with RGB-Dcameras.&nbsp; With such a 3D model, it is possible to augment floorplansand maps with semantic information, train models suitable for semanticunderstanding of new scenes, and support 3D applications from avariety of disciplines, including urban planning, self-drivingnavigation, etc.</p>\n<p><br />Over the course of the project, our research has supported these goalsin several ways.&nbsp; First, we developed benchmark datasets for RGB-Dsurface reconstruction, semantic object detection, and sceneunderstanding.&nbsp; Second, we developed algorithms for estimating cameraposes by aligning semantic and structural features, learning shapedescriptor with self-supervions from prior surface reconstructions,completing partially observed scenes based on semantic segmentation,and parsing scenes based on learned contextual priors, in addition toseveral other challenging problems.&nbsp; We have disseminated thisresearch through peer-reviewed publications, in addition to publiclyavailable datasets, benchmarks, and code.</p>\n<p><br />The educational goals of the project have been addressed through teachingand mentoring at several levels.&nbsp; &nbsp;The PI has taught undergraduate courseson computer vision, graduate courses on 3D geometry, and advanced graduateseminars on deep learning for computer vision.&nbsp; The project has providedmentoring for dozens of undergraduate and graduate students.</p>\n<p><br />Overall, the project has contributed to a significant advance in thetechnologies required to understand 3D scenes from large RGB-D datasets.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/20/2017<br>\n\t\t\t\t\tModified by: Thomas&nbsp;A&nbsp;Funkhouser</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe long-term goal of the project is to recover semantically labeled3D models of building and cities from data captured with RGB-Dcameras.  With such a 3D model, it is possible to augment floorplansand maps with semantic information, train models suitable for semanticunderstanding of new scenes, and support 3D applications from avariety of disciplines, including urban planning, self-drivingnavigation, etc.\n\n\nOver the course of the project, our research has supported these goalsin several ways.  First, we developed benchmark datasets for RGB-Dsurface reconstruction, semantic object detection, and sceneunderstanding.  Second, we developed algorithms for estimating cameraposes by aligning semantic and structural features, learning shapedescriptor with self-supervions from prior surface reconstructions,completing partially observed scenes based on semantic segmentation,and parsing scenes based on learned contextual priors, in addition toseveral other challenging problems.  We have disseminated thisresearch through peer-reviewed publications, in addition to publiclyavailable datasets, benchmarks, and code.\n\n\nThe educational goals of the project have been addressed through teachingand mentoring at several levels.   The PI has taught undergraduate courseson computer vision, graduate courses on 3D geometry, and advanced graduateseminars on deep learning for computer vision.  The project has providedmentoring for dozens of undergraduate and graduate students.\n\n\nOverall, the project has contributed to a significant advance in thetechnologies required to understand 3D scenes from large RGB-D datasets.\n\n\t\t\t\t\tLast Modified: 11/20/2017\n\n\t\t\t\t\tSubmitted by: Thomas A Funkhouser"
 }
}