{
 "awd_id": "1245178",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Project CLEAR Calculus: Coherent Labs to Enhance Accessible and Rigorous Calculus Instruction",
 "cfda_num": "47.076",
 "org_code": "11040200",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Haddock",
 "awd_eff_date": "2013-07-01",
 "awd_exp_date": "2016-06-30",
 "tot_intn_awd_amt": 45753.0,
 "awd_amount": 45753.0,
 "awd_min_amd_letter_date": "2013-06-24",
 "awd_max_amd_letter_date": "2013-06-24",
 "awd_abstract_narration": "This collaborative project is a research-based effort to make calculus conceptually accessible to more students while simultaneously increasing the coherence, rigor, and applicability of the content students are learning. Its intellectual merit rests on an ongoing program of research from which the principal investigators have conceptualized a framework for learning and teaching calculus that builds on students' intuitive reasoning about approximations and error analyses. Combining this framework with a constructivist approach, the project team is refining and disseminating lab activities that address the content of a standard course sequence in differential, integral, and multivariable calculus with supporting materials and interactive technology for students. The project is exercising broader impact through its efforts to help develop a community of practice around these ideas through a set of efforts that includes: conducting summer workshops, holding weekly video-conferences, and making available classroom video and instructor notes to support faculty professional development for implementation of the labs. Finally, a research and evaluation component is assessing the impact of the lab activities on student conceptual development of the central ideas in calculus through the use of two quantitative measures: i) a Calculus Concept Assessment (CCA) to measure shifts in students' understanding of the central concepts of calculus and ii) a Limit Models Assessment (LMA) to measure shifts in the cognitive models employed by students while reasoning with these calculus concepts. The project is further adding to the knowledge base of STEM education by studying the effectiveness of its faculty development efforts through an analysis of pilot instructors' exams using an Exam Characterization Framework (ECF) and the continuous collection of detailed feedback on all components of the project.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DUE",
 "org_div_long_name": "Division Of Undergraduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jason",
   "pi_last_name": "Martin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jason Martin",
   "pi_email_addr": "jasonm@uca.edu",
   "nsf_id": "000619470",
   "pi_start_date": "2013-06-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Central Arkansas",
  "inst_street_address": "201 DONAGHEY AVE",
  "inst_street_address_2": "WINGO 106",
  "inst_city_name": "CONWAY",
  "inst_state_code": "AR",
  "inst_state_name": "Arkansas",
  "inst_phone_num": "5014505061",
  "inst_zip_code": "720355001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "AR02",
  "org_lgl_bus_name": "UNIVERSITY OF CENTRAL ARKANSAS",
  "org_prnt_uei_num": "E557HM9TKJ17",
  "org_uei_num": "E557HM9TKJ17"
 },
 "perf_inst": {
  "perf_inst_name": "University of Central Arkansas",
  "perf_str_addr": "",
  "perf_city_name": "Conway",
  "perf_st_code": "AR",
  "perf_st_name": "Arkansas",
  "perf_zip_code": "720350001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "AR02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "153600",
   "pgm_ele_name": "S-STEM-Schlr Sci Tech Eng&Math"
  },
  {
   "pgm_ele_code": "751300",
   "pgm_ele_name": "TUES-Type 1 Project"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0413",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001314DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "13XX",
   "app_name": "H-1B FUND, EHR, NSF",
   "app_symb_id": "045176",
   "fund_code": "1300XXXXDB",
   "fund_name": "H-1B FUND, EDU, NSF",
   "fund_symb_id": "045176"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 45753.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-2e93f3ba-7f9c-ba61-4837-8531693fbe78\" style=\"line-height: 1.7142857142857142; margin-top: 8pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Project CLEAR Calculus Outcomes</span></p>\n<p style=\"line-height: 1.7142857142857142; margin-top: 8pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">During the three years of Coherent Labs to Enhance Accessible and Rigorous (CLEAR) Calculus pilot, over 100 instructors from institutions across the U.S. have downloaded CLEAR materials spanning differential, integral, and multivariable calculus (http://clearcalculus.okstate.edu/). These research-based materials were refined and disseminated in the form of 36 weekly labs that can be adapted to all major textbooks and used for small or large classrooms to facilitate CLEAR&rsquo;s adoption in nearly any context. Students&rsquo; resources include lab handouts, content summaries, interactive applets, and sample lab write-ups supporting conceptual learning of fundamental concepts and their applications. In addition to multiple training workshops, resources for instructors include instructor notes, solutions, sample quizzes, and adjustable versions of the labs. Samples of student work and labs incorporating virtual manipulatives are being added to the Project CLEAR Calculus website. Over the three year period, multiple conference presentations, invited presentations, and peer-reviewed conference proceedings have covered Project CLEAR Calculus. One journal manuscript is about to go under review for publication and a second journal manuscript is planned.</span></p>\n<p style=\"line-height: 1.7142857142857142; margin-top: 8pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">The PIs&rsquo; research on the teaching and learning of calculus has confirmed that an instructional framework which leverages students&rsquo; intuitive reasoning about approximations and error analyses supports the creation of labs meeting design goals for accessibility, coherence, rigor, and applicability across the content of an introductory calculus sequence. The past president of the Mathematical Association of America, David Bressoud, has featured the research supporting CLEAR in a series of three articles for his online </span><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Launchings</span><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\"> column (the first can be found at http://launchings.blogspot.com/2014/06</span><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">/</span><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">beyond-limit-i.html). &nbsp;</span></p>\n<p style=\"line-height: 1.7142857142857142; margin-top: 8pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Shifts in Student Reasoning</span><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\"><br class=\"kix-line-break\" /></span><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Over 1000 students participated in data collection using 1) the 32-item Calculus Concepts Assessment (CCA), developed using techniques from Engelke, Oehrtman, &amp; Carlson (2005) and Carlson, Oehrtman, &amp; Engelke (2010) to measure shifts in students&rsquo; understanding of the central concepts of calculus and 2) the 8-item Limit Models Assessment (LMA), developed following Model Analysis Theory, e.g., Bao and Reddish (2001) and Bao, Hogg, and Zollman (2001), to model the structure of students&rsquo; reasoning with these calculus concepts. We computed normalized average gains (the ratio of the actual average gain to the maximum possible average gain) on the CCA for comparison with our preexisting database normalized average gains from Calculus 1 pretest to Calculus 2 posttest not using CLEAR of 20% on a prior version of the CCA that included more difficult items (which was evidenced by a lower percentage of students getting items correct on our CCA pretest). </span></p>\n<p style=\"line-height: 1.7142857142857142; margin-top: 8pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">We observed conceptual gains on the 32-item CCA of 3.6 points for Calculus 1 (14.4% normalized gain) and 2.2 points for Calculus 2 (11% normalized gain). From Calculus 1 pretest to Calculus 2 posttest, students obtained a 29% normalized gain.</span></p>\n<p style=\"line-height: 1.7142857142857142; margin-top: 8pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Using the LMA we observed a notable shift toward using approximation models when students reason about limits, 31% to 38% for the class model. Simultaneously students became less likely to use surface-level language about approximation without the appropriate conceptual structure: we saw a drop in the approximation distractor from 12% to 9%. Other non-approximation models of limit showed almost no change, which is not surprising since removing these conceptual models were not targeted by CLEAR instruction. One non-approximation model detrimental to students&rsquo; reasoning decreased from 19% to around 15%.</span></p>\n<p style=\"line-height: 1.7142857142857142; margin-top: 8pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Shifts in assessment practices</span><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\"><br class=\"kix-line-break\" /></span><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Seven pilot instructors in charge of writing their own exams supplied their past and current calculus exams for our study. All but one of these instructors demonstrated notable shifts in their assessment practices. Prior to implementing CLEAR labs, their exams resembled the national averages in requiring conceptual understanding, using multiple representations, and requiring explanations. While piloting CLEAR, the instructors averaged a 270% increase in the proportion of exam questions requiring conceptual understanding, 162% increase in use of representations other than symbolic, and 346% increase in items requiring explanations. Even though large shifts were expected with starting low averages, these shifts were large enough that many of the pilot instructors&rsquo; exams would have constituted outliers in each category among the random national sample analyzed by Tallman &amp; Carlson (2016).</span></p>\n<p style=\"line-height: 1.7142857142857142; margin-top: 8pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 14px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Pilot instructors viewed their shifts in assessment practices as positive and frequently attributed shifts to multiple aspects of the labs aligned with CLEAR&rsquo;s design goals. Instructors credited the coherent use of multiple representations throughout the materials with establishing meaningful ways to assess their students using representations other than only symbolic. Instructors cited the conceptually accessible approximation concepts consistently applied across calculus concepts for providing important global ideas and a foundation of common reasoning to assess (e.g., choosing appropriate tools to find an underestimate or overestimate as required). The pilot instructors cited the connection to rigorous mathematical argumentation as providing an opportunity to require additional explanation or justification from students (e.g., justifying that their approximation is sufficiently accurate).</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/12/2016<br>\n\t\t\t\t\tModified by: Jason&nbsp;Martin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Project CLEAR Calculus Outcomes\nDuring the three years of Coherent Labs to Enhance Accessible and Rigorous (CLEAR) Calculus pilot, over 100 instructors from institutions across the U.S. have downloaded CLEAR materials spanning differential, integral, and multivariable calculus (http://clearcalculus.okstate.edu/). These research-based materials were refined and disseminated in the form of 36 weekly labs that can be adapted to all major textbooks and used for small or large classrooms to facilitate CLEAR?s adoption in nearly any context. Students? resources include lab handouts, content summaries, interactive applets, and sample lab write-ups supporting conceptual learning of fundamental concepts and their applications. In addition to multiple training workshops, resources for instructors include instructor notes, solutions, sample quizzes, and adjustable versions of the labs. Samples of student work and labs incorporating virtual manipulatives are being added to the Project CLEAR Calculus website. Over the three year period, multiple conference presentations, invited presentations, and peer-reviewed conference proceedings have covered Project CLEAR Calculus. One journal manuscript is about to go under review for publication and a second journal manuscript is planned.\nThe PIs? research on the teaching and learning of calculus has confirmed that an instructional framework which leverages students? intuitive reasoning about approximations and error analyses supports the creation of labs meeting design goals for accessibility, coherence, rigor, and applicability across the content of an introductory calculus sequence. The past president of the Mathematical Association of America, David Bressoud, has featured the research supporting CLEAR in a series of three articles for his online Launchings column (the first can be found at http://launchings.blogspot.com/2014/06/beyond-limit-i.html).  \nShifts in Student ReasoningOver 1000 students participated in data collection using 1) the 32-item Calculus Concepts Assessment (CCA), developed using techniques from Engelke, Oehrtman, &amp; Carlson (2005) and Carlson, Oehrtman, &amp; Engelke (2010) to measure shifts in students? understanding of the central concepts of calculus and 2) the 8-item Limit Models Assessment (LMA), developed following Model Analysis Theory, e.g., Bao and Reddish (2001) and Bao, Hogg, and Zollman (2001), to model the structure of students? reasoning with these calculus concepts. We computed normalized average gains (the ratio of the actual average gain to the maximum possible average gain) on the CCA for comparison with our preexisting database normalized average gains from Calculus 1 pretest to Calculus 2 posttest not using CLEAR of 20% on a prior version of the CCA that included more difficult items (which was evidenced by a lower percentage of students getting items correct on our CCA pretest). \nWe observed conceptual gains on the 32-item CCA of 3.6 points for Calculus 1 (14.4% normalized gain) and 2.2 points for Calculus 2 (11% normalized gain). From Calculus 1 pretest to Calculus 2 posttest, students obtained a 29% normalized gain.\nUsing the LMA we observed a notable shift toward using approximation models when students reason about limits, 31% to 38% for the class model. Simultaneously students became less likely to use surface-level language about approximation without the appropriate conceptual structure: we saw a drop in the approximation distractor from 12% to 9%. Other non-approximation models of limit showed almost no change, which is not surprising since removing these conceptual models were not targeted by CLEAR instruction. One non-approximation model detrimental to students? reasoning decreased from 19% to around 15%.\nShifts in assessment practicesSeven pilot instructors in charge of writing their own exams supplied their past and current calculus exams for our study. All but one of these instructors demonstrated notable shifts in their assessment practices. Prior to implementing CLEAR labs, their exams resembled the national averages in requiring conceptual understanding, using multiple representations, and requiring explanations. While piloting CLEAR, the instructors averaged a 270% increase in the proportion of exam questions requiring conceptual understanding, 162% increase in use of representations other than symbolic, and 346% increase in items requiring explanations. Even though large shifts were expected with starting low averages, these shifts were large enough that many of the pilot instructors? exams would have constituted outliers in each category among the random national sample analyzed by Tallman &amp; Carlson (2016).\nPilot instructors viewed their shifts in assessment practices as positive and frequently attributed shifts to multiple aspects of the labs aligned with CLEAR?s design goals. Instructors credited the coherent use of multiple representations throughout the materials with establishing meaningful ways to assess their students using representations other than only symbolic. Instructors cited the conceptually accessible approximation concepts consistently applied across calculus concepts for providing important global ideas and a foundation of common reasoning to assess (e.g., choosing appropriate tools to find an underestimate or overestimate as required). The pilot instructors cited the connection to rigorous mathematical argumentation as providing an opportunity to require additional explanation or justification from students (e.g., justifying that their approximation is sufficiently accurate).\n\n\t\t\t\t\tLast Modified: 08/12/2016\n\n\t\t\t\t\tSubmitted by: Jason Martin"
 }
}