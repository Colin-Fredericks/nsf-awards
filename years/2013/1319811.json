{
 "awd_id": "1319811",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Approximation Algorithms for Uncertain Environments and Graph Partitioning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rahul Shah",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 399898.0,
 "awd_amount": 406298.0,
 "awd_min_amd_letter_date": "2013-08-13",
 "awd_max_amd_letter_date": "2014-04-30",
 "awd_abstract_narration": "This project focuses on research and teaching activities in the general area of approximation and online algorithms. Many optimization problems are intractable, so it is natural to approximate the optimum instead of computing an exact solution. With this insight, the past two decades have seen tremendous activity in approximation algorithms, to the point where the approximability of some basic problems is well-understood. In addition to this enhanced understanding of the computational complexity of optimization problems, an ever-increasing set of techniques and tools to attack problems old and new have been proposed. Given this situation, it is natural to take a two-pronged plan of research: while continuing to resolve some of the long-standing open problems of interest, the investigator will concurrently extend the scope of the new techniques, and also investigate more expressive models and problem abstractions that attempt to capture the rich diversity of optimization problems that arise in practice.\r\n\r\nAlong these lines, a major theme of this research is to investigate how to solve optimization problems in the presence of partial information, and hence uncertainty.\u00a0This is something often considered in practice: based only on probabilities of various events happening in the future, and subject to constraints on resources (time/money), a system must make decisions. In the spirit of computational thinking, this research is aimed at formalizing some of these problems so that efficient solutions can be found for more realistic models than the traditional worst-case model. Research progress on these questions will advance the state-of-the-art in decision-making under uncertainty, an area lying at the intersection of computer science, operations research, and decision theory. This research will also be instrumental in training of graduate and undergraduate students.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anupam",
   "pi_last_name": "Gupta",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anupam Gupta",
   "pi_email_addr": "ag10120@nyu.edu",
   "nsf_id": "000486839",
   "pi_start_date": "2013-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "551400",
   "pgm_ele_name": "OPERATIONS RESEARCH"
  },
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "792600",
   "pgm_ele_name": "ALGORITHMS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7796",
   "pgm_ref_txt": "ALGORITHMIC FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "7934",
   "pgm_ref_txt": "PARAL/DISTRIBUTED ALGORITHMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 399898.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 6400.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The proposal investigated computational problems in the presence of uncertainty, when the input is not precisely known and there is uncertainty in the both the data and in the computational process. The aim is to develop algorithms that are robust to noise, that produce near-optimal solutions, and that run in polynomial time. Along these lines we developed algorithms for convex optimization under constraints that arrive online (and hence there is uncertainty about the feasible solutions). We gave algorithms to solve packing linear programs when the columns are presented in random order.</p>\n<p>We also developed algorithms for optimizing where we are given probabilistic predictions about the future (as opposed to not knowing anything about the future, as is assumed in online algorithms). E.g., we showed how to develop strategies that are non-adaptive and are comparable in performance to the best adaptive algorithms. This can be thought of as a compression result, since the adaptive algortihms can be very large and expensive to represent, whereas the non-adaptive algorithms are easy and compact.</p>\n<p>Finally, we also considered problems of learning for combinatorial problems. We showed how to learn, e.g., the max-weight spanning tree or the maximum matching from noisy samples from the underlying graph. We also showed nearly matching lower bounds. Since data can be expensive, we hope that these results about tight sample-complexity bounds for commonly occurring cobminatorial problems can be extended to yet other problems of interest.</p>\n<p>Overall, the proposal gave a set of new tools and ideas to combat uncertainty in computation, and helped us design new provably good algorithms for several different problems of interest.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/12/2017<br>\n\t\t\t\t\tModified by: Anupam&nbsp;Gupta</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe proposal investigated computational problems in the presence of uncertainty, when the input is not precisely known and there is uncertainty in the both the data and in the computational process. The aim is to develop algorithms that are robust to noise, that produce near-optimal solutions, and that run in polynomial time. Along these lines we developed algorithms for convex optimization under constraints that arrive online (and hence there is uncertainty about the feasible solutions). We gave algorithms to solve packing linear programs when the columns are presented in random order.\n\nWe also developed algorithms for optimizing where we are given probabilistic predictions about the future (as opposed to not knowing anything about the future, as is assumed in online algorithms). E.g., we showed how to develop strategies that are non-adaptive and are comparable in performance to the best adaptive algorithms. This can be thought of as a compression result, since the adaptive algortihms can be very large and expensive to represent, whereas the non-adaptive algorithms are easy and compact.\n\nFinally, we also considered problems of learning for combinatorial problems. We showed how to learn, e.g., the max-weight spanning tree or the maximum matching from noisy samples from the underlying graph. We also showed nearly matching lower bounds. Since data can be expensive, we hope that these results about tight sample-complexity bounds for commonly occurring cobminatorial problems can be extended to yet other problems of interest.\n\nOverall, the proposal gave a set of new tools and ideas to combat uncertainty in computation, and helped us design new provably good algorithms for several different problems of interest.\n\n\t\t\t\t\tLast Modified: 10/12/2017\n\n\t\t\t\t\tSubmitted by: Anupam Gupta"
 }
}