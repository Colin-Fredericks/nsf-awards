{
 "awd_id": "1305401",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "II-NEW: Virtual Reality Infrastructure and Technology Development to Support Architectural Education and Basic Research in Immersive Design, Embodied Interaction, Spatial Cognition",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2013-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 164490.0,
 "awd_amount": 164490.0,
 "awd_min_amd_letter_date": "2013-08-26",
 "awd_max_amd_letter_date": "2013-08-26",
 "awd_abstract_narration": "Immersive virtual environments offer tremendous potential for fundamental and transformative advances in education, training, rehabilitation, architectural design, as well as a wide range of other application areas. The technology has special potential to enhance the process of architectural design by enabling designers to work with their ideas at full scale from the earliest stages of the design process, and to experience the interior spaces of their designed structures from a firsthand egocentric perspective before they are built. The research and educational opportunities made possible by the requested equipment will enable designers and their clients to experience a virtual environment as if the designers and their clients were truly standing in the physical environment that is represented by the virtual environment, and to make decisions based on their experience in the virtual world that are equivalent to the decisions that they would have made as a result of a similar experience in the physical world. The project will teach students of architectural design the value of developing their design ideas from an egocentric as well as allocentric perspective. Through this work, architects, and their clients, will be able to make reliable design decisions that can enhance the livability of a planned space based on their first-person experience of the 3D spatial layout. The project will enable archaeologists, historians, city planners, tourists, and others to gain an intrinsic, egocentric understanding of the spatial layout of large, remote sites through virtual exploration.\r\n\r\nIntellectual Merit\r\n\r\nAn interdisciplinary team consisting of an associate professor of computer science in the college of science and engineering and an associate professor of architecture in the college of design requested funding for three pieces of major equipment and related supplies that will enable them to (a) pursue a multi-faceted research agenda in the development of groundbreaking methods to enhance the cognitive and perceptual realism of immersive virtual experiences, leveraging fundamental insights from visual perception and cognition, and (b) maximize the potential of virtual reality technology to fundamentally enhance the process of design education, emphasizing the importance of integrating an experiential understanding of planned spaces into the earliest stages of the design process.  The proposal requests funding for the purchase of (a) a wide field of view head mounted display with an embedded stereo eye tracking system that the researchers will augment with lightweight, close-range depth sensors and a custom-built dual camera and mirror system to achieve a convergence-adaptable stereoscopic video-see-through augmented reality capability, (b) a set of cameras that will enable real time tracking throughout the full extent of the space available in a virtual reality design lab, and (c) an untethered, moderate field of view head-mounted display with optional optical see through capabilities that will, in conjunction with a backpack-worn laptop computer, allow unencumbered free physical movement through large virtual spaces and, in conjunction with the other head-mounted display, enable the project to pursue research in self-embodied multi-person interaction in immersive virtual environments.\r\n\r\nBroader Impact\r\n\r\nThe requested equipment will benefit society by permitting research that will advance an understanding of how people can have experiences in immersive virtual environments that are equivalent to experiences in real world environments. This equipment will support significant advances in design education by enabling the broader effective use of virtual environments technology in teaching fundamental concepts of visual imagination and will support closer interdisciplinary collaboration between faculty and students in computer science, architecture and design. The project will promote science and engineering to the general public through community outreach such as through frequent lab tours for local K-12 students, and will promote participation in science through mentoring and summer programs for middle and high school students.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Victoria",
   "pi_last_name": "Interrante",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Victoria L Interrante",
   "pi_email_addr": "interran@cs.umn.edu",
   "nsf_id": "000160817",
   "pi_start_date": "2013-08-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Lee",
   "pi_last_name": "Anderson",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Lee B Anderson",
   "pi_email_addr": "",
   "nsf_id": "000379719",
   "pi_start_date": "2013-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "University of Minnesota-Twin Cities",
  "perf_str_addr": "117 Pleasant St",
  "perf_city_name": "Minneapolis",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "554552070",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MN05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 164490.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The ultimate goal of immersive virtual reality (VR) is to enable people to derive equivalent, or better, benefit from experiencing a simulated situation than could alternatively have been achieved in the real world. &nbsp;As such, virtual reality technology has the potential to enable transformative advances in a wide range of application areas, from education and training, to psychotherapy and rehabilitation, to architectural design and data/information visualization. However, despite decades of research that have led to substantive advances in VR software and technology, numerous challenges to the full realization of this vision remain.</p>\n<p><br />This grant enabled the acquisition of a broad collection of equipment critical to supporting a multi-faceted research agenda aimed at developing groundbreaking new methods to enhance the perceptual, cognitive, and functional realism of immersive virtual experiences, and to enable fundamental advances in architectural design education, emphasizing the importance of integrating an experiential understanding of planned spaces into the earliest stages of the design process.</p>\n<p><br />Historically, one of the principal challenges in effectively using immersive virtual reality for architectural design has been the difficulty of ensuring an accurate understanding of the depicted 3D space; years of prior research have found that under most common conditions, people tend to perceive distances as being shorter when experienced in VR than they actually are in reality. &nbsp;Our research has probed the causes of this misperception, and explored methods to overcome it. &nbsp;We also considered the feasibility of enabling accurate spatial perception during the conceptual phase of design, when models take the form of sketches and only the rough outlines of the spaces have been defined. &nbsp;</p>\n<p><br />Some of the technology we developed allows people to see themselves and others in 3D while jointly immersed in a shared virtual model. &nbsp;In addition to providing a stronger sense of immersion in the virtual space and potentially facilitating more accurate spatial understanding, this technology may also support more effective interpersonal discussion and collaboration during architectural design reviews.&nbsp;</p>\n<p><br />Our Virtual Reality Design Lab provides a large tracked area within which multiple people can jointly explore a large architectural model by physically walking around. &nbsp;This mode of interaction allows stakeholders to more effectively assess the functionality as well as the aesthetics of the designed spaces. &nbsp;The VRDL has also been heavily used in architectural education, through classes such as ARCH 3611: Design in the Digital Age.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/09/2017<br>\n\t\t\t\t\tModified by: Victoria&nbsp;L&nbsp;Interrante</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496976418008_SocialVR-sahar-small--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496976418008_SocialVR-sahar-small--rgov-800width.jpg\" title=\"SocialVR\"><img src=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496976418008_SocialVR-sahar-small--rgov-66x44.jpg\" alt=\"SocialVR\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">By augmenting head-mounted-display systems with RGBD sensors, we can enable people to see each other while immersed together in a virtual architectural model.</div>\n<div class=\"imageCredit\">Department of Computer Science and Engineering, University of Minnesota</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Victoria&nbsp;L&nbsp;Interrante</div>\n<div class=\"imageTitle\">SocialVR</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496975560174_video-see-thru2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496975560174_video-see-thru2--rgov-800width.jpg\" title=\"Video-See-Thru-NPR\"><img src=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496975560174_video-see-thru2--rgov-66x44.jpg\" alt=\"Video-See-Thru-NPR\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Seeing the world as a line drawing. Top: 3D custom camera mount; custom-built computer; worn as a backpack.  Bottom: Two cameras stream images to the computer, from a point-of-view close to that of the user's own eyes; line-drawng-style view; system being used in a study of spatial perception.</div>\n<div class=\"imageCredit\">Koorosh Vaziri</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Victoria&nbsp;L&nbsp;Interrante</div>\n<div class=\"imageTitle\">Video-See-Thru-NPR</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496975959962_eye-tracking--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496975959962_eye-tracking--rgov-800width.jpg\" title=\"Eye-Tracking-for-Destination-Prediction\"><img src=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496975959962_eye-tracking--rgov-66x44.jpg\" alt=\"Eye-Tracking-for-Destination-Prediction\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We can predict a person's future intended direction of travel from where they look while they walk; such information can be used in re-direction controllers that enable an illusion of freely walking in a large virtual space while actually walking in circles in a smaller physical room.</div>\n<div class=\"imageCredit\">Jonathan Gandrud</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Victoria&nbsp;L&nbsp;Interrante</div>\n<div class=\"imageTitle\">Eye-Tracking-for-Destination-Prediction</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496975033640_video-see-thru1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496975033640_video-see-thru1--rgov-800width.jpg\" title=\"3DVideoSeeThruHMD\"><img src=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496975033640_video-see-thru1--rgov-66x44.jpg\" alt=\"3DVideoSeeThruHMD\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Seeing a live 3D model of your own body within a virtual environment. Top row: RGB-D sensor mounted on HMD; example use case; seeing one's own hands in 3D, while interacting with a virtual hallway model; Bottom row: 2D color data; 2D depth data; resulting 3D reconstruction.</div>\n<div class=\"imageCredit\">Loren Fiore and Peng Liu</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Victoria&nbsp;L&nbsp;Interrante</div>\n<div class=\"imageTitle\">3DVideoSeeThruHMD</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496976748022_VRDL-screen-capture--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496976748022_VRDL-screen-capture--rgov-800width.jpg\" title=\"Virtual Reality Design Lab (VRDL)\"><img src=\"/por/images/Reports/POR/2017/1305401/1305401_10270848_1496976748022_VRDL-screen-capture--rgov-66x44.jpg\" alt=\"Virtual Reality Design Lab (VRDL)\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The VRDL enables multiple people to be jointly immersed in a large virtual architectural model, which they can explore by freely walking.</div>\n<div class=\"imageCredit\">Aaron Westre and Lee Anderson</div>\n<div class=\"imageSubmitted\">Victoria&nbsp;L&nbsp;Interrante</div>\n<div class=\"imageTitle\">Virtual Reality Design Lab (VRDL)</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe ultimate goal of immersive virtual reality (VR) is to enable people to derive equivalent, or better, benefit from experiencing a simulated situation than could alternatively have been achieved in the real world.  As such, virtual reality technology has the potential to enable transformative advances in a wide range of application areas, from education and training, to psychotherapy and rehabilitation, to architectural design and data/information visualization. However, despite decades of research that have led to substantive advances in VR software and technology, numerous challenges to the full realization of this vision remain.\n\n\nThis grant enabled the acquisition of a broad collection of equipment critical to supporting a multi-faceted research agenda aimed at developing groundbreaking new methods to enhance the perceptual, cognitive, and functional realism of immersive virtual experiences, and to enable fundamental advances in architectural design education, emphasizing the importance of integrating an experiential understanding of planned spaces into the earliest stages of the design process.\n\n\nHistorically, one of the principal challenges in effectively using immersive virtual reality for architectural design has been the difficulty of ensuring an accurate understanding of the depicted 3D space; years of prior research have found that under most common conditions, people tend to perceive distances as being shorter when experienced in VR than they actually are in reality.  Our research has probed the causes of this misperception, and explored methods to overcome it.  We also considered the feasibility of enabling accurate spatial perception during the conceptual phase of design, when models take the form of sketches and only the rough outlines of the spaces have been defined.  \n\n\nSome of the technology we developed allows people to see themselves and others in 3D while jointly immersed in a shared virtual model.  In addition to providing a stronger sense of immersion in the virtual space and potentially facilitating more accurate spatial understanding, this technology may also support more effective interpersonal discussion and collaboration during architectural design reviews. \n\n\nOur Virtual Reality Design Lab provides a large tracked area within which multiple people can jointly explore a large architectural model by physically walking around.  This mode of interaction allows stakeholders to more effectively assess the functionality as well as the aesthetics of the designed spaces.  The VRDL has also been heavily used in architectural education, through classes such as ARCH 3611: Design in the Digital Age.\n\n\t\t\t\t\tLast Modified: 06/09/2017\n\n\t\t\t\t\tSubmitted by: Victoria L Interrante"
 }
}