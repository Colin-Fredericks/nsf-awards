{
 "awd_id": "1305622",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: FTLA: Fault Tolerant Linear Algebra Software for Massively Parallel Architectures",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 324913.0,
 "awd_amount": 340913.0,
 "awd_min_amd_letter_date": "2012-11-02",
 "awd_max_amd_letter_date": "2012-11-02",
 "awd_abstract_narration": "As the number of cores in high performance computing (HPC) systems continues to grow, the mean-time-to-failure (MTTF) for large HPC systems is becoming shorter than the execution time of many HPC applications. Fault tolerance is becoming one of the critical techniques for the effective use of large HPC systems.\r\n\r\nThis project develops highly efficient algorithmic fault tolerance techniques for selected linear algebra computations to tolerate both fail-stop and fail-continue failures. \r\nFail-stop failures, where the failed computation crashes, are often tolerated by checkpoint. This project removes checkpoint from fault tolerance for selected linear algebra computations so that neither checkpoint nor rollback is necessary for the protection of these computations.  Fail-continue failures, where the corrupted computation continues to make progress but the computation results cannot be trusted any more, are usually tolerated offline by checking the computation results after the computation finishes. This project designs novel online fault tolerance techniques to detect fail-continue failures in the middle of the computation so that better efficiency can be achieved by stopping the corrupted computations in the middle of the computation in a timely manner.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zizhong",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zizhong Chen",
   "pi_email_addr": "chen@cs.ucr.edu",
   "nsf_id": "000347508",
   "pi_start_date": "2012-11-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Riverside",
  "inst_street_address": "200 UNIVERSTY OFC BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "RIVERSIDE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9518275535",
  "inst_zip_code": "925210001",
  "inst_country_name": "United States",
  "cong_dist_code": "39",
  "st_cong_dist_code": "CA39",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA AT RIVERSIDE",
  "org_prnt_uei_num": "",
  "org_uei_num": "MR5QC5FCAVH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California Riverside",
  "perf_str_addr": "200 University Office Building",
  "perf_city_name": "Riverside",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "925210001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "39",
  "perf_st_cong_dist": "CA39",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 324913.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In computer industry, a computer&rsquo;s central processing unit is often called a core.&nbsp;The desire of modern computer users to perform faster computations has driven&nbsp;the size of computers from single core, to multicores, and even to millions of cores.&nbsp;The current fastest computer in the world (i.e., Sunway TaihuLight in China)&nbsp;now consists of more than ten million cores. Computers capable of exaFLOP&nbsp;calculations (i.e., 10^18 calculations per second) available soon will be made&nbsp;up of 100 million to 1 billion cores. While today&rsquo;s computer is often susceptible&nbsp;to single bit-flip errors, users of small computers usually do not see such errors&nbsp;because they have already been effectively protected by existing error correction&nbsp;mechanisms. However, as the number of cores in computers continues to increase,&nbsp;the current error protection mechanisms will not be enough any more because&nbsp;double bit-flip errors, miscalculations (i.e., errors like 1+1=3), and many other&nbsp;types of errors, which are less common for small computers, will increase at&nbsp;least linearly with the number of cores. Therefore, in the field of high&nbsp;performance computing (HPC), fault tolerance has been identified as&nbsp;one of the major challenges that must be addressed before computers are&nbsp;able to achieve exaFLOP performance. &nbsp;</p>\n<p>When an error occurs, the affected application either continues or stops.&nbsp;If the application continues, it is called a fail-continue error. Otherwise,&nbsp;it is called a fail-stop error. This project has developed a series of highly&nbsp;efficient novel fault tolerance techniques that can be used to effectively&nbsp;protect widely used linear algebra computations from both fail-stop and&nbsp;fail-continue errors. This research is very challenging because it must balance many&nbsp;competing requirements including large number of cores, low hardware&nbsp;redundancy, low space and time cost, low communication overhead,&nbsp;high error coverage, high computing efficiency, high energy efficiency,&nbsp;high numerical accuracy, and good numerical stability.&nbsp;</p>\n<p>Linear algebra is widely used in many science and&nbsp;engineering fields. Highly efficient fault tolerance techniques for linear&nbsp;algebra computations will therefore benefit a larger number of users and&nbsp;a wide range of fields. These techniques are especially important for&nbsp;large scale numerical simulations that aim to achieve scientific breakthroughs&nbsp;via computation and U.S. Department of Energy (DOE) mission-critical&nbsp;applications that need the DOE Leadership Computing Facilities because&nbsp;these computations often need to simultaneously use millions of computing&nbsp;cores.&nbsp;</p>\n<p>This project has also promoted teaching, training, and learning throughawarding research assistantships to both graduate students and&nbsp;undergraduate students, creating training opportunities for underrepresentedgroups, and incorporating research results into regular teaching.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/28/2016<br>\n\t\t\t\t\tModified by: Zizhong&nbsp;Chen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn computer industry, a computer?s central processing unit is often called a core. The desire of modern computer users to perform faster computations has driven the size of computers from single core, to multicores, and even to millions of cores. The current fastest computer in the world (i.e., Sunway TaihuLight in China) now consists of more than ten million cores. Computers capable of exaFLOP calculations (i.e., 10^18 calculations per second) available soon will be made up of 100 million to 1 billion cores. While today?s computer is often susceptible to single bit-flip errors, users of small computers usually do not see such errors because they have already been effectively protected by existing error correction mechanisms. However, as the number of cores in computers continues to increase, the current error protection mechanisms will not be enough any more because double bit-flip errors, miscalculations (i.e., errors like 1+1=3), and many other types of errors, which are less common for small computers, will increase at least linearly with the number of cores. Therefore, in the field of high performance computing (HPC), fault tolerance has been identified as one of the major challenges that must be addressed before computers are able to achieve exaFLOP performance.  \n\nWhen an error occurs, the affected application either continues or stops. If the application continues, it is called a fail-continue error. Otherwise, it is called a fail-stop error. This project has developed a series of highly efficient novel fault tolerance techniques that can be used to effectively protect widely used linear algebra computations from both fail-stop and fail-continue errors. This research is very challenging because it must balance many competing requirements including large number of cores, low hardware redundancy, low space and time cost, low communication overhead, high error coverage, high computing efficiency, high energy efficiency, high numerical accuracy, and good numerical stability. \n\nLinear algebra is widely used in many science and engineering fields. Highly efficient fault tolerance techniques for linear algebra computations will therefore benefit a larger number of users and a wide range of fields. These techniques are especially important for large scale numerical simulations that aim to achieve scientific breakthroughs via computation and U.S. Department of Energy (DOE) mission-critical applications that need the DOE Leadership Computing Facilities because these computations often need to simultaneously use millions of computing cores. \n\nThis project has also promoted teaching, training, and learning throughawarding research assistantships to both graduate students and undergraduate students, creating training opportunities for underrepresentedgroups, and incorporating research results into regular teaching.\n\n \n\n\t\t\t\t\tLast Modified: 11/28/2016\n\n\t\t\t\t\tSubmitted by: Zizhong Chen"
 }
}