{
 "awd_id": "1319828",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Theory, Algorithms, and Applications of Super-Nyquist Coding",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Richard Brown",
 "awd_eff_date": "2013-07-01",
 "awd_exp_date": "2017-06-30",
 "tot_intn_awd_amt": 464513.0,
 "awd_amount": 464513.0,
 "awd_min_amd_letter_date": "2013-06-21",
 "awd_max_amd_letter_date": "2013-06-21",
 "awd_abstract_narration": "With the ever growing demand for ubiquitous connectivity and data access, there is a driving need to deploy ever more extensive and higher capacity network infrastructure---wired and wireless.  With such increases in network density, the propagation environments become increasingly challenging, and new communication techniques, architectures, and protocols are needed to meet these critical challenges.  Examples include intersymbol (or self-), inter-channel, intra-network, and extra-network interference.  Over the years, the error-control coding community has developed a wide range of codes for efficiently mitigating the effects of noise in communication systems. Ultimately, the goal of this research can be viewed as developing a signaling architecture that efficiently and effectively transforms interference into standard, more benign noise from the perspective of the underlying code.\r\n\r\nTo approach these challenges, this research develops the role of super-Nyquist signaling formats in modern coded digital communication systems.  In traditional systems, the symbol rate is chosen to match the channel bandwidth.  With this classical approach, the transmit pulses can be designed to be orthogonal, corresponding to signaling on independent degrees of freedom.  However, in systems with super-Nyquist signaling, the symbol rate is chosen to be significantly higher than the channel bandwidth, resulting in a transmission with self-interference, whose effects can be compensated through the use of appropriate equalization.  The investigation develops the role of super-Nyquist coding in a range of network scenarios, starting from simple point-to-point intersymbol-interference channel models, and progressing to richer multi-input/multi-output, multiple-access, and interference channel models.  The research emphasizes the special role that such signaling plays in joint design of the physical and link layers in the protocol stack.  Dual problems in source coding are also explored.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gregory",
   "pi_last_name": "Wornell",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Gregory W Wornell",
   "pi_email_addr": "gww@mit.edu",
   "nsf_id": "000097642",
   "pi_start_date": "2013-06-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Mass Ave",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "793500",
   "pgm_ele_name": "COMM & INFORMATION THEORY"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 464513.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Motivated by the ever growing demand for ubiquitous connectivity, data access, and computing, there is a driving need to deploy ever more extensive and higher capacity network infrastructure. A major challenge is how to provide reliable and responsive services from such distributed resources. This project addressed key aspects of this problem, emphasizing the novel, intensive, and tailored use of ``super-dense'' redundancy techniques. The resulting methods are shown to offer significant advantages over existing technologies, and, as importantly, establish new directions in system, information, and communication science.</p>\n<p><br />For wireless networks, we developed a novel class of approaches to rateless coding for time-varying interference environments, based on a framework in which symbols are transmitted at a rate exceeding the Nyquist rate for the associated channels. The analysis showed that this ``super-Nyquist'' (SNQ) signaling framework is naturally matched to addressing intersymbol interference on point-to-point links. More specifically, when used in conjunction with standard low-complexity codes for the additive white Gaussian noise channel, low-complexity SNQ ``meta-codes'' can approach the white-input capacity. Interestingly, our construction can be viewed as an efficient ``jam-proof'' code, whereby reliable communication is achievable no matter how a jammer distributes its energy, and no matter how much jamming energy is used.</p>\n<p><br />The super-Nyquist approach was extended to commonly used multiterminal and multichannel network architectures, yielding SNQ-based rateless codes for orthogonal frequency-division multiplexing (OFDM) and multiple-antenna systems employing multi-input multi-output (MIMO) technology, and a novel layered code for decode-and-forward relay networks based on simultaneous matrix diagonalization.</p>\n<p><br />Building on the underlying insights from this analysis, the research developed a novel pulse-position modulation (PPM) architecture for optical communication in which the constituent light pulses span multiple time slots and spatial pixels. We show that with single-photon detectors, the highest rates are achieved in a low-photon regime. A key result is that density is good: optimum systems do not avoid crosstalk.</p>\n<p><br />Extending the key concepts to the problem of cloud data storage, where servers with variability in their responsiveness, we showed that using a redundant ``dense'' representation for the content can, when combined with efficient job distribution and termination protocols, significantly reduce latency in content delivery without requiring significantly greater cloud resources. We showed similar behavior for cloud computing. In particular, representing a computing job using a redundant ``dense'' collection of tasks allows efficient tradeoffs between latency and machine time to be achieved. Perhaps surprisingly, in many scenarios of interest such architectures can simultaneously reduce both latency and computing cost.</p>\n<p><br />Complementing our results on cloud computing, we addressed the design of reliable nanoscale computing fabrics, and developed a framework for reliable systems based on dense circuits with physical redundancy. Using a mathematical model for the problem in terms of a bitartite graph, we showed that provided the number of types of circuit elements is smaller than the number of circuit elements, new forms of physical redundancy are possible. In particular, using novel combinatorial analysis, we showed that both i) using dedicated spare copies of primary elements, and 2) using fully shared copies of primary elements are generally inefficient in terms of chip area, wiring complexity, or both. Our analysis is constructive, practical, and complemented by a detailed evaluation of fundamental limits.</p>\n<p><br />Finally, the research had significant broader impacts, emphasizing the professional and intellectual development of students. Of particular note, almost half the students and collaborators involved in this project were students from groups traditionally underrepresented in engineering.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/16/2017<br>\n\t\t\t\t\tModified by: Gregory&nbsp;W&nbsp;Wornell</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMotivated by the ever growing demand for ubiquitous connectivity, data access, and computing, there is a driving need to deploy ever more extensive and higher capacity network infrastructure. A major challenge is how to provide reliable and responsive services from such distributed resources. This project addressed key aspects of this problem, emphasizing the novel, intensive, and tailored use of ``super-dense'' redundancy techniques. The resulting methods are shown to offer significant advantages over existing technologies, and, as importantly, establish new directions in system, information, and communication science.\n\n\nFor wireless networks, we developed a novel class of approaches to rateless coding for time-varying interference environments, based on a framework in which symbols are transmitted at a rate exceeding the Nyquist rate for the associated channels. The analysis showed that this ``super-Nyquist'' (SNQ) signaling framework is naturally matched to addressing intersymbol interference on point-to-point links. More specifically, when used in conjunction with standard low-complexity codes for the additive white Gaussian noise channel, low-complexity SNQ ``meta-codes'' can approach the white-input capacity. Interestingly, our construction can be viewed as an efficient ``jam-proof'' code, whereby reliable communication is achievable no matter how a jammer distributes its energy, and no matter how much jamming energy is used.\n\n\nThe super-Nyquist approach was extended to commonly used multiterminal and multichannel network architectures, yielding SNQ-based rateless codes for orthogonal frequency-division multiplexing (OFDM) and multiple-antenna systems employing multi-input multi-output (MIMO) technology, and a novel layered code for decode-and-forward relay networks based on simultaneous matrix diagonalization.\n\n\nBuilding on the underlying insights from this analysis, the research developed a novel pulse-position modulation (PPM) architecture for optical communication in which the constituent light pulses span multiple time slots and spatial pixels. We show that with single-photon detectors, the highest rates are achieved in a low-photon regime. A key result is that density is good: optimum systems do not avoid crosstalk.\n\n\nExtending the key concepts to the problem of cloud data storage, where servers with variability in their responsiveness, we showed that using a redundant ``dense'' representation for the content can, when combined with efficient job distribution and termination protocols, significantly reduce latency in content delivery without requiring significantly greater cloud resources. We showed similar behavior for cloud computing. In particular, representing a computing job using a redundant ``dense'' collection of tasks allows efficient tradeoffs between latency and machine time to be achieved. Perhaps surprisingly, in many scenarios of interest such architectures can simultaneously reduce both latency and computing cost.\n\n\nComplementing our results on cloud computing, we addressed the design of reliable nanoscale computing fabrics, and developed a framework for reliable systems based on dense circuits with physical redundancy. Using a mathematical model for the problem in terms of a bitartite graph, we showed that provided the number of types of circuit elements is smaller than the number of circuit elements, new forms of physical redundancy are possible. In particular, using novel combinatorial analysis, we showed that both i) using dedicated spare copies of primary elements, and 2) using fully shared copies of primary elements are generally inefficient in terms of chip area, wiring complexity, or both. Our analysis is constructive, practical, and complemented by a detailed evaluation of fundamental limits.\n\n\nFinally, the research had significant broader impacts, emphasizing the professional and intellectual development of students. Of particular note, almost half the students and collaborators involved in this project were students from groups traditionally underrepresented in engineering. \n\n\t\t\t\t\tLast Modified: 09/16/2017\n\n\t\t\t\t\tSubmitted by: Gregory W Wornell"
 }
}