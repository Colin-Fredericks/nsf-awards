{
 "awd_id": "9309820",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Efficiency of Heading Perception",
 "cfda_num": "47.075",
 "org_code": "04040500",
 "po_phone": "7032924833",
 "po_email": "jyoung@nsf.gov",
 "po_sign_block_name": "Jasmine Young",
 "awd_eff_date": "1993-08-15",
 "awd_exp_date": "1997-07-31",
 "tot_intn_awd_amt": 225081.0,
 "awd_amount": 225081.0,
 "awd_min_amd_letter_date": "1993-09-02",
 "awd_max_amd_letter_date": "1995-05-19",
 "awd_abstract_narration": "9309820  BANKS    Humans are able to move rapidly through complex environments while  avoiding stationary and moving obstacles; clearly the sensory  modality most important for this skill is vision.  The ease with  which people use visual motion information to guide navigation  belies the underlying complexity of the task.  Self-motion through  an environment produces a pattern of movement on the retina called  the optic flow field.  An influential early proposal was to  identify the direction of self-motion with respect to obstacles by  locating the source of flow, i.e., the focus of expansion, but the  task is actually much more complicated.  First, since the sensing  of 2D motion (which is required to derive the optic flow field in  the first place) is a difficult problem in its own right, one  cannot assume that a noise-free vector field is available for  calculation of observer motion.  Second, since people commonly move  their eyes and head while locomoting, these movements obliterate  the focus of expansion.  Third, since visual scenes often contain  moving objects besides the observer, those objects do not produce  a consistent focus.  Despite these complications, people use the  optic flow field very effectively to judge heading relative to  landmarks and other moving objects.  This research is mainly  concerned with how efficiently human observers use the information  contained in the optic flow field to determine the parameters of  their self-motion.  A measure of efficiency derives from the  comparison of the performance of an ideal observer for heading  tasks to that of human observers in the same tasks.  Because the  ideal observer uses all of the information in the flow field, its  performance provides a rigorous benchmark against which to compare  human performance.  Specific comparisons will not only allow the  measurement of human efficiency but also the identification of some  of the causes of inefficiency.  The research will demonstrate how  variables such as number of elemen ts in the display, type of flow  field displayed, sharpness and size of the display, position of  stimulation on the retina, presence of rotational flow due to  eye/head movements, and knowledge of the scene geometry affect  human efficiency in determining the direction of self-motion.    While the products of this research will enhance our understanding  of space and motion perception, they may also have important  practical consequences.  For one thing, since biological systems  have evolved robust mechanisms to subserve visually-guided  navigation, a better understanding of how this is accomplished  should lead to better algorithms for mobile robotic systems.   Second, the development of an ideal observer for heading tasks will  provide a benchmark against which to compare the performance of  computer algorithms.  Third, since perception of heading with  respect to stationary and moving objects is crucial for driving and  flying, a better understanding could lead to improved procedures  for screening and training drivers and pilots and for designing  instruments, cockpits, and roadway and runway markings.    ***",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Martin",
   "pi_last_name": "Banks",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Martin Banks",
   "pi_email_addr": "martybanks@berkeley.edu",
   "nsf_id": "000457309",
   "pi_start_date": "1993-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "1608 4TH ST STE 201",
  "perf_city_name": "BERKELEY",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947101749",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "118000",
   "pgm_ele_name": "HUMAN COGNITION & PERCEPTION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0193",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0193",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0194",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0194",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0195",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0195",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 1993,
   "fund_oblg_amt": 70706.0
  },
  {
   "fund_oblg_fiscal_yr": 1994,
   "fund_oblg_amt": 74735.0
  },
  {
   "fund_oblg_fiscal_yr": 1995,
   "fund_oblg_amt": 79640.0
  }
 ],
 "por": null
}