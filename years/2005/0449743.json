{
 "awd_id": "0449743",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Model-Based fMRI of Human Object Recognition",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Peter Vishton",
 "awd_eff_date": "2005-07-01",
 "awd_exp_date": "2011-06-30",
 "tot_intn_awd_amt": 0.0,
 "awd_amount": 742316.0,
 "awd_min_amd_letter_date": "2005-07-27",
 "awd_max_amd_letter_date": "2009-06-02",
 "awd_abstract_narration": "Object recognition is a fundamental cognitive task that is performed effortlessly countless times every day, such as when gauging a conversation partner's facial expression, looking for a friend's face in a crowd, or reading the words of this abstract. All these tasks depend on the visual system's ability to recognize specific objects, despite significant variations in their appearance due to changes in lighting, position, viewpoint, or the simultaneous presence of other objects. Importantly, the visual system is not hard-wired but can be trained for specific tasks, e.g., detecting terrorist camps in satellite images or tumors in X-ray films. Despite the apparent ease with which we see, visual recognition is widely acknowledged to be a very difficult computational problem. From a biological systems perspective, visual recognition involves several levels of understanding, from the computational level, to the levels of cellular and biophysical mechanisms and the level of neuronal circuits, up to the level of behavior. Computational approaches to visual recognition are becoming increasingly important to integrate data from different experiments and levels of description (such as electrophysiology, brain imaging, and behavior) into one coherent, quantitative framework that can then be used to provide rigorous hypotheses for further experiments. With a CAREER award from the National Science Foundation, Dr. Maximilian Riesenhuber is continuing his work on a computational model of object recognition in cortex. He is applying this model to study how visual experience and training on specific tasks shape the brain's representation of the external world and its object recognition capabilities, and how the visual system can successfully recognize objects, even in the presence of interfering stimuli. In particular, the model is being used to provide detailed hypotheses on how training on specific object recognition tasks (ranging from the discrimination of novel stimuli to categorization and object recognition in visual clutter) can modify processing at different levels of the visual system, and how these changes are related to improvements in behavioral performance. This leads to a set of hypotheses that are to be tested with human volunteers in a series of behavioral and brain imaging experiment, using the same stimuli and tasks as in the simulations. Importantly, simulations and experiments are tightly integrated so that experimental results from simpler tasks can be used to refine the model, which can then be used to provide more specific hypotheses for more complex tasks.\r\nThe results of this research will be relevant for the design of machine vision systems in artificial intelligence that better mimic how humans see, for the development of human-machine interfaces that optimally leverage the brain's ability to process visual information, and for applications involving human training on object recognition tasks ranging from baggage screening to satellite image analysis. Understanding the neural circuitry involved in object recognition in the typical brain is also important for understanding and ultimately treating object recognition deficits in neural disorders such as autism, schizophrenia, and dyslexia. A key element of the CAREER award is Dr. Riesenhuber's plan to use the same computational model that forms the basis of the research effort as an educational tool by developing a model-based curriculum in integrative cognitive neuroscience. \r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maximilian",
   "pi_last_name": "Riesenhuber",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maximilian Riesenhuber",
   "pi_email_addr": "mr287@georgetown.edu",
   "nsf_id": "000106418",
   "pi_start_date": "2005-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgetown University",
  "inst_street_address": "MAIN CAMPUS",
  "inst_street_address_2": "",
  "inst_city_name": "WASHINGTON",
  "inst_state_code": "DC",
  "inst_state_name": "District of Columbia",
  "inst_phone_num": "2026250100",
  "inst_zip_code": "20057",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DC00",
  "org_lgl_bus_name": "GEORGETOWN UNIVERSITY",
  "org_prnt_uei_num": "TF2CMKY1HMX9",
  "org_uei_num": "TF2CMKY1HMX9"
 },
 "perf_inst": {
  "perf_inst_name": "Georgetown University School of Medicine",
  "perf_str_addr": "MAIN CAMPUS",
  "perf_city_name": "WASHINGTON",
  "perf_st_code": "DC",
  "perf_st_name": "District of Columbia",
  "perf_zip_code": "20057",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DC00",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169900",
   "pgm_ele_name": "Cognitive Neuroscience"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0105",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0105",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0106",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2005,
   "fund_oblg_amt": 198442.0
  },
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 86888.0
  },
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 152472.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 145658.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 158856.0
  }
 ],
 "por": null
}