{
 "awd_id": "0448111",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Markov Chain Monte Carlo Methods for Large Scale Correspondence Problems in Computer Vision and Robotics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2005-04-01",
 "awd_exp_date": "2011-03-31",
 "tot_intn_awd_amt": 0.0,
 "awd_amount": 422000.0,
 "awd_min_amd_letter_date": "2005-03-30",
 "awd_max_amd_letter_date": "2009-05-26",
 "awd_abstract_narration": "The goal of this project is to investigate tractable approaches to large-scale correspondence problems in computer vision and robotics. Correspondence is a central problem in many vision and robotics applications, and the proposed research centers on three of those: large-scale 3D reconstruction from digital imagery in space and time, simultaneous localization and mapping using mobile robots, and tracking large numbers of visually similar objects, such as ants in an ant-hill or people in a crowd. To eclipse existing state of the art methods, this proposal aims to investigate approximate inference through Markov chain Monte Carlo (MCMC) sampling. MCMC provides an approximate solution for an otherwise intractable problem, and has a number of attractive advantages with respect to other approaches. In addition, practical insights gained in applying MCMC to this problem can cross-pollinate other fields and spawn new theoretical investigations. In terms of broader impact, this project's integrated research and education plan will help produce a next generation of researchers, intimately familiar with these new methods first discovered in statistical mechanics. In addition, the project has a strong outreach component through museum exhibits and interaction with local high schools. Taking a longer view, the proposed research will enable novel and large-scale\r\napplications of computer vision and robotics that are expected to have far-reaching\r\nimplications for society. Robots are on the verge of playing a much larger role in our lives, as evidenced for example by the increasingly popular consumer robots now available. More immediately, the advent of cheap digital photography and video is exponentially increasing the volume of digital imagery that can be used, analyzed, and re-synthesized in new and creative ways. The correspondence problem lies at the heart of many of these novel uses.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Frank",
   "pi_last_name": "Dellaert",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Frank Dellaert",
   "pi_email_addr": "dellaert@cc.gatech.edu",
   "nsf_id": "000274425",
   "pi_start_date": "2005-03-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 NORTH AVE NW",
  "perf_city_name": "ATLANTA",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "684000",
   "pgm_ele_name": "ROBOTICS"
  },
  {
   "pgm_ele_code": "733900",
   "pgm_ele_name": "COMPUTER VISION"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0105",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0105",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0106",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2005,
   "fund_oblg_amt": 90000.0
  },
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 92000.0
  },
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 80000.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 80000.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 80000.0
  }
 ],
 "por": null
}