{
 "awd_id": "0505303",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Rigorous Methods for Dimensionality Reduction of High-Dimensional Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2005-07-01",
 "awd_exp_date": "2010-06-30",
 "tot_intn_awd_amt": 0.0,
 "awd_amount": 799890.0,
 "awd_min_amd_letter_date": "2005-02-07",
 "awd_max_amd_letter_date": "2009-01-23",
 "awd_abstract_narration": "A research effort is proposed to create tools for data analysis and inference in high-dimensional settings.  The effort uses tools from random matrix theory (RMT), Banach Space Theory (BST), and differential geometry (DG) to expose new phenomena in high-dimensional statistical inference and data analysis, yielding practical statistical methods with rigorously-established properties under carefully-stated conditions.  The results will impact a wide range of data analysis problems, including the building of linear models, the testing of complex hypotheses about multivariate data, and the detection of subtle nonlinear structures in high-dimensional data. In the research, the investigators build further bridges between RMT, BST, and DG and three problem areas: (a) Sparse Linear Modelling -- How should one build a predictive model choosing relatively few predictors out of many available predictors?; (b) Multivariate Analysis in High Dimensions -- How should one best estimate and test for structure in high-dimensional data, particularly when the number of variables is large and the number of observations is small?; (c) Manifold Learning -- How can one best find nonlinear structure in high-dimensional data and best parametrize that structure?  Each of these areas is of fundamental importance to the analysis of high-dimensional data, and the investigators identify a strategy to use RMT, BST, and DG to make substantial contributions to each.  This strategy builds on the authors' recent research accomplishments using RMT, BST, and DG, which will be extended to show: (a) how to find the best-fitting low-dimensional linear model without spending exponential time searching through model space -- extending previous successes in using Basis Pursuit, LARS and Lasso; (b) how to correctly test a wide range of important hypotheses in multivariate analysis using the Tracy-Widom distribution -- extending previous results in applying the Tracy-Widom distribution to Principal Components Analysis; and (c) how to correctly estimate a nonlinear parametrization of sparsely sampled curved data in high dimensional space -- extending previous successes in developing the Hessian Eigenmap technique of dimensionality reduction.\r\n\r\n\r\nThe motivation for this project lies in the `data deluge' now engulfing every branch of science and technology.  In field after field, new sensors are creating data streams of unparalleled breadth and depth. As a result, today scientific and technological progress depends heavily on the ability to process high-dimensional data and reduce its dimensionality, sometimes drastically, obtaining a good approximation using a few well-chosen combinations of the original measurements. While many methods of dimensionality reduction have already been proposed, much existing research activity in this area is heuristic and speculative; the tools are often of unknown reliability and their properties hold under conditions of unknown generality.  This project develops methods based on careful mathematical analysis to develop methods of dimensionality reduction which are rigorously correct and/or optimal.  These methods give the user the assurance that important features are captured in the dimensions which remain and that little of importance is discarded in the dimensions that are thrown away. The project develops such rigorous methods in three areas: (a) building parsimonious but accurate predictive models out of a database of many possible predictors; (b) testing for hidden structure in what otherwise seems to be high dimensional `noise'; (c) discovering the correct representation for data which are intrinsically nonlinear.  Strong expectations for success of this project can be based on existing solid achievements by the investigators in each of these three areas.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Donoho",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "David L Donoho",
   "pi_email_addr": "donoho@stat.stanford.edu",
   "nsf_id": "000367778",
   "pi_start_date": "2005-02-07",
   "pi_end_date": "2008-12-01"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Iain",
   "pi_last_name": "Johnstone",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Iain M Johnstone",
   "pi_email_addr": "imj@stanford.edu",
   "nsf_id": "000155839",
   "pi_start_date": "2009-01-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Donoho",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "David L Donoho",
   "pi_email_addr": "donoho@stat.stanford.edu",
   "nsf_id": "000367778",
   "pi_start_date": "2008-12-01",
   "pi_end_date": "2009-01-23"
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Iain",
   "pi_last_name": "Johnstone",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Iain M Johnstone",
   "pi_email_addr": "imj@stanford.edu",
   "nsf_id": "000155839",
   "pi_start_date": "2005-02-07",
   "pi_end_date": "2008-12-01"
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "450 JANE STANFORD WAY",
  "perf_city_name": "STANFORD",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943052004",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0105",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0105",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0106",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2005,
   "fund_oblg_amt": 197730.0
  },
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 204622.0
  },
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 207417.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 190121.0
  }
 ],
 "por": null
}