{
 "awd_id": "0413004",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Flexible State Representations in Reinforcement Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2005-02-15",
 "awd_exp_date": "2010-01-31",
 "tot_intn_awd_amt": 0.0,
 "awd_amount": 274992.0,
 "awd_min_amd_letter_date": "2005-01-24",
 "awd_max_amd_letter_date": "2009-05-08",
 "awd_abstract_narration": "Reinforcement learning (RL) applies to any task that involves an agent taking a sequence of actions where the effects of one action influence the long-term utility of subsequent actions. How should such a learning agent represent its knowledge about its environment? Traditional models typically capture the agent's state as composed of objects and events in the environment and relations among them. Since these relations cannot be directly observed by the agent through its sensors, they have meaning only in the mind of the human designer of the agent. Recently, the PI and colleagues have instead proposed modeling the agent's state as composed of a set of predictions of observable outcomes of tests or experiments that the agent could perform in its environment. Such representations, called predictive state representations (PSRs), are composed entirely of observable quantities and therein lies much of their promise for efficient and scalable planning and learning in RL tasks. In this project many foundational questions about PSRs are being explored. These include: (1) How can an agent discover what predictions it should keep to capture the state of its environment?; (2) How can the long-term action-conditional predictions that are part of PSR state representations be used to speed up planning that is about evaluating long-term effects of actions?; (3) How can memory of past observations be combined with PSR predictions of future observations for computational benefit?; and (4) How can the flexible temporally abstract representations of state -- specifically PSRs -- be combined with similarly temporally abstract representations of actions? This project is developing the nascent idea of PSRs into a full-fledged theory of learning and planning. If successful, this research will result in a dramatic increase in the applicability of RL for building learning agents in large-scale domains in AI, operations research, control, and dynamical systems. This project also plans to construct and make publically available a set of benchmark RL tasks. This will help remediate the lack of such widely available test beds in the RL community.\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Satinder",
   "pi_last_name": "Baveja",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Satinder S Baveja",
   "pi_email_addr": "baveja@umich.edu",
   "nsf_id": "000100173",
   "pi_start_date": "2005-01-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "Regents of the University of Michigan - Ann Arbor",
  "perf_str_addr": "1109 GEDDES AVE STE 3300",
  "perf_city_name": "ANN ARBOR",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091015",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "685600",
   "pgm_ele_name": "ARTIFICIAL INTELL & COGNIT SCI"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0105",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0105",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0106",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2005,
   "fund_oblg_amt": 87856.0
  },
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 187136.0
  }
 ],
 "por": null
}