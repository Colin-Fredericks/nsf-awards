{
 "awd_id": "9626187",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Multivariate Nonparametric Methodology Studies",
 "cfda_num": "47.049",
 "org_code": "03040300",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Joseph M. Rosenblatt",
 "awd_eff_date": "1996-06-15",
 "awd_exp_date": "1999-08-31",
 "tot_intn_awd_amt": 219081.0,
 "awd_amount": 219081.0,
 "awd_min_amd_letter_date": "1996-06-17",
 "awd_max_amd_letter_date": "1998-08-04",
 "awd_abstract_narration": "DSM9616187  Scott    Nonparametric methodology is widely used in one and two dimensions, but not  in high dimensions.  This research focuses on the mid-range dimensions and  provides a deeper understanding of the implications of the curse of  dimensionality and related problems associated with massive data sets.  Particular emphasis has been given to multivariate regression and density  estimation problems, and closely related applications such as clustering  and ridges.  Anecdotal evidence has suggested a gap between the apparent  successes of nonparametric methodology in practice and the poor performance  predicted by theory.  We have examined new points of view, especially related  to locally adaptive estimation.  Higher quality estimation has often required  use of negative kernels, but our results have shown that equivalent gains  are possible in regions where the Hessian is indefinite, often in the tails  which dominate in higher dimensions.  In addition, we have developed a  class of locally adaptive but not higher order algorithms that work  better in practical problems and avoid problems of negativity.  We have  addressed problems arising from high dimensionality in several ways.  We have created algorithms for finding interesting subspaces from the density  estimation point of view.  Such subspaces are defined by maximal bias content,  sequentially peeling off low bias subspaces.  We have examined semiparametric  models for density estimation that can work better than ordinary nonparametric  algorithms, extending feasibility by several extra dimensions.  Visualization  is especially important when dealing with medium dimensional data and the  growing body of massive data sets.  One example of a new visualization tool  is provided by the density grand tour, which performs an ordinary grand tour  but displays a real-time view of a derived density estimate, the averaged  shifted histogram.  We have found that traversing ridges and contours is useful  to control or constrain viewing.  We h ave extended our density visualization  capabilities to regression surfaces and related problems in visual clustering  and visual discrimination applications.  Visualization is also important  for organizing complicated multiple testing problems is clustering, such as  our results in mode estimation and testing based on the mode tree.  We have  investigated a local testing algorithm for collapsing modes as the basis for  an improved clustering algorithm.  A natural extension has been demonstrated  for multiprocessor and parallel architectures for massive data sets.  A great challenge in mathematical sciences is provided by massive data sets.  At a recent National Research Council workshop, numerous scientists identified  critical statistical needs in their work:  alternatives to principal  components, specialized visualization tools for exploring massive data,  better clustering algorithms, and techniques for handling nonstationary data.  Results from our research directly impact three of these four critical  opportunities.  This program represents a comprehensive and long-term attack  on a host of important data analytic problems in multivariate estimation.  %%%  Statistical techniques that do not require formulae to be written down  explicitly are called nonparametric methods and include the well-known  histogram as a simple example.  Such techniques are widely used with data  in one and two dimensions, but not in higher dimensions where most of the  grand challenge problems are to be found.  This research focuses on  the mid-range dimensions where many serious theoreticians have  expressed concern that nonparametric methods may not work.  However, it is  well-known that many practicing scientists and engineers have been  successfully using nonparametric methods with data from signal processing,  image understanding, data mining, among a wide array of real problems.  This research is providing a deeper understanding of the implications of  the so-called curse of dimensionality and particular p roblems associated  with massive data sets.  Particular emphasis is given to problems in  multivariate regression and density estimation, as well as closely  related applications such as clustering and ridges.  We have obtained  a new understanding of how locally adaptive estimation should work  in overcoming the usual limitations of nonparametric methodology in  several dimensions.  For higher dimensional data, we have developed  algorithms for finding maximally interesting subspaces from the density  estimation point of view.  Such subspaces are defined by maximal bias  content and are constructed sequentially, peeling off low bias subspaces.  Beyond two dimensions, visualization is a critical task, especially as  related to the growing body of massive data sets.  One example of a success  is provided by our new density grand tour, which provides a new way  of looking at high dimensional data in real-time. We have extended our  density estimation visualization capabilities to regression surfaces.  Visualization is also very useful for examining data to detect the  presence of clusters.  Such clusters are critical for determining  the usefulness of data collected for proposes such as character  recognition, remote sensing crop identification, ground water pollution,  as well as many more specialized engineering and scientific applications.  Multiprocessor and parallel architectures versions of these algorithms  are particularly relevant in the massive data set situation.  A great challenge in mathematical sciences is provided by handling  massive data sets.  At a recent National Research Council workshop,  numerous scientists identified critical statistical needs in their work:  alternatives to principal components, specialized visualization tools  for exploring massive data, better clustering algorithms, and techniques  for handling nonstationary data.  Results from our research directly  impact three of these four critical opportunities.  This program represents  a comprehensive and long-term  attack on a host of important data analytic  problems in multivariate estimation.  Nonparametric methodology seems to work  well in the hands of experts, and this research is designed to not only aid  the expert but to facilitate the use of the methodology by a wider audience.  ***",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Scott",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "David W Scott",
   "pi_email_addr": "scottdw@rice.edu",
   "nsf_id": "000350909",
   "pi_start_date": "1996-06-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Dennis",
   "pi_last_name": "Cox",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Dennis D Cox",
   "pi_email_addr": "dcox@stat.rice.edu",
   "nsf_id": "000419643",
   "pi_start_date": "1996-06-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "William Marsh Rice University",
  "inst_street_address": "6100 MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "Houston",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7133484820",
  "inst_zip_code": "770051827",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "TX09",
  "org_lgl_bus_name": "WILLIAM MARSH RICE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "K51LECU1G8N3"
 },
 "perf_inst": {
  "perf_inst_name": "William Marsh Rice University",
  "perf_str_addr": "6100 MAIN ST",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "770051827",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "TX09",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9187",
   "pgm_ref_txt": "TOXIC SUBSTANCES/SOLID & HAZARDOUS WASTE"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "EGCH",
   "pgm_ref_txt": "ENVIRONMENT AND GLOBAL CHANGE"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0196",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0196",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0197",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0197",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0198",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0198",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 1996,
   "fund_oblg_amt": 73027.0
  },
  {
   "fund_oblg_fiscal_yr": 1997,
   "fund_oblg_amt": 73027.0
  },
  {
   "fund_oblg_fiscal_yr": 1998,
   "fund_oblg_amt": 73027.0
  }
 ],
 "por": null
}