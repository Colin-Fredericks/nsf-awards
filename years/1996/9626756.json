{
 "awd_id": "9626756",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Exact Sampling via Markov Chains",
 "cfda_num": "47.049",
 "org_code": "03040300",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "K Crank",
 "awd_eff_date": "1996-07-01",
 "awd_exp_date": "1998-06-30",
 "tot_intn_awd_amt": 64000.0,
 "awd_amount": 64000.0,
 "awd_min_amd_letter_date": "1996-06-14",
 "awd_max_amd_letter_date": "1996-06-14",
 "awd_abstract_narration": "9626756 Fill  ABSTRACT  For many statistical physics examples, such as the stochastic Ising model, one seeks to sample from a probability distribution on an enormously large state space, but elementary sampling is ruled out by the infeasibility of calculating an appropriate normalizing constant.  Similar difficulties arise in computer science when one seeks to sample randomly from a large combinatorial space whose precise size cannot be ascertained in any reasonable amount of time. The Markov chain Monte Carlo (MCMC) approximate sampling approach to such a problem is to construct and run \"for a long time\" a Markov chain with long-run distribution equal to the given distribution.  But determining how long is long enough can be both analytically and empirically difficult. Very recently, researchers have devised an algorithm to use the same Markov chains to produce exact samples from the desired distribution.  However, the running time of the algorithm is unbounded and not independent of the state sampled, so a user with limited patience will introduce systematic bias by aborting a long run.  The investigator assesses the extent of this bias, implements and studies (via a certain \"duality\" theory) the performance of a new algorithm he devises to eliminate the bias, and establishes bounds on the performance of any such Markov-chain-based algorithm.   Physicists are interested in models for ferromagnetism and for phase transitions (such as freezing and thawing).  In such statistical mechanics problems, in image processing (the cleaning up of noisy or blurred images), and in computer science, much can be learned by studying certain probability distributions on sets having enormously large numbers of elements.  The standard \"Monte Carlo\" approach to studying a distribution is to draw a (representative) random sample, but this approach is computationally infeasible for problems of such large size.  To handle such problems, researchers use computers to simulate certain probabilistic processes, called Mar kov chains, which, in a certain precise sense, \"settle down\" to the distribution of interest \"in the long run.\"  But determining how long is long enough to run the chain in order to approximate the distribution sufficiently closely can be difficult to assess, both theoretically and empirically.  Very recently, researchers have devised an algorithm to use the same Markov chains to produce exact samples from the desired distribution.  However, the running time of the algorithm is sometimes very large, and the distribution of the output can depend on the running time, so a user with limited patience will introduce systematic bias by aborting a long run. The investigator, a probabilist, assesses the extent of this bias, implements and analyzes the performance of a new algorithm he devises to eliminate the bias, and considers how well any such Markov-chain-based algorithm can perform.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Fill",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "James A Fill",
   "pi_email_addr": "jimfill@jhu.edu",
   "nsf_id": "000312441",
   "pi_start_date": "1996-06-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "3400 N CHARLES ST",
  "perf_city_name": "BALTIMORE",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182608",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126300",
   "pgm_ele_name": "PROBABILITY"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0196",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0196",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 1996,
   "fund_oblg_amt": 64000.0
  }
 ],
 "por": null
}