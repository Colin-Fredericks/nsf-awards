{
 "awd_id": "0830458",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Toward Software Tools for Memory-Efficient Matrix Algebra",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Dmitri Maslov",
 "awd_eff_date": "2008-09-15",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 100000.0,
 "awd_amount": 130000.0,
 "awd_min_amd_letter_date": "2008-08-05",
 "awd_max_amd_letter_date": "2012-09-14",
 "awd_abstract_narration": "A scientific program is a mathematical one so there are two factors\r\ncontributing to its performance.  One is the time required to perform\r\narithmetic.  The other is the time needed to move data through the\r\nmemory hierarchy of the computer.  In today's large applications, the\r\nlatter cost often dominates.   The work funded by this grant focuses on\r\nefficient computational methods for solving the problems in matrix algebra\r\nthat arise in a wide variety of science and engineering applications.\r\nCodes for such problems are typically constructed as sequences of calls to\r\nthe routines known as the Basic Linear Algebra Subprograms (BLAS). Writing\r\nprograms in this way promotes readability and maintainability but can\r\nbe costly in terms of memory efficiency especially for matrices of\r\nlarge order.\r\n\r\nThe grant will be used primarily to support a Ph.D. student who will\r\nstudy ways to combine multiple BLAS routines into a single routine that\r\nperforms the functions of more than one BLAS.  He will examine ways to\r\ncreate composed BLAS via novel algorithms and performance programming\r\ntechniques, developing a general methodology for their creation in the\r\nprocess.  His work will ultimately form the basis for a tool that creates\r\ncomposed BLAS automatically.  Composed routines can significantly reduce\r\nthe amount of data read from main memory.  Preliminary results include\r\nspeedups as large as 90\\%.\r\n\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Elizabeth",
   "pi_last_name": "Jessup",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Elizabeth R Jessup",
   "pi_email_addr": "jessup@cs.colorado.edu",
   "nsf_id": "000293670",
   "pi_start_date": "2008-08-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Colorado at Boulder",
  "inst_street_address": "3100 MARINE ST",
  "inst_street_address_2": "STE 481 572 UCB",
  "inst_city_name": "Boulder",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "3034926221",
  "inst_zip_code": "803090001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "THE REGENTS OF THE UNIVERSITY OF COLORADO",
  "org_prnt_uei_num": "",
  "org_uei_num": "SPVKK1RC2MZ3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Colorado at Boulder",
  "perf_str_addr": "3100 MARINE ST",
  "perf_city_name": "Boulder",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "803090001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "286500",
   "pgm_ele_name": "NUMERIC, SYMBOLIC & GEO COMPUT"
  },
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "793400",
   "pgm_ele_name": "PARAL/DISTRIBUTED ALGORITHMS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "7934",
   "pgm_ref_txt": "PARAL/DISTRIBUTED ALGORITHMS"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 100000.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 6000.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>A scientist needing high quality computational tools is tasked with mastering advanced concepts in computer science and with carrying out complex programming tasks in addition to managing the scientific content of the work. &nbsp;The problem is compounded by the constant evolution of computer hardware. &nbsp;Scientists are often forced to choose between investing substantial time in tuning computer codes or accepting performance that can be significantly lower than the best attainable. In both cases, the productivity ofthe scientist degrades. To aid in the process of software tuning, our research concerned tools for automating the development of high-performance software for scientific applications.</p>\n<p>A scientific program is a mathematical one, and there are two contributing factors to its performance. &nbsp;One is the time required for performing arithmetic. The other is the time needed for moving data through the memory hierarchy of the computer. &nbsp;In today's large applications, the latter cost often dominates. &nbsp;Our work focused on reducing memory access costs in the solution of the matrix algebra problems that constitute the most expensive part of many scientific computations.</p>\n<p>Historically, codes for matrix algebra have been constructed as sequences of calls to subprograms that perform fundamental operations. Writing programs in this way promotes readability and maintainability but can be costly in terms of memory efficiency as the same data are accessed by the routines one after another. One remedy is to employ a powerful optimization known as loop fusion that combines the subprograms into a single routine that employs the data only once. &nbsp;Our work began with a study of the performance effects of loop fusion which ultimately led us to develop a formal, analytical model of the computer's memory hierarchy for fused matrix algebra problems. &nbsp;We integrated the model into the Build to Order (BTO) compiler which converts high level descriptions of matrix algebra into optimized implementations. &nbsp;Including the model accurately and efficiently reduced compilation times for BTO.</p>\n<p><br />Intellectual Merit: We have improved the understanding the factors that influence memory traffic in matrix algebra computations, and we have built a tool that aids in the development of high-performance matrix algebra implementations.</p>\n<p><br />Broader Impacts: The model developed during this grant's funding is now released to the public as part of the open source compiler BTO which helps to remove the onus of high-performance programming for scientists. The grant funded a number of educational opportunities. &nbsp;It primarily supported one PhD student, but it also provided a number of undergraduates with their first research experiences.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/01/2013<br>\n\t\t\t\t\tModified by: Elizabeth&nbsp;R&nbsp;Jessup</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nA scientist needing high quality computational tools is tasked with mastering advanced concepts in computer science and with carrying out complex programming tasks in addition to managing the scientific content of the work.  The problem is compounded by the constant evolution of computer hardware.  Scientists are often forced to choose between investing substantial time in tuning computer codes or accepting performance that can be significantly lower than the best attainable. In both cases, the productivity ofthe scientist degrades. To aid in the process of software tuning, our research concerned tools for automating the development of high-performance software for scientific applications.\n\nA scientific program is a mathematical one, and there are two contributing factors to its performance.  One is the time required for performing arithmetic. The other is the time needed for moving data through the memory hierarchy of the computer.  In today's large applications, the latter cost often dominates.  Our work focused on reducing memory access costs in the solution of the matrix algebra problems that constitute the most expensive part of many scientific computations.\n\nHistorically, codes for matrix algebra have been constructed as sequences of calls to subprograms that perform fundamental operations. Writing programs in this way promotes readability and maintainability but can be costly in terms of memory efficiency as the same data are accessed by the routines one after another. One remedy is to employ a powerful optimization known as loop fusion that combines the subprograms into a single routine that employs the data only once.  Our work began with a study of the performance effects of loop fusion which ultimately led us to develop a formal, analytical model of the computer's memory hierarchy for fused matrix algebra problems.  We integrated the model into the Build to Order (BTO) compiler which converts high level descriptions of matrix algebra into optimized implementations.  Including the model accurately and efficiently reduced compilation times for BTO.\n\n\nIntellectual Merit: We have improved the understanding the factors that influence memory traffic in matrix algebra computations, and we have built a tool that aids in the development of high-performance matrix algebra implementations.\n\n\nBroader Impacts: The model developed during this grant's funding is now released to the public as part of the open source compiler BTO which helps to remove the onus of high-performance programming for scientists. The grant funded a number of educational opportunities.  It primarily supported one PhD student, but it also provided a number of undergraduates with their first research experiences.\n\n\t\t\t\t\tLast Modified: 12/01/2013\n\n\t\t\t\t\tSubmitted by: Elizabeth R Jessup"
 }
}