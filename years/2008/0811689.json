{
 "awd_id": "0811689",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPA-CPL-T: Collaborative Research:  REEact:  A Robust Execution Environment for Fragile Multicore Systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2008-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 525000.0,
 "awd_amount": 565998.0,
 "awd_min_amd_letter_date": "2008-08-16",
 "awd_max_amd_letter_date": "2010-06-17",
 "awd_abstract_narration": "With the emergence of the multicore architecture comes the promise of integrating enormous computing power in a single chip, thereby enabling parallel computing in all types of platforms including handheld computers and desktop machines. Providing proper software support for applications is critical to harness the true power of this architecture. An inherent characteristic of multicores that presents a significant obstacle is runtime variation: reliability, energy/thermal behavior and process variation will vary across identically designed components of a multicore, producing a negative impact on application power consumption and performance. Runtime variation has been identified as one of the key problems that could block further scaling of circuits if not properly addressed. \r\n\r\nThis research project is developing an advanced execution system, called a Robust Execution Environment (REEact), that dynamically mediates, controls and adapts an application's execution to the runtime resource landscape originating from runtime variations. It employs a combination of techniques in adapting both the hardware resources and the application software code to overcome the impact of runtime variations. At the hardware level, it adapts the resources, such as setting the speed/voltage of a node on the multicore. At the software level, REEact dynamically optimizes code, taking into account performance and power consumption due to runtime variations. It elicits the help of the OS in determining what resources to use in running the application. REEact informs the OS about information it dynamically discovers about latency, power, and application behavior. REEact is built as multi-layer hierarchical runtime system that interacts with the parallel application, the OS, and the underlying multicore architecture to ensure that maximum performance is achieved.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mary Lou",
   "pi_last_name": "Soffa",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mary Lou Soffa",
   "pi_email_addr": "soffa@cs.virginia.edu",
   "nsf_id": "000203853",
   "pi_start_date": "2008-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jack",
   "pi_last_name": "Davidson",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Jack W Davidson",
   "pi_email_addr": "jwd@virginia.edu",
   "nsf_id": "000349080",
   "pi_start_date": "2008-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Virginia Main Campus",
  "inst_street_address": "1001 EMMET ST N",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTESVILLE",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "4349244270",
  "inst_zip_code": "229034833",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "VA05",
  "org_lgl_bus_name": "RECTOR & VISITORS OF THE UNIVERSITY OF VIRGINIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJG6HU8PA4S5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Virginia Main Campus",
  "perf_str_addr": "1001 EMMET ST N",
  "perf_city_name": "CHARLOTTESVILLE",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "229034833",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "VA05",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "735200",
   "pgm_ele_name": "COMPUTING PROCESSES & ARTIFACT"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "794200",
   "pgm_ele_name": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 525000.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 15998.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 25000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><!--  /* Font Definitions */ @font-face \t{font-family:Calibri; \tpanose-1:2 15 5 2 2 2 4 3 2 4; \tmso-font-charset:0; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:-520092929 1073786111 9 0 415 0;}  /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal \t{mso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-parent:\"\"; \tmargin-top:0in; \tmargin-right:0in; \tmargin-bottom:10.0pt; \tmargin-left:0in; \tline-height:115%; \tmso-pagination:widow-orphan; \tfont-size:11.0pt; \tfont-family:Calibri; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:Calibri; \tmso-fareast-theme-font:minor-latin; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi;} p.MsoListParagraph, li.MsoListParagraph, div.MsoListParagraph \t{mso-style-priority:34; \tmso-style-unhide:no; \tmso-style-qformat:yes; \tmargin-top:0in; \tmargin-right:0in; \tmargin-bottom:10.0pt; \tmargin-left:.5in; \tmso-add-space:auto; \tline-height:115%; \tmso-pagination:widow-orphan; \tfont-size:11.0pt; \tfont-family:Calibri; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:Calibri; \tmso-fareast-theme-font:minor-latin; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi;} p.MsoListParagraphCxSpFirst, li.MsoListParagraphCxSpFirst, div.MsoListParagraphCxSpFirst \t{mso-style-priority:34; \tmso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-type:export-only; \tmargin-top:0in; \tmargin-right:0in; \tmargin-bottom:0in; \tmargin-left:.5in; \tmargin-bottom:.0001pt; \tmso-add-space:auto; \tline-height:115%; \tmso-pagination:widow-orphan; \tfont-size:11.0pt; \tfont-family:Calibri; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:Calibri; \tmso-fareast-theme-font:minor-latin; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi;} p.MsoListParagraphCxSpMiddle, li.MsoListParagraphCxSpMiddle, div.MsoListParagraphCxSpMiddle \t{mso-style-priority:34; \tmso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-type:export-only; \tmargin-top:0in; \tmargin-right:0in; \tmargin-bottom:0in; \tmargin-left:.5in; \tmargin-bottom:.0001pt; \tmso-add-space:auto; \tline-height:115%; \tmso-pagination:widow-orphan; \tfont-size:11.0pt; \tfont-family:Calibri; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:Calibri; \tmso-fareast-theme-font:minor-latin; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi;} p.MsoListParagraphCxSpLast, li.MsoListParagraphCxSpLast, div.MsoListParagraphCxSpLast \t{mso-style-priority:34; \tmso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-type:export-only; \tmargin-top:0in; \tmargin-right:0in; \tmargin-bottom:10.0pt; \tmargin-left:.5in; \tmso-add-space:auto; \tline-height:115%; \tmso-pagination:widow-orphan; \tfont-size:11.0pt; \tfont-family:Calibri; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:Calibri; \tmso-fareast-theme-font:minor-latin; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi;} .MsoChpDefault \t{mso-style-type:export-only; \tmso-default-props:yes; \tfont-size:11.0pt; \tmso-ansi-font-size:11.0pt; \tmso-bidi-font-size:11.0pt; \tfont-family:Calibri; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:Calibri; \tmso-fareast-theme-font:minor-latin; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi;} .MsoPapDefault \t{mso-style-type:export-only; \tmargin-bottom:10.0...",
  "por_txt_cntn": "\n\nWith chip multiprocessors (CMPs) comes the promise of high-performance computing on a desktop. CMPs impact the design, implementation and the way that high performance applications execute. These applications, which have become increasingly more complex, larger in scale, and handle huge data sets, can benefit greatly from CMPs. These applications are expected to use parallel systems with tens to several hundreds of nodes to handle their ever growing problem sizes. For example, simulating complex ocean circulation models requires exploiting significant parallelism. Similarly, emerging applications in biomedical computing, automated surgery, and data mining have inherent parallelism and CMPs can increase their performance by several factors. With the shift to CMPs, managing shared resources has become a critical issue in realizing their full potential. In this research, we focused on the contention for memory resources in a CMP.\n \nTo develop approaches to reduce shared resource contention for emerging multi-threaded applications, we studied how their performances are affected by contention for a particular shared resource. We developed a general methodology for characterizing multi-threaded applications by determining the effect of shared-resource contention on performance.  We characterized the applications using the PARSEC benchmark suite for shared-memory resource contention.  The characterization revealed several interesting aspects. Three of twelve PARSEC benchmarks exhibit no contention for cache resources. Nine exhibit contention for the L2-cache, with only three exhibiting contention among their own threads&ndash;most contention is because of competition with a co-runner. Interestingly, contention for the Front Side Bus is a major factor and degrades performance by more than 11%\n \nEffective resource and application management on CMPs requires consideration of user specific requirements and dynamic adaption of management decisions based on the actual run-time environment. However, designing an algorithm to manage resources and applications that can dynamically adapt based on the run-time environment is difficult because most resource and application management and monitoring facilities are only available at the OS level. We developed REEact, an infrastructure that provides the capability to specify user-level management policies with dynamic adaptation.  REEact is a virtual execution environment that provides a framework and core services to quickly enable the design of custom management policies for dynamically managing resources and applications.  We evaluated REEact on three case studies, each illustrating the use of REEact to apply a specific dynamic management policy on a real CMP. Through these case studies, we demonstrated that REEact can effectively and efficiently implement policies to dynamically manage resources and adapt application execution.\n \nPrevious research has shown that thread mapping is a powerful tool for resource management. However, the difficulty of simultaneously managing multiple hardware resources and the varying nature of the workloads has impeded the efficiency of thread mapping algorithms. We developed an in-depth analysis of PARSEC benchmarks running under different thread mappings to investigate the interaction of various thread mappings with microarchitectural resources, including L1 I/D-caches, I/D TLBs, L2 caches, hardware prefetchers, off-chip memory interconnects, branch predictors, memory disambiguation units and the cores. Our experiments show that when only memory resources are considered, thread mapping improves an application\u00c6s performance by as much as 14% over the default Linux scheduler. In contrast, when both memory and processor resources are considered the mapping algorithm achieves performance improvements by as much as 28%. \n \nWe also developed ReSense, the first run-time system that uses application characteristics to dynamically map multi-threaded applications from dy..."
 }
}