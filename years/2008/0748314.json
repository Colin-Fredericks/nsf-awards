{
 "awd_id": "0748314",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Perceptual and Neural Analysis of Biological Motion",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "alumit ishai",
 "awd_eff_date": "2008-09-15",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 511261.0,
 "awd_amount": 511261.0,
 "awd_min_amd_letter_date": "2008-09-18",
 "awd_max_amd_letter_date": "2011-08-22",
 "awd_abstract_narration": "Humans are remarkably adept at recognizing the actions of others, even based on movement patterns alone. This ability is most dramatically shown by \"point-light biological motion\" animations, in which just a few dots are visible, placed at joints or other critical places.  It is often easy to recognize which action is being performed, what the actor's emotional state is, and even who the person is. Although we know this information is available, little is known as to how it is perceived. This is particularly interesting because visual motion and form cues are assumed to be processed in parallel and independent streams, yet these two types of information have to be combined for point-light displays to be meaningful. Neuroimaging studies in humans have further linked biological motion perception to a regions of the brain called the superior temporal sulcus, which seems to be involved in many complex processes including social perception. With the support of the National Science Foundation, Dr. Emily Grossman at the University of California Irvine will investigate the perceptual means for the recognition of biological motion, and the brain systems involved. The perception tests will use a novel behavioral technique in which perceivers make yes/no decisions about biological motion animations viewed on a computer screen.  The brain work will use functional Magnetic Resonance Imaging (fMRI) to test specific hypotheses of the combination of form and motion cues in biological motion perception. These experiments will also measure the tuning properties of brain regions supporting biological motion perception, something that has already been achieved in monkeys but not yet in humans.\r\n\r\nTheories of biological motion draw from a number of scientific domains, including research in visual perception, social perception, action understanding and motor imitation (the \"mirror neuron\" system). Results from the present project will influence thinking in all of these domains. The work in this proposal also involves hands-on research experience for undergraduate and graduate students, including the design and analysis of neuroimaging studies. Because UC Irvine and Dr. Grossman's laboratory both have a historical record of recruiting an ethnically diverse student population, these projects provide the opportunity to promote science among under-represented minorities. Finally, as part of the pedagogical activities in this CAREER proposal, this project will support the development of a new Neuroimaging Laboratory course in which students are trained in the practical skills necessary for brain imaging data analysis, a skill highly desirable in the upcoming cohort of cognitive neuroscientists.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Emily",
   "pi_last_name": "Grossman",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Emily D Grossman",
   "pi_email_addr": "grossman@uci.edu",
   "nsf_id": "000269142",
   "pi_start_date": "2008-09-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Irvine",
  "inst_street_address": "160 ALDRICH HALL",
  "inst_street_address_2": "",
  "inst_city_name": "IRVINE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9498247295",
  "inst_zip_code": "926970001",
  "inst_country_name": "United States",
  "cong_dist_code": "47",
  "st_cong_dist_code": "CA47",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA IRVINE",
  "org_prnt_uei_num": "MJC5FCYQTPE6",
  "org_uei_num": "MJC5FCYQTPE6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Irvine",
  "perf_str_addr": "160 ALDRICH HALL",
  "perf_city_name": "IRVINE",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "926970001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "47",
  "perf_st_cong_dist": "CA47",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169900",
   "pgm_ele_name": "Cognitive Neuroscience"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "1699",
   "pgm_ref_txt": "COGNEURO"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "01S8",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "0100999999",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 400000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 111261.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Humans are remarkably adept at recognizing the actions of others, dramatically exemplified by &ldquo;point-light&rdquo; animations in which the hierarchical and pendular motions characteristic of human movement are portrayed by a handful of tokens (Johansson, 1973). Actions depicted in these sequences are interpreted quickly (in less than 200 msec) and without deliberate intent of the viewer. The perception of biological motion is linked to a number of brain areas, and most specifically to the posterior superior temporal sulcus (STS). The goal of this proposal was to identify the means by which motion and form cues combine to construct biological motion perception, and to identify how this is achieved in the neural machinery.</p>\n<p>The work under this proposal developed a new means by which to identify key features (space-time fragments) that observers use to analyze biological motion. This technique demonstrated a waxing and waning of sensitivity to body movements throughout natural action cycles, with peak sensitivity when local regions of the body experience high velocity and crossing (such as when the ankles or knees cross when viewing a person walking in profile). Subsequent findings demonstrated neural signals in the brain tuned to these features when individuals are searching for actions among visual clutter. We also demonstrated that the ability to integrate these local features into the global actor requires neural mechanisms outside of the traditional visual system (feature-based attention mechanisms).</p>\n<p>In a second set of experiments we examined the receptive field properties (as estimated from the aggegrated human fMRI BOLD response) of STS neurons that respond selectively to point-light biological motion. We found that STS neurons were highly tuned to specific actions, and that while a subpopulation of the STS required very specific viewing conditions, other subpopulations could generalize to changes in viewing conditions that would be associated with common everyday experiences (e.g. viewing a person walking from the left, versus walking directly in the line of sight). These results dovetail with findings from monkey single-unit recordings and suggest that the STS has all the right properties to build complex neural representations from simpler perceptual units.</p>\n<p>In a final set of experiments, we examine the link between visual perception of biological motion and other visual cues that are also used to interpret the intent of individuals (so-called &ldquo;theory of mind&rdquo;, or &ldquo;mentalizing&rdquo;). We found that biological motion perception (action recognition), face recognition and interpreting social vignettes all drive cortical activation in a core set of brain areas, with the STS being a key hub. Within the STS response, however, we were able to decouple patterns of activity that dissociated the different types of cues, indicating anatomically proximal distinct neural populations tuned to the different types of cues. We also found that the patterns of functional connectivity (communication between brain areas as measured in the fMRI response) of the STS to other far-ranging brain sites, particularly to the prefrontal cortex, reflected key differences in the tasks.</p>\n<p>The scientific and intellectual merit of these findings reflect on a number of literatures. Our findings that feature-based attention mechanisms operate on simple mid-level features provides a means by which models of action recognition can be built from empirically-validated basic units. The measurement of response tuning on the STS were the first if their kind in the human, and provide a nice homologue to measurements made in monkey. Msot of the theoretical models of biological motion perception are built from empirical evidence derived from monkey studies, and our results were among the first to apply the same approaches to the human STS.</p>\n<p>A second i...",
  "por_txt_cntn": "\nHumans are remarkably adept at recognizing the actions of others, dramatically exemplified by \"point-light\" animations in which the hierarchical and pendular motions characteristic of human movement are portrayed by a handful of tokens (Johansson, 1973). Actions depicted in these sequences are interpreted quickly (in less than 200 msec) and without deliberate intent of the viewer. The perception of biological motion is linked to a number of brain areas, and most specifically to the posterior superior temporal sulcus (STS). The goal of this proposal was to identify the means by which motion and form cues combine to construct biological motion perception, and to identify how this is achieved in the neural machinery.\n\nThe work under this proposal developed a new means by which to identify key features (space-time fragments) that observers use to analyze biological motion. This technique demonstrated a waxing and waning of sensitivity to body movements throughout natural action cycles, with peak sensitivity when local regions of the body experience high velocity and crossing (such as when the ankles or knees cross when viewing a person walking in profile). Subsequent findings demonstrated neural signals in the brain tuned to these features when individuals are searching for actions among visual clutter. We also demonstrated that the ability to integrate these local features into the global actor requires neural mechanisms outside of the traditional visual system (feature-based attention mechanisms).\n\nIn a second set of experiments we examined the receptive field properties (as estimated from the aggegrated human fMRI BOLD response) of STS neurons that respond selectively to point-light biological motion. We found that STS neurons were highly tuned to specific actions, and that while a subpopulation of the STS required very specific viewing conditions, other subpopulations could generalize to changes in viewing conditions that would be associated with common everyday experiences (e.g. viewing a person walking from the left, versus walking directly in the line of sight). These results dovetail with findings from monkey single-unit recordings and suggest that the STS has all the right properties to build complex neural representations from simpler perceptual units.\n\nIn a final set of experiments, we examine the link between visual perception of biological motion and other visual cues that are also used to interpret the intent of individuals (so-called \"theory of mind\", or \"mentalizing\"). We found that biological motion perception (action recognition), face recognition and interpreting social vignettes all drive cortical activation in a core set of brain areas, with the STS being a key hub. Within the STS response, however, we were able to decouple patterns of activity that dissociated the different types of cues, indicating anatomically proximal distinct neural populations tuned to the different types of cues. We also found that the patterns of functional connectivity (communication between brain areas as measured in the fMRI response) of the STS to other far-ranging brain sites, particularly to the prefrontal cortex, reflected key differences in the tasks.\n\nThe scientific and intellectual merit of these findings reflect on a number of literatures. Our findings that feature-based attention mechanisms operate on simple mid-level features provides a means by which models of action recognition can be built from empirically-validated basic units. The measurement of response tuning on the STS were the first if their kind in the human, and provide a nice homologue to measurements made in monkey. Msot of the theoretical models of biological motion perception are built from empirical evidence derived from monkey studies, and our results were among the first to apply the same approaches to the human STS.\n\nA second important intellectual merit of the proposal is the success that we have had linking our findings to previous reports in the pati..."
 }
}