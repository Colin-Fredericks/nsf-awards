{
 "awd_id": "0746117",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Intuitive Appearance Design",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2008-07-01",
 "awd_exp_date": "2014-06-30",
 "tot_intn_awd_amt": 399999.0,
 "awd_amount": 302693.0,
 "awd_min_amd_letter_date": "2008-01-08",
 "awd_max_amd_letter_date": "2013-12-12",
 "awd_abstract_narration": "CAREER: Intuitive Appearance Design\r\n\r\nF. Pellacini\r\n\r\nAbstract\r\n\r\nSynthetic images have reached considerable sophistication, to the point where we can render images indistinguishable from reality. Today the major limiting factor for a ubiquitous use of computer-generated images is the human labor and expertise required to create the shape, materials and lights of synthetic environments. This project is a combined research and education effort that brings us closer to making the creation the synthetic imagery accessible to all. The research component of this project simplifies the design of objects' appearance, which comes from the interaction of materials and lights, to complement recent advances in shape modeling and animation. The goal is to allow users, including novices, to design the appearance of complex scenes in just minutes. On the education side, the project explores the interaction between the conceptual, technical, and aesthetic principles of image synthesis through curriculum development and out-of-classroom experiences. \r\n\r\nMore specifically, the project investigates interfaces that allow designers to intuitively and effectively specify design goals on objects? appearance, algorithms that derive lights and materials parameters robustly from such goals, and representations of appearance that are effective to manipulate. These investigations allow designers to manipulate complex lighting and materials with intuitive user-interface metaphors and to transfer appearance from example images. Qualitative and quantitative user studies guide our investigation and serve as rigorous validation of our results. We focus on novice users, but expect our work to benefit experts as well. The resulting methods allow intuitive and fast modeling, while remaining consistent across all aspects of appearance design, from simple lighting and materials to complex environmental illumination and textured surfaces, in realistic and non-photorealistic renderings of static and dynamic scenes.\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Fabio",
   "pi_last_name": "Pellacini",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Fabio Pellacini",
   "pi_email_addr": "fabio@cs.dartmouth.edu",
   "nsf_id": "000148886",
   "pi_start_date": "2008-01-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Dartmouth College",
  "inst_street_address": "7 LEBANON ST",
  "inst_street_address_2": "",
  "inst_city_name": "HANOVER",
  "inst_state_code": "NH",
  "inst_state_name": "New Hampshire",
  "inst_phone_num": "6036463007",
  "inst_zip_code": "037552170",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NH02",
  "org_lgl_bus_name": "TRUSTEES OF DARTMOUTH COLLEGE",
  "org_prnt_uei_num": "T4MWFG59C6R3",
  "org_uei_num": "EB8ASJBCFER9"
 },
 "perf_inst": {
  "perf_inst_name": "Dartmouth College",
  "perf_str_addr": "7 LEBANON ST",
  "perf_city_name": "HANOVER",
  "perf_st_code": "NH",
  "perf_st_name": "New Hampshire",
  "perf_zip_code": "037552170",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NH02",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735200",
   "pgm_ele_name": "COMPUTING PROCESSES & ARTIFACT"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 59602.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 59254.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 90152.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 93663.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 21.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The use of synthetic images is ubiquitous for many applications, from engineering to fine arts, but it is often limited by the human labor and expertise required to create synthetic environments. The goal of this project was to investigate methods that simplify the design of objects' appearance, which comes from the interaction of surface materials and scene lighting, through the development of interactive rendering algorithms and intuitive appearance design interfaces.</p>\n<p>&nbsp;The first main finding of our work is that novices can perform appearance design tasks without necessary training, if supported by the user interface. This dispels an old believe in the graphics and design communities that only trained artists can effectively perform design tasks.</p>\n<p>&nbsp;The fundamental concept that we have introduced is that the most effective paradigm to edit complex natural materials and illumination is a select-and-modify formulation where selection is the most crucial part and should be supported well by the interface. This is not trivial since in 3D graphics and with natural appearance data, selection boils down to solving complex non-linear optimization problems that are computationally intensive to solve and hard to model precisely. Nonetheless, this project has shown that this is not only possible, but that very effective solution can be developed.</p>\n<p>&nbsp;We have validated this idea by introducing a new user study methodology geared toward measuring design tasks with statistical certainty. Our methodology works by performing both matching tasks, to measure the accuracy and speed that artists have when performing simple tasks, and open tasks, to measure the ability of artists to explore the design space.</p>\n<p>&nbsp;Through the project we also found the need to provide interactive feedback to artists, without which some editing tasks cannot be performed efficiently. To do so, we have introduce new computational methods for complex appearance.</p>\n<p>&nbsp;The second main finding of our work is that the combination of interactive rendering algorithms and accurate selection for complex appearance lets artists work well with direct interface rather than using indirect algorithms that match final appearance by optimization.</p>\n<p>&nbsp;This work supported in this grant has been published in main conferences and journal in our field and has seen some use in industry. We believe that the main applications that will benefit from our work are the entertainment and design industries. This funding for this project have partially supported three PhD students, all of which have started successful careers in the movie industry and academia.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/02/2016<br>\n\t\t\t\t\tModified by: Fabio&nbsp;Pellacini</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe use of synthetic images is ubiquitous for many applications, from engineering to fine arts, but it is often limited by the human labor and expertise required to create synthetic environments. The goal of this project was to investigate methods that simplify the design of objects' appearance, which comes from the interaction of surface materials and scene lighting, through the development of interactive rendering algorithms and intuitive appearance design interfaces.\n\n The first main finding of our work is that novices can perform appearance design tasks without necessary training, if supported by the user interface. This dispels an old believe in the graphics and design communities that only trained artists can effectively perform design tasks.\n\n The fundamental concept that we have introduced is that the most effective paradigm to edit complex natural materials and illumination is a select-and-modify formulation where selection is the most crucial part and should be supported well by the interface. This is not trivial since in 3D graphics and with natural appearance data, selection boils down to solving complex non-linear optimization problems that are computationally intensive to solve and hard to model precisely. Nonetheless, this project has shown that this is not only possible, but that very effective solution can be developed.\n\n We have validated this idea by introducing a new user study methodology geared toward measuring design tasks with statistical certainty. Our methodology works by performing both matching tasks, to measure the accuracy and speed that artists have when performing simple tasks, and open tasks, to measure the ability of artists to explore the design space.\n\n Through the project we also found the need to provide interactive feedback to artists, without which some editing tasks cannot be performed efficiently. To do so, we have introduce new computational methods for complex appearance.\n\n The second main finding of our work is that the combination of interactive rendering algorithms and accurate selection for complex appearance lets artists work well with direct interface rather than using indirect algorithms that match final appearance by optimization.\n\n This work supported in this grant has been published in main conferences and journal in our field and has seen some use in industry. We believe that the main applications that will benefit from our work are the entertainment and design industries. This funding for this project have partially supported three PhD students, all of which have started successful careers in the movie industry and academia.\n\n\t\t\t\t\tLast Modified: 03/02/2016\n\n\t\t\t\t\tSubmitted by: Fabio Pellacini"
 }
}