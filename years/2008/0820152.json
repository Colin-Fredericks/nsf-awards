{
 "awd_id": "0820152",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SRS: A Decentralized and Rule-Based Approach to Data Dependency Analysis and Failure Recovery in Service-Oriented Environments",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2008-06-15",
 "awd_exp_date": "2012-05-31",
 "tot_intn_awd_amt": 328331.0,
 "awd_amount": 354581.0,
 "awd_min_amd_letter_date": "2008-06-06",
 "awd_max_amd_letter_date": "2010-07-13",
 "awd_abstract_narration": "NSF Proposal 0820152\r\n\r\nA Decentralized and Rule-Based Approach to Data Dependency Analysis and Failure Recovery in a Service-Oriented Environment\r\n\r\nPI: Susan D. Urban    \r\n \r\nThe objective of this research is to develop a decentralized approach to data dependency analysis and failure recovery among concurrently executing processes in a loosely-coupled service-oriented environment. The approach involves monitoring externalized data changes of individual service executions. Peer-to-peer, decentralized communication among process execution agents is then used to discover data dependencies among concurrently executing processes that may lead to data inconsistencies during the recovery of a failed process. Process interference rules of dependent processes are used to test user-defined semantic conditions to determine if 1) critical data conditions have been affected by the recovery of a failed process and 2) recovery procedures should be invoked for dependent processes. The research includes the development of a methodology for using process interference rules.  The correctness and efficiency of decentralized data dependency analysis and rule-based recovery procedures are also demonstrated for concurrent processes in the context of a service composition model that supports compensation, contingency, rollback, and retry techniques. This research provides a new way of thinking about traditional transaction recoverability concepts, providing a dynamic approach to discovering data dependencies and responding to failures in a manner that guarantees user-defined correctness conditions for concurrent processes that execute without isolation guarantees.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Susan",
   "pi_last_name": "Urban",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Susan D Urban",
   "pi_email_addr": "susan.urban@ttu.edu",
   "nsf_id": "000358633",
   "pi_start_date": "2008-06-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas Tech University",
  "inst_street_address": "2500 BROADWAY",
  "inst_street_address_2": "",
  "inst_city_name": "LUBBOCK",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "8067423884",
  "inst_zip_code": "79409",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "TX19",
  "org_lgl_bus_name": "TEXAS TECH UNIVERSITY SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "EGLKRQ5JBCZ7"
 },
 "perf_inst": {
  "perf_inst_name": "Texas Tech University",
  "perf_str_addr": "2500 BROADWAY",
  "perf_city_name": "LUBBOCK",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "79409",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "TX19",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735200",
   "pgm_ele_name": "COMPUTING PROCESSES & ARTIFACT"
  },
  {
   "pgm_ele_code": "772400",
   "pgm_ele_name": "SOFTWARE FOR REAL-WORLD SYSTMS"
  },
  {
   "pgm_ele_code": "794400",
   "pgm_ele_name": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7724",
   "pgm_ref_txt": "SOFTWARE FOR REAL-WORLD SYSTMS"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "app-0108",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 339581.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 15000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The advent of Web Services and Service-Oriented Computing has significantly changed software development practices and data access patterns for distributed computing environments, creating the ability to develop processes that are composed of distributed service executions. Service-oriented computing, however, also poses new challenges for software design and execution environments, especially with respect to failure recovery and semantic correctness in the context of concurrent process execution. Our research is innovative in that we provide a new paradigm for service execution that supports the dynamic discovery of data dependencies, with rule-based techniques for testing user-defined semantic conditions for correct execution.</p>\n<p>In particular, this research has extended an abstract execution model for establishing user-defined correctness and recovery in a service composition environment. The service composition model defines a hierarchical service composition structure, where a service is composed of atomic and/or composite groups. The model provides multi-level protection against service execution failure by using compensation and contingency at different composition granularity levels. The model is enhanced with the concept of assurance points (APS), integration rules, invariant rules, and application exception rules. APs serve as logical and physical checkpoints for user-defined consistency checking, invoking integration rules that check pre and post conditions at different points in the execution process. Invariants provide a stronger way of monitoring constraints and guaranteeing that a condition holds for a specific duration of execution as defined by starting and ending assurance points. Application exception rules extend integration rules with a case-based structure that is used to respond variably to events and exceptions that interrupt the execution of a process, allowing a process to determine recovery actions depending on the state of the process execution. A unique aspect of APs is that they provide intermediate rollback points when failures occur, thus allowing a process to be compensated to a specific AP for the purpose of rechecking pre-conditions before retry attempts. APs also support a dynamic backward recovery process, known as cascaded contingency, for hierarchically nested processes in an attempt to recover to a previous AP that can be used to invoke contingent procedures or alternate execution paths for failure of a nested process. As a result, the assurance point approach provides flexibility with respect to the combined use of backward and forward recovery options. Figure 1 illustrates the use of APs, integration rules, invariant rules, and application exception rules for process P1.</p>\n<p>This research also involved the investigation of decentralized data dependency analysis in support of process recovery procedures. In processes composed of Web Services, interleaved access to data between service executions of concurrent processes can potentially cause data inconsistency problems. If a process fails, data items modified by the recovery of a failed process may affect other processes that are concurrently executing and have accessed the same data items. The results of this research present a decentralized approach to analyzing data dependencies among concurrently executing processes in a service-oriented environment. The decentralized approach is an extension of past research with Delta-Enabled Grid Services (DEGS), which provides a technique for analyzing data changes capture from service execution to determine process dependencies. Process Execution Agents (PEXAs) have been defined that control the execution of processes and maintain local information about data changes. Process execution histories are then enhanced with control information that allows the construction of data dependency graphs to be distributed among multiple PE...",
  "por_txt_cntn": "\nThe advent of Web Services and Service-Oriented Computing has significantly changed software development practices and data access patterns for distributed computing environments, creating the ability to develop processes that are composed of distributed service executions. Service-oriented computing, however, also poses new challenges for software design and execution environments, especially with respect to failure recovery and semantic correctness in the context of concurrent process execution. Our research is innovative in that we provide a new paradigm for service execution that supports the dynamic discovery of data dependencies, with rule-based techniques for testing user-defined semantic conditions for correct execution.\n\nIn particular, this research has extended an abstract execution model for establishing user-defined correctness and recovery in a service composition environment. The service composition model defines a hierarchical service composition structure, where a service is composed of atomic and/or composite groups. The model provides multi-level protection against service execution failure by using compensation and contingency at different composition granularity levels. The model is enhanced with the concept of assurance points (APS), integration rules, invariant rules, and application exception rules. APs serve as logical and physical checkpoints for user-defined consistency checking, invoking integration rules that check pre and post conditions at different points in the execution process. Invariants provide a stronger way of monitoring constraints and guaranteeing that a condition holds for a specific duration of execution as defined by starting and ending assurance points. Application exception rules extend integration rules with a case-based structure that is used to respond variably to events and exceptions that interrupt the execution of a process, allowing a process to determine recovery actions depending on the state of the process execution. A unique aspect of APs is that they provide intermediate rollback points when failures occur, thus allowing a process to be compensated to a specific AP for the purpose of rechecking pre-conditions before retry attempts. APs also support a dynamic backward recovery process, known as cascaded contingency, for hierarchically nested processes in an attempt to recover to a previous AP that can be used to invoke contingent procedures or alternate execution paths for failure of a nested process. As a result, the assurance point approach provides flexibility with respect to the combined use of backward and forward recovery options. Figure 1 illustrates the use of APs, integration rules, invariant rules, and application exception rules for process P1.\n\nThis research also involved the investigation of decentralized data dependency analysis in support of process recovery procedures. In processes composed of Web Services, interleaved access to data between service executions of concurrent processes can potentially cause data inconsistency problems. If a process fails, data items modified by the recovery of a failed process may affect other processes that are concurrently executing and have accessed the same data items. The results of this research present a decentralized approach to analyzing data dependencies among concurrently executing processes in a service-oriented environment. The decentralized approach is an extension of past research with Delta-Enabled Grid Services (DEGS), which provides a technique for analyzing data changes capture from service execution to determine process dependencies. Process Execution Agents (PEXAs) have been defined that control the execution of processes and maintain local information about data changes. Process execution histories are then enhanced with control information that allows the construction of data dependency graphs to be distributed among multiple PEXAs by sharing data dependency information. Research results include the f..."
 }
}