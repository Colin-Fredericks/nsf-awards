{
 "awd_id": "0812307",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III-COR-Small: Developing Novel Mosaic Generation Methods for Object-Based Multimedia Information Systems",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2008-10-01",
 "awd_exp_date": "2012-09-30",
 "tot_intn_awd_amt": 189441.0,
 "awd_amount": 205441.0,
 "awd_min_amd_letter_date": "2008-08-16",
 "awd_max_amd_letter_date": "2012-05-04",
 "awd_abstract_narration": "This project provides solutions to one of the important components of an interactive, object-based, semantic multimedia information retrieval system: \"mosaic\" generation.  A mosaic can be considered as a static component (or background) of a scene that does not change over a sequence of frames and is obtained by computing the global motion between frames, warping according to the global motion, and then blending the frames.  Mosaic generation plays an important role in many applications including object-based coding  (where objects in a scene are also coded or compressed independent of regular rectangular frame coding), video compression, video indexing, object tracking, virtual environments, security surveillance, wide-area surveillance, panoramic video, traffic monitoring, object recognition, and human behavior analysis  since these applications usually require the subtraction of actual scenes from the background (or the mosaic) to determine the foreground objects. Since traditional mosaic generation methods require object segmentation for videos containing moving objects, they are not suitable for real-time mosaic generation and especially for video encoders that require sprite coding (coding based on layering objects on top of a mosaic or a sprite). This project (i) develops mosaic generation solutions for larger domains of videos; (ii) generates mosaics for videos containing many shots by classifying video shots; and  (iii) develops objective evaluation methods for mosaic generation  by producing ground-truths. Sprite fusion method blends assertive and conservative sprites that are generated using the aligned frame differences without object segmentation thus eliminating the object occlusion problem especially for videos where the camera tracks an object. Since the sprite fusion method computes the global motion once for a pair of frames and does not require object segmentation, it suits well for real-time mosaic generation or sprite coding for video encoders. As the mosaic is constructed for a sequence, the global motion vectors are stored to be able to generate (or warp) any frame with respect to another frame thus allowing to provide multiple degrees-of-freedom for spatial interactions including up-down, left-right, move forward-backward, and rotation. The multiple degrees-of-freedom with the warping of the current (or active) scene forms the basis of interactive video reproduction by regenerating any frame from the mosaic and then overlaying the active (current scene) on top of the reproduced frame.  \r\n\r\nThe educational component of this project includes development of a new course on multimedia that appeals to any freshman students in order to grow interest in computer science. This course covers fundamental concepts in computer science including types of media, color models, storage devices, multimedia authoring, and internet. A multimedia workshop is planned for K-12 students.  The results of this research project will be disseminated via Internet (http://www.cs.uah.edu/~raygun/projects/mosaics.htm), including a video database system (video sets and any truth annotation for it) to share test data with other researchers and to encourage open metrics-based evaluations across research institutions. This project will foster the development of photo-realistic visualization systems using interactive video reproduction, with a wide range of applications.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ramazan",
   "pi_last_name": "Aygun",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ramazan Aygun",
   "pi_email_addr": "raygun@kennesaw.edu",
   "nsf_id": "000148908",
   "pi_start_date": "2008-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Alabama in Huntsville",
  "inst_street_address": "301 SPARKMAN DR NW",
  "inst_street_address_2": "",
  "inst_city_name": "HUNTSVILLE",
  "inst_state_code": "AL",
  "inst_state_name": "Alabama",
  "inst_phone_num": "2568242657",
  "inst_zip_code": "358051911",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "AL05",
  "org_lgl_bus_name": "THE UNIVERSITY OF ALABAMA IN HUNTSVILLE",
  "org_prnt_uei_num": "",
  "org_uei_num": "HB6KNGVNJRU1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Alabama in Huntsville",
  "perf_str_addr": "301 SPARKMAN DR NW",
  "perf_city_name": "HUNTSVILLE",
  "perf_st_code": "AL",
  "perf_st_name": "Alabama",
  "perf_zip_code": "358051911",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "AL05",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 189441.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Mosaic generation is the process of generating a static component (or background) of a scene that does not change in a video by computing the displacement (or camera motion in general) between images of video, aligning images on top of each other according to the camera motion, and then blending these images to get the big picture of the static scene or object. Mosaic generation plays an important role in many applications including object-based compression (where objects in a scene are also coded or compressed independent of regular rectangular image coding), video compression, video indexing, object tracking, virtual environments, security surveillance, wide-area surveillance, panoramic video, traffic monitoring, object recognition, and human behavior analysis since these applications usually require the subtraction of actual scenes from the background (or the mosaic) to determine the foreground objects.</p>\n<p><br />In this project, we developed a video classification method by extracting features based on presence of moving objects and global motion (or camera motion in general) in the video. This classification helps to determine the suitability of video for mosaic generation. Hence, this helps for real or commercial systems to determine whether the video is suitable for mosaic generation or not.</p>\n<p><br />Past research worked on a small set of videos to demonstrate on how mosaic generation algorithms worked. However, providing results on a few videos does not indicate that proposed algorithms work on other videos. In this research, the videos are categorized into domains so that research in mosaic generation targets video domains rather than a small set of videos.</p>\n<p>One major problem in mosaic generation is the presence of moving objects that should be removed from the mosaic. We proposed &ldquo;sprite fusion&rdquo; method by merging two types of mosaics that are called as &ldquo;assertive&rdquo; and &ldquo;conservative&rdquo;. Sprite fusion is a blending method for mosaic generation that targets tracking videos and do not require identification or segmentation of moving objects to generate the mosaic. Moving object segmentation is fairly complex and limits the deployment of mosaic generation in commercial systems. Sprite fusion is not affected by the slow motion, visual static pattern, occlusion, size, or the number of moving objects. Sprite fusion deals tracking videos where moving objects are tried to be maintained in the center of video. We provide a formal proof that sprite fusion provides good results for this domain of videos (not just a few videos).</p>\n<p>It is hard to assess the quality and correctness of a mosaic. In the past, an expert checks the correctness of the mosaic subjectively, and an objective measure (i.e., Peak-Signal-To-Noise-Ratio (PSNR)) is used to quantify the correctness. To overcome the limitations of this objective measure, we proposed &ldquo;synthetic video generation&rdquo; from a high-resolution image by applying camera motion patterns. Since the video is generated by predetermined camera motion patterns, the correct motion and the correct mosaic are stored and used to validate the results of a mosaic generation algorithm. Synthetic videos can also identify the parts of a video that a mosaic generation algorithm fails or identify its weaknesses with respect to camera motion patterns.</p>\n<p>We have developed a video database that is available to researchers in mosaic generation area. The video database contains original videos and synthetic videos for researchers to test and compare their results.</p>\n<p>We have developed three types of applications: video reproduction, interactive retrieval, and virtual tour. Video reproduction provides video editing such as object centralization and aspect ratio conversion (4:3 -&gt; 16:9) using mosaics. Interactive retrieval provides retrieval of spatio-temporal content of video usi...",
  "por_txt_cntn": "\nMosaic generation is the process of generating a static component (or background) of a scene that does not change in a video by computing the displacement (or camera motion in general) between images of video, aligning images on top of each other according to the camera motion, and then blending these images to get the big picture of the static scene or object. Mosaic generation plays an important role in many applications including object-based compression (where objects in a scene are also coded or compressed independent of regular rectangular image coding), video compression, video indexing, object tracking, virtual environments, security surveillance, wide-area surveillance, panoramic video, traffic monitoring, object recognition, and human behavior analysis since these applications usually require the subtraction of actual scenes from the background (or the mosaic) to determine the foreground objects.\n\n\nIn this project, we developed a video classification method by extracting features based on presence of moving objects and global motion (or camera motion in general) in the video. This classification helps to determine the suitability of video for mosaic generation. Hence, this helps for real or commercial systems to determine whether the video is suitable for mosaic generation or not.\n\n\nPast research worked on a small set of videos to demonstrate on how mosaic generation algorithms worked. However, providing results on a few videos does not indicate that proposed algorithms work on other videos. In this research, the videos are categorized into domains so that research in mosaic generation targets video domains rather than a small set of videos.\n\nOne major problem in mosaic generation is the presence of moving objects that should be removed from the mosaic. We proposed \"sprite fusion\" method by merging two types of mosaics that are called as \"assertive\" and \"conservative\". Sprite fusion is a blending method for mosaic generation that targets tracking videos and do not require identification or segmentation of moving objects to generate the mosaic. Moving object segmentation is fairly complex and limits the deployment of mosaic generation in commercial systems. Sprite fusion is not affected by the slow motion, visual static pattern, occlusion, size, or the number of moving objects. Sprite fusion deals tracking videos where moving objects are tried to be maintained in the center of video. We provide a formal proof that sprite fusion provides good results for this domain of videos (not just a few videos).\n\nIt is hard to assess the quality and correctness of a mosaic. In the past, an expert checks the correctness of the mosaic subjectively, and an objective measure (i.e., Peak-Signal-To-Noise-Ratio (PSNR)) is used to quantify the correctness. To overcome the limitations of this objective measure, we proposed \"synthetic video generation\" from a high-resolution image by applying camera motion patterns. Since the video is generated by predetermined camera motion patterns, the correct motion and the correct mosaic are stored and used to validate the results of a mosaic generation algorithm. Synthetic videos can also identify the parts of a video that a mosaic generation algorithm fails or identify its weaknesses with respect to camera motion patterns.\n\nWe have developed a video database that is available to researchers in mosaic generation area. The video database contains original videos and synthetic videos for researchers to test and compare their results.\n\nWe have developed three types of applications: video reproduction, interactive retrieval, and virtual tour. Video reproduction provides video editing such as object centralization and aspect ratio conversion (4:3 -&gt; 16:9) using mosaics. Interactive retrieval provides retrieval of spatio-temporal content of video using gamepad. Virtual tour enables photo-realistic virtual tour of an environment with actions such as \"open the door\".\n\nWe have organized two workshops: acad..."
 }
}