{
 "awd_id": "0711186",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Collaborative Research: Foreign accent conversion through articulatory inversion of the vocal-tract frontal cavity",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2008-08-01",
 "awd_exp_date": "2012-07-31",
 "tot_intn_awd_amt": 220000.0,
 "awd_amount": 220000.0,
 "awd_min_amd_letter_date": "2008-07-31",
 "awd_max_amd_letter_date": "2010-07-27",
 "awd_abstract_narration": "The ability to transform a ?foreign? accented voice into its ?native? counterpart could be an invaluable tool in pronunciation training for second-language learners. This requires separating those aspects of the speech signal that are determined by the anatomy of the vocal tract from those that result from the idiosyncratic way in which the speaker controls it. While these two sources interact in complex ways in the acoustic domain, a few studies indicate that they may be decoupled in the articulatory space, specifically in the vocal tract frontal cavity. \r\n\r\nThe objective of this research is to determine the extent to which foreign-accent conversion can be performed through articulatory inversion of the frontal cavity. For this purpose, two complementary problems are being investigated. First, existing articulatory datasets are being used to develop a foreign-accent conversion model that operates in the frontal cavity domain. Second, articulatory inversion models are being developed to estimate the frontal cavity configuration from speech acoustics. Results from these models are being systematically validated through perceptual tests of foreign-accentedness, speaker identity and acoustic quality. \r\n\r\nEnglish is a second language for a significant percentage of the workforce in the United States. Reduction of foreign accent becomes increasingly difficult beyond the ?critical period? of language learning, but substantial improvements in pronunciation do occur for adult second-language learners. This work will stimulate the development of new technology to facilitate such improvements. Its results may also find application for film dubbing/looping, as well as in speech technology at large (e.g., feature extraction, data compression).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Miguel",
   "pi_last_name": "Carreira-Perpinan",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Miguel A Carreira-Perpinan",
   "pi_email_addr": "mcarreira-perpinan@ucmerced.edu",
   "nsf_id": "000233489",
   "pi_start_date": "2008-07-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California - Merced",
  "inst_street_address": "5200 N LAKE RD",
  "inst_street_address_2": "",
  "inst_city_name": "MERCED",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2092012039",
  "inst_zip_code": "953435001",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "CA13",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, MERCED",
  "org_prnt_uei_num": "",
  "org_uei_num": "FFM7VPAG8P92"
 },
 "perf_inst": {
  "perf_inst_name": "University of California - Merced",
  "perf_str_addr": "5200 N LAKE RD",
  "perf_city_name": "MERCED",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "953435001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "CA13",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 77231.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 77617.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 65152.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Foreign accent conversion is the problem of transforming English speech produced by a speaker with a foreign accent into English speech with a native English accent. The goal of this NSF-funded project is the development of accent conversion algorithms that work at a fundamental level, closer to the mechanism of speech production: they transform a sequence of vocal tract shapes of a foreign speaker into a sequence of vocal tract shapes of a native speaker, rather than transforming their acoustic utterances directly. This project was a collaboration with Prof. Ricardo Gutierrez-Osuna (Texas A&amp;M University). The research at UC Merced, carried out by Prof. Miguel A. Carreira-Perpinan, focused on models of the vocal tract, specifically the tongue shape, constructed using statistical machine learning techniques. A major result was the quick adaptation to new speakers of an existing tongue-shape model.<br /><br />Imagine we collect a few (say, 10) snapshots of the shape of your tongue, for example using an ultrasound probe as available in doctors' offices. Is it possible to reconstruct realistically the complex shapes that your tongue assumes during continuous speech? It turns out it is possible. The idea consists of first constructing a detailed predictive model of the tongue shape for a reference speaker, and then adapting this detailed model to the new speaker (you) based on those few snapshots. Firstly, we have shown that, given a large dataset of thousands of tongue shapes from a given speaker, one can reconstruct tongue shapes for that same speaker during continuous speech using a machine learning algorithm. The algorithm is able to reconstruct the entire midsagittal tongue contour from the locations of just 3 or 4 points on it with submillimetric accuracy. Second, we have developed another machine learning algorithm that is able to adapt the detailed tongue shape model created for one speaker to a new speaker <em>based only on a few contours recorded from the latter</em>. The adaptation algorithm takes only a few seconds of computing time, and the accuracy for the new speaker remains submillimetric and almost as good as for the original speaker. Crucially, adapting the model requires only a small number of tongue contours for the new speaker, and this affords easy, fast adaptation---creating a reconstruction model from scratch requires recording, segmenting and labeling (in a semi-automatic procedure) thousands of ultrasound images. Further, the algorithm also works even if portions of the tongue contours are missing (as is often the case with ultrasound imaging). The algorithm should also with 3D shapes (surfaces rather than contours) and with shapes of the entire vocal tract rather than just the tongue. It opens the door to the quick creation and adaptation of realistic vocal tract models for different people and for different languages. The ultrasound data was recorded using ultrasound imaging by the PI's collaborators at Queen Margaret University and the University of Edinburgh, UK, and is available for free from the PI, as well as Matlab implementations for most of the algorithms resulting from this research.<br /><br />Applications of this work include the creation and adaptation of articulatory speech models for foreign accent conversion, which itself can be used to improve pronunciation training tools for non-native speakers, as well as for entertainment (e.g. film dubbing or voice morphing). Other important applications of this work are the synthesis of computer speech from tongue shapes, and its inverse problem, the recovery of the tongue shape from recorded speech alone; as well as the study of low-dimensional models of the tongue. Being able to recover the tongue shape from the speech means we can reveal the intricate dynamics that speech production organs have for specific sounds during continuous speech, with applications to phonetics, language l...",
  "por_txt_cntn": "\nForeign accent conversion is the problem of transforming English speech produced by a speaker with a foreign accent into English speech with a native English accent. The goal of this NSF-funded project is the development of accent conversion algorithms that work at a fundamental level, closer to the mechanism of speech production: they transform a sequence of vocal tract shapes of a foreign speaker into a sequence of vocal tract shapes of a native speaker, rather than transforming their acoustic utterances directly. This project was a collaboration with Prof. Ricardo Gutierrez-Osuna (Texas A&amp;M University). The research at UC Merced, carried out by Prof. Miguel A. Carreira-Perpinan, focused on models of the vocal tract, specifically the tongue shape, constructed using statistical machine learning techniques. A major result was the quick adaptation to new speakers of an existing tongue-shape model.\n\nImagine we collect a few (say, 10) snapshots of the shape of your tongue, for example using an ultrasound probe as available in doctors' offices. Is it possible to reconstruct realistically the complex shapes that your tongue assumes during continuous speech? It turns out it is possible. The idea consists of first constructing a detailed predictive model of the tongue shape for a reference speaker, and then adapting this detailed model to the new speaker (you) based on those few snapshots. Firstly, we have shown that, given a large dataset of thousands of tongue shapes from a given speaker, one can reconstruct tongue shapes for that same speaker during continuous speech using a machine learning algorithm. The algorithm is able to reconstruct the entire midsagittal tongue contour from the locations of just 3 or 4 points on it with submillimetric accuracy. Second, we have developed another machine learning algorithm that is able to adapt the detailed tongue shape model created for one speaker to a new speaker based only on a few contours recorded from the latter. The adaptation algorithm takes only a few seconds of computing time, and the accuracy for the new speaker remains submillimetric and almost as good as for the original speaker. Crucially, adapting the model requires only a small number of tongue contours for the new speaker, and this affords easy, fast adaptation---creating a reconstruction model from scratch requires recording, segmenting and labeling (in a semi-automatic procedure) thousands of ultrasound images. Further, the algorithm also works even if portions of the tongue contours are missing (as is often the case with ultrasound imaging). The algorithm should also with 3D shapes (surfaces rather than contours) and with shapes of the entire vocal tract rather than just the tongue. It opens the door to the quick creation and adaptation of realistic vocal tract models for different people and for different languages. The ultrasound data was recorded using ultrasound imaging by the PI's collaborators at Queen Margaret University and the University of Edinburgh, UK, and is available for free from the PI, as well as Matlab implementations for most of the algorithms resulting from this research.\n\nApplications of this work include the creation and adaptation of articulatory speech models for foreign accent conversion, which itself can be used to improve pronunciation training tools for non-native speakers, as well as for entertainment (e.g. film dubbing or voice morphing). Other important applications of this work are the synthesis of computer speech from tongue shapes, and its inverse problem, the recovery of the tongue shape from recorded speech alone; as well as the study of low-dimensional models of the tongue. Being able to recover the tongue shape from the speech means we can reveal the intricate dynamics that speech production organs have for specific sounds during continuous speech, with applications to phonetics, language learning, and speech therapy, among others. Being able to synthesize speech, and to transfor..."
 }
}