{
 "awd_id": "0757557",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Pilot: Let Your Notes Come Alive: The SkRUI  Classroom Sketchbook",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2008-06-01",
 "awd_exp_date": "2011-05-31",
 "tot_intn_awd_amt": 0.0,
 "awd_amount": 247000.0,
 "awd_min_amd_letter_date": "2008-04-14",
 "awd_max_amd_letter_date": "2010-05-27",
 "awd_abstract_narration": "This project develops a creativity enhancing tool for innovative education by building an electronic laboratory notebook application for a tablet PC in which students can combine graphical and handwritten notes in electronic form.  The graphical diagrams are understood by sketch recognition systems built by the students and their teachers.   Students take their electronic laboratory notebooks from class to class; the application studies the user's context to determine the most likely domain in which the student is drawing.  This new model of active visualization will increase students' understanding of the graphical material.  This tool allows students to draw free-hand drawings, just as they would on paper into a tablet PC, that are automatically recognized by the computer using sketch recognition system that provides simulation, feedback, and search capabilities.  The tool will be evaluated by observation and interview to determine if the students are more creative when using the sketching tool. This work will aid the learning process through a new visualization model for real-time simulation of the students' hand-drawn sketches, ultimately being used to teach students at all levels from kindergarten to graduate students.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tracy",
   "pi_last_name": "Hammond",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Tracy A Hammond",
   "pi_email_addr": "hammond@tamu.edu",
   "nsf_id": "000118785",
   "pi_start_date": "2008-04-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Donald",
   "pi_last_name": "Maxwell",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Donald A Maxwell",
   "pi_email_addr": "dmaxwell@civil.tamu.edu",
   "nsf_id": "000370232",
   "pi_start_date": "2008-04-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M Engineering Experiment Station",
  "perf_str_addr": "3124 TAMU",
  "perf_city_name": "COLLEGE STATION",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433124",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "778800",
   "pgm_ele_name": "CreativeIT"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7655",
   "pgm_ref_txt": "ITR-CreativeIT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 200000.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 31000.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>If one wanders through a university, high school, middle school, elementary school, and even pre-school, one will certainly notice a plethora of teachers and students sketching graphical diagrams on the board or in their notebooks. Sketches are used throughout the educational process; one can think an endless list of topics which are taught through the use of graphical diagrams: geometry, supply chain graphs, evolutionary models, finite state machines, mechanical engineering diagrams, electrical circuit diagrams, physics diagrams, chemical symbols and reactions, flow charts, UML diagrams to design software, musical notation, tree data structures, graphs, &hellip;we can go on an on. But these hand-sketches remain static and uninterpreted. CAD systems exist to animate and correct diagrams, but their mouse-and-palette interfaces have to be learned, not only taking valuable time away from the subject material, but also diverts the student away from his or her creative impulses.&nbsp; An additional issue is the time delay between a student&rsquo;s completion of hand-drawn homework and the receipt of graded feedback.</p>\n<p>&nbsp;</p>\n<p>A sketch-based system allows students to interact with a computer with the same creative freedom as they would on paper, removing the need to &lsquo;teach the tool&rsquo; and improving students&rsquo; spatial cognition skills and manual dexterity, while providing immediate feedback. It seems counter-productive to have to spend precious time learning how to use the system before focusing on learning the actual course material. Sketched-based homework problems allow students to actually <strong>create </strong>the answer to a problem rather than simply <strong>identify </strong>the answer, as in traditional Scantron or standard computerized multiple-choice questions. Such systems are not designed as a teacher replacement but rather as a supplementary tutoring system, providing additional human-like feedback, where they otherwise would get none. The computer is not responsible for teaching actual processes; instead it serves to monitor students' performance on homework problems, correct misunderstandings, and assist in grading assignments.</p>\n<p>&nbsp;</p>\n<p>Through the resources provided by this project, we have created multiple artificial intelligence algorithms to improve the recognition of hand-sketches, including low-level primitive stroke recognizers, multi-stroke recognizers, corner finding algorithms, high level algorithms that allow for interspersed free-form sketching, perception-based constraint recognizers, a language to facilitate the develop of domain specific sketch applications, and a domain-independent algorithm that automatically distinguishes text versus shape within a diagram. In order to further the field of sketch recognition in general, we have also created a public data collection tool and implemented an international sketch recognition accuracy contest to encourage other researchers to collect and share data. To improve interaction with a sketch tool we have developed multiple improved interaction methods including improved editing techniques.</p>\n<p>&nbsp;</p>\n<p>Using our algorithms, we have developed a number of domain-specific sketch recognition educational applications that teach Chinese characters, MPS1 characters, Japanese, Urdu, Biology cells, military course of action diagrams, facial drawing, constraint diagrams, free body diagrams, trusses, and UAV control.&nbsp; Additionally, we have developed multiple algorithms that allow a user to search for their sketches by sketch.</p>\n<p>&nbsp;</p>\n<p>In order to facilitate collaborative drawing, we have developed collaborative drawing software that allows multiple people to draw from remote locations in real-time. To allow people to also use this software on a multi-user surface, we have developed a novel algorithm to automatically determine who is drawing on a ...",
  "por_txt_cntn": "\nIf one wanders through a university, high school, middle school, elementary school, and even pre-school, one will certainly notice a plethora of teachers and students sketching graphical diagrams on the board or in their notebooks. Sketches are used throughout the educational process; one can think an endless list of topics which are taught through the use of graphical diagrams: geometry, supply chain graphs, evolutionary models, finite state machines, mechanical engineering diagrams, electrical circuit diagrams, physics diagrams, chemical symbols and reactions, flow charts, UML diagrams to design software, musical notation, tree data structures, graphs, &hellip;we can go on an on. But these hand-sketches remain static and uninterpreted. CAD systems exist to animate and correct diagrams, but their mouse-and-palette interfaces have to be learned, not only taking valuable time away from the subject material, but also diverts the student away from his or her creative impulses.  An additional issue is the time delay between a student\u00c6s completion of hand-drawn homework and the receipt of graded feedback.\n\n \n\nA sketch-based system allows students to interact with a computer with the same creative freedom as they would on paper, removing the need to \u00e6teach the tool\u00c6 and improving students\u00c6 spatial cognition skills and manual dexterity, while providing immediate feedback. It seems counter-productive to have to spend precious time learning how to use the system before focusing on learning the actual course material. Sketched-based homework problems allow students to actually create the answer to a problem rather than simply identify the answer, as in traditional Scantron or standard computerized multiple-choice questions. Such systems are not designed as a teacher replacement but rather as a supplementary tutoring system, providing additional human-like feedback, where they otherwise would get none. The computer is not responsible for teaching actual processes; instead it serves to monitor students' performance on homework problems, correct misunderstandings, and assist in grading assignments.\n\n \n\nThrough the resources provided by this project, we have created multiple artificial intelligence algorithms to improve the recognition of hand-sketches, including low-level primitive stroke recognizers, multi-stroke recognizers, corner finding algorithms, high level algorithms that allow for interspersed free-form sketching, perception-based constraint recognizers, a language to facilitate the develop of domain specific sketch applications, and a domain-independent algorithm that automatically distinguishes text versus shape within a diagram. In order to further the field of sketch recognition in general, we have also created a public data collection tool and implemented an international sketch recognition accuracy contest to encourage other researchers to collect and share data. To improve interaction with a sketch tool we have developed multiple improved interaction methods including improved editing techniques.\n\n \n\nUsing our algorithms, we have developed a number of domain-specific sketch recognition educational applications that teach Chinese characters, MPS1 characters, Japanese, Urdu, Biology cells, military course of action diagrams, facial drawing, constraint diagrams, free body diagrams, trusses, and UAV control.  Additionally, we have developed multiple algorithms that allow a user to search for their sketches by sketch.\n\n \n\nIn order to facilitate collaborative drawing, we have developed collaborative drawing software that allows multiple people to draw from remote locations in real-time. To allow people to also use this software on a multi-user surface, we have developed a novel algorithm to automatically determine who is drawing on a collaborative surface using only the pressure and tilt sensors of the stylus.\n\n \n\nBecause a tabletPC or stylus is not always available, we developed a vectorization algorithm to translate paper sket..."
 }
}