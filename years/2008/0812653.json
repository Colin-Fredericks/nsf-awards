{
 "awd_id": "0812653",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Supporting Wilderness Search and Rescue Personnel: Acquiring and Visualizing Aerial Imagery",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2008-11-01",
 "awd_exp_date": "2012-10-31",
 "tot_intn_awd_amt": 446784.0,
 "awd_amount": 462784.0,
 "awd_min_amd_letter_date": "2008-08-29",
 "awd_max_amd_letter_date": "2011-04-13",
 "awd_abstract_narration": "Wilderness search and rescue (WiSAR) is the task of finding and giving assistance to humans who are lost or injured in mountain, desert, lake, river, or other remote settings.  Rapid coverage of large search areas and difficult terrain is critical; as the search radius increases, the probability of finding and successfully aiding the missing person decreases.  Prior NSF-sponsored research established the hypothesis that mini (2-8 foot wing span), fixed-wing Unmanned Aerial Vehicles (UAVs) equipped with video cameras can support WiSAR personnel.  In this project the PIs plan to extend that work, by addressing key human factors and technology obstacles that must be overcome to make such support practical and efficient.  Through enhanced WiSAR-oriented UAV operator interfaces and visualization, the PIs will improve both the UAV's coverage of the search area by people without piloting skills and the searcher's detection of the missing person or other signs in the video.  The design of these WiSAR systems will integrate the PIs' expertise in human-robot interaction, computer vision, visualization, and artificial intelligence.  The project adopts a human-centered evaluation approach that uses both laboratory and field tests.  Innovative aspects of the work include integration of video mapping, missing-person modeling, and human interaction to create prioritized search maps that are dynamically updated as information is acquired, and which can then be used to perform search planning based on this dynamic information, requiring real-time planning algorithms that can adapt to uncertainty and new information.  The prioritized search maps and resulting plans can be used directly by WiSAR personnel, or integrated into the UAV operator?s interface, or allow WiSAR personnel to outline a plan and grant the UAV sufficient autonomy to optimize coverage subject to this outline.   The PIs will also integrate multiple video sources (including infrared imaging), anomaly detection and tracking, and geo-registered video annotation in order to further assist WiSAR personnel in detecting, identifying, and communicating information about objects of potential interest in the video sources.  These will be presented to WiSAR personnel in the form of interfaces designed for their separate roles: UAV operator, video searcher, incident commander, and field searcher, as well as integrated interfaces for individuals acting in multiple roles simultaneously.  Finally, the PIs will extend this work to support video-equipped manned aircraft and ground search teams.\r\n\r\nBroader Impacts:  Each year, many people are lost or find themselves in jeopardy while hiking, boating/kayaking, skiing, fishing, etc.  WiSAR consumes thousands of man-hours and hundreds of thousands of dollars each year in Utah alone.  Creating appropriate visualization algorithms and user interfaces to support planning, visualization, and UAV control should decrease the amount of time required to locate and offer assistance to missing persons, increasing the likelihood of successful rescue.  The PIs plan to include in this project undergraduate students from nearby Utah Valley State College (UVSC), a school that does not yet have a graduate program and consequently has few opportunities for socially relevant, interdisciplinary undergraduate research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bryan",
   "pi_last_name": "Morse",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Bryan S Morse",
   "pi_email_addr": "morse@byu.edu",
   "nsf_id": "000244122",
   "pi_start_date": "2008-08-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Goodrich",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Goodrich",
   "pi_email_addr": "mike@cs.byu.edu",
   "nsf_id": "000425455",
   "pi_start_date": "2008-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brigham Young University",
  "inst_street_address": "A-153 ASB",
  "inst_street_address_2": "",
  "inst_city_name": "PROVO",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8014223360",
  "inst_zip_code": "846021128",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "UT03",
  "org_lgl_bus_name": "BRIGHAM YOUNG UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JWSYC7RUMJD1"
 },
 "perf_inst": {
  "perf_inst_name": "Brigham Young University",
  "perf_str_addr": "A-153 ASB",
  "perf_city_name": "PROVO",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "846021128",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "UT03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 141314.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 305470.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>As unmanned aerial vehicles (UAVs) become smaller, more portable, and less expensive, they are beginning to be used for a variety of purposes. This project has focused on ways to use camera-equipped UAVs to assist personnel conducting search-and-rescue operations in remote wilderness areas.</p>\n<p>Basic UAV deployment can be as simple as the plane, an onboard video camera, a video transmitter to the ground, a video antenna receiver, a display, and command/control transmission both ways. But just being able to fly the plane and watch the transmitted video doesn't always make for effective searching. Through field trials over eight years (seven of which were funded by the NSF), this line of work has identified problems users have efficiently working with these systems and sought to develop more usable systems. The human operators, not the technology, are at the center of the project.</p>\n<p>This project has made contributions three main areas:</p>\n<ul>\n<li>Enhanced imagery for video-based searchers,</li>\n<li>More efficient and intuitive control of the UAV and its search paths, and</li>\n<li>Data-driven and probabilistic modeling of terrain, missing person behavior, and searchers.</li>\n</ul>\n<p>Our methods for video analysis and enhancement are designed to make it easier for video-based searchers to identify the missing person or other items of interest. These methods include dynamically stitching together multiple video frames to create views with larger field of view and allow for more persistent viewing, automatically and adaptively identifying objects that look \"out of place\" in the setting, fusing together visible-spectrum and infrared video, providing geographically-based indexing into the search video, and aligning and synchronizing low-resolution video with higher-resolution still photographs.</p>\n<p>To allow UAV-search operators to more easily and effectively control the aircraft, we have developed more intuitive piloting interfaces, including showing the UAV's position and planned path in 3-D using terrain maps and pre-acquired satellite imagery. To allow operators to better assess the quality and coverage of a search flight or series of flights, we have also developed coverage quality maps as a way to see not only what was seen but how well it was seen.</p>\n<p>To further assist planning for UAV-based search deployment, we have also developed models for missing-person behavior. These methods incorporate properties of the terrain and vegetation, input from the incident commander or other experienced searchers, and data gathered on how missing persons move--and where they are eventually found--to prioritize areas for searching. These can then be combined with optimization methods to suggest search paths for the UAV to fly. Users can also loosely say \"fly over here for this long\", and the system automatically guides the UAV in an optimized search of that area given the time allotted.</p>\n<p>The results of this work have been disseminated in peer-reviewed academic papers, presentations at academic conferences, presentations at conferences for search-and-rescue personnel, presentations at universities and to other groups, and through articles in online, print, and broadcast media.</p>\n<p>The work has involved collaborators from Utah County Search and Rescue as well as colleagues from Utah Valley University and George Mason University.</p>\n<p>We are in the process of converting our various systems for open source distribution to the growing UAV hobbyist community. Our hope has always been that someday these ideas will find their ways into systems that help searchers save lives.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/17/2013<br>\n\t\t\t\t\tModified by: Bryan&nbsp;S&nbsp;Morse</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhot...",
  "por_txt_cntn": "\nAs unmanned aerial vehicles (UAVs) become smaller, more portable, and less expensive, they are beginning to be used for a variety of purposes. This project has focused on ways to use camera-equipped UAVs to assist personnel conducting search-and-rescue operations in remote wilderness areas.\n\nBasic UAV deployment can be as simple as the plane, an onboard video camera, a video transmitter to the ground, a video antenna receiver, a display, and command/control transmission both ways. But just being able to fly the plane and watch the transmitted video doesn't always make for effective searching. Through field trials over eight years (seven of which were funded by the NSF), this line of work has identified problems users have efficiently working with these systems and sought to develop more usable systems. The human operators, not the technology, are at the center of the project.\n\nThis project has made contributions three main areas:\n\nEnhanced imagery for video-based searchers,\nMore efficient and intuitive control of the UAV and its search paths, and\nData-driven and probabilistic modeling of terrain, missing person behavior, and searchers.\n\n\nOur methods for video analysis and enhancement are designed to make it easier for video-based searchers to identify the missing person or other items of interest. These methods include dynamically stitching together multiple video frames to create views with larger field of view and allow for more persistent viewing, automatically and adaptively identifying objects that look \"out of place\" in the setting, fusing together visible-spectrum and infrared video, providing geographically-based indexing into the search video, and aligning and synchronizing low-resolution video with higher-resolution still photographs.\n\nTo allow UAV-search operators to more easily and effectively control the aircraft, we have developed more intuitive piloting interfaces, including showing the UAV's position and planned path in 3-D using terrain maps and pre-acquired satellite imagery. To allow operators to better assess the quality and coverage of a search flight or series of flights, we have also developed coverage quality maps as a way to see not only what was seen but how well it was seen.\n\nTo further assist planning for UAV-based search deployment, we have also developed models for missing-person behavior. These methods incorporate properties of the terrain and vegetation, input from the incident commander or other experienced searchers, and data gathered on how missing persons move--and where they are eventually found--to prioritize areas for searching. These can then be combined with optimization methods to suggest search paths for the UAV to fly. Users can also loosely say \"fly over here for this long\", and the system automatically guides the UAV in an optimized search of that area given the time allotted.\n\nThe results of this work have been disseminated in peer-reviewed academic papers, presentations at academic conferences, presentations at conferences for search-and-rescue personnel, presentations at universities and to other groups, and through articles in online, print, and broadcast media.\n\nThe work has involved collaborators from Utah County Search and Rescue as well as colleagues from Utah Valley University and George Mason University.\n\nWe are in the process of converting our various systems for open source distribution to the growing UAV hobbyist community. Our hope has always been that someday these ideas will find their ways into systems that help searchers save lives.\n\n \n\n\t\t\t\t\tLast Modified: 05/17/2013\n\n\t\t\t\t\tSubmitted by: Bryan S Morse"
 }
}