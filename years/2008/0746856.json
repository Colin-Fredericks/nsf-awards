{
 "awd_id": "0746856",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER:  Systematic Software Testing Using Test Abstractions",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2008-06-01",
 "awd_exp_date": "2014-05-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 406000.0,
 "awd_min_amd_letter_date": "2008-02-08",
 "awd_max_amd_letter_date": "2012-06-01",
 "awd_abstract_narration": "CCF-0746856\r\nCAREER: Systematic Software Testing Using Test Abstractions\r\nDarko Marinov\r\n\r\nSoftware testing is important for increasing software reliability, but expensive and can account for more than half of the software development cost.  Automated testing can significantly help programmers to develop and maintain reliable software.  However, test automation is mainly limited to test execution, while test generation remains manual and mostly ad hoc, which not only makes it hard to develop tests initially but also to maintain and reuse tests.\r\n\r\nTo reduce the cost of developing, maintaining, and reusing tests, this project investigates a novel approach to automated testing based on test abstractions.  Conceptually, each test abstraction provides a high-level description of a desired test suite: programmers do not need to manually write large suites of individual tests but instead write only test abstractions from which tools automatically generate individual tests.  This project investigates five aspects of test abstractions: (1) What languages to use for writing test abstractions?  (2) Which tests to generate from test abstractions? (3) How to automatically generate tests from test abstractions? (4) How to determine whether the code under test passed or failed? (5) How to determine which failing tests are caused by the same code error?\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Darko",
   "pi_last_name": "Marinov",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Darko Marinov",
   "pi_email_addr": "marinov@illinois.edu",
   "nsf_id": "000095315",
   "pi_start_date": "2008-02-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "506 S WRIGHT ST",
  "perf_city_name": "URBANA",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735200",
   "pgm_ele_name": "COMPUTING PROCESSES & ARTIFACT"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 80000.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 80000.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 80000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 86000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 80000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Software testing is important for increasing software quality but expensive and can account for more than half of the software development cost. Automated testing can significantly help programmers to develop and maintain reliable software. However, test automation is mainly limited to test execution, while test generation remains manual and mostly ad hoc, which not only makes it hard to develop tests initially but also to maintain and reuse tests.</p>\n<p>To reduce the cost of developing, maintaining, and reusing tests, this project investigated a novel approach to automated testing based on \"test abstractions\". Conceptually, each test abstraction provides a high-level description of a desired test suite: programmers do not need to manually write large suites of individual tests but instead write only test abstractions from which tools automatically generate individual tests. This project investigated five aspects of test abstractions: (1) What languages to use for writing test abstractions. (2) Which tests to generate from test abstractions. (3) How to automatically generate tests from test abstractions. (4) How to determine whether the code under test passed or failed. (5) How to determine which failing tests are caused by the same code error.</p>\n<p>The grant partially supported 40 papers (including one award-winning paper, two conference papers invited for journal submissions, and one more paper nominated for a best-paper award), public release of 11 testing tools and datasets (available from http://mir.cs.illinois.edu page on software and data), and training of at least a dozen graduate students (including three PhD theses and four MS theses) and eight undergraduate students. The broader impacts also include the use of test abstractions to find hundreds of bugs in various open-source software projects (linked from the above page), and the research is a step toward better testing tools and frameworks for reducing bugs in software, thus helping to improve the quality of software used in our daily lives.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/26/2014<br>\n\t\t\t\t\tModified by: Darko&nbsp;Marinov</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSoftware testing is important for increasing software quality but expensive and can account for more than half of the software development cost. Automated testing can significantly help programmers to develop and maintain reliable software. However, test automation is mainly limited to test execution, while test generation remains manual and mostly ad hoc, which not only makes it hard to develop tests initially but also to maintain and reuse tests.\n\nTo reduce the cost of developing, maintaining, and reusing tests, this project investigated a novel approach to automated testing based on \"test abstractions\". Conceptually, each test abstraction provides a high-level description of a desired test suite: programmers do not need to manually write large suites of individual tests but instead write only test abstractions from which tools automatically generate individual tests. This project investigated five aspects of test abstractions: (1) What languages to use for writing test abstractions. (2) Which tests to generate from test abstractions. (3) How to automatically generate tests from test abstractions. (4) How to determine whether the code under test passed or failed. (5) How to determine which failing tests are caused by the same code error.\n\nThe grant partially supported 40 papers (including one award-winning paper, two conference papers invited for journal submissions, and one more paper nominated for a best-paper award), public release of 11 testing tools and datasets (available from http://mir.cs.illinois.edu page on software and data), and training of at least a dozen graduate students (including three PhD theses and four MS theses) and eight undergraduate students. The broader impacts also include the use of test abstractions to find hundreds of bugs in various open-source software projects (linked from the above page), and the research is a step toward better testing tools and frameworks for reducing bugs in software, thus helping to improve the quality of software used in our daily lives.\n\n\t\t\t\t\tLast Modified: 08/26/2014\n\n\t\t\t\t\tSubmitted by: Darko Marinov"
 }
}