{
 "awd_id": "0811038",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III-COR-Small: Beyond Keyword Search: Enabling Diverse Structured Query Paradigms over Text Databases",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2008-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 448976.0,
 "awd_amount": 448976.0,
 "awd_min_amd_letter_date": "2008-08-14",
 "awd_max_amd_letter_date": "2012-09-11",
 "awd_abstract_narration": "The text available on the Web and beyond embeds unprecedented volumes\r\nof valuable structured data, \"hidden\" in natural language. For\r\nexample, a news article might discuss an outbreak of an infectious\r\ndisease, reporting the name of the disease, the number of people\r\naffected, and the geographical regions involved.  Keyword search, the\r\nprevalent query paradigm for text, is often insufficiently expressive\r\nfor complex information needs that require structured data embedded in\r\ntext. For such needs, users (e.g., an epidemiologist compiling\r\nstatistics, as reported in the media, on recent foodborne disease\r\noutbreaks in a remote country) are forced to embark in labor-intensive\r\ncycles of keyword-based document retrieval and manual document\r\nfiltering, until they locate the appropriate (structured) information.\r\nTo move beyond keyword search, this project exploits information\r\nextraction technology, which identifies structured data in text, to\r\nenable structured querying. To capture diverse user information needs\r\nand depart from a \"one-size-fits-all\" querying approach, which is\r\ninappropriate for this extraction-based scenario, this project\r\nexplores a wealth of structured query paradigms: sometimes users\r\n(e.g., a high-school student in need of some quick examples and\r\nstatistics for a report on recent salmonella outbreaks in developing\r\ncountries) are after a few exploratory results, which should be\r\nreturned fast; some other times, users (e.g., the above epidemiologist\r\ninvestigating foodborne diseases) are after comprehensive results, for\r\nwhich waiting a longer time is acceptable.  The project develops\r\nspecialized cost-based query optimizers for each query paradigm,\r\naccounting for the efficiency and, critically, the result quality of\r\nthe query execution plans.  The technology produced will assist a vast\r\nrange of users and information needs, by enabling efficient, diverse\r\ninteractions with text databases -- for sophisticated searching and\r\ndata mining -- that are cumbersome or impossible with today's\r\ntechnology.  The research and educational components of the project\r\nwill rely on -- and encourage -- a tight integration of three\r\ncomplementary Computer Science disciplines, namely, natural language\r\nprocessing, information retrieval, and databases. The project will\r\nalso provide data sets and source code, for experimentation and\r\nevaluation, to the community at large over the Web (http://extraction.cs.columbia.edu/).\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Luis",
   "pi_last_name": "Gravano",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Luis Gravano",
   "pi_email_addr": "gravano@cs.columbia.edu",
   "nsf_id": "000490154",
   "pi_start_date": "2008-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "615 W 131ST ST",
  "perf_city_name": "NEW YORK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100277922",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 295153.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 153823.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The text available on the Web and beyond embeds unprecedented volumes of  valuable structured data, \"hidden\" in natural language. For example, a  news article might discuss an outbreak of an infectious disease,  reporting the name of the disease, the number of people affected, and  the geographical regions involved. Traditional keyword search, the  prevalent query paradigm for text, is often insufficiently expressive  for complex information needs that require structured data embedded in  text. For such needs, users (e.g., an epidemiologist compiling  statistics, as reported in the media, on recent food-borne disease  outbreaks in a remote country) are forced to embark in labor-intensive  cycles of keyword-based document retrieval and manual document  filtering, until they locate the appropriate (structured) information.  To move beyond traditional keyword search, this project exploited  information extraction technology, which identifies structured data in  text, to enable structured querying. Furthermore, at the center of this  project was the observation that user information needs are diverse, and  \"one-size-fits-all\" approaches are hence inappropriate: sometimes users  (e.g., a high-school student in need of some quick examples and  statistics for a report on recent salmonella outbreaks in developing  countries) are after a few exploratory results, which should be returned  fast; some other times, users (e.g., the above epidemiologist  investigating food-borne diseases) are after comprehensive results, for  which waiting a longer time is acceptable. The project developed  specialized cost-based query optimizers that adapt to the spectrum of  user needs, accounting for the efficiency and, critically, the result  quality and completeness of the query execution plans. The technology produced is likely  to assist a vast range of users and information needs, by enabling  efficient, diverse interactions with text databases --for sophisticated  searching and data mining-- that are cumbersome or impossible with  traditional technology. The research and educational components of the  project relied on --and encouraged-- a tight integration of three  complementary Computer Science disciplines, namely, natural language  processing, information retrieval, and databases. The project provided source code for experimentation and evaluation to the community at  large over the Web at http://reel.cs.columbia.edu/.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/23/2013<br>\n\t\t\t\t\tModified by: Luis&nbsp;Gravano</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe text available on the Web and beyond embeds unprecedented volumes of  valuable structured data, \"hidden\" in natural language. For example, a  news article might discuss an outbreak of an infectious disease,  reporting the name of the disease, the number of people affected, and  the geographical regions involved. Traditional keyword search, the  prevalent query paradigm for text, is often insufficiently expressive  for complex information needs that require structured data embedded in  text. For such needs, users (e.g., an epidemiologist compiling  statistics, as reported in the media, on recent food-borne disease  outbreaks in a remote country) are forced to embark in labor-intensive  cycles of keyword-based document retrieval and manual document  filtering, until they locate the appropriate (structured) information.  To move beyond traditional keyword search, this project exploited  information extraction technology, which identifies structured data in  text, to enable structured querying. Furthermore, at the center of this  project was the observation that user information needs are diverse, and  \"one-size-fits-all\" approaches are hence inappropriate: sometimes users  (e.g., a high-school student in need of some quick examples and  statistics for a report on recent salmonella outbreaks in developing  countries) are after a few exploratory results, which should be returned  fast; some other times, users (e.g., the above epidemiologist  investigating food-borne diseases) are after comprehensive results, for  which waiting a longer time is acceptable. The project developed  specialized cost-based query optimizers that adapt to the spectrum of  user needs, accounting for the efficiency and, critically, the result  quality and completeness of the query execution plans. The technology produced is likely  to assist a vast range of users and information needs, by enabling  efficient, diverse interactions with text databases --for sophisticated  searching and data mining-- that are cumbersome or impossible with  traditional technology. The research and educational components of the  project relied on --and encouraged-- a tight integration of three  complementary Computer Science disciplines, namely, natural language  processing, information retrieval, and databases. The project provided source code for experimentation and evaluation to the community at  large over the Web at http://reel.cs.columbia.edu/.\n\n\t\t\t\t\tLast Modified: 12/23/2013\n\n\t\t\t\t\tSubmitted by: Luis Gravano"
 }
}