{
 "awd_id": "0803148",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI-Medium: Collaborative: Corpus-Based Studies of Lexical, Acoustic-Prosodic, and Discourse Entrainment in Spoken Dialogue",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2008-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 441911.0,
 "awd_amount": 449911.0,
 "awd_min_amd_letter_date": "2008-08-05",
 "awd_max_amd_letter_date": "2013-08-13",
 "awd_abstract_narration": "Participants in human-human conversation often entrain to one another, adopting the vocabulary and other behaviors of their partners.\r\nEvidence of this has been found from laboratory studies and observations of real life situations.  We are investigating many types of entrainment in two large corpora of human-human conversations to improve system behavior in Spoken Dialogue Systems (SDS).  We want to discover which types of entrainment occur generally across speakers and which seem to be speaker-specific, which types of entrainment can be reliably linked to task success and perceived naturalness, and which types of entrainment can be automatically modeled in SDS.\r\n\r\nOur research has importance for the construction of better SDS.\r\nCurrently, research SDS have attempted to entrain users to system vocabularies to improve speech recognition accuracy: Since users are likely to employ the same vocabulary in their answers that systems use in their queries, systems have a better chance of recognizing user input correctly if they can predict word usage.  However, there has been little attempt to create SDS that entrain to user behavior, despite evidence that human beings rate humans and systems that behave more like them more highly than those that do not.  Our work focuses on determining which types of system entrainment to users will be most important to users and most feasible for SDS.  Our results will be disseminated through papers and presentations at speech and language conferences.  We will also provide publicly available annotated corpora for future research by others.\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Julia",
   "pi_last_name": "Hirschberg",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Julia B Hirschberg",
   "pi_email_addr": "julia@cs.columbia.edu",
   "nsf_id": "000399629",
   "pi_start_date": "2008-08-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "615 W 131ST ST",
  "perf_city_name": "NEW YORK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100277922",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "729800",
   "pgm_ele_name": "International Research Collab"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5937",
   "pgm_ref_txt": "SWEDEN"
  },
  {
   "pgm_ref_code": "5948",
   "pgm_ref_txt": "NETHERLANDS"
  },
  {
   "pgm_ref_code": "5979",
   "pgm_ref_txt": "Europe and Eurasia"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 441911.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Project Outcomes Report for the General Public on:</p>\n<p>&nbsp;</p>\n<p><strong>Award Title: </strong>RI-Medium: Collaborative: Corpus-Based Studies of Lexical, Acoustic-Prosodic, and Discourse Entrainment in Spoken Dialogue</p>\n<p><strong>Federal Award ID: </strong>0803148</p>\n<p>&nbsp;</p>\n<p>In this research we have studied an important phenomenon in human communication, entrainment, the propensity of people to become more like one another when they communicate.&nbsp; Entrainment has been studied in many dimensions: pronunciation, word choice, speaking rate, facial and other gestures, joking and laughter, posture, inter alia. People who entrain have been shown to be more attractive, more likable and more competent by their conversational partners, and conversations in which partners entrain have been seen as more successful. However, most studies have focused on entrainment in a single feature and have been performed on very different datasets.&nbsp; In our work we study entrainment in a large number of acoustic, prosodic and lexical dimensions on a common dataset to answer questions such as:&nbsp;</p>\n<ul>\n<li>How do people entrain in spoken language?&nbsp; Does this differ across cultures?&nbsp; Does gender play a role?</li>\n<li>What measures best test entrainment?</li>\n<li>What aspects of spoken language entrainment can we model in Spoken Dialogue Systems (e.g. the iPhone&rsquo;s Siri or Amtrak&rsquo;s Julie)?</li>\n<li>Is a computer system which entrains to its users preferred or seen as more trustworthy?</li>\n</ul>\n<p>We studied entrainment in multiple dimensions including word usage, pitch, intensity (loudness), speaking rate, and voice quality in the Columbia Games Corpus, a set of recorded dialogues recorded earlier, in which two speakers (strangers) of Standard American English play a series of collaborative computer games, designed to give them an incentive to cooperate.&nbsp; Twelve speakers each spoke with two different partners on different days in a sound-proof booth, with no visual contact, producing +9h of speech.&nbsp; Speech was transcribed by hand and labeled for turn-taking behaviors and intonation. Acoustic-prosodic features such as pitch, intensity, speaking rate and voice quality were extracted using Praat and compared statistically for the conversational partners to see whether these partners were similar, became more similar (converged), or varied in synchrony &ndash; compared to their performance when compared to other speakers in the dataset with whom they did not speak.&nbsp; That is, we measured partner behavior against non-partner behavior to look for evidence of entrainment in partners.&nbsp; We also looked at whether speakers entrained globally, over whole sessions, or locally, from turn to turn.</p>\n<p>&nbsp;</p>\n<p>We found evidence that speakers entrained in pitch, intensity, speaking rate, and voice quality &ndash; but in different ways.&nbsp; In some cases we found similarity at the local or global level, in some we found synchrony or convergence.&nbsp; We also found correlations between certain social variables and entrainment, when our speakers were judged by independent raters.&nbsp; Another finding was that speakers who were &lsquo;outliers&rsquo; in some acoustic-prosodic features (e.g. who spoken much more loudly or softly than other speakers in the dataset) were more entrained to than other speakers. We also found that speakers entrained on backchannel-inviting behavior &ndash; the way in which their speech changed to indicate that feedback from their interlocutor would be welcome.</p>\n<p>&nbsp;</p>\n<p>When we compared entrainment in this American corpus to a similar Mandarin study done in collaboration with us on the Tongji Games Corpus we found striking similarities in acoustic-prosodic entrainment by American and Mandarin speakers, who also entrained on pitch, intensity, and speaking rate.&nbsp; We also found in both...",
  "por_txt_cntn": "\nProject Outcomes Report for the General Public on:\n\n \n\nAward Title: RI-Medium: Collaborative: Corpus-Based Studies of Lexical, Acoustic-Prosodic, and Discourse Entrainment in Spoken Dialogue\n\nFederal Award ID: 0803148\n\n \n\nIn this research we have studied an important phenomenon in human communication, entrainment, the propensity of people to become more like one another when they communicate.  Entrainment has been studied in many dimensions: pronunciation, word choice, speaking rate, facial and other gestures, joking and laughter, posture, inter alia. People who entrain have been shown to be more attractive, more likable and more competent by their conversational partners, and conversations in which partners entrain have been seen as more successful. However, most studies have focused on entrainment in a single feature and have been performed on very different datasets.  In our work we study entrainment in a large number of acoustic, prosodic and lexical dimensions on a common dataset to answer questions such as: \n\nHow do people entrain in spoken language?  Does this differ across cultures?  Does gender play a role?\nWhat measures best test entrainment?\nWhat aspects of spoken language entrainment can we model in Spoken Dialogue Systems (e.g. the iPhone\u00c6s Siri or Amtrak\u00c6s Julie)?\nIs a computer system which entrains to its users preferred or seen as more trustworthy?\n\n\nWe studied entrainment in multiple dimensions including word usage, pitch, intensity (loudness), speaking rate, and voice quality in the Columbia Games Corpus, a set of recorded dialogues recorded earlier, in which two speakers (strangers) of Standard American English play a series of collaborative computer games, designed to give them an incentive to cooperate.  Twelve speakers each spoke with two different partners on different days in a sound-proof booth, with no visual contact, producing +9h of speech.  Speech was transcribed by hand and labeled for turn-taking behaviors and intonation. Acoustic-prosodic features such as pitch, intensity, speaking rate and voice quality were extracted using Praat and compared statistically for the conversational partners to see whether these partners were similar, became more similar (converged), or varied in synchrony &ndash; compared to their performance when compared to other speakers in the dataset with whom they did not speak.  That is, we measured partner behavior against non-partner behavior to look for evidence of entrainment in partners.  We also looked at whether speakers entrained globally, over whole sessions, or locally, from turn to turn.\n\n \n\nWe found evidence that speakers entrained in pitch, intensity, speaking rate, and voice quality &ndash; but in different ways.  In some cases we found similarity at the local or global level, in some we found synchrony or convergence.  We also found correlations between certain social variables and entrainment, when our speakers were judged by independent raters.  Another finding was that speakers who were \u00e6outliers\u00c6 in some acoustic-prosodic features (e.g. who spoken much more loudly or softly than other speakers in the dataset) were more entrained to than other speakers. We also found that speakers entrained on backchannel-inviting behavior &ndash; the way in which their speech changed to indicate that feedback from their interlocutor would be welcome.\n\n \n\nWhen we compared entrainment in this American corpus to a similar Mandarin study done in collaboration with us on the Tongji Games Corpus we found striking similarities in acoustic-prosodic entrainment by American and Mandarin speakers, who also entrained on pitch, intensity, and speaking rate.  We also found in both studies that, when speaker pairs were examined in terms of their gender composition (MM, FF, FM pairs), both language groups showed greatest evidence of entrainment for FM pairs and least in MM pairs.\n\nFinally, to evaluate the utility of entrainment in spoken dialogue systems, we built a real-time simulation..."
 }
}