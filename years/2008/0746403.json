{
 "awd_id": "0746403",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Psychophysical Investigation of the Auditory Periphery",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2008-04-15",
 "awd_exp_date": "2011-09-30",
 "tot_intn_awd_amt": 355086.0,
 "awd_amount": 355086.0,
 "awd_min_amd_letter_date": "2008-04-08",
 "awd_max_amd_letter_date": "2010-01-26",
 "awd_abstract_narration": "For the past 60 years, the peripheral auditory system has been modeled  as a bank of bandpass filters, which is analogous to a graphic equalizer on a  high-end stereo system. Some filters respond  only to low frequencies  whereas other filters respond only to high frequencies. In effect, the output from  the filterbank represents a rough analysis of the spectral content of  the input, which is critical information for discriminating and identifying sounds.   However, a number of key experiments during the last few years have shown that a  single filterbank model is too simplistic. Acoustic information exists in different  forms that require different processing mechanisms. A more sophisticated  view of the auditory system, that holds much promise, is one of multiple parallel processes. The envelope of the sound waveform, for instance, contains much useful information and  requires a temporal analysis rather than a spectral analysis. This research introduces the theory that temporal and spectral processes have distinct filtering  mechanisms that operate in parallel. There is some psychophysical data to support this idea but a more thorough investigation is needed to lay the groundwork for developing a  theory that is sufficiently complete to have practical applications. For example, a complete understanding of the filtering properties  of the auditory system is crucial for improving the design of cochlear implants and hearing aids.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bruce",
   "pi_last_name": "Berg",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bruce Berg",
   "pi_email_addr": "bgberg@uci.edu",
   "nsf_id": "000401548",
   "pi_start_date": "2008-04-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Irvine",
  "inst_street_address": "160 ALDRICH HALL",
  "inst_street_address_2": "",
  "inst_city_name": "IRVINE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9498247295",
  "inst_zip_code": "926970001",
  "inst_country_name": "United States",
  "cong_dist_code": "47",
  "st_cong_dist_code": "CA47",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA IRVINE",
  "org_prnt_uei_num": "MJC5FCYQTPE6",
  "org_uei_num": "MJC5FCYQTPE6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Irvine",
  "perf_str_addr": "160 ALDRICH HALL",
  "perf_city_name": "IRVINE",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "926970001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "47",
  "perf_st_cong_dist": "CA47",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 124660.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 114110.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 116316.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>A Psychophysical Investigation of the Auditory Periphery</strong></p>\n<p><strong>Bruce G. Berg- Principal Investigator</strong></p>\n<p><strong>Department of Cognitive Sciences, University of California, Irvine</strong><strong>&nbsp;</strong></p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The term &ldquo;auditory periphery&rdquo; is an abstract theoretical construct that refers to the initial stages of any auditory process.&nbsp; It is the point at which the acoustic information is transformed into what can be called a neural code.&nbsp; For example, the firing rates of neurons in the auditory nerve increase as the intensity of a sound increases, and so it can be said that firing rate is a neural code the conveys loudness information.&nbsp; A greater understanding of neural code is important for the development of theories of hearing.&nbsp; More important, a sophisticated understanding of the auditory periphery is bound to have a significant impact on the refinement of devices such as hearing aids and cochlear implants.&nbsp; Cochlear implants stimulate the auditory nerve through a pattern of electronic pulses delivered at different locations along the length of the implant (inserted into the cochlear duct).&nbsp; The temporal-spatial patterns of pulses are controlled by signal processing algorithms built into an external central processor.&nbsp; This is the point at which theoretical psychoacoustics can contribute the most to the collective enterprise of improving the effectiveness of cochlear implants.&nbsp; A more complete understanding of the peripheral neural code will provide a target to be potentially matched by an &ldquo;electronic neural code&rdquo;.</p>\n<p>In theory, information conveyed by a sound can be coded in different ways.&nbsp; One is the so called &ldquo;place-equals-frequency&rdquo; information in reference to the fact that the locations of maximum displacement along the length of the basilar membrane correspond to the vibration frequencies of a sound.&nbsp; Neurons at specific locations are &ldquo;tuned&rdquo; to specific frequencies and so the end result is a &ldquo;place code&rdquo;, also referred to as a &ldquo;spectral code&rdquo;, that conveys information about the spectral content of a complex sound.&nbsp; Acoustic information can also be coded by the time pattern of neural firings.&nbsp; For frequencies critical to speech perception, neural discharges generally occur only with upward motions of the basilar membrane, whereas the neural response is relatively quiet with downward motions.&nbsp; A complex pattern of on-off cycles in neural firings is thus produced that is synchronized to the sound.&nbsp; This &ldquo;temporal code&rdquo; is the primary focus of the project and the key contribution is the development, testing, and refinement of an algorithm that quantifies the acoustic information carried by the time pattern, or cadence, of neural discharges.&nbsp; &nbsp;&nbsp;</p>\n<p>Theoretically, two sounds that can be discriminated should produce different discharge cadences and quantifying the information carried by the cadence is an important step in testing this assertion. &nbsp;A &ldquo;systems-level&rdquo; approach is taken in which simulated data from a model that bases decisions on the cadence algorithm is compared to the data of listeners in several different listening tasks.&nbsp; Thus far, the model accounts for data from several historically important experiments as well as new experiments designed to test specific assumptions of the theory.&nbsp; One question of interest is how many neurons are required to transmit the essential information.&nbsp; This is a difficult problem with no current solution, but it can be approached to some extent by estimating the effective bandwidth of the underlying auditory process.&nbsp; Our laboratory uses three different experimental para...",
  "por_txt_cntn": "\nA Psychophysical Investigation of the Auditory Periphery\n\nBruce G. Berg- Principal Investigator\n\nDepartment of Cognitive Sciences, University of California, Irvine \n\n                The term \"auditory periphery\" is an abstract theoretical construct that refers to the initial stages of any auditory process.  It is the point at which the acoustic information is transformed into what can be called a neural code.  For example, the firing rates of neurons in the auditory nerve increase as the intensity of a sound increases, and so it can be said that firing rate is a neural code the conveys loudness information.  A greater understanding of neural code is important for the development of theories of hearing.  More important, a sophisticated understanding of the auditory periphery is bound to have a significant impact on the refinement of devices such as hearing aids and cochlear implants.  Cochlear implants stimulate the auditory nerve through a pattern of electronic pulses delivered at different locations along the length of the implant (inserted into the cochlear duct).  The temporal-spatial patterns of pulses are controlled by signal processing algorithms built into an external central processor.  This is the point at which theoretical psychoacoustics can contribute the most to the collective enterprise of improving the effectiveness of cochlear implants.  A more complete understanding of the peripheral neural code will provide a target to be potentially matched by an \"electronic neural code\".\n\nIn theory, information conveyed by a sound can be coded in different ways.  One is the so called \"place-equals-frequency\" information in reference to the fact that the locations of maximum displacement along the length of the basilar membrane correspond to the vibration frequencies of a sound.  Neurons at specific locations are \"tuned\" to specific frequencies and so the end result is a \"place code\", also referred to as a \"spectral code\", that conveys information about the spectral content of a complex sound.  Acoustic information can also be coded by the time pattern of neural firings.  For frequencies critical to speech perception, neural discharges generally occur only with upward motions of the basilar membrane, whereas the neural response is relatively quiet with downward motions.  A complex pattern of on-off cycles in neural firings is thus produced that is synchronized to the sound.  This \"temporal code\" is the primary focus of the project and the key contribution is the development, testing, and refinement of an algorithm that quantifies the acoustic information carried by the time pattern, or cadence, of neural discharges.    \n\nTheoretically, two sounds that can be discriminated should produce different discharge cadences and quantifying the information carried by the cadence is an important step in testing this assertion.  A \"systems-level\" approach is taken in which simulated data from a model that bases decisions on the cadence algorithm is compared to the data of listeners in several different listening tasks.  Thus far, the model accounts for data from several historically important experiments as well as new experiments designed to test specific assumptions of the theory.  One question of interest is how many neurons are required to transmit the essential information.  This is a difficult problem with no current solution, but it can be approached to some extent by estimating the effective bandwidth of the underlying auditory process.  Our laboratory uses three different experimental paradigms to measure the bandwidth of temporal processing and all three yield results that are wider than conventional measurements associated with the spectral processing system (i.e. critical bands).   Other laboratories have reported similar findings.  Collectively, these results suggest that the peripheral stages of spectral and temporal neural processes are different.  The existence of distinct peripheral processes for the two systems is a n..."
 }
}