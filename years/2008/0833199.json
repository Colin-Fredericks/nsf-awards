{
 "awd_id": "0833199",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "A Compositional Approach to Scalable Parallel Software",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2008-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 999623.0,
 "awd_amount": 1327412.0,
 "awd_min_amd_letter_date": "2008-08-16",
 "awd_max_amd_letter_date": "2014-05-19",
 "awd_abstract_narration": "High-end computing systems are needed to study important, compute-intensive applications such as scientific simulations, multimedia stream processing, and geographical information systems.  While these systems are still evolving, it is clear that they will be extremely large and complex, with tens to hundreds of thousands of processors providing a deep hierarchy of systems and resources.  This research will develop the theory, techniques, and building blocks that can be used by domain scientists who are not expert parallel programmers to compose efficient applications for such complex systems.\r\nHence, the outcomes of the research should greatly increase the number of potential users of high-end machines to include essentially all scientists whose problems could take advantage of such systems.  The software resulting from this research, including the testbed applications for important problems in computational biology and physics, will be made publically available.\r\n\r\nComposition is a natural way to construct and reason about large, complex systems.  This research will develop compositional strategies for building applications and for optimizing and controlling the application and its use of system resources.\r\nThis project will use the STAPL (the Standard Template Adaptive Parallel Library) infrastructure for parallel C++ code.  STAPL includes of a collection of generic parallel algorithms and distributed containers.  In this research, STAPL's existing adaptive capabilities will be further refined and novel techniques will be developed for compositional performance modeling and for providing fault-tolerance capabilities that can be set individually for each container or algorithm instance in the program.  A modern programming interface will be designed based on composition of parallel operations that will be modeled on the range abstractions in STAPL and C++0x and directly supported by a high-level compiler.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lawrence",
   "pi_last_name": "Rauchwerger",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lawrence Rauchwerger",
   "pi_email_addr": "rwerger@illinois.edu",
   "nsf_id": "000468621",
   "pi_start_date": "2008-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Nancy",
   "pi_last_name": "Amato",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Nancy M Amato",
   "pi_email_addr": "namato@illinois.edu",
   "nsf_id": "000430397",
   "pi_start_date": "2008-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Bjarne",
   "pi_last_name": "Stroustrup",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bjarne Stroustrup",
   "pi_email_addr": "bs@cs.tamu.edu",
   "nsf_id": "000197460",
   "pi_start_date": "2008-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M Engineering Experiment Station",
  "perf_str_addr": "3124 TAMU",
  "perf_city_name": "COLLEGE STATION",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433124",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "794200",
   "pgm_ele_name": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ele_code": "795200",
   "pgm_ele_name": "HECURA"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "7952",
   "pgm_ref_txt": "HECURA"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 999623.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 231789.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 32000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 32000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 32000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>High-end computing systems are needed to study important, compute-intensive applications such as scientific simulations, multimedia stream processing, and geographical information systems. These systems are extremely large and complex and require expert programmers to develop applications that can efficiently utilize them.<br /><br />In this project, we designed and developed theory, techniques, and building blocks that can be used by domain scientists who are not expert parallel programmers to develop efficient applications for such complex systems.&nbsp; This project made several novel contributions to the theory and practice of parallel programming that were demonstrated using the STAPL (the Standard Template Adaptive Parallel Library) infrastructure for parallel C++ code, two of which are highlighted next.&nbsp; (1) A new algorithmic paradigm - k-level asynchronous (KLA) - was designed that enables the level of asynchrony in parallel graph algorithms to be parametrically varied from none (level-synchronous) to full (asynchronous), enabling execution times to be improved through an appropriate trade-off between the use of fewer, but more expensive global synchronizations, as in level-synchronous algorithms, and more, but less expensive local synchronizations (and perhaps also redundant work), as in asynchronous algorithms.&nbsp; Experimental results of an implementation of KLA in the STAPL Graph Library showed excellent scalability on systems with tens of thousands of processors and improvements of 10x or more over level-synchronous and asynchronous versions for common graph algorithms such as breadth-first search, PageRank, k-core decomposition on certain classes of real-world graphs.&nbsp; (2) Algorithmic skeletons are high-level representations for parallel programs that hide the underlying parallelism details from program specification.&nbsp; This project developed a novel skeleton framework that represents skeletons as parametric data flow graphs and allows the composition of skeletons by point-to-point dependencies of their data flow graph representations, which eliminates&nbsp; the need for reimplementation and global synchronizations in composed skeletons. An implementation in the STAPL infrastructure showed that expressivity can be achieved without loss of performance even in complex real-world applications.<br /><br />An important objective of this project was to enable domain scientists to compose efficient applications for high-end computing systems.&nbsp; Towards this goal, we worked with several important computational science applications and representative platforms throughout the development process.&nbsp; From computational physics, we developed a code PDT (parallel deterministic transport) that implements discrete-ordinates methods for deterministic particle transport in irregular problems with complex geometries. This code is used in several multidisciplinary research projects, including multiple centers in the Department of Energy's Predictive Science Academic Alliance Program (PSAAP).&nbsp; From computational biology, we developed a STAPL code which parallelizes a motion planning algorithm that can be used to model molecular motions, such as protein folding. This project designed a new approach for parallelizing these algorithms that achieved better scalability than previous methods.<br /><br />To support high-level parallelism expressed in terms of C++ libraries we built a static analysis and transformation system, the Pivot, which can handle all of C++. We placed particular emphasis on the higher levels of abstraction, such as systematically use of templates.&nbsp; We contributed in the ISO C++ standardization effort to provide direct language support for generic programming (concepts) including a notation for semantic properties of types (axioms). Partially because of our analysis of weaknesses in actual use ``concepts'' did not make it ...",
  "por_txt_cntn": "\nHigh-end computing systems are needed to study important, compute-intensive applications such as scientific simulations, multimedia stream processing, and geographical information systems. These systems are extremely large and complex and require expert programmers to develop applications that can efficiently utilize them.\n\nIn this project, we designed and developed theory, techniques, and building blocks that can be used by domain scientists who are not expert parallel programmers to develop efficient applications for such complex systems.  This project made several novel contributions to the theory and practice of parallel programming that were demonstrated using the STAPL (the Standard Template Adaptive Parallel Library) infrastructure for parallel C++ code, two of which are highlighted next.  (1) A new algorithmic paradigm - k-level asynchronous (KLA) - was designed that enables the level of asynchrony in parallel graph algorithms to be parametrically varied from none (level-synchronous) to full (asynchronous), enabling execution times to be improved through an appropriate trade-off between the use of fewer, but more expensive global synchronizations, as in level-synchronous algorithms, and more, but less expensive local synchronizations (and perhaps also redundant work), as in asynchronous algorithms.  Experimental results of an implementation of KLA in the STAPL Graph Library showed excellent scalability on systems with tens of thousands of processors and improvements of 10x or more over level-synchronous and asynchronous versions for common graph algorithms such as breadth-first search, PageRank, k-core decomposition on certain classes of real-world graphs.  (2) Algorithmic skeletons are high-level representations for parallel programs that hide the underlying parallelism details from program specification.  This project developed a novel skeleton framework that represents skeletons as parametric data flow graphs and allows the composition of skeletons by point-to-point dependencies of their data flow graph representations, which eliminates  the need for reimplementation and global synchronizations in composed skeletons. An implementation in the STAPL infrastructure showed that expressivity can be achieved without loss of performance even in complex real-world applications.\n\nAn important objective of this project was to enable domain scientists to compose efficient applications for high-end computing systems.  Towards this goal, we worked with several important computational science applications and representative platforms throughout the development process.  From computational physics, we developed a code PDT (parallel deterministic transport) that implements discrete-ordinates methods for deterministic particle transport in irregular problems with complex geometries. This code is used in several multidisciplinary research projects, including multiple centers in the Department of Energy's Predictive Science Academic Alliance Program (PSAAP).  From computational biology, we developed a STAPL code which parallelizes a motion planning algorithm that can be used to model molecular motions, such as protein folding. This project designed a new approach for parallelizing these algorithms that achieved better scalability than previous methods.\n\nTo support high-level parallelism expressed in terms of C++ libraries we built a static analysis and transformation system, the Pivot, which can handle all of C++. We placed particular emphasis on the higher levels of abstraction, such as systematically use of templates.  We contributed in the ISO C++ standardization effort to provide direct language support for generic programming (concepts) including a notation for semantic properties of types (axioms). Partially because of our analysis of weaknesses in actual use ``concepts'' did not make it into C++11. \n\nTraining and the development of human resources was an important aspect of this project.  A large number of graduate students, m..."
 }
}