{
 "awd_id": "0803288",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI-Medium: Collaborative Research: Learning Multiscale Representations using Harmonic Analysis on Graphs",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2008-09-01",
 "awd_exp_date": "2012-08-31",
 "tot_intn_awd_amt": 345157.0,
 "awd_amount": 365407.0,
 "awd_min_amd_letter_date": "2008-08-20",
 "awd_max_amd_letter_date": "2010-05-18",
 "awd_abstract_narration": "This project exercises and expands upon methods for automatic discovery of new representations at multiple temporal and spatial scales. The specific framework generalizes classical harmonic analysis, in particular wavelet-based methods, to graphs and manifolds, thereby greatly extending the scope and the desirable characteristics of this multiscale-analysis framework to domains with arbitrary geometries. This framework, termed diffusion wavelets because it is associated with a diffusion process that defines the different scales, has unique properties relevant to learning, function approximation, compression and denoising. The set of core problems that this project addresses include fast algorithms for construction of multiscale diffusion wavelets, approximation of functions on very large graphs and high-dimensional manifolds, out-of-sample extensions of functions on manifolds and graphs, compression and denoising of functions on data sets, perturbation analysis, and randomized algorithms for multiscale analysis. Challenging application domains are being investigated, including analysis of document corpora, Markov decision processes, and 3D image rendering. In each case, multiscale diffusion analysis yields interpretable and meaningful results. For example, when applied to Markov decision processes, diffusion wavelet analysis yields new optimization methods that dynamically aggregate states and actions at multiple levels of abstraction; and when applied to 3D computer graphics, it yields new compression methods that capture geometric features of objects at multiple resolutions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sridhar",
   "pi_last_name": "Mahadevan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sridhar Mahadevan",
   "pi_email_addr": "mahadeva@cs.umass.edu",
   "nsf_id": "000203723",
   "pi_start_date": "2008-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "101 COMMONWEALTH AVE",
  "perf_city_name": "AMHERST",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010039252",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 345157.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 20250.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We are literally drowning in 'big data', caused by an explosion in our ability to record, transmit, and store data (from sensor networks to documents on the world wide web). The analysis of data has become one of the most important computational problems of the 21st century. Conventional statistical methods were developed in the early part of the 20th century, and are not readily able to meet the challenge of high-dimensional data analysis in the 21st century. This grant explores new approaches to extracting multi-scale structure from data, building on recent developments in the analysis of digital data developed in mathematics. Specifically, the framework generalizes classical Fourier and wavelet analysis in Euclidean spaces to discrete domains and non-Euclidean spaces, such as &nbsp;graphs and manifolds, thereby enabling these powerful analytical methods to become much more widely applicable to the analysis of massive discrete digital data sets, such as social network analysis on Facebook and other groups, 3D computer graphics, information retrieval using a new generation of more intelligent search engines, and the solution of difficult optimization problems in decision making.&nbsp;</p>\n<p>The overall goals of this project were to investigate a new class of dimensionality reduction methods that work, not by constructing eigenvectors such as most popular methods such as principal components analysis, a widely used 100 year old method from statistics for constructing lower-dimensional representations, but by constructing a multi-scale analysis of the underlying space using the principles of wavelets on continuous spaces. These methods are called diffusion wavelets, because they perform a multi-scale analysis of random walks on a graph. Although wavelets in continuous spaces have been explored a lot, their discrete counterparts on a graph have been far less explored. The aims of the project were to investigate one specific class of multi-scale wavelets on graphs, understand their theoretical properties, investigate their applications in a variety of areas, and introduce them to the machine learning and AI communities.</p>\n<p>The major findings from this grant include the development of new ways of reducing the dimensionality of high-dimensional (text, image) data, so that structure can be found at a variety of levels. Additionally, new algorithms were developed to transfer knowledge between data that come from different sources (e.g. text documents in English and Arabic, where the surface level features (words) are entirely different; or two different proteins). These new developments extend the field of machine learning in new directions, building closer connections to classical ideas in harmonic analysis. ??Applications of these algorithms to a variety of large data sets was undertaken. One challenging data set involves a set of 100,000 documents from the European Union, which has documents in 12 different languages (e.g., English, Italian, German etc.). To build correspondences between documents in different languages, one must find mappings that align latent (hidden) concepts, since the surface features (words) are entirely different. The multi-scale manifold alignment framework provides a powerful way to find correspondences between structured objects, by automatically finding latent features.</p>\n<p>Another application involves the construction of compressed 3D object representations, an unsolved problem in computer graphics. 20 years from now, digital cameras may be capable of routinely taking high-resolution 3D digital images of the world around us. Conventional image compression methods, such as JPEG, do not extend to 3D representations. The multi-scale data analysis method explored in this project was applied to the problem of compressing 3D object representations, and was found to be more effective than previously proposed eigenvector methods.</p>\n<p>Ano...",
  "por_txt_cntn": "\nWe are literally drowning in 'big data', caused by an explosion in our ability to record, transmit, and store data (from sensor networks to documents on the world wide web). The analysis of data has become one of the most important computational problems of the 21st century. Conventional statistical methods were developed in the early part of the 20th century, and are not readily able to meet the challenge of high-dimensional data analysis in the 21st century. This grant explores new approaches to extracting multi-scale structure from data, building on recent developments in the analysis of digital data developed in mathematics. Specifically, the framework generalizes classical Fourier and wavelet analysis in Euclidean spaces to discrete domains and non-Euclidean spaces, such as  graphs and manifolds, thereby enabling these powerful analytical methods to become much more widely applicable to the analysis of massive discrete digital data sets, such as social network analysis on Facebook and other groups, 3D computer graphics, information retrieval using a new generation of more intelligent search engines, and the solution of difficult optimization problems in decision making. \n\nThe overall goals of this project were to investigate a new class of dimensionality reduction methods that work, not by constructing eigenvectors such as most popular methods such as principal components analysis, a widely used 100 year old method from statistics for constructing lower-dimensional representations, but by constructing a multi-scale analysis of the underlying space using the principles of wavelets on continuous spaces. These methods are called diffusion wavelets, because they perform a multi-scale analysis of random walks on a graph. Although wavelets in continuous spaces have been explored a lot, their discrete counterparts on a graph have been far less explored. The aims of the project were to investigate one specific class of multi-scale wavelets on graphs, understand their theoretical properties, investigate their applications in a variety of areas, and introduce them to the machine learning and AI communities.\n\nThe major findings from this grant include the development of new ways of reducing the dimensionality of high-dimensional (text, image) data, so that structure can be found at a variety of levels. Additionally, new algorithms were developed to transfer knowledge between data that come from different sources (e.g. text documents in English and Arabic, where the surface level features (words) are entirely different; or two different proteins). These new developments extend the field of machine learning in new directions, building closer connections to classical ideas in harmonic analysis. ??Applications of these algorithms to a variety of large data sets was undertaken. One challenging data set involves a set of 100,000 documents from the European Union, which has documents in 12 different languages (e.g., English, Italian, German etc.). To build correspondences between documents in different languages, one must find mappings that align latent (hidden) concepts, since the surface features (words) are entirely different. The multi-scale manifold alignment framework provides a powerful way to find correspondences between structured objects, by automatically finding latent features.\n\nAnother application involves the construction of compressed 3D object representations, an unsolved problem in computer graphics. 20 years from now, digital cameras may be capable of routinely taking high-resolution 3D digital images of the world around us. Conventional image compression methods, such as JPEG, do not extend to 3D representations. The multi-scale data analysis method explored in this project was applied to the problem of compressing 3D object representations, and was found to be more effective than previously proposed eigenvector methods.\n\nAnother dataset that has been used in this research is a collection of 5000 NSF Research Award abst..."
 }
}