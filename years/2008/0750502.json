{
 "awd_id": "0750502",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR  Phase II:   Ultra-Fast Software Image Reconstruction for Micro-CT",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gregory T. Baxter",
 "awd_eff_date": "2008-03-15",
 "awd_exp_date": "2011-08-31",
 "tot_intn_awd_amt": 490576.0,
 "awd_amount": 521394.0,
 "awd_min_amd_letter_date": "2008-03-12",
 "awd_max_amd_letter_date": "2010-09-16",
 "awd_abstract_narration": "The SBIR Phase II project aims to develop a software package that enables rapid image reconstruction for X-ray Micro-CT (computerized Tomography) imaging.   Over the last few years, Micro-CT has become a very valuable tool in pharmaceutical and basic research.  Current Micro-CT scanners have reached a resolution of 1 micrometer and thus allow high resolution in-vivo and ex-vivo three dimensional examination of entire small animals such as mice.  Other applications of Micro-CT range from functional imaging to use in material science.  Yet, high resolution reconstruction of a single data set can be extremely time intensive, thus limiting the use.  \r\n\r\nIf analysis software capable of speeding up image reconstruction by 2 or 3 orders of magnitude can be developed, such software would significantly decrease the time to analyze high-resolution Micro-CT images and would thus increase the utility of this powerful imaging method.  \r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeffrey",
   "pi_last_name": "Brokish",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jeffrey Brokish",
   "pi_email_addr": "brokish@instarecon.com",
   "nsf_id": "000304312",
   "pi_start_date": "2008-03-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "InstaRecon, Inc.",
  "inst_street_address": "414 Brookens Dr.",
  "inst_street_address_2": "",
  "inst_city_name": "Urbana",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173847530",
  "inst_zip_code": "618016720",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": null,
  "org_prnt_uei_num": null,
  "org_uei_num": "LJXECHU8C5J7"
 },
 "perf_inst": {
  "perf_inst_name": "InstaRecon, Inc.",
  "perf_str_addr": "414 Brookens Dr.",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618016720",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537300",
   "pgm_ele_name": "SBIR Phase II"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1491",
   "pgm_ref_txt": "BIOTECH, BIOCHEM & BIOMASS ENG"
  },
  {
   "pgm_ref_code": "1718",
   "pgm_ref_txt": "BIOINFORMATICS"
  },
  {
   "pgm_ref_code": "1719",
   "pgm_ref_txt": "COMPUTATIONAL BIOLOGY"
  },
  {
   "pgm_ref_code": "9183",
   "pgm_ref_txt": "GENERAL FOUNDATIONS OF BIOTECHNOLOGY"
  },
  {
   "pgm_ref_code": "BIOT",
   "pgm_ref_txt": "BIOTECHNOLOGY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 453488.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 67906.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goals of this SBIR Phase II project were to develop and rigorously evaluate prototype software for ultra-fast image reconstruction for x-ray Micro-CT imaging.&nbsp; The computational bottleneck in x-ray Micro-CT image reconstruction is the backprojection step of the industry standard filtered backprojection (FBP) algorithm, which can lead to waiting times of weeks for a high resolution reconstruction of a single data set, even with state of the art computational facilities.&nbsp; These delays and restricted capabilities limit the productivity of researchers in diverse fields ranging from drug development, where hundreds of animals are scanned in a single drug trial, to biology, to materials science and nanotechnology.</p>\n<p>The ultra-fast software developed in this project employs fundamentally new algorithms for tomographic reconstruction, which address the computational bottleneck of the backprojection step.&nbsp; Hierarchical backprojection (HBP) recursively breaks down the volume into smaller and smaller sub-volumes, reducing the amount of projection data at each step.&nbsp; At the end of the algorithm, small sub-volumes are reconstructed from a small set of projections.&nbsp; This reduces the computational cost of the reconstruction algorithmically, by performing fewer calculations, accelerating the reconstruction rates of high-resolution 3D Micro-CT images by 10x-100x (ten to a hundred fold), without increasing the cost of hardware.&nbsp; HBP provides higher speedup for larger images, as it reduces the complexity of the backprojection operation from O(N<sup>4</sup>) for FBP to O(N<sup>3</sup>logN).</p>\n<p>The first objective of the Phase II research was to develop automatic adaptation of the HBP algorithm to Micro-CT scanning geometry for optimum performance.&nbsp; The HBP algorithm is actually a family of algorithms, spanning the tradeoff between computational efficiency and image fidelity.&nbsp; A calibration modules serves as an automated mechanism is choosing the optimal configuration that delivers significant speedup without compromising image quality.&nbsp;&nbsp;</p>\n<p>The second objective was to extend the software to support super-high resolution data sets (up to 8Kx8K cross-sectional area).&nbsp; Here the data set sizes can grow beyond 500 GB, greatly exceeding system memory.&nbsp; The processing in the HBP algorithm was reorganized into subproblems with sizes amenable to the system memory constraints, with the hard disk serving as a caching mechanism for intermediate calculations.&nbsp; The algorithmic organization was chosen to minimize the impact of the disk reads and writes, preserving the delivered reconstruction acceleration.</p>\n<p>The third objective explored parallel models of execution for HBP.&nbsp; Initially, this dealt with explorations into multi-threaded implementations of the HBP algorithms for use on modern multi-core and multi-processor systems.&nbsp; The current implementation of the software supports up to 12 threads (i.e. a dual hex-core processor configuration).&nbsp; Later, the software was extended to support a cluster configuration of up to 4 nodes to further accelerate the reconstruction process.&nbsp; Finally, the use of a GPU (graphics processing units) as a reconstruction co-processor was evaluated, which had the potential of accelerating the reconstruction by over 2x.</p>\n<p>Working with collaborator and Micro-CT manufacturer SkyScan, the ultra-fast reconstruction software was augmented with SkyScan&rsquo;s communication API to enable seamless integration into their image formation process.&nbsp; The only thing that an end-user will notice is the substantial acceleration of the reconstruction.&nbsp; The software was tested extensively in-house, by our collaborator SkyScan, and at several alpha and beta test sites.&nbsp; Acceleration factors of 15x-80x were independently validated in these evaluations.</p>\n<p>The Ph...",
  "por_txt_cntn": "\nThe goals of this SBIR Phase II project were to develop and rigorously evaluate prototype software for ultra-fast image reconstruction for x-ray Micro-CT imaging.  The computational bottleneck in x-ray Micro-CT image reconstruction is the backprojection step of the industry standard filtered backprojection (FBP) algorithm, which can lead to waiting times of weeks for a high resolution reconstruction of a single data set, even with state of the art computational facilities.  These delays and restricted capabilities limit the productivity of researchers in diverse fields ranging from drug development, where hundreds of animals are scanned in a single drug trial, to biology, to materials science and nanotechnology.\n\nThe ultra-fast software developed in this project employs fundamentally new algorithms for tomographic reconstruction, which address the computational bottleneck of the backprojection step.  Hierarchical backprojection (HBP) recursively breaks down the volume into smaller and smaller sub-volumes, reducing the amount of projection data at each step.  At the end of the algorithm, small sub-volumes are reconstructed from a small set of projections.  This reduces the computational cost of the reconstruction algorithmically, by performing fewer calculations, accelerating the reconstruction rates of high-resolution 3D Micro-CT images by 10x-100x (ten to a hundred fold), without increasing the cost of hardware.  HBP provides higher speedup for larger images, as it reduces the complexity of the backprojection operation from O(N4) for FBP to O(N3logN).\n\nThe first objective of the Phase II research was to develop automatic adaptation of the HBP algorithm to Micro-CT scanning geometry for optimum performance.  The HBP algorithm is actually a family of algorithms, spanning the tradeoff between computational efficiency and image fidelity.  A calibration modules serves as an automated mechanism is choosing the optimal configuration that delivers significant speedup without compromising image quality.  \n\nThe second objective was to extend the software to support super-high resolution data sets (up to 8Kx8K cross-sectional area).  Here the data set sizes can grow beyond 500 GB, greatly exceeding system memory.  The processing in the HBP algorithm was reorganized into subproblems with sizes amenable to the system memory constraints, with the hard disk serving as a caching mechanism for intermediate calculations.  The algorithmic organization was chosen to minimize the impact of the disk reads and writes, preserving the delivered reconstruction acceleration.\n\nThe third objective explored parallel models of execution for HBP.  Initially, this dealt with explorations into multi-threaded implementations of the HBP algorithms for use on modern multi-core and multi-processor systems.  The current implementation of the software supports up to 12 threads (i.e. a dual hex-core processor configuration).  Later, the software was extended to support a cluster configuration of up to 4 nodes to further accelerate the reconstruction process.  Finally, the use of a GPU (graphics processing units) as a reconstruction co-processor was evaluated, which had the potential of accelerating the reconstruction by over 2x.\n\nWorking with collaborator and Micro-CT manufacturer SkyScan, the ultra-fast reconstruction software was augmented with SkyScan\u00c6s communication API to enable seamless integration into their image formation process.  The only thing that an end-user will notice is the substantial acceleration of the reconstruction.  The software was tested extensively in-house, by our collaborator SkyScan, and at several alpha and beta test sites.  Acceleration factors of 15x-80x were independently validated in these evaluations.\n\nThe Phase IIB work focused on extension and incorporation of new decomposition operators into the software, which provide a better quality/computational cost tradeoff than those used in the Phase II work.  The evaluation software wa..."
 }
}