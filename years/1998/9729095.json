{
 "awd_id": "9729095",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Time Course of Spoken Word Recognition",
 "cfda_num": "47.075",
 "org_code": "04040500",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Guy Van Orden",
 "awd_eff_date": "1998-04-15",
 "awd_exp_date": "2002-03-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "1998-04-23",
 "awd_max_amd_letter_date": "2000-05-16",
 "awd_abstract_narration": "Understanding the mechanisms by which people recognize spoken words in continuous speech is of central importance for theories of  how language is processed, how it develops, and how it is affected by  brain injury. An understanding of how people recognize words in continuous speech also provides valuable informative for researchers  developing speech recognition technology and human-computer  interaction systems.  It is well-established that during spoken word recognition listeners evaluate the unfolding input by activating a set of potential  lexical candidates which compete for recognition.   However, numerous questions remain about how the set of possibilities is established and how it is evaluated during real-time processing.  For example, little is known about  whether or not people are able to use fine-grained acoustic differences during initial word recognition.  Thus, it is not clear whether as the word `carpet` is heard in continuous speech, the word recognition system considers all words that begin with similar sequences of sounds, e.g., (car, card, etc.) or whether subtle differences in the length of vowels in one-syllable and polysyllabic words are used to restrict the set of alternatives. Questions like these have important implications for how we understand and model the word recognition system.  However, our ability to answer these questions has been limited because few of the experimental methods sensitive spoken word recognition can be used with continuous speech in natural tasks. This is an important limitation because natural speech often occurs in noisy conditions, there is considerable speaker variability, and linguistic units, such as the beginning and end of a word are not clearly marked in continuous speech.      The proposed research explores how candidate words are retrieved from memory and evaluated during continuous speech using: (a) experimental studies in English with digitized natural speech and synthesized speech; (b) computational modeling; and (c) experimental and computational explorations with artificial languages. The experiments measure eye-movements to objects in a circumscribed visual world, extending the methodology pioneered by the PI and his collaborators.  Participants will follow spoken instructions to pick up and move (with a mouse) line drawings of concrete objects on a computer monitor (e.g., `Pick up the candy. Now put it above the circle`.).  Preliminary studies have established that: (a) the pattern and timing of eye-movements are remarkably sensitive to the uptake of information, allowing for a detailed mapping of the nature of the candidate set and how it changes over time during continuous speech; and (b) there is a simple quantitative mapping from hypothesized underlying speech recognition processes to the probability of making an eye-movement to a target object, allowing for precise testing of different theories of word recognition. Moreover, the basic task, either with pictures or real objects, can be naturally extended for use with infants, young children, and neurologically-impaired populations.  The project should result in both methodological advances and in a body of empirical data important for scientists studying normal and impaired language processing, as well as for scientists developing speech recognition systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Tanenhaus",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Michael K Tanenhaus",
   "pi_email_addr": "mtan@bcs.rochester.edu",
   "nsf_id": "000387818",
   "pi_start_date": "1998-04-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Aslin",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Richard N Aslin",
   "pi_email_addr": "richard.aslin@yale.edu",
   "nsf_id": "000336579",
   "pi_start_date": "1998-04-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "910 GENESEE ST",
  "perf_city_name": "ROCHESTER",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146113847",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "118000",
   "pgm_ele_name": "HUMAN COGNITION & PERCEPTION"
  },
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0100",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0100",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0198",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0198",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0199",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0199",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 1998,
   "fund_oblg_amt": 110000.0
  },
  {
   "fund_oblg_fiscal_yr": 1999,
   "fund_oblg_amt": 94000.0
  },
  {
   "fund_oblg_fiscal_yr": 2000,
   "fund_oblg_amt": 96000.0
  }
 ],
 "por": null
}