{
 "awd_id": "0323693",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Feedback Control of Visual Appearance With Maximally Sensitive Sensors for Decentralized Event Detection and Security",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Radhakisan Baheti",
 "awd_eff_date": "2003-08-15",
 "awd_exp_date": "2007-07-31",
 "tot_intn_awd_amt": 256101.0,
 "awd_amount": 256101.0,
 "awd_min_amd_letter_date": "2003-08-07",
 "awd_max_amd_letter_date": "2003-08-07",
 "awd_abstract_narration": "\r\nIn many surveillance problems, one would use several c.c.d. (charged coupled device) cameras\r\nconnected in a network, that would generate a stream of images. The problem is to process the\r\nimage stream so as to detect a typical event in the scene from the observed recording of the image\r\nsequences. Such an event might be quantified, for example, by a sudden movement in the scene or\r\nexistence of an unfamiliar target. Difficulty in identifying an event is that the 'event characteristic'\r\nis hard to quantify and extracted from the complex scene imagery, a process that would typically\r\nrequired to be done in real time. Additional difficulty arises from the fact that a single view of the\r\nscene may not be enough to isolate an event - hence the need for multiple view over an interval of\r\ntime.\r\nWe propose that every visual stream be quantified and represented locally by an internal dy-namic\r\nmodel that produces its own spatiotemporal sequence. The importance of this internal repre-sentation\r\nis that it does not represent the entire scene, or all the events in the scene. Rather, its sole\r\npurpose is to amplify specific intruding event anywhere in the scene and to respond as to 'when'\r\nand 'where' it has occurred. The design problem that we propose to investigate is to synthesize\r\nthe internal dynamics so as to respond 'maximally' in presence of an intruding event as opposed\r\nto somewhat more routine events. The internal dynamics would be implemented on a processor\r\nlocally connected to the sensor and in its simplest form would be a directionally selective flow\r\nmodel with inputs from the scene images taken by the camera. The model parameters are tuned\r\nto respond to specific events in the scene. In order to be able to synthesize the above described\r\n'maximally sensitive sensor', we subdivide this project into three distinct parts.\r\nThe first is to introduce 'appearance models' to represent a sequence of images taken by a\r\ncamera. Such an appearance model results in a suitable data-compression and is particularly useful\r\nwhen a suitable set of appearances have to be isolated and detected in the scene. Our second goal\r\nis to introduce a suitable internal representation of the observed spatiotemporal signal using 'flow\r\nmodels'. The proposed flow models have flow velocities that are dependant on the direction of\r\npropagation and can be altered by the magnitude and position of the input target events. The flow\r\nmodels can be tuned by feedback to produce maximal activity to selected targets in the scene. Our\r\nthird goal is to network a distributed set of cameras, together with associated internal models, for\r\ndistributed detection. The model activity from each camera sensor, confirming detection of a local\r\nevent, is fused together in order to detect a spatio-temporal global event.\r\nThe intellectual merits of this project are described as follows. The first is Selective Encoding\r\nof the Spatio-Temporal Events in the Scene through Appearance Models. The second is Internal\r\nModelling and Feedback Tuning for Maximal Response. Finally the third is Decentralized Detec-tion\r\nand Feedback Control of the Network Structure.\r\nBroader impact of the proposal includes interaction between Signal Processing, Sensor Based\r\nControl and Sensor Networks. Feedback control for sensor tuning and network reconfiguration are\r\ntwo research areas that this proposal makes the most impact.\r\nThe project would be carried out by the PI with 2 PhD students at the Center for BioCybernetics\r\nand Intelligent Systems and would also provide an interdisciplinary training ground for senior\r\nundergraduates from Computer Science, Electrical and Systems Engineering.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bijoy",
   "pi_last_name": "Ghosh",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Bijoy K Ghosh",
   "pi_email_addr": "bijoy.ghosh@ttu.edu",
   "nsf_id": "000098417",
   "pi_start_date": "2003-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Washington University",
  "inst_street_address": "1 BROOKINGS DR",
  "inst_street_address_2": "",
  "inst_city_name": "SAINT LOUIS",
  "inst_state_code": "MO",
  "inst_state_name": "Missouri",
  "inst_phone_num": "3147474134",
  "inst_zip_code": "631304862",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MO01",
  "org_lgl_bus_name": "WASHINGTON UNIVERSITY, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "L6NFUM28LQM5"
 },
 "perf_inst": {
  "perf_inst_name": "Washington University",
  "perf_str_addr": "1 BROOKINGS DR",
  "perf_city_name": "SAINT LOUIS",
  "perf_st_code": "MO",
  "perf_st_name": "Missouri",
  "perf_zip_code": "631304862",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "MO01",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "151900",
   "pgm_ele_name": "INTEGRATIVE SYSTEMS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "7238",
   "pgm_ref_txt": "ENG ITR CORE ACTIVITIES"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0103",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0103",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2003,
   "fund_oblg_amt": 256101.0
  }
 ],
 "por": null
}