{
 "awd_id": "0324864",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "ITR:  Collaborative Research: Multi-Robot Emergency Response",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Darleen Fisher",
 "awd_eff_date": "2003-09-15",
 "awd_exp_date": "2011-02-28",
 "tot_intn_awd_amt": 1600000.0,
 "awd_amount": 1824825.0,
 "awd_min_amd_letter_date": "2003-09-11",
 "awd_max_amd_letter_date": "2010-06-23",
 "awd_abstract_narration": "This project, a collaborative with 03-24977 Kostas Daniilidis at University of Pennsylvania and 03-25017 Joel Burdick at California Institute of Technology, addresses research issues key to an important application of robot teams and information technology (emergency response in hazardous environments for various tasks). The research sets 6 goals:\r\n\tDevelopment of new algorithms that enable collaborative sensing.\r\n\tDevelopment of distributed localization/mapping methods that leverage capabilities of the heterogeneous robots.\r\n\tIn-depth study of communication issues with emphasis on transparent integration of ultra wideband communication methodologies.\r\n\tDevelopment of methods for team coordination and dynamic distribution of tasks to robots.\r\n\tCreation of algorithms for the presentation of sensory information to users.\r\n\tExperimental validation of the scalability of the aforementioned algorithms and techniques.\r\nThe PIs use the Scout and MegaScout robotic platforms designed at the University of Minnesota along with other testbeds at CalTech and U Penn to conduct the research. The project integrates the algorithms with first responder teams, emphasizing realistic scenarios; mentors students from underrepresented groups in order to retain them in CS/EE programs; conducts outreach activities through demonstrations at local schools and youth groups; conducts workshops that emphasize cross-disciplinary interaction; creates web resources; innovates classroom uses of multi-robot teams; and includes parts of the research in design projects for seniors. The project also includes international collaboration with groups at NTUA (Greece) and the University Louis Pasteur-Strasbourg I (France).\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nikolaos",
   "pi_last_name": "Papanikolopoulos",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Nikolaos P Papanikolopoulos",
   "pi_email_addr": "npapas@cs.umn.edu",
   "nsf_id": "000205563",
   "pi_start_date": "2003-09-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Maria",
   "pi_last_name": "Gini",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Maria L Gini",
   "pi_email_addr": "gini@cs.umn.edu",
   "nsf_id": "000468121",
   "pi_start_date": "2003-09-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Georgios",
   "pi_last_name": "Giannakis",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Georgios B Giannakis",
   "pi_email_addr": "georgios@umn.edu",
   "nsf_id": "000472431",
   "pi_start_date": "2003-09-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Baoquan",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Baoquan Chen",
   "pi_email_addr": "baoquan@cs.umn.edu",
   "nsf_id": "000168552",
   "pi_start_date": "2003-09-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Stergios",
   "pi_last_name": "Roumeliotis",
   "pi_mid_init": "I",
   "pi_sufx_name": "",
   "pi_full_name": "Stergios I Roumeliotis",
   "pi_email_addr": "stergios@cs.umn.edu",
   "nsf_id": "000487045",
   "pi_start_date": "2003-09-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "University of Minnesota-Twin Cities",
  "perf_str_addr": "2221 UNIVERSITY AVE SE STE 100",
  "perf_city_name": "MINNEAPOLIS",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "554143074",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MN05",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "763100",
   "pgm_ele_name": "ITR-NeTS"
  },
  {
   "pgm_ele_code": "576100",
   "pgm_ele_name": "IUCRC-Indust-Univ Coop Res Ctr"
  },
  {
   "pgm_ele_code": "168700",
   "pgm_ele_name": "ITR MEDIUM (GROUP) GRANTS"
  },
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "163100",
   "pgm_ele_name": "CIS-Civil Infrastructure Syst"
  },
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  },
  {
   "pgm_ref_code": "1654",
   "pgm_ref_txt": "HUMAN COMPUTER INTERFACE"
  },
  {
   "pgm_ref_code": "1686",
   "pgm_ref_txt": "ITR SMALL GRANTS"
  },
  {
   "pgm_ref_code": "1687",
   "pgm_ref_txt": "ITR MEDIUM (GROUP) GRANTS"
  },
  {
   "pgm_ref_code": "2890",
   "pgm_ref_txt": "CISE RESEARCH RESOURCES"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0103",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0103",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0104",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0104",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0105",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0105",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0106",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2003,
   "fund_oblg_amt": 400000.0
  },
  {
   "fund_oblg_fiscal_yr": 2004,
   "fund_oblg_amt": 312000.0
  },
  {
   "fund_oblg_fiscal_yr": 2005,
   "fund_oblg_amt": 362000.0
  },
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 394825.0
  },
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 312000.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 12000.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Emergency response is a significant component of modern society's ability to respond to a wide range of events. Examples of these events include&nbsp; earthquakes, floods, collapsed bridges, accidents, bomb blasts, etc. Currently&nbsp;emergency &nbsp;response often involves engaging and dispatching human resources to assess the situation and provide assistance.&nbsp;Human responders are often overloaded and the many false alarms could create a big burden on a system that already faces dwindling financial resources.&nbsp; This project's outcomes&nbsp;try to promote algorithms and robos that will augment the human responders' capabilities.&nbsp;&nbsp;</p>\n<p>&nbsp;</p>\n<p>We developed a marsupial robotic system based on the Loper platform (acting as the mothership) that could be quickly deployed to assess the damage. One of the challenges is how we can use multiple robots as optimal observers of events or the environment while we satisfy power constraints. In terms of immediacy and effectiveness, mobile robots acting as a sensor network (immediately deployed after a catastrophic event) provide an interesting solution.&nbsp; They can be deployed swiftly to cover immediate needs, and they can be packed up and moved to another area if needs change. However, as the duration of the mission in which they are used increases, the robotic team will run out of power. This work addresses some of the issues with keeping a robot team active while their batteries drain. Multiple task-reallocation methods are used in conjunction with an analysis of the effects of fixed vs. mobile robotic motherships. We also looked at the problem of understanding where to place cameras (mounted on robots) in a given scene. In our work, the cameras are actually modeled by individual mobile robots and the approach is to adapt their location as the scene changes. Our recent work expands the results a&nbsp; step further. In addition to assuming that cameras must move over time to respond to dynamic events, the amount of power available to the mobile cameras is constrained. Individual mobile cameras must seek a source of power when they are running low. Coordination between individual members of the team must occur when parts of the team are no longer able to perform their aspect of the mission.</p>\n<p>To support the multi-robot work, we also developed the Loper robotic platform which is a versatile mobile robot capable of operation in a number of environments. A unique combination of Tri-lobe wheels and a highly compliant chassis allow the Loper to easily traverse complex natural and man-made terrains. The hybrid quadruped design consists of a highly compliant chassis and four Tri-lobe wheels. Each Tri-lobe wheel is coupled directly to a high torque, highly accurate AC servo actuator. The direct coupling of the wheels to the motors creates a mechanically simple and robust system.</p>\n<p>We also worked and devised algorithms in the following pertinent&nbsp; problems:</p>\n<p>(i) In order for robots to navigate based on visual observations (from a camera), they need to distinguish between visual features that are close-by and those that are distant (i.e., in the horizon). The first ones can provide primarily information about the position of the robot while the latter are useful for determining the heading of the robot.&nbsp; We have introduced a novel framework for processing both types of features in a unified way without distinguishing their type. <br /><br />(ii) One of the key problems is simultaneous localization and mapping (SLAM) is to be able to determine the expected positioning accuracy of a robot given the accuracy of its sensors and the distribution of landmarks within the area it operates in.&nbsp; During this work, we have derived closed-form expressions for the robot's positioning accuracy independent of the heading precision. This was achieved by a new formulation of the SLAM problem refe...",
  "por_txt_cntn": "\nEmergency response is a significant component of modern society's ability to respond to a wide range of events. Examples of these events include  earthquakes, floods, collapsed bridges, accidents, bomb blasts, etc. Currently emergency  response often involves engaging and dispatching human resources to assess the situation and provide assistance. Human responders are often overloaded and the many false alarms could create a big burden on a system that already faces dwindling financial resources.  This project's outcomes try to promote algorithms and robos that will augment the human responders' capabilities.  \n\n \n\nWe developed a marsupial robotic system based on the Loper platform (acting as the mothership) that could be quickly deployed to assess the damage. One of the challenges is how we can use multiple robots as optimal observers of events or the environment while we satisfy power constraints. In terms of immediacy and effectiveness, mobile robots acting as a sensor network (immediately deployed after a catastrophic event) provide an interesting solution.  They can be deployed swiftly to cover immediate needs, and they can be packed up and moved to another area if needs change. However, as the duration of the mission in which they are used increases, the robotic team will run out of power. This work addresses some of the issues with keeping a robot team active while their batteries drain. Multiple task-reallocation methods are used in conjunction with an analysis of the effects of fixed vs. mobile robotic motherships. We also looked at the problem of understanding where to place cameras (mounted on robots) in a given scene. In our work, the cameras are actually modeled by individual mobile robots and the approach is to adapt their location as the scene changes. Our recent work expands the results a  step further. In addition to assuming that cameras must move over time to respond to dynamic events, the amount of power available to the mobile cameras is constrained. Individual mobile cameras must seek a source of power when they are running low. Coordination between individual members of the team must occur when parts of the team are no longer able to perform their aspect of the mission.\n\nTo support the multi-robot work, we also developed the Loper robotic platform which is a versatile mobile robot capable of operation in a number of environments. A unique combination of Tri-lobe wheels and a highly compliant chassis allow the Loper to easily traverse complex natural and man-made terrains. The hybrid quadruped design consists of a highly compliant chassis and four Tri-lobe wheels. Each Tri-lobe wheel is coupled directly to a high torque, highly accurate AC servo actuator. The direct coupling of the wheels to the motors creates a mechanically simple and robust system.\n\nWe also worked and devised algorithms in the following pertinent  problems:\n\n(i) In order for robots to navigate based on visual observations (from a camera), they need to distinguish between visual features that are close-by and those that are distant (i.e., in the horizon). The first ones can provide primarily information about the position of the robot while the latter are useful for determining the heading of the robot.  We have introduced a novel framework for processing both types of features in a unified way without distinguishing their type. \n\n(ii) One of the key problems is simultaneous localization and mapping (SLAM) is to be able to determine the expected positioning accuracy of a robot given the accuracy of its sensors and the distribution of landmarks within the area it operates in.  During this work, we have derived closed-form expressions for the robot's positioning accuracy independent of the heading precision. This was achieved by a new formulation of the SLAM problem referred to as the dual-map.\n\nand (iii) When robot teams cooperate to perform SLAM, one of the requirements is to be able to merge maps constructed independently by different r..."
 }
}