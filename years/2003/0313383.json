{
 "awd_id": "0313383",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ITR:     Objective Methods for Predicting and Optimizing Synthetic Speech Quality",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2003-09-01",
 "awd_exp_date": "2007-08-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 410000.0,
 "awd_min_amd_letter_date": "2003-08-01",
 "awd_max_amd_letter_date": "2004-08-27",
 "awd_abstract_narration": "The goal of this project is to improve the quality of text-to-speech synthesis.  Text-to-speech synthesis is an increasingly more widely used technology that plays a core role in automated information access by telephone, and universal access for individuals with visual or other challenges, and educational software.\r\n\r\nThe project focuses on how humans perceive acoustic discontinuities in speech.  Current text-to-speech synthesis technology operates by retrieving intervals of stored digitized speech from a database and splicing (\"concatenating\") them to form the output utterance.  Unavoidably, there are acoustic discontinuities at the time points where the successive speech intervals meet.  For reasons that are currently poorly understood, many of these acoustic discontinuities are not audible even when they seem large by any objective measure.  This relative insensitivity of human hearing is the reason that concatenative synthesis works at all.  However, conversely it also often occurs that seemingly small discontinuities are audible.  These facts raise the scientific question of how one can construct an objective acoustic discontinuity measure that accurately predicts from the quantitative, acoustic properties of two to-be-concatenated speech intervals whether humans will hear a discontinuity.\r\n\r\nThis question is not only of interest for a better understanding of human hearing, but is also of immediate practical relevance.  Many text-to-speech synthesis systems select speech intervals at run time from a large speech corpus.  During selection, the systems search through the space of all possible sequences of speech intervals that can be used for the utterance and selects the sequence that has the lowest overall objective cost measure, such as the Euclidean distance between the final frame and initial frame of two successive intervals.  However, research has already shown that this method and related methods do not predict well whether humans will hear a discontinuity.  The current research, by being explicitly focused on perceptually optimized objective cost measures, will directly contribute to the perceptual accuracy of cost measures and hence to synthesis quality.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jan",
   "pi_last_name": "van Santen",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Jan P van Santen",
   "pi_email_addr": "vansantj@ohsu.edu",
   "nsf_id": "000319411",
   "pi_start_date": "2003-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Oregon Health & Science University",
  "inst_street_address": "3181 SW SAM JACKSON PARK RD",
  "inst_street_address_2": "",
  "inst_city_name": "PORTLAND",
  "inst_state_code": "OR",
  "inst_state_name": "Oregon",
  "inst_phone_num": "5034947784",
  "inst_zip_code": "972393011",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "OR01",
  "org_lgl_bus_name": "OREGON HEALTH & SCIENCE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPSNT86JKN51"
 },
 "perf_inst": {
  "perf_inst_name": "Oregon Health & Science University, West Campus",
  "perf_str_addr": "20000 N.W. Walker Road",
  "perf_city_name": "Beaverton",
  "perf_st_code": "OR",
  "perf_st_name": "Oregon",
  "perf_zip_code": "970068921",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "OR01",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "168600",
   "pgm_ele_name": "ITR SMALL GRANTS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1654",
   "pgm_ref_txt": "HUMAN COMPUTER INTERFACE"
  },
  {
   "pgm_ref_code": "1687",
   "pgm_ref_txt": "ITR MEDIUM (GROUP) GRANTS"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0103",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0103",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0104",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0104",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2003,
   "fund_oblg_amt": 300000.0
  },
  {
   "fund_oblg_fiscal_yr": 2004,
   "fund_oblg_amt": 110000.0
  }
 ],
 "por": null
}