{
 "awd_id": "0328295",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research:     Monitoring Student State in Tutorial Spoken Dialogue",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2003-09-01",
 "awd_exp_date": "2006-07-31",
 "tot_intn_awd_amt": 270000.0,
 "awd_amount": 270000.0,
 "awd_min_amd_letter_date": "2003-08-15",
 "awd_max_amd_letter_date": "2005-05-02",
 "awd_abstract_narration": "This research investigates the feasibility and utility of monitoring student emotions in spoken dialogue tutorial systems.  While human tutors respond to both the content of student utterances and underlying perceived emotions, most tutorial dialogue systems cannot detect student emotions, and furthermore are text-based, which may limit their success at emotion prediction.  While there has been increasing interest in identifying problematic emotions (e.g. frustration, anger) in spoken dialogue applications such as call centers, little work has addressed the tutorial domain.\r\n\r\nThe PIs are investigating the use of lexical, syntactic, dialogue, prosodic and acoustic cues to enable a computer tutor to automatically predict and respond to student emotions.  The research is being performed in the context of ITSPOKE, a speech-based tutoring dialogue system for conceptual physics.  The PIs are recording students interacting with ITSPOKE, manually annotating student emotions in these as well as in human-human dialogues, identifying linguistic and paralinguistic cues to the annotations, and using machine learning to predict emotions from potential cues.  The PIs are then deriving strategies for adapting the system's tutoring based upon emotion identification.\r\n\r\nThe major scientific contribution will be an understanding of whether cues available to spoken dialogue systems can be used to predict emotion, and ultimately to improve tutoring performance.  The results will be of value to other applications that can benefit from monitoring emotional speech.  Progress towards closing the performance gap between human tutors and current machine tutors will also expand the usefulness of current computer tutors.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Julia",
   "pi_last_name": "Hirschberg",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Julia B Hirschberg",
   "pi_email_addr": "julia@cs.columbia.edu",
   "nsf_id": "000399629",
   "pi_start_date": "2003-08-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jennifer",
   "pi_last_name": "Venditti-Ramprashad",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Jennifer J Venditti-Ramprashad",
   "pi_email_addr": "jjv@cs.columbia.edu",
   "nsf_id": "000157676",
   "pi_start_date": "2003-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "615 W 131ST ST",
  "perf_city_name": "NEW YORK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100277922",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "727400",
   "pgm_ele_name": "HUMAN LANGUAGE & COMMUNICATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0103",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0103",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0104",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0104",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0105",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0105",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2003,
   "fund_oblg_amt": 90000.0
  },
  {
   "fund_oblg_fiscal_yr": 2004,
   "fund_oblg_amt": 90000.0
  },
  {
   "fund_oblg_fiscal_yr": 2005,
   "fund_oblg_amt": 90000.0
  }
 ],
 "por": null
}