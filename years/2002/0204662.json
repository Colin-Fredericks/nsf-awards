{
 "awd_id": "0204662",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "New Directions in Dimension Reduction",
 "cfda_num": "47.049",
 "org_code": "03040200",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Grace Yang",
 "awd_eff_date": "2002-07-01",
 "awd_exp_date": "2006-01-31",
 "tot_intn_awd_amt": 178543.0,
 "awd_amount": 178543.0,
 "awd_min_amd_letter_date": "2002-06-28",
 "awd_max_amd_letter_date": "2004-04-05",
 "awd_abstract_narration": "Abstract\r\n\r\nDMS-0204662\r\nPI: Bing Li\r\n\r\nThis research will develop methods in dimension reduction, which aim at increased accuracy and a wider spectrum of applications. Specifically, the work will proceed in three main directions. (1) The classical formulation makes the conditional density in regression the target for dimension reduction. This does not take into consideration that in many applications the primary interest centers in the conditional mean. Moreover, the classical formulation requires homoskedasticity among predictors, which can be too restrictive for some problems. To address these issues the investigator proposes to reformulate the problem as reducing the dimensions of the predictors as they appear in the conditional mean. This will allow further dimension reduction, it will improve accuracy and remove the requirement for homoskedasticity. (2) Within the classical formulation one cannot handle categorical predictors, which occur frequently in practice. This research will broaden the proposed formulation so that it can handle such cases. (3) It is then possible and natural to combine these two new elements to further develop a more focused, and less restricted dimension reduction method for conditional means for regressions involving categorical predictors. \r\n\r\nThe methods of dimension reduction were introduced originally to provide a comprehensive graphical tool for exploratory data analysis. Recently, active developments are under way due to the rapid growth of computing power; this has dramatically increased the scope and dimensions of the collected data sets. Besides its important role as a graphic method, dimension reduction is particularly useful in problems where interest lies in identifying connections among the variables, such as classification and clustering. It is also useful when the dimension of a data point exceeds the total number of data points, which is typically the case for many scientific data sets, such as gene expression data. But the available dimension reduction methods have several limitations, such as assuming homogeneity between predictors and not be able to handle categorical predictors. This research will tackle these limitations of the current methodology. \r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bing",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bing Li",
   "pi_email_addr": "bing@stat.psu.edu",
   "nsf_id": "000312183",
   "pi_start_date": "2002-06-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "201 OLD MAIN",
  "perf_city_name": "UNIVERSITY PARK",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168021503",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "PA15",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0102",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0102",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0103",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0103",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0104",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0104",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2002,
   "fund_oblg_amt": 63512.0
  },
  {
   "fund_oblg_fiscal_yr": 2003,
   "fund_oblg_amt": 65772.0
  },
  {
   "fund_oblg_fiscal_yr": 2004,
   "fund_oblg_amt": 49259.0
  }
 ],
 "por": null
}