{
 "awd_id": "0702798",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Mimir: A Geometric Approach to Multi-dimensional Program Profiling Architectures",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2007-09-01",
 "awd_exp_date": "2012-08-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 316000.0,
 "awd_min_amd_letter_date": "2007-08-17",
 "awd_max_amd_letter_date": "2010-04-09",
 "awd_abstract_narration": "CCF-0702798\r\n\r\nMimir: A Geometric Approach to Multi-dimensional Program Profiling Architectures\r\n\r\nTimothy P. Sherwood\r\n\r\nWhile mixed static-dynamic program analysis can be done completely in software through binary instrumentation, the amount of analysis that can be done at test-time is bounded by the performance impact that can be tolerated. The end goal of the Mimir project is to enable a new breed of hardware/software analysis tools, for researchers and system builders that can sift through on-line profile data at unprecedented speeds, yielding a highly accurate and timely image of computer system execution.  The cross-layer approach to be investigated combines the raw computational ability of custom architectures with the formal guarantees provided by carefully crafted stream algorithms. At a high level, the proposed algorithmic approach to profiling is grounded in geometry, implicitly motivated by the belief that many profiling patterns, trends, or anomalies have natural geometric representations that become discernible under a geometric lens.  At a low level, novel programmable hardware methods will provide a scalable and high performance substrate onto which these stream algorithms can be mapped. The combination of these two methods will allow online monitors to make streaming queries over live data at unprecedented speeds with the goal of enabling a new class of previously intractable dynamic analysis methods.\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "Sherwood",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy P Sherwood",
   "pi_email_addr": "sherwood@cs.ucsb.edu",
   "nsf_id": "000488790",
   "pi_start_date": "2007-08-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Subhash",
   "pi_last_name": "Suri",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Subhash Suri",
   "pi_email_addr": "suri@cs.ucsb.edu",
   "nsf_id": "000228429",
   "pi_start_date": "2007-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Barbara",
  "inst_street_address": "3227 CHEADLE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA BARBARA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8058934188",
  "inst_zip_code": "931060001",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SANTA BARBARA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G9QBQDH39DF4"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Barbara",
  "perf_str_addr": "3227 CHEADLE HALL",
  "perf_city_name": "SANTA BARBARA",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "931060001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "735200",
   "pgm_ele_name": "COMPUTING PROCESSES & ARTIFACT"
  },
  {
   "pgm_ele_code": "794400",
   "pgm_ele_name": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 109217.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 190783.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Software bugs are so damaging and widespread that they cost the U.S. economy an estimated $59.5 billion annually (more than half a percent of the GNP). Although it is certainly not possible to remove all errors, it is estimated that more than a third of the cost associated with bugs could be eliminated through an improved testing and analysis infrastructure. This grant funded new science aimed at developing the sophisticated software analysis and testing tools needed to discover complex pointer errors, memory leaks, race conditions, and performance anomalies from a sea of runtime data.</p>\n<p>Specifically, the Mimir project was successful in creating a new breed of hardware/software analysis tools (for researchers and system builders) that can sift through on-line profile data at unprecedented speeds, yielding a highly accurate and timely image of system execution. The techniques developed are useful in a variety of profiling situations, incur very little overhead even during complex on-line profile analysis, and provide guarantees of bounded error. Importantly, this meant showing not just how to do these analysis on pen and paper, but to scale the system to handle profile data at hundreds of gigabytes per second, the ability to perform significant streaming computation over irregular data structures, and non-trivial data aggregation and query methods. The key to success for this project was a cross-layer approach that combines the raw computational ability of custom architectures with the formal guarantees provided by carefully crafted stream algorithms.</p>\n<p>There were three major intellectual challenges to realizing a stream algorithm based profiling model: The first challenge was finding ways by which long slices of data can be extracted efficiently from an executing machine. Here we demonstrated that experimental new interconnect technologies, such as 3d-integration, offer a novel ability to include \"snap-on\" profiling functionality yielding access to processor signals at a rate of terabits/sec.&nbsp; The second challenge was managing this immense fountain of data; new online methods were used that operated on data in a streaming fashion to prevent storing all of this data for post processing. At a high level, our algorithmic approach to profiling is grounded in geometry, implicitly motivated by the belief that many profiling patterns, trends, or anomalies have natural geometric representations that become discernible under a geometric lens. The third challenge was in building a system that can implement a broad class of online program analysis algorithms, including the above streaming algorithms, in a high throughput and programmable way. Here we demonstrated that such an analysis can be efficiently supported on a reconfigurable logic platform, and building such a prototype system for the first time netted the researchers a best paper award from the International Conference on Parallel Architectures and Compilation Techniques in 2009.&nbsp; Our algorithmic approach to profiling builds upon concepts in computational geometry, driven by the understanding that many online program analysis problems have natural representation in geometric terms. Counting and tracking edges is a problem in the two dimensional space of code address x code address. Even race conditions are queries in the space of threadsets and virtual clocks. While this is not the way such problems are normally framed, in doing so we brought to bear the significant power of existing and developing streaming geometry algorithms. Our preliminary work on Range Adaptive Profiling is a geometric approach to tracking simple profile types (such as basic block execution frequencies, or the value profiling example above) and it describes a new and general purpose profiling method capable of hierarchically classifying streams of data efficiently in hardware.</p>\n<p>With respect to the broader impact of the...",
  "por_txt_cntn": "\nSoftware bugs are so damaging and widespread that they cost the U.S. economy an estimated $59.5 billion annually (more than half a percent of the GNP). Although it is certainly not possible to remove all errors, it is estimated that more than a third of the cost associated with bugs could be eliminated through an improved testing and analysis infrastructure. This grant funded new science aimed at developing the sophisticated software analysis and testing tools needed to discover complex pointer errors, memory leaks, race conditions, and performance anomalies from a sea of runtime data.\n\nSpecifically, the Mimir project was successful in creating a new breed of hardware/software analysis tools (for researchers and system builders) that can sift through on-line profile data at unprecedented speeds, yielding a highly accurate and timely image of system execution. The techniques developed are useful in a variety of profiling situations, incur very little overhead even during complex on-line profile analysis, and provide guarantees of bounded error. Importantly, this meant showing not just how to do these analysis on pen and paper, but to scale the system to handle profile data at hundreds of gigabytes per second, the ability to perform significant streaming computation over irregular data structures, and non-trivial data aggregation and query methods. The key to success for this project was a cross-layer approach that combines the raw computational ability of custom architectures with the formal guarantees provided by carefully crafted stream algorithms.\n\nThere were three major intellectual challenges to realizing a stream algorithm based profiling model: The first challenge was finding ways by which long slices of data can be extracted efficiently from an executing machine. Here we demonstrated that experimental new interconnect technologies, such as 3d-integration, offer a novel ability to include \"snap-on\" profiling functionality yielding access to processor signals at a rate of terabits/sec.  The second challenge was managing this immense fountain of data; new online methods were used that operated on data in a streaming fashion to prevent storing all of this data for post processing. At a high level, our algorithmic approach to profiling is grounded in geometry, implicitly motivated by the belief that many profiling patterns, trends, or anomalies have natural geometric representations that become discernible under a geometric lens. The third challenge was in building a system that can implement a broad class of online program analysis algorithms, including the above streaming algorithms, in a high throughput and programmable way. Here we demonstrated that such an analysis can be efficiently supported on a reconfigurable logic platform, and building such a prototype system for the first time netted the researchers a best paper award from the International Conference on Parallel Architectures and Compilation Techniques in 2009.  Our algorithmic approach to profiling builds upon concepts in computational geometry, driven by the understanding that many online program analysis problems have natural representation in geometric terms. Counting and tracking edges is a problem in the two dimensional space of code address x code address. Even race conditions are queries in the space of threadsets and virtual clocks. While this is not the way such problems are normally framed, in doing so we brought to bear the significant power of existing and developing streaming geometry algorithms. Our preliminary work on Range Adaptive Profiling is a geometric approach to tracking simple profile types (such as basic block execution frequencies, or the value profiling example above) and it describes a new and general purpose profiling method capable of hierarchically classifying streams of data efficiently in hardware.\n\nWith respect to the broader impact of the work completed, in addition to addressing an important problem facing the information tec..."
 }
}