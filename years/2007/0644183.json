{
 "awd_id": "0644183",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Cross-Layer Schemes For Flexible Resource Sharing in Multicore Systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Hong Jiang",
 "awd_eff_date": "2007-08-01",
 "awd_exp_date": "2013-07-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2007-05-07",
 "awd_max_amd_letter_date": "2011-07-04",
 "awd_abstract_narration": "PROJECT ABSTRACT:\r\n\r\nThe proposal addresses the challenge of flexibly and efficiently managing the allocation of shared caches and shared memory bandwidth among applications/threads for diverse sharing scenarios (co-operative, competitive and adversarial) in multicore systems. The proposed solution which spans the hardware, operating system (OS) and application layers, consists of two parts, one at the hardware-OS boundary and another at the OS-application boundary. The first part proposes a hardware-assisted, OS-driven resource allocation technique that effectively combines the flexibility of OS-based resource management with the efficiency of hardware resource management. The second part proposes adoption of currency-based market mechanisms at the application/OS boundary wherein contenders negotiate/bid for access to resources in exchange for some notional currency. Market mechanisms, which have been studied for other resource allocation problems, incentivize good behavior because it is in the participants' interest to make efficient use of resources and release resources that are not used. \r\nIn the specific context of shared caches and shared memory bandwidth, market mechanisms allow development of sophisticated management policies with prioritization across and within applications. With appropriate interfaces, they also enable several other optimizations at the OS and application layers such as (a) adaptive applications that modify their behavior according to resource availability, (b) co-scheduling of sharers with complementary resource needs and (c) demand-driven pricing\" of resources.\r\n\r\nThe key components of the education plan include (a) integration of parallelism and multicore  concepts into the graduate and undergraduate computer architecture related courses, (b) development of a graduate-level, advanced computer architecture course to focus on architecture design patterns recurring architecture optimizations similar to the high-level, object-oriented programming design patterns\" \r\ncaptured by Gamma et.al. and (c) fostering research participation at both undergraduate and graduate levels.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mithuna",
   "pi_last_name": "Thottethodi",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Mithuna S Thottethodi",
   "pi_email_addr": "mithuna@purdue.edu",
   "nsf_id": "000253970",
   "pi_start_date": "2007-05-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "2550 NORTHWESTERN AVE # 1100",
  "perf_city_name": "WEST LAFAYETTE",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479061332",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735200",
   "pgm_ele_name": "COMPUTING PROCESSES & ARTIFACT"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "2884",
   "pgm_ref_txt": "NEXT GENERATION SOFTWARE PROGR"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "0100999999",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 50000.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 50000.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 50000.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 50000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Shared resources in multicore servers, unless carefully managed, can result in destructive interference among the processes/threads/applications that use these resources. This project addresses the challenge of designing mechanisms and policies to manage such shared resources to minimize such destructive interference. The project addresses shared resources within a single multicore server (e.g., shared cache capacity, shared memory bandwidth and shared interconnect bandwidth) as well as shared pools of resources such as clusters of servers that are used as memory-caching pools in the cloud computing context.</p>\n<p>The key outcomes of this project are as follows:</p>\n<p>&nbsp;The project developed mechanisms and policies that span the operating system (OS) and architecture layers to manage shared memory (DRAM) bandwidth. We extend the design to enable a unified mechanism that supports both shared cache and shared memory bandwidth management. Further the unified mechanism can allow for hierarchical management of shared resources in virtualized environments. For example, at the lowest level, the hypervisor may manage resource allocation among guest operating systems; each guest OS may then hierarchically manage its resource allocation among its own applications/processes.<br /><br />The project also addressed shared interconnect bandwidth and developed a cross-layer technique that spans the compiler layer and the hardware layer to provide optimal application specific network bandwidth. Effectively, the technique enables communication routing with minimal interference on shared network links.</p>\n<p>Beyond a single multicore node, the project developed cost-minimizing resource provisioning techniques in certain cloud computing environments (specifically, infrastructure-as-a-service environments such as Amazon EC2). &nbsp;This outcome enables significant cost savings for users of cloud services while retaining the statistical performance guarantees of running with dedicated server pool.</p>\n<p>Finally, the project also developed automatic load-balancing techniques for shared pools of memory-caching servers which are a key part of the infrastructure at many large companies such as Facebook, Google, and Yahoo. Compared to a popular memory caching architecture, the new design with improved load balancing &nbsp;can achieve similar performance with fewer servers or significantly better performance with the same number of servers.&nbsp;</p>\n<p>In addition to the above research outcomes, the project also supported the training of multiple graduate students in key aspects of computer and systems architecture. The research on this project directly lead to the Ph.D. thesis research and final dissertation of two graduate students.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/19/2014<br>\n\t\t\t\t\tModified by: Mithuna&nbsp;S&nbsp;Thottethodi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nShared resources in multicore servers, unless carefully managed, can result in destructive interference among the processes/threads/applications that use these resources. This project addresses the challenge of designing mechanisms and policies to manage such shared resources to minimize such destructive interference. The project addresses shared resources within a single multicore server (e.g., shared cache capacity, shared memory bandwidth and shared interconnect bandwidth) as well as shared pools of resources such as clusters of servers that are used as memory-caching pools in the cloud computing context.\n\nThe key outcomes of this project are as follows:\n\n The project developed mechanisms and policies that span the operating system (OS) and architecture layers to manage shared memory (DRAM) bandwidth. We extend the design to enable a unified mechanism that supports both shared cache and shared memory bandwidth management. Further the unified mechanism can allow for hierarchical management of shared resources in virtualized environments. For example, at the lowest level, the hypervisor may manage resource allocation among guest operating systems; each guest OS may then hierarchically manage its resource allocation among its own applications/processes.\n\nThe project also addressed shared interconnect bandwidth and developed a cross-layer technique that spans the compiler layer and the hardware layer to provide optimal application specific network bandwidth. Effectively, the technique enables communication routing with minimal interference on shared network links.\n\nBeyond a single multicore node, the project developed cost-minimizing resource provisioning techniques in certain cloud computing environments (specifically, infrastructure-as-a-service environments such as Amazon EC2).  This outcome enables significant cost savings for users of cloud services while retaining the statistical performance guarantees of running with dedicated server pool.\n\nFinally, the project also developed automatic load-balancing techniques for shared pools of memory-caching servers which are a key part of the infrastructure at many large companies such as Facebook, Google, and Yahoo. Compared to a popular memory caching architecture, the new design with improved load balancing  can achieve similar performance with fewer servers or significantly better performance with the same number of servers. \n\nIn addition to the above research outcomes, the project also supported the training of multiple graduate students in key aspects of computer and systems architecture. The research on this project directly lead to the Ph.D. thesis research and final dissertation of two graduate students.\n\n\t\t\t\t\tLast Modified: 01/19/2014\n\n\t\t\t\t\tSubmitted by: Mithuna S Thottethodi"
 }
}