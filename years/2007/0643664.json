{
 "awd_id": "0643664",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Modeling Data Locality For Next Generation Systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2007-04-15",
 "awd_exp_date": "2015-03-31",
 "tot_intn_awd_amt": 316960.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2007-04-09",
 "awd_max_amd_letter_date": "2014-01-13",
 "awd_abstract_narration": "Although the introduction of multi-core systems has increased overall processor speed without significantly increasing CPU clock rates, a significant speed disparity remains between the CPU core and main memory. Multi-level caches have long been used to bridge this gap. Conventional cache design favors applications with good locality.  The community's understanding of locality, however, is more qualitative than quantitative.  A quantitative understanding of locality is essential to exploit memory hierarchy and achieve maximal performance.  The new generation of multi-core systems adds the challenge of quantifying data locality for multi-threaded programs.\r\n\r\nThis research models data locality as a function of three parameters: data size, path history, and thread count, relying on close cooperation among the compiler, the profiler, and hardware just-in-time monitoring.  The compiler provides a global view of the program. The profiler, using traces, has a view of the run-time behavior of a program, but this view is based on only a limited number of training inputs. Although the hardware's view is run specific, its prediction, often depending on hardware buffers, is not always effective due to buffer size limitations.  The cooperative model being developed combines the advantages of static analysis and run-time sampling and profiling, providing an accurate view of program locality for both single-threaded and multi-threaded programs.  Given this model the project explores memory system performance including managing data movement in conventional multi-level cache as well as non-uniform cache architecture (NUCA) caches, reducing the memory traffic of a state-of-the-art hardware-only region prefetcher, and improving spatial locality of Java programs.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zhenlin",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zhenlin Wang",
   "pi_email_addr": "zlwang@mtu.edu",
   "nsf_id": "000105719",
   "pi_start_date": "2007-04-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Michigan Technological University",
  "inst_street_address": "1400 TOWNSEND DR",
  "inst_street_address_2": "",
  "inst_city_name": "HOUGHTON",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "9064871885",
  "inst_zip_code": "499311200",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MI01",
  "org_lgl_bus_name": "MICHIGAN TECHNOLOGICAL UNIVERSITY",
  "org_prnt_uei_num": "GKMSN3DA6P91",
  "org_uei_num": "GKMSN3DA6P91"
 },
 "perf_inst": {
  "perf_inst_name": "Michigan Technological University",
  "perf_str_addr": "1400 TOWNSEND DR",
  "perf_city_name": "HOUGHTON",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "499311200",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "MI01",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "732900",
   "pgm_ele_name": "COMPILERS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "0100999999",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 74876.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 162161.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 79541.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 83422.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The research goal of this award is to model and predict data locality for modern architectures and applications, With better locality models, we are able to develop techniques to improve performance for modern applications and data centers.<br /><br />We have developed a series of models and techniques to explore how data is accessed in a system. The research community terms the property of data accesses and their reuses ``locality''. Locality modeling is a key to tackle the dilemma between enormous amount of data and limited capacity of computer systems. Our research finding on application and system locality shows that future data accesses are highly predictable with limited online sampling and/or offline analysis. This research opens a new path for compiler optimization, operating system and architecture design. We have applied and extended our locality models to guide cache partitioning and improve the overall throughput of a multi-core machine. We have developed a cross-architecture co-run performance regression model. This model helps us to better understand the impact of different memory architectures on the performance of multiple applications that share cache and memory bandwidth. We have designed a low-overhead dynamic locality model that predicts memory demands of a virtual machine. Using this model to balance memory allocation in a virtualized system, the overall system performance can be significantly improved. Dynamic memory resource allocation can help a data center reduce it operating cost without sacrificing quality of service (QoS). Our research can thus benefit data centers as well as cloud computing users.<br /><br />With a better understanding of applications' behavior, we have improved the state-of-the-art C/C++ memory allocators so they can better fit into modern data centers that employ virtualization technology. With our algorithms, we show that some hardware support for memory virtualization is no longer necessary and can be replaced by a software solution. This research will lead us to reconsider memory management algorithms and runtime system design for cloud computing. Our work on data server key-value memory caching shows that data center requests that benefit from memory caching to boost performance still pertain strong locality. We propose a locality-based memory allocation scheme to manage memory cache allocation dynamically and effectively improve its performance. <br /><br />The project has helped to train and educate four PhD students and five masters students in the Department of Computer Science at Michigan Tech. One PhD and four masters students graduated with the support of this grant. Another PhD student is expected to receive his PhD in a year. The grant has supported, in part, 11 Conference papers, 6 workshop, abstract, or short papers, and 5 journal papers.<br /><br />Two new courses, ``Virtual Machines'' and ``Cloud Computing'' were introduced into the PI's department. The results in this research have been integrated into the curricula. The PI has also developed a module to attract high school students into computer science through the summer youth program at Michigan Tech.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/12/2015<br>\n\t\t\t\t\tModified by: Zhenlin&nbsp;Wang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe research goal of this award is to model and predict data locality for modern architectures and applications, With better locality models, we are able to develop techniques to improve performance for modern applications and data centers.\n\nWe have developed a series of models and techniques to explore how data is accessed in a system. The research community terms the property of data accesses and their reuses ``locality''. Locality modeling is a key to tackle the dilemma between enormous amount of data and limited capacity of computer systems. Our research finding on application and system locality shows that future data accesses are highly predictable with limited online sampling and/or offline analysis. This research opens a new path for compiler optimization, operating system and architecture design. We have applied and extended our locality models to guide cache partitioning and improve the overall throughput of a multi-core machine. We have developed a cross-architecture co-run performance regression model. This model helps us to better understand the impact of different memory architectures on the performance of multiple applications that share cache and memory bandwidth. We have designed a low-overhead dynamic locality model that predicts memory demands of a virtual machine. Using this model to balance memory allocation in a virtualized system, the overall system performance can be significantly improved. Dynamic memory resource allocation can help a data center reduce it operating cost without sacrificing quality of service (QoS). Our research can thus benefit data centers as well as cloud computing users.\n\nWith a better understanding of applications' behavior, we have improved the state-of-the-art C/C++ memory allocators so they can better fit into modern data centers that employ virtualization technology. With our algorithms, we show that some hardware support for memory virtualization is no longer necessary and can be replaced by a software solution. This research will lead us to reconsider memory management algorithms and runtime system design for cloud computing. Our work on data server key-value memory caching shows that data center requests that benefit from memory caching to boost performance still pertain strong locality. We propose a locality-based memory allocation scheme to manage memory cache allocation dynamically and effectively improve its performance. \n\nThe project has helped to train and educate four PhD students and five masters students in the Department of Computer Science at Michigan Tech. One PhD and four masters students graduated with the support of this grant. Another PhD student is expected to receive his PhD in a year. The grant has supported, in part, 11 Conference papers, 6 workshop, abstract, or short papers, and 5 journal papers.\n\nTwo new courses, ``Virtual Machines'' and ``Cloud Computing'' were introduced into the PI's department. The results in this research have been integrated into the curricula. The PI has also developed a module to attract high school students into computer science through the summer youth program at Michigan Tech.\n\n\t\t\t\t\tLast Modified: 06/12/2015\n\n\t\t\t\t\tSubmitted by: Zhenlin Wang"
 }
}