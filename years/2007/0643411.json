{
 "awd_id": "0643411",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Advanced End-to-End Cyberinfrastructure Installation, Validation, and Optimization for the Barrow Global Climate Change Research Facility",
 "cfda_num": "47.078",
 "org_code": "06090100",
 "po_phone": "7032924482",
 "po_email": "rcrain@nsf.gov",
 "po_sign_block_name": "Renee Crain",
 "awd_eff_date": "2007-09-15",
 "awd_exp_date": "2011-08-31",
 "tot_intn_awd_amt": 1787509.0,
 "awd_amount": 2114821.0,
 "awd_min_amd_letter_date": "2007-09-17",
 "awd_max_amd_letter_date": "2010-06-30",
 "awd_abstract_narration": "Given the need to understand global climate change and its likely effects upon daily life in the Arctic and the need for more and better data for global models, Congress has funded construction of a Barrow Global Climate Change Research Facility (BGCCRF) to replace the aging Naval Arctic Research Laboratory (NARL). NSF, acknowledging the key role of information technology (IT) in Earth System Science, is supporting this proposal by the BGCCRF operator, the Barrow Arctic Science Consortium (BASC), to design and install the facility's information architecture. This project delivers modern IT infrastructure and an approach to instrumentation that is based around the new BGCCRF with a wireless radius of about 10 miles around the BGCCRF. This wireless radius focuses on supporting work in the Barrow Environmental Observatory (BEO), on coastal sea-ice, and research vessels offshore. BASC is drawing on faculty at the University of Cincinnati (UC) and IT professionals at the University of Alaska Fairbanks (UAF) to meet these needs. The IT effort here will support the approximately 30-40 active NSF research projects as well as other agency projects in the Barrow area. The proposal includes UC and UAF working jointly on the infrastructure and instrumentation plan, with UC focusing on developing a wireless radius of about 10 miles around the BGCCRF. This proposal covers the wireless radius and the solid cyberinfrastructure of the new science support facility. To develop the plan implemented here, BASC convened three national science community meetings on IT planning. Two focused on user needs assessment. The 1st, in Williamsburg in 2003, identified funding agencies' (NOAA, NSF, NASA, DOE, etc.) scientists' needs. Convened by UC faculty, two dozen network engineers, federal agency representatives and academic IT experts attended, targeting federal agency bandwidth, acceptable use policy and IT security requirements. The 2nd meeting (Boulder 2004) assessed end-user (scientist) needs. Several dozen current and potential Barrow researchers attended. A straw person information architecture was developed from these meetings, then reviewed, refined and vetted at a 3rd meeting held in Barrow in January 2006, that took into account more recent and definite construction and budget constraints. This project slightly modifies those recommendations to keep the overall project costs reasonable while meeting the essential needs of the research community in the Barrow area. The improved IT capability in the Barrow area will better enable wireless connectivity to instrumentation and data flow back to researchers' home institutions as well as improve local network stability and connectivity to the internet.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "GEO",
 "org_dir_long_name": "Directorate for Geosciences",
 "div_abbr": "OPP",
 "org_div_long_name": "Office of Polar Programs (OPP)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Machida",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Richard Machida",
   "pi_email_addr": "rm@alaska.edu",
   "nsf_id": "000462619",
   "pi_start_date": "2007-09-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Alaska Fairbanks Campus",
  "inst_street_address": "2145 N TANANA LOOP",
  "inst_street_address_2": "",
  "inst_city_name": "FAIRBANKS",
  "inst_state_code": "AK",
  "inst_state_name": "Alaska",
  "inst_phone_num": "9074747301",
  "inst_zip_code": "997750001",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "AK00",
  "org_lgl_bus_name": "UNIVERSITY OF ALASKA FAIRBANKS",
  "org_prnt_uei_num": "",
  "org_uei_num": "FDLEQSJ8FF63"
 },
 "perf_inst": {
  "perf_inst_name": "University of Alaska Fairbanks Campus",
  "perf_str_addr": "2145 N TANANA LOOP",
  "perf_city_name": "FAIRBANKS",
  "perf_st_code": "AK",
  "perf_st_name": "Alaska",
  "perf_zip_code": "997750001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "AK00",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "520500",
   "pgm_ele_name": "ARC Rsch Support & Logistics"
  },
  {
   "pgm_ele_code": "521900",
   "pgm_ele_name": "ARCSS-Arctic System Science"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "1079",
   "pgm_ref_txt": "ARCTIC RESEARCH"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "02XX",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "0100CYXXDB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 1026990.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 352201.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 408318.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 327312.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In March, 2008, nine months after the grand opening, the Barrow Arctic Science Center (BARC) was turned over from the construction contractors to allow the installation of the information technology infrastructure. Network equipment was installed to provide 10/100/1000 copper connections to approximately 20% of the network jacks in the building. Server infrastructure was set up to provide network services, storage, authentication, voice over IP (VoIP) and the ability to set up virtual machines to support specific projects as needed by the research community. Later, video encoding servers were added as well as network flow capture and analysis hosts.</p>\n<p>In the BARC large conference room, audio and video live capture equipment was installed to easily record lectures, classes and conferences. Standards based video conferencing equipment was also installed in the BARC as well as the conference room in NARL-360 and has been used to support classes and for outreach activities. Flexible video routing using a matrix switch allowed technicians to easily route audio and video content throughout the facility. From June 2010 through December 2011, at least 1 lecture or class session per week was captured and encoded. Many were made availble as podcasts and through the University of Alaska (UAF) iTuneU site.</p>\n<p>VoIP instruments were installed throughout the facility and later the scope was expanded to include other labs and residential huts used by visiting researchers scattered througout the NARL campus. An existing point to multipoint network was utilized to interconnect these other buildings. The software used for VoIP is a mixture of multiple open souce packages. OpenSER, an offshoot of SIP Express Router, is being used for the SIP proxy and Asterisk for voice mail and a rudimentary menu system. OpenSER was chosen to support the anticipated additional phases of building construction envisioned by UIC, the owner of the facility. The system will be replaced with Asterisk for simplicity now that the capacity and flexibility provided by OpenSER is no longer needed. A controller-based wireless network was installed throughout the NARL campus using the same point-to-multipoint network infrastructure. In 2011, the scope of support was expanded to also include the point-to-point links supporting remote sites such as the Barrow Environmental Observatory (BEO) control shed and the Cakeeater Lab. The UAF staff also provided support and materials for the 700 mHz WipLL system which provided wide-area network access to NSF researchers.</p>\n<p>Initially, four T1 point-to-point circuits were installed from NARL-360 to the UAF campus to provide researcher access to the commodity Internet as well as Internet2. To reduce costs, the number of T1 circuits was cut in half. In January, 2011, the two T1 circuits was replaced by a virtual private lan service increasing the bandwidth from 3mbps to 5mbps at no additional cost. Connectivity to Barrow is still only via geosynchronous satellite so latency remains an issue. The network performance of individual hosts were optimized by increasing the TCP window size as well as using UDP whenever possible. IPv4 multicast was enabled early on as a method for Barrow based staff to participate in tech events such as ACM meetings or the Internet2 Joint Techs. We also experimented with hosting multicast streams from the BARC to receivers scattered throughout the higher ed community. Multicast remains available only within the research and education networks such as Internet2 in the United States and not at all on the commodity Internet. IPv6 addresses have been assigned to the site by UAF but we have not received a request for the service.</p>\n<p>In 2010, the scope was expanded to include network flow accounting to track Internet usage by project and by type. A combination of open source software and customized Perl scripts were used to collect the flow...",
  "por_txt_cntn": "\nIn March, 2008, nine months after the grand opening, the Barrow Arctic Science Center (BARC) was turned over from the construction contractors to allow the installation of the information technology infrastructure. Network equipment was installed to provide 10/100/1000 copper connections to approximately 20% of the network jacks in the building. Server infrastructure was set up to provide network services, storage, authentication, voice over IP (VoIP) and the ability to set up virtual machines to support specific projects as needed by the research community. Later, video encoding servers were added as well as network flow capture and analysis hosts.\n\nIn the BARC large conference room, audio and video live capture equipment was installed to easily record lectures, classes and conferences. Standards based video conferencing equipment was also installed in the BARC as well as the conference room in NARL-360 and has been used to support classes and for outreach activities. Flexible video routing using a matrix switch allowed technicians to easily route audio and video content throughout the facility. From June 2010 through December 2011, at least 1 lecture or class session per week was captured and encoded. Many were made availble as podcasts and through the University of Alaska (UAF) iTuneU site.\n\nVoIP instruments were installed throughout the facility and later the scope was expanded to include other labs and residential huts used by visiting researchers scattered througout the NARL campus. An existing point to multipoint network was utilized to interconnect these other buildings. The software used for VoIP is a mixture of multiple open souce packages. OpenSER, an offshoot of SIP Express Router, is being used for the SIP proxy and Asterisk for voice mail and a rudimentary menu system. OpenSER was chosen to support the anticipated additional phases of building construction envisioned by UIC, the owner of the facility. The system will be replaced with Asterisk for simplicity now that the capacity and flexibility provided by OpenSER is no longer needed. A controller-based wireless network was installed throughout the NARL campus using the same point-to-multipoint network infrastructure. In 2011, the scope of support was expanded to also include the point-to-point links supporting remote sites such as the Barrow Environmental Observatory (BEO) control shed and the Cakeeater Lab. The UAF staff also provided support and materials for the 700 mHz WipLL system which provided wide-area network access to NSF researchers.\n\nInitially, four T1 point-to-point circuits were installed from NARL-360 to the UAF campus to provide researcher access to the commodity Internet as well as Internet2. To reduce costs, the number of T1 circuits was cut in half. In January, 2011, the two T1 circuits was replaced by a virtual private lan service increasing the bandwidth from 3mbps to 5mbps at no additional cost. Connectivity to Barrow is still only via geosynchronous satellite so latency remains an issue. The network performance of individual hosts were optimized by increasing the TCP window size as well as using UDP whenever possible. IPv4 multicast was enabled early on as a method for Barrow based staff to participate in tech events such as ACM meetings or the Internet2 Joint Techs. We also experimented with hosting multicast streams from the BARC to receivers scattered throughout the higher ed community. Multicast remains available only within the research and education networks such as Internet2 in the United States and not at all on the commodity Internet. IPv6 addresses have been assigned to the site by UAF but we have not received a request for the service.\n\nIn 2010, the scope was expanded to include network flow accounting to track Internet usage by project and by type. A combination of open source software and customized Perl scripts were used to collect the flow export from the border routers, associate the flows with individual projects and atte..."
 }
}