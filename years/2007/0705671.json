{
 "awd_id": "0705671",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Exploiting and Exploring Discourse Connectivity: Deriving New Technology and Knowledge from the Penn Discourse Treebank",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2007-09-15",
 "awd_exp_date": "2012-08-31",
 "tot_intn_awd_amt": 955000.0,
 "awd_amount": 987000.0,
 "awd_min_amd_letter_date": "2007-09-10",
 "awd_max_amd_letter_date": "2012-03-20",
 "awd_abstract_narration": "Large scale corpora annotated at the sentence level have played a critical role in natural language research. They have enabled large scale integration of statistical knowledge (derived from the corpora) with linguistic knowledge leading to both technological and scientific applications, such as information extraction, question answering, summarization, and machine translation, among others. This approach is now being extended to the discourse level, thus going beyond the sentence level. Using a resource called the Penn Discourse Treebank (PDTB), a large scale corpus annotated with discourse structure along with the associated semantics, new major experimental work on discourse processing is being carried out, leading to the generation of more coherent summaries and texts, extraction of complex relations in texts, among others, as well as foundational research relevant to language technology. This work is also providing a deeper understanding of the relationship between sentence level and discourse level structures. While pursuing these goals, a variety of tools for making a productive use of the PDTB resource are also being developed. This research program is also coupled with a strong educational program involving training researchers in the PDTB methodology so that similar resources can be developed in other languages substantially divergent from English. This part of the research program has international components including collaboration with research groups in Czech Republic, India,  and Finland.  The international collaboration is funded by the NSF Office of International Science and Engineering.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aravind",
   "pi_last_name": "Joshi",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Aravind K Joshi",
   "pi_email_addr": "joshi@cis.upenn.edu",
   "nsf_id": "000201363",
   "pi_start_date": "2007-09-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rashmi",
   "pi_last_name": "Prasad",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rashmi Prasad",
   "pi_email_addr": "prasadr@uwm.edu",
   "nsf_id": "000284699",
   "pi_start_date": "2007-09-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "3451 WALNUT ST STE 440A",
  "perf_city_name": "PHILADELPHIA",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  },
  {
   "pgm_ele_code": "729800",
   "pgm_ele_name": "International Research Collab"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "5919",
   "pgm_ref_txt": "INDIA (COOPERATIVE SCIENCE)"
  },
  {
   "pgm_ref_code": "5930",
   "pgm_ref_txt": "U.S.-CZECHOSLOVAKIA PROGRAM"
  },
  {
   "pgm_ref_code": "5935",
   "pgm_ref_txt": "FINLAND"
  },
  {
   "pgm_ref_code": "5976",
   "pgm_ref_txt": "AFRICA, NEAR EAST, & SO ASIA"
  },
  {
   "pgm_ref_code": "5979",
   "pgm_ref_txt": "Europe and Eurasia"
  },
  {
   "pgm_ref_code": "5980",
   "pgm_ref_txt": "WESTERN EUROPE PROGRAM"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 323949.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 273908.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 250349.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 130794.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>To benefit people, companies and governments, computers need to be able to automatically extract information from all kinds of texts &ndash; news reports, scientific papers, product manuals, blogs, etc.&nbsp; Currently, computers can only do this effectively when the text is a single clause. But if the needed information is spread across multiple clauses or multiple sentences, then computers first need to recognize how those clauses or sentences relate to each other. The ways in which they can do so are called <strong>discourse</strong><strong> </strong><strong>relations</strong> or <strong>coherence</strong><strong> </strong><strong>relations</strong>: For example, the situation or event described in one sentence may mean to <strong>explain</strong><strong> </strong>the situation or event described in another one. &nbsp;Or it may be presented as <strong>similar</strong><strong> </strong><strong>to</strong> or a <strong>part of</strong> another one. These relations may be signaled explicitly with a word like \"because\" or \"similarly\", or a reader might be assumed to be able to infer the relationship for his or her self. Researchers believe that computers can be helped to recognize discourse relations automatically, using techniques from <strong>Machine</strong><strong> </strong><strong>Learning</strong>, provided that<strong> </strong>sufficient manually annotated data can be made available.</p>\n<p>&nbsp;</p>\n<p>Beginning in 2006, the National Science Foundation awarded funds to researchers at the University of Pennsylvania to start creating such data. The resulting Penn Discourse TreeBank is now the world&rsquo;s largest resource of manually-annotated discourse relations. It contains over 40,000 relations annotated over the widely-used 1-million word Penn TreeBank corpus. Annotated with other linguistic information as well, The Penn TreeBank has become the most richly annotated corpus in the world and a \"gold standard\" for research and development in basic language technologies such as parsing, coreference resolution, word sense disambiguation, and temporal recognition (that is, identifying when and where an event has taken place).&nbsp; With the release of the Penn Discourse TreeBank (PDTB) in 2008, researchers around the world now have both a way of inducing procedures for automatically recognizing how clauses and sentences relate to each other and a gold standard for assessing such procedures. They have even started to use these procedures to improve the quality and capability of advanced language technology systems for automated text summarization, question answering, text quality assessment, and statistical machine translation.</p>\n<p>&nbsp;</p>\n<p>But this wide range of work has also revealed annotation missing from the PDTB that would further help them in their work, as well as stimulating a desire to have discourse relations annotated in text other than news reports, as style and register matter in how text is written. These important augmentations are planned for the PDTB in the near future.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/07/2013<br>\n\t\t\t\t\tModified by: Aravind&nbsp;K&nbsp;Joshi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nTo benefit people, companies and governments, computers need to be able to automatically extract information from all kinds of texts &ndash; news reports, scientific papers, product manuals, blogs, etc.  Currently, computers can only do this effectively when the text is a single clause. But if the needed information is spread across multiple clauses or multiple sentences, then computers first need to recognize how those clauses or sentences relate to each other. The ways in which they can do so are called discourse relations or coherence relations: For example, the situation or event described in one sentence may mean to explain the situation or event described in another one.  Or it may be presented as similar to or a part of another one. These relations may be signaled explicitly with a word like \"because\" or \"similarly\", or a reader might be assumed to be able to infer the relationship for his or her self. Researchers believe that computers can be helped to recognize discourse relations automatically, using techniques from Machine Learning, provided that sufficient manually annotated data can be made available.\n\n \n\nBeginning in 2006, the National Science Foundation awarded funds to researchers at the University of Pennsylvania to start creating such data. The resulting Penn Discourse TreeBank is now the world\u00c6s largest resource of manually-annotated discourse relations. It contains over 40,000 relations annotated over the widely-used 1-million word Penn TreeBank corpus. Annotated with other linguistic information as well, The Penn TreeBank has become the most richly annotated corpus in the world and a \"gold standard\" for research and development in basic language technologies such as parsing, coreference resolution, word sense disambiguation, and temporal recognition (that is, identifying when and where an event has taken place).  With the release of the Penn Discourse TreeBank (PDTB) in 2008, researchers around the world now have both a way of inducing procedures for automatically recognizing how clauses and sentences relate to each other and a gold standard for assessing such procedures. They have even started to use these procedures to improve the quality and capability of advanced language technology systems for automated text summarization, question answering, text quality assessment, and statistical machine translation.\n\n \n\nBut this wide range of work has also revealed annotation missing from the PDTB that would further help them in their work, as well as stimulating a desire to have discourse relations annotated in text other than news reports, as style and register matter in how text is written. These important augmentations are planned for the PDTB in the near future.\n\n \n\n\t\t\t\t\tLast Modified: 01/07/2013\n\n\t\t\t\t\tSubmitted by: Aravind K Joshi"
 }
}