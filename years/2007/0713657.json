{
 "awd_id": "0713657",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Exploring neurobiological strategies of visual scene analysis using oscillations in recurrent neural circuitry",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2007-10-01",
 "awd_exp_date": "2011-09-30",
 "tot_intn_awd_amt": 402133.0,
 "awd_amount": 402133.0,
 "awd_min_amd_letter_date": "2007-09-19",
 "awd_max_amd_letter_date": "2007-09-19",
 "awd_abstract_narration": "Recurrent connections and intrinsic rhythmic neural activity are ubiquitous in biological visual pathways, where they first appear in the retina.  Although the functional role of these properties of the retinal circuit is not fully resolved, recent work suggests that they might help convey information about visual context or even the gist of a scene.  Further, new experimental work shows that the oscillatory patterns of activity generated by retinal networks are relayed from the thalamus to the cortex.  As yet, however, retinal oscillations are usually ignored in systems of computer vision, even those based on neural principles.  If artificial systems matched human performance in visual perception, this lack of attention to the biological circuitry might not be worthy of note.   But this is not the case.  Humans do a far better job than computers in routine tasks like analyzing cluttered scenes or recognizing objects in noisy backgrounds or under different lighting conditions.  Thus this project aims to develop biologically inspired models that include oscillating networks to improve scene analysis in artificial vision.\r\n\r\nThe new models will incorporate local and distributed connections in the retinal circuit and also take advantage of the scheme of efficient sparse coding, a powerful new concept for understanding sensory processing.  By taking both local and spatially extensive circuits into account, the expectation is that the model will be able to encode two complementary types of information about the stimulus.  Past work has shown that changes in spike rate with respect to the stimulus encode information about local features.  This type of rate (or stimulus-locked) coding can be modeled by small scale circuits.  The new models will include ongoing oscillatory activity that is generated internally by large recurrent networks but is also modulated by sensory input.  Further, visually evoked changes in the temporal structure of these intrinsic oscillations occur at finer time scales than visually evoked changes in rate.  Thus, in principle, visual information could be encoded by spike timing with respect to intrinsic rhythms.  Moreover, since the retinal oscillations are generated by distributed networks, it is likely that they provide information about global feature of the stimulus.  Thus, if successful, the new models will be able to capture, at once, information about local detail and the gist of scene.\r\n\r\nNumerous applications would benefit from a deeper understanding of how information is encoded in the early visual system. For example, the models that will result from the research proposed here have value for the development of visual prosthetics as well as for technical applications that involve image-processing from new methods for image compression adapted to sensory perception to the problem of automated object segmentation, scene analysis and recognition. \r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Friedrich",
   "pi_last_name": "Sommer",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Friedrich T Sommer",
   "pi_email_addr": "fsommer@berkeley.edu",
   "nsf_id": "000490098",
   "pi_start_date": "2007-09-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "1608 4TH ST STE 201",
  "perf_city_name": "BERKELEY",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947101749",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 402133.0
  }
 ],
 "por": null
}