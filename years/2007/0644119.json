{
 "awd_id": "0644119",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Information, Optimization and Approximation",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Balasubramanian Kalyanasundaram",
 "awd_eff_date": "2007-03-15",
 "awd_exp_date": "2013-02-28",
 "tot_intn_awd_amt": 400002.0,
 "awd_amount": 400002.0,
 "awd_min_amd_letter_date": "2007-03-13",
 "awd_max_amd_letter_date": "2011-03-01",
 "awd_abstract_narration": "As the capability of data acquisition has increased over the last few years, the challenges of computing with these large datasets has increased as well.  In many scenarios investigating the entire data repeatedly to answer questions is becoming an infeasible strategy. The emerging trend in these contexts is to summarize the information content, perhaps with some loss, such that reasonably accurate answers can still be provided but the algorithm will only inspect the summarized representation. This approach has already gained currency in database query optimizers, network monitoring, and sensor networks.  For the above two phase strategy to work the summarization should be geared towards the end use of the information. However, in many scenarios the two phases are being investigated separately and their development is not being guided by end use but by mathematical and algorithmic tractability. As a consequence the solutions obtained are far from optimal. The goal of this project is to investigate the finer mathematical structure of several of these problems and provide provably near optimal solutions.\r\n\r\nIntellectually this project seeks to develop algorithmic understanding of several representation problems that arise from the interaction of approximation theory and information theory. The existing analytical treatment of these problems, typically, does not consider computational efficiency which is necessary to cope with the ever increasing problem sizes. The focus this research is to use techniques from combinatorial optimization as well as recent developments in sampling, embeddings, and approximate data structures to develop efficient approximation algorithms for these problems. These representation problems are ubiquitous in a broad range of areas such as signal processing, networks, databases. Efficient solutions to these problems will play a significant role in monitoring, reconnaissance and network forensics and is likely to impact practice.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sudipto",
   "pi_last_name": "Guha",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sudipto Guha",
   "pi_email_addr": "sudipto@cis.upenn.edu",
   "nsf_id": "000230002",
   "pi_start_date": "2007-03-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "3451 WALNUT ST STE 440A",
  "perf_city_name": "PHILADELPHIA",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "286000",
   "pgm_ele_name": "THEORY OF COMPUTING"
  },
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 75932.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 79214.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 168713.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 76143.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project we have primarily focused on understanding the computational model of data streams and developing new algorithmic techniques for such. The data streams model considers random access to data as a computational resource and seeks to develop algorithms that use as little space as possible and only use sequential passes over data (again as few as possible). This model serves as an abstraction for a variety of computational problems in resource constrained settings. This model is particularly useful in scenarios where information about an object is presented incrementally. &nbsp;This project made fundamental progress towards four major questions in this model. The questions widen in scope progressively, starting from basic understanding of the model towards more abstract questions.</p>\n<p>First, how does the order of arrival of data impact our computation? Can we provably demonstrate that computation over adversarial arrival is different from benign random order, for natural problems of interest in the context of small space algorithms? &nbsp;Surprisingly, it turns out that the cost of adversarial ordering, measured in number of passes over data, can be exponentially larger than the cost of a benign random order for fairly natural problems.</p>\n<p>Second, if the object being specified incrementally is a vector or a signal, is it possible to measure the similarity between two objects based on small signatures of the signal computed in a distributed setting? It turns out that only the commonplace metric distances can be computed in a distributed fashion, and any involved measure of similarity based on information theoretic distances is hard to compute. Surprisingly the situation changes in a centralized setting or with small amounts of interaction.</p>\n<p>Third, can we compute over large graphs in small space when the graph is specified as a sequence of insertion and deletion of edges? Graphs are, and will likely continue to be, one of the most used abstractions in representing relationships between objects. What are the basic problems that should be solved so that we can solve a large number of problems by reducing them to these basic primitives? We initiate the study of this natural subfield of algorithms and study connectivity, graph distances, cut and spectral sparsifcations, and a few applications of these basic problems.</p>\n<p>Finally, can we modify widely used algorithmic approaches, for example iterative algorithms for approximately solving linear programs, to apply in the streaming model? A positive answer to this question would immediately allow us to reduce the space requirement of these types of algorithms. We show that linear programs for several matching and clustering problems are amenable to this approach. Furthermore we show that the use of streaming algorithms as an abstraction allows us to solve specific problems more efficiently than existing results in the unrestricted model. The space constraint of streaming algorithms forces us to focus on the bare information needs of an algorithm.</p>\n<p>Research supported by this project shows commonalities between streaming and decision theoretic algorithms. Decision theoretic algorithms are geared towards exploration-exploitation tradeoffs in environments where information is dynamic and only partially observable. Therefore these algorithms typically only acquire modest amounts of information in a single step and are incremental by design. This project has supported fundamental progress in the development of optimization algorithms for decision theoretic problems, especially in the area of sequential design of experiments and the area of restless bandit problems. Several of these ideas, such as the notions of adaptivity and Lagrangian formulations, have led to new results in the streaming setting.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/10/2013<br>\n\t\t\t\t\tModified by: Sudipto&nbsp;...",
  "por_txt_cntn": "\nIn this project we have primarily focused on understanding the computational model of data streams and developing new algorithmic techniques for such. The data streams model considers random access to data as a computational resource and seeks to develop algorithms that use as little space as possible and only use sequential passes over data (again as few as possible). This model serves as an abstraction for a variety of computational problems in resource constrained settings. This model is particularly useful in scenarios where information about an object is presented incrementally.  This project made fundamental progress towards four major questions in this model. The questions widen in scope progressively, starting from basic understanding of the model towards more abstract questions.\n\nFirst, how does the order of arrival of data impact our computation? Can we provably demonstrate that computation over adversarial arrival is different from benign random order, for natural problems of interest in the context of small space algorithms?  Surprisingly, it turns out that the cost of adversarial ordering, measured in number of passes over data, can be exponentially larger than the cost of a benign random order for fairly natural problems.\n\nSecond, if the object being specified incrementally is a vector or a signal, is it possible to measure the similarity between two objects based on small signatures of the signal computed in a distributed setting? It turns out that only the commonplace metric distances can be computed in a distributed fashion, and any involved measure of similarity based on information theoretic distances is hard to compute. Surprisingly the situation changes in a centralized setting or with small amounts of interaction.\n\nThird, can we compute over large graphs in small space when the graph is specified as a sequence of insertion and deletion of edges? Graphs are, and will likely continue to be, one of the most used abstractions in representing relationships between objects. What are the basic problems that should be solved so that we can solve a large number of problems by reducing them to these basic primitives? We initiate the study of this natural subfield of algorithms and study connectivity, graph distances, cut and spectral sparsifcations, and a few applications of these basic problems.\n\nFinally, can we modify widely used algorithmic approaches, for example iterative algorithms for approximately solving linear programs, to apply in the streaming model? A positive answer to this question would immediately allow us to reduce the space requirement of these types of algorithms. We show that linear programs for several matching and clustering problems are amenable to this approach. Furthermore we show that the use of streaming algorithms as an abstraction allows us to solve specific problems more efficiently than existing results in the unrestricted model. The space constraint of streaming algorithms forces us to focus on the bare information needs of an algorithm.\n\nResearch supported by this project shows commonalities between streaming and decision theoretic algorithms. Decision theoretic algorithms are geared towards exploration-exploitation tradeoffs in environments where information is dynamic and only partially observable. Therefore these algorithms typically only acquire modest amounts of information in a single step and are incremental by design. This project has supported fundamental progress in the development of optimization algorithms for decision theoretic problems, especially in the area of sequential design of experiments and the area of restless bandit problems. Several of these ideas, such as the notions of adaptivity and Lagrangian formulations, have led to new results in the streaming setting.\n\n \n\n\t\t\t\t\tLast Modified: 06/10/2013\n\n\t\t\t\t\tSubmitted by: Sudipto Guha"
 }
}