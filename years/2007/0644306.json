{
 "awd_id": "0644306",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Automatically Generating and Processing Program Analyses and Optimizations",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Reppy",
 "awd_eff_date": "2007-04-15",
 "awd_exp_date": "2012-03-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2007-04-12",
 "awd_max_amd_letter_date": "2011-04-11",
 "awd_abstract_narration": "Developing efficient, scalable, correct, and precise program analyzers and optimizers is difficult. There is a long time, often up to a decade, before a new optimizing compiler is mature enough to be widely used. These difficulties hinder the development of new languages and new architectures, and can also discourage end-user programmers from extending compilers with domain-specific checkers or optimizers.\r\n\r\nTechniques will be investigated for automatically generating efficient, scalable, correct, and precise dataflow analyzers and optimizers from a very high-level specification. The overarching theme is to understand the underlying principles behind designing program analyses and optimizations, and use this understanding to automate as much as possible the analyzer- and optimizer-writing process. Attempting to automate the process of writing analyzers and optimizers enables many new kinds of usage models for compilers, including: allowing end-user programmers to easily extend the compiler with domain-specific checkers or optimizers; allowing end-user programmers to continuously train the compiler, even after it is deployed, based on additional input-output examples; and automatically generating additional analyses when the optimizer discovers the need for new dataflow information, and linking these new analyses into the optimizer while in execution.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sorin",
   "pi_last_name": "Lerner",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sorin Lerner",
   "pi_email_addr": "lerner@cs.ucsd.edu",
   "nsf_id": "000068847",
   "pi_start_date": "2007-04-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 GILMAN DR",
  "perf_city_name": "LA JOLLA",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735200",
   "pgm_ele_name": "COMPUTING PROCESSES & ARTIFACT"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 80000.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 80000.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 80000.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 80000.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 80000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The compiler is a tool that is central to the development of software. Its role is to translate the human-readable code written by a programmer into machine code that a computer can understand. In the process of doing this translation, the compiler performs many important improvements to the code so that the final code runs as fast as possible. These improvements are commonly referered to as \"optimizations\", and they play a critical role in the compiler.&nbsp;</p>\n<p>Where do optimizations come from? Currently, the programmer who develops the compiler writes these optimizations via a process that is laborious, error-prone, and often considered an art. The intellectual merit of this project is to investigate and develop new techniques for making this optimization-writing process not only less laborious but also less error-prone.</p>\n<p>In particular, advances made under this project now provide compiler programmers with a much easier path to writing optimizations: instead of engineering an optimization by manually writing every single detail of the optimization, programmers can instead \"train\" the compiler by showing examples of what it should be doing. The compiler can learn from these examples, and automatically come up with a general optimization, without programmers having to specify the details.</p>\n<p>The broader impact of this research is that it will reduce the cost of developing good and reliable optimizations, which in the end will lead to better compilers, and ultimately more reliable and efficient software.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/03/2012<br>\n\t\t\t\t\tModified by: Sorin&nbsp;Lerner</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe compiler is a tool that is central to the development of software. Its role is to translate the human-readable code written by a programmer into machine code that a computer can understand. In the process of doing this translation, the compiler performs many important improvements to the code so that the final code runs as fast as possible. These improvements are commonly referered to as \"optimizations\", and they play a critical role in the compiler. \n\nWhere do optimizations come from? Currently, the programmer who develops the compiler writes these optimizations via a process that is laborious, error-prone, and often considered an art. The intellectual merit of this project is to investigate and develop new techniques for making this optimization-writing process not only less laborious but also less error-prone.\n\nIn particular, advances made under this project now provide compiler programmers with a much easier path to writing optimizations: instead of engineering an optimization by manually writing every single detail of the optimization, programmers can instead \"train\" the compiler by showing examples of what it should be doing. The compiler can learn from these examples, and automatically come up with a general optimization, without programmers having to specify the details.\n\nThe broader impact of this research is that it will reduce the cost of developing good and reliable optimizations, which in the end will lead to better compilers, and ultimately more reliable and efficient software.\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 07/03/2012\n\n\t\t\t\t\tSubmitted by: Sorin Lerner"
 }
}