{
 "awd_id": "0713688",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "HCC:  Easy-to-Learn and Easy-to-Use Eye-Controlled Musical Expression For Children with Severe Disabilities",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2007-07-15",
 "awd_exp_date": "2015-12-31",
 "tot_intn_awd_amt": 449319.0,
 "awd_amount": 481319.0,
 "awd_min_amd_letter_date": "2007-07-17",
 "awd_max_amd_letter_date": "2015-01-15",
 "awd_abstract_narration": "Despite the opportunity afforded by the relatively low-cost eye tracking technology now becoming available, practical eye-control of computers is still very limited.  This is particularly unfortunate for children with severe motor impairments who retain control of their eye movements and have the potential to use an eye tracker, but who miss out on important childhood developmental activities because of a lack of suitable interactive software to support these activities.  In a previous research project in which he developed EyeDraw, software that enables children with severe motor impairments to draw pictures with their eye movements, the PI showed that for this community eye tracking can provide a powerful and noninvasive means of creative expression.  Though EyeDraw was in many ways a success, during its development the PI identified three major problems that hinder efforts by researchers and practitioners to create eye-controlled software for these children. Firstly, no rapid prototyping tools or software application frameworks are available specifically for developing eye-controlled applications.  Furthermore, eye-controlled software is typically intended for expert use and does not provide enjoyable experiences at first glance.  Last but not least, there is no established practice for working with children with severe disabilities as partners in software design.  This project responds to these problems by pursuing a number of related activities, within the concrete context of computer applications that support playing music.   The PI will determine which participatory design techniques can work with children with severe motor impairments, and will establish a design practice that allows him to collaborate directly with them and their caregivers, to develop software that enables the children to make music with eye movements.  He will create a framework that supports rapid prototyping of eye-controlled applications for this user community by giving caregivers, practitioners, and researchers a means to quickly generate eye-interactive sketches so that the children can communicate, explore alternatives, provide feedback, and express themselves creatively.  And he will design intervention techniques that address the difficulties associated with the initial use of eye-controlled software, to ensure an immediate sense of accomplishment, satisfaction, interaction, control, encouragement, and expression.  This last goal will be accomplished through interfaces that support musical expression even with a low-fidelity zero-point calibration, and which incrementally improve the calibration during expressive musical activities while also gradually introducing advanced functionality and opportunities for creative musical expression.  \r\n\r\nBroader Impacts:  This project will advance an understanding of how to build eye-controlled software for children with severe disabilities, a challenge that is not addressed by the current scientific or design literature.  Project outcomes will provide young people with severe motor impairments with a means of engaging in artistic pursuits that are currently out of reach.  The rapid prototyping framework for eye-controlled applications will provide an infrastructure for university classroom instruction and future researchers.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Michal",
   "pi_last_name": "Young",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Michal T Young",
   "pi_email_addr": "michal@cs.uoregon.edu",
   "nsf_id": "000434200",
   "pi_start_date": "2012-08-17",
   "pi_end_date": "2014-09-25"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anthony",
   "pi_last_name": "Hornof",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Anthony J Hornof",
   "pi_email_addr": "hornof@cs.uoregon.edu",
   "nsf_id": "000298770",
   "pi_start_date": "2014-09-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Oregon Eugene",
  "inst_street_address": "1776 E 13TH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "EUGENE",
  "inst_state_code": "OR",
  "inst_state_name": "Oregon",
  "inst_phone_num": "5413465131",
  "inst_zip_code": "974031905",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "OR04",
  "org_lgl_bus_name": "UNIVERSITY OF OREGON",
  "org_prnt_uei_num": "Z3FGN9MF92U2",
  "org_uei_num": "Z3FGN9MF92U2"
 },
 "perf_inst": {
  "perf_inst_name": "University of Oregon Eugene",
  "perf_str_addr": "1776 E 13TH AVE",
  "perf_city_name": "EUGENE",
  "perf_st_code": "OR",
  "perf_st_name": "Oregon",
  "perf_zip_code": "974031905",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "OR04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "0100999999",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 173610.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 129941.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 161768.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project developed participatory design techniques that will permit researchers and practitioners to collaborate directly work with children with severe motor impairments, and with their parents parents, in the design of assistive technology and communication devices and protocols. The techniques include, for example (a) throughout the design process, actively utilizing high-tech, low-tech, and no-tech communication techniques that are already in place for the children and (b) for children whose disabilities limit their communication abilities largely to answering yes/no questions, it is important to decompose design activities into discrete subtasks that can be phrased as yes/no questions.<br /><br />The project developed new techniques for playing music with eye-controlled interfaces, and explored the long-term prospects for eye-controlled musical performance. The fundamental human constraints and processes that govern eye movements create a challenge for eye-controlled music in that the instrument needs to be designed to motivate or at least permit specific unique visual goals, each of which when accomplished must then be mapped, using the eye tracker and some sort of sound generator, to different musical outcomes. The control of the musical instrument is less direct than if it were played with muscles that can be controlled in a more direct manner, such as the muscles in the hands. The project established an upper limit of four commands (such as beats) per second for eye-controlled music.<br /><br />The University of Oregon&rsquo;s Eye Tracking Design Studio, developed in the context of this award, has been made available to and visited by many guests, including members of the public, museums, and other academic institutions who are interested in assessing whether eye tracking might be an appropriate means for enhancing a museum experience, and for individuals with severe motor impairments to communicate more effectively than with their current non-eye-tracking communication methods. The project contributed to a practical understanding of how to configure, design, and develop communication devices, both eye-controlled and other, for multiple children and adults with motor impairments.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/22/2016<br>\n\t\t\t\t\tModified by: Anthony&nbsp;J&nbsp;Hornof</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project developed participatory design techniques that will permit researchers and practitioners to collaborate directly work with children with severe motor impairments, and with their parents parents, in the design of assistive technology and communication devices and protocols. The techniques include, for example (a) throughout the design process, actively utilizing high-tech, low-tech, and no-tech communication techniques that are already in place for the children and (b) for children whose disabilities limit their communication abilities largely to answering yes/no questions, it is important to decompose design activities into discrete subtasks that can be phrased as yes/no questions.\n\nThe project developed new techniques for playing music with eye-controlled interfaces, and explored the long-term prospects for eye-controlled musical performance. The fundamental human constraints and processes that govern eye movements create a challenge for eye-controlled music in that the instrument needs to be designed to motivate or at least permit specific unique visual goals, each of which when accomplished must then be mapped, using the eye tracker and some sort of sound generator, to different musical outcomes. The control of the musical instrument is less direct than if it were played with muscles that can be controlled in a more direct manner, such as the muscles in the hands. The project established an upper limit of four commands (such as beats) per second for eye-controlled music.\n\nThe University of Oregon\u00c6s Eye Tracking Design Studio, developed in the context of this award, has been made available to and visited by many guests, including members of the public, museums, and other academic institutions who are interested in assessing whether eye tracking might be an appropriate means for enhancing a museum experience, and for individuals with severe motor impairments to communicate more effectively than with their current non-eye-tracking communication methods. The project contributed to a practical understanding of how to configure, design, and develop communication devices, both eye-controlled and other, for multiple children and adults with motor impairments.\n\n\t\t\t\t\tLast Modified: 05/22/2016\n\n\t\t\t\t\tSubmitted by: Anthony J Hornof"
 }
}