{
 "awd_id": "0623805",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "DHB: An Interdisciplinary Study of the Dynamics of  Second Language Fluency",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2007-02-01",
 "awd_exp_date": "2011-01-31",
 "tot_intn_awd_amt": 0.0,
 "awd_amount": 710781.0,
 "awd_min_amd_letter_date": "2007-01-25",
 "awd_max_amd_letter_date": "2010-05-04",
 "awd_abstract_narration": "This project will develop and test psycholinguistic models of the relationship between first language fluency, second language competence and second language fluency.  These models will be applied toward the automatic assessment of fluency in a second language.  The project involves a unique collaboration between researchers with backgrounds in second-language pedagogy, testing methodology, linguistics, speech and language technology, and psychology, and is organized around a common set of data, namely oral presentations given by university students in third year Mandarin classes. These student performances are videotaped, transcribed and rated by trained raters who rate the students' fluency according to a custom-designed and validated testing procedure.  The same students will be recruited at the beginning of the semester to participate in psycholinguistic experiments to measure their first language fluency, and related studies will be conducted during the course of the year. The results from expert rating of second-language fluency will be correlated with the psycholinguistic studies of first-language fluency. In parallel with this, the team will develop algorithms that will automatically assign scores to a student's second-language performance that will correlate with expert judgments.  These algorithms will range from low-level signal processing methods to estimate such factors as syllable rate and pause duration, to Dynamic Bayesian Networks that combine information from large number of sources to improve the performance of Automatic Speech Recognition on the data. The results of this work will be both a better understanding of what it means to be fluent in a second language, as well as robust methods that will allow for objective automatic assessment of fluency.\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Sproat",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Richard Sproat",
   "pi_email_addr": "rws@uiuc.edu",
   "nsf_id": "000454475",
   "pi_start_date": "2007-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Brian",
   "pi_last_name": "Ross",
   "pi_mid_init": "H",
   "pi_sufx_name": "PhD",
   "pi_full_name": "Brian H Ross",
   "pi_email_addr": "bross@s.psych.uiuc.edu",
   "nsf_id": "000182912",
   "pi_start_date": "2007-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "J. Kathryn",
   "pi_last_name": "Bock",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "J. Kathryn Bock",
   "pi_email_addr": "jkbock@uiuc.edu",
   "nsf_id": "000227074",
   "pi_start_date": "2007-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Chi-Lin",
   "pi_last_name": "Shih",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chi-Lin Shih",
   "pi_email_addr": "cls@illinois.edu",
   "nsf_id": "000236013",
   "pi_start_date": "2007-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Hasegawa-Johnson",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Mark A Hasegawa-Johnson",
   "pi_email_addr": "jhasegaw@illinois.edu",
   "nsf_id": "000431210",
   "pi_start_date": "2007-01-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "506 S WRIGHT ST",
  "perf_city_name": "URBANA",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "731900",
   "pgm_ele_name": "HSD - DYNAMICS OF HUMAN BEHAVI"
  },
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7319",
   "pgm_ref_txt": "HSD - DYNAMICS OF HUMAN BEHAVI"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 686781.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 24000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>How can you speak a foreign language fluently?&nbsp; <br /><br />What does a native speaker listen to?<br /><br />Researchers at the University of Illinois have collected 180 hours of longitudinal conversational data from Chinese Language classes in the US.&nbsp; Snippets extracted from this database were rated for second-language fluency using four radically different methods: (1) speech extracts were rated by trained second-language fluency experts, (2) extracts were rated by untrained native speakers of Mandarin Chinese, in web-based rating experiments conducted both in the US and in Taiwan, (3) automatic second-language fluency rating systems were trained, using methods related to automatic speech recognition, and finally, (4) twenty of the original students were recruited to participate in a carefully timed cartoon narration task, in which they narrated (in Chinese) the action occurring in a simple cartoon, while an automatic eye tracker logged all of their eye movements.&nbsp; <br /><br />First impressions are important.&nbsp; Native speakers, without any formal fluency-rating expertise, can judge the fluency of a second-language learner within fifteen seconds.&nbsp; Their judgments are reliable (different raters agree), and they match pretty well with the ratings generated by trained raters.&nbsp; Automatic second-language fluency systems perform almost as well using fifteen-second speech samples as using fifty-second samples.<br /><br />Besides rating the fluency of the second-language learners, raters were also asked questions like \"is the speaker a native speaker of Chinese,\" \"how strong is his/her accent,\" \"are there a lot of disfluencies (uh's and um's),\" \"does he/she have good pronunciation, grammar and vocabulary,\" and \"can the speech be easily understood?\"&nbsp;&nbsp; Results were surprising.&nbsp; For raters who currently live in the United States (whether trained or untrained), the term \"fluency\" refers to overall second-language proficiency, and is indistinguishable from the other rated measures including speech flow, phonological control, grammatical accuracy, lexical accuracy, communication skill, nativeness, and accent.&nbsp; On the other hand, raters who currently live in Taiwan are willing to call a speaker fluent even if that speaker has a perceptible non-native accent: the two measures are highly correlated, but distinguishable.&nbsp; <br /><br />Experiments with automatic second-language fluency rating systems suggest that human raters depend primarily on measures of speech timing, even when they claim to be rating vocabulary size, grammatical competence, or the number of disfluencies.&nbsp; Three types of measures were tested: (1) automatic measures of vocabulary size were estimated based on the variety of words used by a talker during the rated speech sample, (2) automatic measures of disfluency rate were computed by detecting filled pauses (um and uh) and other types of difluency, (3) measures of timing included the number of syllables per second, and the \"phonation time ratio\" --- literally, the demonstrated ability of the speaker to fill every second of the recording with some kind of speech sound.&nbsp; All three types of measure were significantly correlated with human-rated fluency measures, but the best predictors were all in the third category.&nbsp; Furthermore, when timing measures are considered, no further accuracy boost is achieved by adding information about vocabulary size or disfluencies.&nbsp; The data suggest that the best way to sound fluent in a second language is to talk as much as you can.&nbsp; Researchers at the University of Illinois are currently exploring new ideas for second-language training programs, based on this research, that will enhance fluency (with real-time feedback to the user) by encouraging the learner to speak rapidly and confidently, consistently planning his or her speech a few words ahead.<br ...",
  "por_txt_cntn": "\nHow can you speak a foreign language fluently?  \n\nWhat does a native speaker listen to?\n\nResearchers at the University of Illinois have collected 180 hours of longitudinal conversational data from Chinese Language classes in the US.  Snippets extracted from this database were rated for second-language fluency using four radically different methods: (1) speech extracts were rated by trained second-language fluency experts, (2) extracts were rated by untrained native speakers of Mandarin Chinese, in web-based rating experiments conducted both in the US and in Taiwan, (3) automatic second-language fluency rating systems were trained, using methods related to automatic speech recognition, and finally, (4) twenty of the original students were recruited to participate in a carefully timed cartoon narration task, in which they narrated (in Chinese) the action occurring in a simple cartoon, while an automatic eye tracker logged all of their eye movements.  \n\nFirst impressions are important.  Native speakers, without any formal fluency-rating expertise, can judge the fluency of a second-language learner within fifteen seconds.  Their judgments are reliable (different raters agree), and they match pretty well with the ratings generated by trained raters.  Automatic second-language fluency systems perform almost as well using fifteen-second speech samples as using fifty-second samples.\n\nBesides rating the fluency of the second-language learners, raters were also asked questions like \"is the speaker a native speaker of Chinese,\" \"how strong is his/her accent,\" \"are there a lot of disfluencies (uh's and um's),\" \"does he/she have good pronunciation, grammar and vocabulary,\" and \"can the speech be easily understood?\"   Results were surprising.  For raters who currently live in the United States (whether trained or untrained), the term \"fluency\" refers to overall second-language proficiency, and is indistinguishable from the other rated measures including speech flow, phonological control, grammatical accuracy, lexical accuracy, communication skill, nativeness, and accent.  On the other hand, raters who currently live in Taiwan are willing to call a speaker fluent even if that speaker has a perceptible non-native accent: the two measures are highly correlated, but distinguishable.  \n\nExperiments with automatic second-language fluency rating systems suggest that human raters depend primarily on measures of speech timing, even when they claim to be rating vocabulary size, grammatical competence, or the number of disfluencies.  Three types of measures were tested: (1) automatic measures of vocabulary size were estimated based on the variety of words used by a talker during the rated speech sample, (2) automatic measures of disfluency rate were computed by detecting filled pauses (um and uh) and other types of difluency, (3) measures of timing included the number of syllables per second, and the \"phonation time ratio\" --- literally, the demonstrated ability of the speaker to fill every second of the recording with some kind of speech sound.  All three types of measure were significantly correlated with human-rated fluency measures, but the best predictors were all in the third category.  Furthermore, when timing measures are considered, no further accuracy boost is achieved by adding information about vocabulary size or disfluencies.  The data suggest that the best way to sound fluent in a second language is to talk as much as you can.  Researchers at the University of Illinois are currently exploring new ideas for second-language training programs, based on this research, that will enhance fluency (with real-time feedback to the user) by encouraging the learner to speak rapidly and confidently, consistently planning his or her speech a few words ahead.\n\nSome of the human raters judged speech samples with video, some with audio only.  The two types of measurement were different: apparently, video changes one's perceived fluency.  Those who judge..."
 }
}