{
 "awd_id": "0712799",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III-COR: Collaborative Research:  The Morpheus Data Transformation Management System",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2007-09-01",
 "awd_exp_date": "2011-08-31",
 "tot_intn_awd_amt": 269263.0,
 "awd_amount": 277159.0,
 "awd_min_amd_letter_date": "2007-08-09",
 "awd_max_amd_letter_date": "2010-04-06",
 "awd_abstract_narration": "The goal of this research project is to facilitate the sharing of information across enterprise boundaries, by facilitating the integration of separately constructed data bases.  Because such data bases never have identical content, it is necessary to write transforms (or adaptors) to convert such disparate data into a common form. The construction of such transforms is widely believed to be a major cost of data integration projects.  \r\nThe purpose of the Morpheus project is to capture a large number of such transforms in a repository by crawling the web for publicly available ones and providing high level tools for efficient transform construction.  In addition, powerful browsing tools are anticipated that allow users to locate \"\"interesting\"\" transforms quickly in the repository by providing keyword search of documentation, search within a classification hierarchy of transforms, search by the provenance of transforms, as well as search by the input/output characteristics.  \r\nMorpheus is expected to dramatically reduce the cost of writing and maintaining data integration transforms, which will ease the difficulty of future data integration projects.  \r\nThis project will support graduate students at both Massachusetts Institute of Technology and University of Florida.  In addition, transform construction will be used as student exercises in data base classes at both institutions.  Further information can be obtained from the project web site: http://www.cise.ufl.edu/~jhammer/morpheus/ where research results will be disseminated and prototype code will be available.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Joseph",
   "pi_last_name": "Wilson",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Joseph N Wilson",
   "pi_email_addr": "jnw@cise.ufl.edu",
   "nsf_id": "000267981",
   "pi_start_date": "2008-10-22",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Joachim",
   "pi_last_name": "Hammer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Joachim Hammer",
   "pi_email_addr": "joachimhammer@hotmail.com",
   "nsf_id": "000120792",
   "pi_start_date": "2007-08-09",
   "pi_end_date": "2008-10-22"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Dobbins",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Peter J Dobbins",
   "pi_email_addr": "pjd@cise.ufl.edu",
   "nsf_id": "000484055",
   "pi_start_date": "2007-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1523 UNION RD RM 207",
  "perf_city_name": "GAINESVILLE",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326111941",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 269263.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 7896.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Morpheus Project set out to develop a system for simplifying the development of web-based <em>data transformations</em>, that convert data in one form to some other form. As a simple example, consider monetary unit conversions, e.g. Euros to U.S. Dollars. We successfully developed and deployed a Transform Construction Toolkit and two versions of the Morpheus system that support the cataloging of websites that perform such transformations and allow them to be effectively employed.</p>\n<p>This early work in mining the web for transformations led us to consider the task of identifying and making available information from the <em>deep web</em>, that is from the many web pages that are dynamically constructed from large data stores that do not appear in readily searchable web pages. As a result of that work, we developed a Firefox plugin to record both queries and the web-site interactions needed to solve them. Initially we considered the use of a manual cataloging process that involved the specification of an ontology for each deep web source.</p>\n<p>To help automate the larger problem of categorizing the types of data contained in the deep web, we began work on using natural language document topic modeling techniques. That work led to a new approach to identifying the topical content of a document (such as a web page) using a product partition model Gibbs sampler for Latent Dirichlet Allocation and performing Metropolis search to identify the topic mixture of a newly encountered document.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/31/2014<br>\n\t\t\t\t\tModified by: Joseph&nbsp;N&nbsp;Wilson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe Morpheus Project set out to develop a system for simplifying the development of web-based data transformations, that convert data in one form to some other form. As a simple example, consider monetary unit conversions, e.g. Euros to U.S. Dollars. We successfully developed and deployed a Transform Construction Toolkit and two versions of the Morpheus system that support the cataloging of websites that perform such transformations and allow them to be effectively employed.\n\nThis early work in mining the web for transformations led us to consider the task of identifying and making available information from the deep web, that is from the many web pages that are dynamically constructed from large data stores that do not appear in readily searchable web pages. As a result of that work, we developed a Firefox plugin to record both queries and the web-site interactions needed to solve them. Initially we considered the use of a manual cataloging process that involved the specification of an ontology for each deep web source.\n\nTo help automate the larger problem of categorizing the types of data contained in the deep web, we began work on using natural language document topic modeling techniques. That work led to a new approach to identifying the topical content of a document (such as a web page) using a product partition model Gibbs sampler for Latent Dirichlet Allocation and performing Metropolis search to identify the topic mixture of a newly encountered document.\n\n\t\t\t\t\tLast Modified: 07/31/2014\n\n\t\t\t\t\tSubmitted by: Joseph N Wilson"
 }
}