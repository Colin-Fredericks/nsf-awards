{
 "awd_id": "0546554",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Semantics for Statistical Machine Translation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2006-01-01",
 "awd_exp_date": "2011-12-31",
 "tot_intn_awd_amt": 499955.0,
 "awd_amount": 513158.0,
 "awd_min_amd_letter_date": "2005-12-22",
 "awd_max_amd_letter_date": "2010-03-09",
 "awd_abstract_narration": "The past few years have seen a revolution in machine\r\ntranslation, with the widespread adoption of\r\nstatistical systems trained on large amounts of\r\nparallel bilingual text.  Recent evaluations have shown\r\nthat current statistically trained research technology\r\nsignificantly outperforms commercially available MT\r\nsystems such as those available on the web.  But even\r\nstate-of-the-art systems produce garbled translations\r\nmore often than not.  Further improvements in machine\r\ntranslation will require major changes in the\r\narchitecture of statistical systems.  Our research aims\r\nto improve the quality of machine translation output by\r\nallowing statistical systems to handle deeper, semantic\r\nrepresentations.\r\n\r\nOur approach focuses on improving statistical machine\r\ntranslation by using a semantic representation at the\r\nlevel of predicate-argument structure.  This work\r\nbuilds on the recent success in statistical approaches\r\nto shallow language understanding, and tree-based\r\nalgorithms for machine translation using syntactic\r\nparses of the source and target sentences.  Over the\r\ncourse of the project we aim to: first, develop robust\r\nsemantic parsing systems capable of generalizing to new\r\ndomains and apply them to large bilingual corpora,\r\nsecond, develop probabilistic models of translation\r\nthat use the resulting level of representation and can\r\nbe practically trained, and third, integrate language\r\nunderstanding and translation to allow efficient search\r\nfor the best overall translation of new sentences.\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Gildea",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel Gildea",
   "pi_email_addr": "gildea@cs.rochester.edu",
   "nsf_id": "000449779",
   "pi_start_date": "2005-12-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "910 GENESEE ST",
  "perf_city_name": "ROCHESTER",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146113847",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "727400",
   "pgm_ele_name": "HUMAN LANGUAGE & COMMUNICATION"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "9215",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING SYSTEMS"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0106",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 108140.0
  },
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 94530.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 109971.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 99068.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 101449.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project developed new technology for statistical machine<br />translation (MT) systems, for example for automatic translation of<br />Chinese into English.&nbsp; Statistical MT systems are created from<br />parallel, bilingual text, that is, documents that are available with<br />translations in the desired source and target languages.&nbsp; We apply<br />machine learning techniques to automatically derive the correspondence<br />between words and phrases in the two languages, and thus learn to<br />translate new sentences.<br /><br />This project focused on learning tree-based representations of<br />language to model translation.&nbsp; This enables machine translation<br />systems to achieve the complex re-ordering patterns between languages<br />that are often necessary to convey the correct meaning, as well as to<br />correctly generate function words such as pronouns, prepositions, and<br />case markers that often differ between languages.<br /><br />We applied tree-based representations to three general areas of machine<br />translation: decoding algorithms, evaluation, and the theory of <br />translation grammars and their computational complexity.<br /><br />In the area of decoding algorithms, we developed methods to rapidly<br />produce translations of new sentences given a translation model.&nbsp; Here<br />the interaction between tree-based translation grammars and the<br />statistical model of the target language can lead to high<br />computational complexity.&nbsp; Our methods to attack this problem include<br />a multi-pass strategy where possible translation hypotheses are first<br />scored with a simpler model to identify promising areas of the search<br />space before rescoring with a more complex, and more precise, language<br />model.<br /><br />The field of machine translation evaluation develops methods for<br />automatically judging the quality of system output by comparing it to<br />human translations of the same sentences.&nbsp; This can reduce the need to<br />manually read and evaluate system output, making the development and<br />tuning of machine translation systems significantly faster.&nbsp; We developed<br />metrics that generate syntactic parses of system output and human<br />translations, and then compare the trees with a kernel-based similarity<br />measure.&nbsp; This enables machine translation evaluation to take into account<br />structural properties of the sentences, essential for preserving meaning.<br /><br />In the theoretical domain, we developed algorithms for factorizing<br />Synchronous Context-Free Grammars (SCFG) into grammars having shorter<br />rules.&nbsp; Rule size is a key component in the computational complexity<br />of machine translation systems; shorter rules mean less computation<br />time.&nbsp; We also explored a more general class of translation grammar<br />based on Linear Context-Free Rewriting Systems (LCFRS), and showed<br />how to factorize such grammars using the notion of tree decomposition<br />from graph theory.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/27/2012<br>\n\t\t\t\t\tModified by: Daniel&nbsp;Gildea</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project developed new technology for statistical machine\ntranslation (MT) systems, for example for automatic translation of\nChinese into English.  Statistical MT systems are created from\nparallel, bilingual text, that is, documents that are available with\ntranslations in the desired source and target languages.  We apply\nmachine learning techniques to automatically derive the correspondence\nbetween words and phrases in the two languages, and thus learn to\ntranslate new sentences.\n\nThis project focused on learning tree-based representations of\nlanguage to model translation.  This enables machine translation\nsystems to achieve the complex re-ordering patterns between languages\nthat are often necessary to convey the correct meaning, as well as to\ncorrectly generate function words such as pronouns, prepositions, and\ncase markers that often differ between languages.\n\nWe applied tree-based representations to three general areas of machine\ntranslation: decoding algorithms, evaluation, and the theory of \ntranslation grammars and their computational complexity.\n\nIn the area of decoding algorithms, we developed methods to rapidly\nproduce translations of new sentences given a translation model.  Here\nthe interaction between tree-based translation grammars and the\nstatistical model of the target language can lead to high\ncomputational complexity.  Our methods to attack this problem include\na multi-pass strategy where possible translation hypotheses are first\nscored with a simpler model to identify promising areas of the search\nspace before rescoring with a more complex, and more precise, language\nmodel.\n\nThe field of machine translation evaluation develops methods for\nautomatically judging the quality of system output by comparing it to\nhuman translations of the same sentences.  This can reduce the need to\nmanually read and evaluate system output, making the development and\ntuning of machine translation systems significantly faster.  We developed\nmetrics that generate syntactic parses of system output and human\ntranslations, and then compare the trees with a kernel-based similarity\nmeasure.  This enables machine translation evaluation to take into account\nstructural properties of the sentences, essential for preserving meaning.\n\nIn the theoretical domain, we developed algorithms for factorizing\nSynchronous Context-Free Grammars (SCFG) into grammars having shorter\nrules.  Rule size is a key component in the computational complexity\nof machine translation systems; shorter rules mean less computation\ntime.  We also explored a more general class of translation grammar\nbased on Linear Context-Free Rewriting Systems (LCFRS), and showed\nhow to factorize such grammars using the notion of tree decomposition\nfrom graph theory.\n\n\t\t\t\t\tLast Modified: 06/27/2012\n\n\t\t\t\t\tSubmitted by: Daniel Gildea"
 }
}