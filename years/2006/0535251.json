{
 "awd_id": "0535251",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Machine learning algorithms for analyzing auditory scenes with multiple sound sources",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2006-01-01",
 "awd_exp_date": "2009-12-31",
 "tot_intn_awd_amt": 0.0,
 "awd_amount": 375000.0,
 "awd_min_amd_letter_date": "2006-01-18",
 "awd_max_amd_letter_date": "2008-04-01",
 "awd_abstract_narration": "\r\n\r\nComputer algorithms that analyze auditory scenes and extract individual sound sources would have a strong impact in several domains. For example, to facilitate natural interaction with computing devices by voice, an automatic speech recognition system must be able to focus on the voice of the person speaking to it and ignore sounds from all other sources. A hearing device must perform a similar task to allow a hearing impaired person conduct a conversation in a noisy, multiple source environment. Building on recent advances in the fields of machine learning and signal processing, we are developing sophisticated adaptive algorithms for analyzing auditory scenes with multiple sound sources. Our algorithms are based on probabilistic modeling of different sound sources and of the manner in which they overlap each other and distorted by reverberation and background noise. We use advanced recent techniques for inferring our models from sound data captured by a microphone array, separating those data into individual sources, and automatically determining the type of each source present and its location. Moreover, by reconstructing the clean signal of individual sound sources, we dramatically enhance the accuracy of automatic speech recognition for human speakers in multiple source environments. To facilitate the development and evaluation of our algorithms, and also to encourage competition between other research groups ultimately resulting in improved techniques, we collect a large dataset of multiple source auditory scenes, and make it publicly available on a dedicated website.\r\n\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Terrence",
   "pi_last_name": "Sejnowski",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Terrence J Sejnowski",
   "pi_email_addr": "terry@salk.edu",
   "nsf_id": "000273216",
   "pi_start_date": "2008-04-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Te-Won",
   "pi_last_name": "Lee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Te-Won Lee",
   "pi_email_addr": "tewon@ucsd.edu",
   "nsf_id": "000486426",
   "pi_start_date": "2006-01-18",
   "pi_end_date": "2008-04-01"
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 GILMAN DR",
  "perf_city_name": "LA JOLLA",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "727400",
   "pgm_ele_name": "HUMAN LANGUAGE & COMMUNICATION"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0106",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 375000.0
  }
 ],
 "por": null
}