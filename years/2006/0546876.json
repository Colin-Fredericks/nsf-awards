{
 "awd_id": "0546876",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Design and Evaluation of Methods for Robot Learning by Demonstration",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Edwina L. Rissland",
 "awd_eff_date": "2006-01-15",
 "awd_exp_date": "2011-12-31",
 "tot_intn_awd_amt": 410000.0,
 "awd_amount": 442000.0,
 "awd_min_amd_letter_date": "2006-01-05",
 "awd_max_amd_letter_date": "2010-06-24",
 "awd_abstract_narration": "CAREER: Design and Evaluation of Methods for Robot Learning by Demonstration\r\n\r\nAbstract\r\nThe goal of this career proposal is to create a research and educational program dedicated to developing and evaluating novel algorithms for robotic systems that learn from demonstration and interaction with human users. This program's research plan is to develop algorithms for automated generation of robot controllers from demonstration and interaction with human users. The main research questions of this project pertain to the investigation, design, and implementation of: (1) an autonomous robot control architecture that provides support for task knowledge acquisition from user provided demonstration, (2) algorithms for robot learning by demonstration that facilitate training of robot assistants by non-specialist users, (3) quantitative evaluation metrics that provide objective means for assessing the performance of human-robot interaction in the context of robot teaching by demonstration. The proposed robot control architecture will create the infrastructure for complex task learning and will provide a new representation for multiple action selection mechanisms. The learning by demonstration algorithms will use a novel approach for interpreting a user's demonstration, based on particle filtering that identifies superpositions of multiple concurrent activities. In addition, generalization algorithms will use inductive learning methods to capture and represent variations in task execution strategies. User feedback will allow for refinement of learned tasks, through verbal instructions or teleoperation interventions. The quantitative evaluation metrics will not only provide objective measures for the proposed interactive learning approach, but could also serve as more general tools for the broader field of HRI. This research will open new possibilities for the use of robots in everyday tasks, by allowing human users to customize robots to their own needs, without the necessity of being trained as computer scientists or robotics engineers. The educational plan of this project has three main components: (1) advancing and promoting teaching related activities, including the development of new robotics courses and establishing a new Robotics Laboratory at UNR, (2) outreach to local high-schools through seminars and internships and (3) dissemination of results in peer reviewed journals, conference proceedings, and on the Internet.\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Monica",
   "pi_last_name": "Nicolescu",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Monica N Nicolescu",
   "pi_email_addr": "monica@cse.unr.edu",
   "nsf_id": "000488151",
   "pi_start_date": "2006-01-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Board of Regents, NSHE, obo University of Nevada, Reno",
  "inst_street_address": "1664 N VIRGINIA ST # 285",
  "inst_street_address_2": "",
  "inst_city_name": "RENO",
  "inst_state_code": "NV",
  "inst_state_name": "Nevada",
  "inst_phone_num": "7757844040",
  "inst_zip_code": "895570001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NV02",
  "org_lgl_bus_name": "BOARD OF REGENTS OF THE NEVADA SYSTEM OF HIGHER ED",
  "org_prnt_uei_num": "WLDGTNCFFJZ3",
  "org_uei_num": "WLDGTNCFFJZ3"
 },
 "perf_inst": {
  "perf_inst_name": "Board of Regents, NSHE, obo University of Nevada, Reno",
  "perf_str_addr": "1664 N VIRGINIA ST # 285",
  "perf_city_name": "RENO",
  "perf_st_code": "NV",
  "perf_st_name": "Nevada",
  "perf_zip_code": "895570001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NV02",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0106",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0107",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0107",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0108",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000809DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 102458.0
  },
  {
   "fund_oblg_fiscal_yr": 2007,
   "fund_oblg_amt": 95655.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 80259.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 77137.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 86491.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p style=\"text-align: left;\">The goal of this project was to create a research and educational program dedicated to developing and evaluating novel algorithms for robotic systems that learn from demonstration and interaction with human users. While recent advances in robotics research bring robots closer to entering our daily lives, real-world uses of autonomous robots are very limited. One of the main reasons for this is that designing robot controllers is still usually done by people specialized in programming robots: the lack of accessible methods for robot programming restricts the use of robots solely to people with programming skills. The motivation of this project was to provide algorithms that would enable non-expert users to design robot controllers for their specific needs, thus facilitating the integration of robots in people&rsquo;s daily lives.</p>\n<p style=\"text-align: left;\">This project has resulted in the following main outcomes:</p>\n<p style=\"text-align: left;\">1)&nbsp;&nbsp;&nbsp; The development of a robot control architecture that enables the representation, execution and automatic construction of complex, hierarchically structured robotic tasks.</p>\n<p style=\"text-align: left;\">The main contribution of the architecture is that it combines command <em>arbitration </em>and command <em>fusion </em>within a single framework. The architecture is based on biological inspiration, which states that motor behavior is typically expressed in terms of concurrent control of multiple different activities. Thus, <em>fusion</em> of simple motor primitives is used to generate higher-level, goal-oriented behaviors and <em>sequencing</em> of such behaviors enables the representation of higher-level robot tasks.</p>\n<p style=\"text-align: left;\">&nbsp;</p>\n<p style=\"text-align: left;\">2)&nbsp;&nbsp;&nbsp; New algorithms for robot task learning from user provided demonstrations.&nbsp;</p>\n<p style=\"text-align: left;\">The learning by demonstration approach developed in this project has two main contributions: first, it allows a robot to map a demonstrator&rsquo;s actions onto multiple behavior primitives from its repertoire, and second, it enables a robot to learn complex, sequentially structured tasks.</p>\n<p style=\"text-align: left;\">This method has been shown to capture not only the overall goals of the task, but also the specifics of the user&rsquo;s demonstration, which indicate different ways of executing the same task. Experiments with physical robots demonstrated that a mobile robot can learn multiple different ways of navigation in office-like environments: staying away from narrow places, navigating through wide corridors, walking on left/center/right side of a corridor and learning preferences for turn direction at corridor junctions. An additional feature of this method is that similar robot tasks could be learned from combinations of different subsets of low-level, generic primitive behaviors. This new approach eliminates the need for task-dependent knowledge typical in learning by demonstration systems and provides an increased level of robustness and generalization. Furthermore, the capability of learning complex, sequentially structured tasks has been demonstrated in experiments of teaching a mobile robot various navigation tasks, and involved sequences of visiting locations of interest in our office building (Figure 1).</p>\n<p style=\"text-align: left;\">&nbsp;</p>\n<p style=\"text-align: left;\">3)&nbsp;&nbsp;&nbsp; New algorithms for generalization from a small number of teaching demonstrations&nbsp;</p>\n<p style=\"text-align: left;\">The main contribution of this approach is that it enables the correct learning of robot tasks in the presence of either small (noise), or large (structural) differences in the training examples. The proposed solution consists of two main components: a representation that enables the learner to store the generalized representat...",
  "por_txt_cntn": "The goal of this project was to create a research and educational program dedicated to developing and evaluating novel algorithms for robotic systems that learn from demonstration and interaction with human users. While recent advances in robotics research bring robots closer to entering our daily lives, real-world uses of autonomous robots are very limited. One of the main reasons for this is that designing robot controllers is still usually done by people specialized in programming robots: the lack of accessible methods for robot programming restricts the use of robots solely to people with programming skills. The motivation of this project was to provide algorithms that would enable non-expert users to design robot controllers for their specific needs, thus facilitating the integration of robots in people\u00c6s daily lives.\nThis project has resulted in the following main outcomes:\n1)    The development of a robot control architecture that enables the representation, execution and automatic construction of complex, hierarchically structured robotic tasks.\nThe main contribution of the architecture is that it combines command arbitration and command fusion within a single framework. The architecture is based on biological inspiration, which states that motor behavior is typically expressed in terms of concurrent control of multiple different activities. Thus, fusion of simple motor primitives is used to generate higher-level, goal-oriented behaviors and sequencing of such behaviors enables the representation of higher-level robot tasks.\n \n2)    New algorithms for robot task learning from user provided demonstrations. \nThe learning by demonstration approach developed in this project has two main contributions: first, it allows a robot to map a demonstrator\u00c6s actions onto multiple behavior primitives from its repertoire, and second, it enables a robot to learn complex, sequentially structured tasks.\nThis method has been shown to capture not only the overall goals of the task, but also the specifics of the user\u00c6s demonstration, which indicate different ways of executing the same task. Experiments with physical robots demonstrated that a mobile robot can learn multiple different ways of navigation in office-like environments: staying away from narrow places, navigating through wide corridors, walking on left/center/right side of a corridor and learning preferences for turn direction at corridor junctions. An additional feature of this method is that similar robot tasks could be learned from combinations of different subsets of low-level, generic primitive behaviors. This new approach eliminates the need for task-dependent knowledge typical in learning by demonstration systems and provides an increased level of robustness and generalization. Furthermore, the capability of learning complex, sequentially structured tasks has been demonstrated in experiments of teaching a mobile robot various navigation tasks, and involved sequences of visiting locations of interest in our office building (Figure 1).\n \n3)    New algorithms for generalization from a small number of teaching demonstrations \nThe main contribution of this approach is that it enables the correct learning of robot tasks in the presence of either small (noise), or large (structural) differences in the training examples. The proposed solution consists of two main components: a representation that enables the learner to store the generalized representation of the task and the learning algorithm that allows the construction of a generalized task representation. The approach has been validated in simulation, showing the ability to generalize to a wide range of scenarios that may typically occur in teaching by demonstration.\n \n4)    Educational and societal impact\nThe students involved in this project have been a part of a unique educational experience, which has enhanced their knowledge in robotics (in particular) and in science and engineering (in general). Some of the most importa..."
 }
}