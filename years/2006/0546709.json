{
 "awd_id": "0546709",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER:  Observing to Plan - Planning to Observe",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928074",
 "po_email": "jdonlon@nsf.gov",
 "po_sign_block_name": "James Donlon",
 "awd_eff_date": "2006-06-01",
 "awd_exp_date": "2013-05-31",
 "tot_intn_awd_amt": 439998.0,
 "awd_amount": 446123.0,
 "awd_min_amd_letter_date": "2006-05-04",
 "awd_max_amd_letter_date": "2011-05-09",
 "awd_abstract_narration": "Abstract  for Proposal # 0546709\r\n\r\n\r\nThis proposal aims to perform fundamental research on planning, perception and probabilistic reasoning in the context of a deceptively simple challenge task: A robot is given a crude description of a relatively easily recognizable object to find, and sent into a new environment to find this object.  The robot is expected to return with a map showing the location of the object. The following can be said about this task: 1) It is a prerequisite or enabling technology for many other tasks of economic and practical importance; 2) It ought to be possible given existing hardware and computing power; 3) It is not adequately addressed by existing techniques; and 4) It reveals fundamental shortcomings in our understanding of core AI problems.  This proposal aims to address these challenges directly with novel approaches to acquiring, representing, and planning with sense data.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ronald",
   "pi_last_name": "Parr",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ronald Parr",
   "pi_email_addr": "parr@cs.duke.edu",
   "nsf_id": "000188767",
   "pi_start_date": "2006-05-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "2200 W MAIN ST",
  "perf_city_name": "DURHAM",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277054640",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "0100999999",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "01S8",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "0100999999",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 256998.0
  },
  {
   "fund_oblg_fiscal_yr": 2008,
   "fund_oblg_amt": 90500.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 92500.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 6125.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project considered the problem of how robots or distributed collections of sensors can construct representations of their environment. This is a challenging problem for several reasons: 1) Sensors provide incomplete information about the world: The have limited range, accuracy and field of view. 2) The exact positions of the robots or sensors may not always be known. For example, even when GPS is available it is accurate only up to several meters. 3) Modern sensors are capable of providing a vast amount information, but it is not always practical to use all of this information at once due to the computational considerations, as well as the time and cost of transmitting information, and 4) Raw sensor information may require substantial additional processing to be useful to people. For example, it's not that hard to send a mobile robot out in the environment and have it take lots of pictures, but it's much more difficult to ask a robot to use this information to help you find your keys or report if something has been stolen.</p>\n<p>Some of the key research accomplishments of this project are summarized below:</p>\n<p>- A technique by which a robot can use digital still images to determine its position with accuracy very close to what can be achieved with much larger and more expensive laser range finders.*</p>\n<p>- A technique by which a network of pan/tilt cameras can be intelligently managed to detect the presence of objects, e.g. intruders, using a small number of camera movements.</p>\n<p>- A technique by which surveillance devices with taskable (capable of being aimed)&nbsp;sensors (e.g., drones or satellites) can be used to pinpoint a moving adversary using a small number of sensor aims.</p>\n<p>- A family of techniques by which a robot can autonomous or semi-autonomously discover a set of \"interesting\" objects in an environment by monitoring the environment over a period of time. Interesting objects would be objects that are capable of being manipulated by people.*</p>\n<p>* Starred items in the above list have publicly available computer code and data sets.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/28/2013<br>\n\t\t\t\t\tModified by: Ronald&nbsp;Parr</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project considered the problem of how robots or distributed collections of sensors can construct representations of their environment. This is a challenging problem for several reasons: 1) Sensors provide incomplete information about the world: The have limited range, accuracy and field of view. 2) The exact positions of the robots or sensors may not always be known. For example, even when GPS is available it is accurate only up to several meters. 3) Modern sensors are capable of providing a vast amount information, but it is not always practical to use all of this information at once due to the computational considerations, as well as the time and cost of transmitting information, and 4) Raw sensor information may require substantial additional processing to be useful to people. For example, it's not that hard to send a mobile robot out in the environment and have it take lots of pictures, but it's much more difficult to ask a robot to use this information to help you find your keys or report if something has been stolen.\n\nSome of the key research accomplishments of this project are summarized below:\n\n- A technique by which a robot can use digital still images to determine its position with accuracy very close to what can be achieved with much larger and more expensive laser range finders.*\n\n- A technique by which a network of pan/tilt cameras can be intelligently managed to detect the presence of objects, e.g. intruders, using a small number of camera movements.\n\n- A technique by which surveillance devices with taskable (capable of being aimed) sensors (e.g., drones or satellites) can be used to pinpoint a moving adversary using a small number of sensor aims.\n\n- A family of techniques by which a robot can autonomous or semi-autonomously discover a set of \"interesting\" objects in an environment by monitoring the environment over a period of time. Interesting objects would be objects that are capable of being manipulated by people.*\n\n* Starred items in the above list have publicly available computer code and data sets.\n\n\t\t\t\t\tLast Modified: 08/28/2013\n\n\t\t\t\t\tSubmitted by: Ronald Parr"
 }
}