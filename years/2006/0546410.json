{
 "awd_id": "0546410",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Autonomous and Assistive Trail Following",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2006-05-01",
 "awd_exp_date": "2012-04-30",
 "tot_intn_awd_amt": 499927.0,
 "awd_amount": 499927.0,
 "awd_min_amd_letter_date": "2006-04-13",
 "awd_max_amd_letter_date": "2010-04-06",
 "awd_abstract_narration": "CAREER: Autonomous and Assistive Trail Following\r\nPI: Christopher Rasmussen\r\n\r\nAbstract:\r\n\r\nThis project will study algorithms for finding and following trails, both in the context of autonomous mobile robots and assistive devices that may be mounted on vehicles or carried by people.  Paths along the ground are ubiquitous features of man-made and natural outdoor environments, \"showing the way\" to those who can recognize them and ``smoothing the way'' to ease passage.  These two functions place each path along a spectrum of distinctiveness and traversability, which bear on the difficulty of the perceptual and control tasks, respectively, that following it poses.  Trails occupy the more tenuous ends of both axes, comprising dirt and other unimproved roads as well as true hiking trails.  A unique characteristic exhibited by some trails is discontinuity, in which visual markers such as cairns, blazes, footprints, and other \"tells\" indicate a sequence of waypoints.  The research will focus on computer vision and robotic problems stemming from three core trail following tasks: (1) keeping, or discriminating and staying on continuous and discontinuous trails;  (2) negotiation, or avoiding within-trail obstacles and setting control policies appropriate to changing terrain conditions; and (3) finding trails and mapping unknown trail networks, including detecting branches, dead-ends, and discontinuities.  Using stereo color cameras, GPS, static aerial imagery, and topographical data, the PI will investigate (1) Texture-based methods for robust segmentation to incorporate rich models of natural image statistics, (2) On-line visual tracking and activity analysis of other mobile agents for efficiently learning control policies, and (3) Integration of directed search, recognition, and footprint structure estimation algorithms for discontinuous trails.  The benefits of robust trail following skills will extend to wheeled, walking, and low-and-slow-flying robots, with applications including resupply of difficult-to-reach camps and research stations, inspection and maintenance of trails, and patrolling and reconnaissance operations as part of a border security or military force.  Assistive applications include augmenting driver awareness on dangerous roads, guiding for visually-impaired hikers, and as a smart device for wildlife study through animal tracking and search-and-rescue efforts through person tracking.  Educational impacts will derive from extensive involvement in this work by students from the graduate level down through high school.  The PI will start an undergraduate team to compete in national robot competitions in order to encourage participation in vision and robotics research, run a program of summer internships for high school and undergraduate students to help program and test aspects of the trail following system, and introduce a novel web-based system to allow a wider group of students to contribute to the research through image segmentation and video annotation to provide data for robot\r\nlearning.\r\n\r\nURL: http://vision.cis.udel.edu/trails\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Rasmussen",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher E Rasmussen",
   "pi_email_addr": "cer@cis.udel.edu",
   "nsf_id": "000491111",
   "pi_start_date": "2006-04-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Delaware",
  "inst_street_address": "550 S COLLEGE AVE",
  "inst_street_address_2": "",
  "inst_city_name": "NEWARK",
  "inst_state_code": "DE",
  "inst_state_name": "Delaware",
  "inst_phone_num": "3028312136",
  "inst_zip_code": "197131324",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DE00",
  "org_lgl_bus_name": "UNIVERSITY OF DELAWARE",
  "org_prnt_uei_num": "",
  "org_uei_num": "T72NHKM259N3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Delaware",
  "perf_str_addr": "550 S COLLEGE AVE",
  "perf_city_name": "NEWARK",
  "perf_st_code": "DE",
  "perf_st_name": "Delaware",
  "perf_zip_code": "197131324",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DE00",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0106",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0106",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0109",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000910DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0406",
   "app_name": "NSF,Education & Human Resource",
   "app_symb_id": "490106",
   "fund_code": "app-0406",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2006,
   "fund_oblg_amt": 297815.0
  },
  {
   "fund_oblg_fiscal_yr": 2009,
   "fund_oblg_amt": 100857.0
  },
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 101255.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project's overarching goal has been to visually find<br />\"trails\"---linear, navigationally-useful features whether man-made or<br />natural, such as hiking paths, roads, and rivers.&nbsp; It began with the<br />development of an algorithm to search images using a top-down approach<br />in which feasible trail shapes were hypothesized in image space and<br />ranked by a likelihood function based on color region contrast with no<br />a priori information about the trail material or appearance.&nbsp; The<br />basic approach was validated with robust performance on a wide variety<br />of trail scenes using a dataset of monocular, uncalibrated color<br />images.<br /><br />The algorithm was optimized for speed and extended to successfully<br />track trails over uncalibrated image sequences, both from ground and<br />low-flying aerial vehicles.&nbsp; To demonstrate the utility of the<br />approach for autonomous robot navigation, an omnidirectional camera<br />was mounted on a Segway RMP 400 platform called \"Warthog,\" and the<br />trail hypothesis space was converted to vehicle coordinates after<br />intrinsic and extrinsic camera calibration.&nbsp; This enabled the<br />estimated trail parameters to be used for motion planning and<br />real-time control of the robot, leading to successful \"trail<br />following.\"<br /><br />One of the broader impacts of the project involved entering Warthog in<br />a student-centered international contest called the Intelligent Ground<br />Vehicle Competition (IGVC).&nbsp; A major part of IGVC was a path-following<br />challenge in which a twisty course was laid out on grass with painted<br />parallel lines, and ostacles such as barrels and sawhorses were<br />scattered along the course *inside* the path.&nbsp; We generalized our<br />trail-following algorithm by (a) modifying the trail likelihood<br />function to use edges instead of regions, and (b) augmenting the<br />motion planner to avoid ladar-detected obstacles within the trail<br />region.&nbsp; Over our five years at IGVC we were very successful at this<br />challenge and won it several times.<br /><br />Lessons learned at IGVC proved useful for following hiking trails.<br />However, in our testing we sometimes encountered areas where the<br />trail's color contrast was not very strong.&nbsp; This led to a new phase<br />in which a variety of different trail likelihood functions were<br />developed and integrated with color contrast using linear weighting.<br />One was based on the ladar obstacle map, since the edges of the trail<br />were often delineated by obstacles; and another on a heightmap derived<br />from stereo depth.&nbsp; These helped the robot \"see\" the trail clearly in<br />more different visual situations.&nbsp; Furthermore, a measure of<br />confidence in the trail estimate was used to sometimes slow the robot<br />down so it had more time to search for the trail, and even to stop the<br />robot so that a 3-D scan could be performed by the ladar to reacquire<br />the trail from a detailed heightmap.<br /><br />All of these improvements continued to increase the mean distance the<br />robot could travel autonomously between human interventions, and by<br />the end of the project's term Warthog could very capably go around a<br />multi-km hiking circuit through a variety of terrains, crossing<br />bridges and handling forks in the path, with only occasional issues<br />where delicate maneuvering over tree roots was required.&nbsp; Additional<br />features investigated in the project's final year included the use of<br />Kinect depth cameras to allow Warthog to \"see in the dark\" for<br />night-time trail following, and algorithms to recognize and avoid specific<br />hazards such as thin tree trunks and low rocks.<br /><br />With the capabilities of the trail-following system fairly mature at<br />the close of this project, we are poised to explore many more<b...",
  "por_txt_cntn": "\nThis project's overarching goal has been to visually find\n\"trails\"---linear, navigationally-useful features whether man-made or\nnatural, such as hiking paths, roads, and rivers.  It began with the\ndevelopment of an algorithm to search images using a top-down approach\nin which feasible trail shapes were hypothesized in image space and\nranked by a likelihood function based on color region contrast with no\na priori information about the trail material or appearance.  The\nbasic approach was validated with robust performance on a wide variety\nof trail scenes using a dataset of monocular, uncalibrated color\nimages.\n\nThe algorithm was optimized for speed and extended to successfully\ntrack trails over uncalibrated image sequences, both from ground and\nlow-flying aerial vehicles.  To demonstrate the utility of the\napproach for autonomous robot navigation, an omnidirectional camera\nwas mounted on a Segway RMP 400 platform called \"Warthog,\" and the\ntrail hypothesis space was converted to vehicle coordinates after\nintrinsic and extrinsic camera calibration.  This enabled the\nestimated trail parameters to be used for motion planning and\nreal-time control of the robot, leading to successful \"trail\nfollowing.\"\n\nOne of the broader impacts of the project involved entering Warthog in\na student-centered international contest called the Intelligent Ground\nVehicle Competition (IGVC).  A major part of IGVC was a path-following\nchallenge in which a twisty course was laid out on grass with painted\nparallel lines, and ostacles such as barrels and sawhorses were\nscattered along the course *inside* the path.  We generalized our\ntrail-following algorithm by (a) modifying the trail likelihood\nfunction to use edges instead of regions, and (b) augmenting the\nmotion planner to avoid ladar-detected obstacles within the trail\nregion.  Over our five years at IGVC we were very successful at this\nchallenge and won it several times.\n\nLessons learned at IGVC proved useful for following hiking trails.\nHowever, in our testing we sometimes encountered areas where the\ntrail's color contrast was not very strong.  This led to a new phase\nin which a variety of different trail likelihood functions were\ndeveloped and integrated with color contrast using linear weighting.\nOne was based on the ladar obstacle map, since the edges of the trail\nwere often delineated by obstacles; and another on a heightmap derived\nfrom stereo depth.  These helped the robot \"see\" the trail clearly in\nmore different visual situations.  Furthermore, a measure of\nconfidence in the trail estimate was used to sometimes slow the robot\ndown so it had more time to search for the trail, and even to stop the\nrobot so that a 3-D scan could be performed by the ladar to reacquire\nthe trail from a detailed heightmap.\n\nAll of these improvements continued to increase the mean distance the\nrobot could travel autonomously between human interventions, and by\nthe end of the project's term Warthog could very capably go around a\nmulti-km hiking circuit through a variety of terrains, crossing\nbridges and handling forks in the path, with only occasional issues\nwhere delicate maneuvering over tree roots was required.  Additional\nfeatures investigated in the project's final year included the use of\nKinect depth cameras to allow Warthog to \"see in the dark\" for\nnight-time trail following, and algorithms to recognize and avoid specific\nhazards such as thin tree trunks and low rocks.\n\nWith the capabilities of the trail-following system fairly mature at\nthe close of this project, we are poised to explore many more\napplications enabled by this technology.  One such application is in\nthe field of forest health monitoring.  Here Warthog can carry\nadditional scientific sensors as it follows trails in order to carry\nout wildlife censuses; measure soil, sunlight, and atmospheric\nvariables; and also deploy a small UAV to make observations in the\ncanopy.  Further demonstrating its generality, we are also using this\ntechnology in the..."
 }
}