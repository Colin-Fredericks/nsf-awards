{
 "awd_id": "0093072",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER:  Quantifying Humanlike Enveloping Grasps",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Lawrence Rosenblum",
 "awd_eff_date": "2001-04-15",
 "awd_exp_date": "2004-03-31",
 "tot_intn_awd_amt": 324631.0,
 "awd_amount": 186370.0,
 "awd_min_amd_letter_date": "2001-05-01",
 "awd_max_amd_letter_date": "2003-01-27",
 "awd_abstract_narration": "Over the past decade, our ability to produce graphical\r\nimages has improved to the extent that we can create\r\nimaginary scenes that are virtually indistinguishable from\r\nreality. Digital humans have been called the last frontier\r\nin this march to graphical realism, and the area of human\r\nanimation has also seen dramatic developments. Increasing\r\nuse of motion capture data and new techniques for\r\nmanipulating that data allow us to reproduce human motion at\r\nan extremely high level of fidelity. Graphically generated\r\ncharacters in video games and films can seem uncannily real.\r\nPending the development of easy-to-use tools for directing\r\ndigital humans, we should soon see digital humans as\r\nplausible user interfaces, and animated characters will\r\nbecome much more prevalent in education, demonstration, and\r\ntraining applications. If digital humans are the last\r\nfrontier in realistic computer graphics, the last frontier\r\nin realistic digital humans is generating believable hand\r\nmotion. Human hands are beautiful and complex mechanisms,\r\namazing in their utility and adaptability. It is argued that\r\nit is our hands that make us human, and that hand evolution\r\nwas a primary factor in the development of intelligence.\r\nHand use in autonomous digital human characters, however, is\r\ngenerally quite unconvincing. Hands may be placed in a\r\nsingle frozen pose, and interaction between characters and\r\nobjects is avoided when possible. The main problem is that\r\ngeometric models of the human hand have far too much\r\nflexibility. This flexibility makes working with hands\r\ndifficult even for trained animators, and it poses a\r\ntremendous challenge for creating autonomous characters that\r\nmust interact with their environment. I believe that the key\r\nto making further progress in hand motion for digital\r\ncharacters is much more detailed consideration of the\r\nanatomy of the human hand. In analysis of human grasps, for\r\nexample, critically important considerations include the\r\namount of contact between finger pads, palm, and object; the\r\nability of muscles to produce or resist task force; and the\r\nstabilization roles of fingers and muscles, yet none of\r\nthese issues have been explored in grasp synthesis research\r\nin either the robotics or computer graphics communities. In\r\npursuit of the goal of believable hand use for digital\r\ncharacters, we propose an anatomy-based model of human\r\ngrasping. In particular, we propose a tendon-based quality\r\nmeasure for humanlike enveloping grasps, and we plan to\r\nevaluate this quality measure (1) for ability to\r\ndiscriminate between grasps, (2) as a predictor of grasp\r\nforces, and (3) for use in modeling grasp acquisition.\r\nBecause of the strong emphasis on human anatomy, this\r\nresearch has the potential for additional impact outside\r\ngraphics and animation in areas including ergonomics (tool\r\ndesign), robotics (robot hand design), and anthropology\r\n(research in human hand evolution and tool use). The\r\neducational portion of this proposal focuses on teaching and\r\nmentoring of undergraduates. The research ideas, techniques,\r\nand results will be incorporated into a course at Brown that\r\nattracts both un-dergraduate and graduate students, and will\r\nprovide them with an opportunity to learn and experiment in\r\na problem domain that is a nice mix of computational\r\ngeometry and numerical optimization, grounded in human\r\nanatomy and supported by data. A special effort will be made\r\nto include undergraduate women in the research program, for\r\nexample, through the CRA Distributed Mentor Program.\r\nResearch results will include a library of example grasps\r\nand applied forces, as well as a tool for adapting the\r\nexamples to new hand and object geometries. Once this\r\nresearch is published, the data and tools will be made\r\navailable to other researchers on the web, and should serve\r\nas a useful resource for creating digital characters for\r\neducation, entertainment, and training applications.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nancy",
   "pi_last_name": "Pollard",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Nancy S Pollard",
   "pi_email_addr": "nsp@cs.cmu.edu",
   "nsf_id": "000271462",
   "pi_start_date": "2001-05-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "1 PROSPECT ST",
  "perf_city_name": "PROVIDENCE",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029129100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "286500",
   "pgm_ele_name": "NUMERIC, SYMBOLIC & GEO COMPUT"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0101",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01000102DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0103",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0103",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0104",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0104",
   "fund_name": "",
   "fund_symb_id": ""
  },
  {
   "app_code": "0105",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "490100",
   "fund_code": "app-0105",
   "fund_name": "",
   "fund_symb_id": ""
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2001,
   "fund_oblg_amt": 121565.0
  },
  {
   "fund_oblg_fiscal_yr": 2003,
   "fund_oblg_amt": 9058.0
  }
 ],
 "por": null
}